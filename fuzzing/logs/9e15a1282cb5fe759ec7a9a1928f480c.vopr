:09:53.231Z debug(replica): 0n: on_message: view=1 status=normal vsr.message_header.Header.Prepare{ .checksum = 221859599298231531114501093791576957971, .checksum_padding = 0, .checksum_body = 32411413746896858696526384829824831279, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 512, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 275713189790845781224572204107528367099, .parent_padding = 0, .request_checksum = 100286166972412602096278910662704428745, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 204161290705302669957276092172686812873, .op = 2, .commit = 1, .timestamp = 1765580993231150649, .request = 0, .operation = vsr.Operation.register, .reserved = { 0, 0, 0 } }
2025-12-12 23:09:53.231Z debug(replica): 1N: append: appending to journal op=2
2025-12-12 23:09:53.231Z debug(replica): 0n: on_prepare: caching prepare.op=2 (commit_min=1 op=1 commit_max=1 prepare_max=1007)
2025-12-12 23:09:53.231Z debug(journal): 1: write: view=1 slot=2 op=2 len=512: 221859599298231531114501093791576957971 starting
2025-12-12 23:09:53.231Z debug(replica): 0n: on_prepare: advancing: op=1..2 checksum=275713189790845781224572204107528367099..221859599298231531114501093791576957971
2025-12-12 23:09:53.231Z debug(journal): 0: set_header_as_dirty: op=2 checksum=221859599298231531114501093791576957971
2025-12-12 23:09:53.231Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.prepares offset=2097152 len=4096 locked
2025-12-12 23:09:53.231Z debug(replica): 2n: on_message: view=1 status=normal vsr.message_header.Header.Prepare{ .checksum = 221859599298231531114501093791576957971, .checksum_padding = 0, .checksum_body = 32411413746896858696526384829824831279, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 512, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 275713189790845781224572204107528367099, .parent_padding = 0, .request_checksum = 100286166972412602096278910662704428745, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 204161290705302669957276092172686812873, .op = 2, .commit = 1, .timestamp = 1765580993231150649, .request = 0, .operation = vsr.Operation.register, .reserved = { 0, 0, 0 } }
2025-12-12 23:09:53.231Z debug(replica): 0n: append: appending to journal op=2
2025-12-12 23:09:53.231Z debug(journal): 0: write: view=1 slot=2 op=2 len=512: 221859599298231531114501093791576957971 starting
2025-12-12 23:09:53.231Z debug(replica): 2n: on_prepare: caching prepare.op=2 (commit_min=1 op=1 commit_max=1 prepare_max=1007)
2025-12-12 23:09:53.231Z debug(journal): 0: write_sectors: ring=vsr.journal.Ring.prepares offset=2097152 len=4096 locked
2025-12-12 23:09:53.231Z debug(replica): 2n: on_prepare: advancing: op=1..2 checksum=275713189790845781224572204107528367099..221859599298231531114501093791576957971
2025-12-12 23:09:53.231Z debug(journal): 2: set_header_as_dirty: op=2 checksum=221859599298231531114501093791576957971
2025-12-12 23:09:53.231Z debug(replica): 2n: append: appending to journal op=2
2025-12-12 23:09:53.231Z debug(journal): 2: write: view=1 slot=2 op=2 len=512: 221859599298231531114501093791576957971 starting
2025-12-12 23:09:53.231Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.prepares offset=2097152 len=4096 locked
2025-12-12 23:09:53.231Z debug(replica): 0n: repair_prepare: op=2 checksum=221859599298231531114501093791576957971 (already writing)
2025-12-12 23:09:53.231Z debug(replica): 2n: repair_prepare: op=2 checksum=221859599298231531114501093791576957971 (already writing)
2025-12-12 23:09:53.231Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 100286166972412602096278910662704428745, .checksum_padding = 0, .checksum_body = 80262522984338905420932325260476423013, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 512, .epoch = 0, .view = 0, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 0, .parent_padding = 0, .client = 204161290705302669957276092172686812873, .session = 0, .timestamp = 0, .request = 0, .operation = vsr.Operation.register, .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 0, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:09:53.231Z debug(replica): 1N: on_request: new session
2025-12-12 23:09:53.231Z debug(replica): 1N: on_request: ignoring (already preparing)
2025-12-12 23:09:53.231Z debug(journal): 0: write_sectors: ring=vsr.journal.Ring.prepares offset=2097152 len=4096 unlocked
2025-12-12 23:09:53.231Z debug(journal): 0: write_header: op=2 sectors[0..4096]
2025-12-12 23:09:53.231Z debug(journal): 0: write_sectors: ring=vsr.journal.Ring.headers offset=0 len=4096 locked
2025-12-12 23:09:53.231Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.prepares offset=2097152 len=4096 unlocked
2025-12-12 23:09:53.231Z debug(journal): 2: write_header: op=2 sectors[0..4096]
2025-12-12 23:09:53.231Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.headers offset=0 len=4096 locked
2025-12-12 23:09:53.231Z debug(journal): 0: write_sectors: ring=vsr.journal.Ring.headers offset=0 len=4096 unlocked
2025-12-12 23:09:53.231Z debug(journal): 0: write: view=1 slot=2 op=2 len=512: 221859599298231531114501093791576957971 complete, marking clean
2025-12-12 23:09:53.231Z debug(replica): 0n: send_prepare_ok: op=2 checksum=221859599298231531114501093791576957971
2025-12-12 23:09:53.231Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.prepares offset=2097152 len=4096 unlocked
2025-12-12 23:09:53.231Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.headers offset=0 len=4096 unlocked
2025-12-12 23:09:53.231Z debug(journal): 2: write: view=1 slot=2 op=2 len=512: 221859599298231531114501093791576957971 complete, marking clean
2025-12-12 23:09:53.231Z debug(journal): 1: write_header: op=2 sectors[0..4096]
2025-12-12 23:09:53.231Z debug(replica): 0n: sending prepare_ok to replica 1: vsr.message_header.Header.PrepareOk{ .checksum = 332168438849619439583624302812950085790, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 1, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 275713189790845781224572204107528367099, .parent_padding = 0, .prepare_checksum = 221859599298231531114501093791576957971, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 204161290705302669957276092172686812873, .op = 2, .commit_min = 1, .timestamp = 1765580993231150649, .request = 0, .operation = vsr.Operation.register, .reserved = { 0, 0, 0 } }
2025-12-12 23:09:53.231Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.headers offset=0 len=4096 locked
2025-12-12 23:09:53.231Z debug(replica): 2n: send_prepare_ok: op=2 checksum=221859599298231531114501093791576957971
2025-12-12 23:09:53.231Z debug(replica): 2n: sending prepare_ok to replica 1: vsr.message_header.Header.PrepareOk{ .checksum = 214939693973067032882921163034227835341, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 1, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 275713189790845781224572204107528367099, .parent_padding = 0, .prepare_checksum = 221859599298231531114501093791576957971, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 204161290705302669957276092172686812873, .op = 2, .commit_min = 1, .timestamp = 1765580993231150649, .request = 0, .operation = vsr.Operation.register, .reserved = { 0, 0, 0 } }
2025-12-12 23:09:53.231Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.headers offset=0 len=4096 unlocked
2025-12-12 23:09:53.231Z debug(journal): 1: write: view=1 slot=2 op=2 len=512: 221859599298231531114501093791576957971 complete, marking clean
2025-12-12 23:09:53.231Z debug(replica): 1N: send_prepare_ok: op=2 checksum=221859599298231531114501093791576957971
2025-12-12 23:09:53.231Z debug(replica): 1N: sending prepare_ok to replica 1: vsr.message_header.Header.PrepareOk{ .checksum = 99549722064522814707879095302720661133, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 1, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 275713189790845781224572204107528367099, .parent_padding = 0, .prepare_checksum = 221859599298231531114501093791576957971, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 204161290705302669957276092172686812873, .op = 2, .commit_min = 1, .timestamp = 1765580993231150649, .request = 0, .operation = vsr.Operation.register, .reserved = { 0, 0, 0 } }
2025-12-12 23:09:53.231Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.PrepareOk{ .checksum = 99549722064522814707879095302720661133, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 1, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 275713189790845781224572204107528367099, .parent_padding = 0, .prepare_checksum = 221859599298231531114501093791576957971, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 204161290705302669957276092172686812873, .op = 2, .commit_min = 1, .timestamp = 1765580993231150649, .request = 0, .operation = vsr.Operation.register, .reserved = { 0, 0, 0 } }
2025-12-12 23:09:53.231Z debug(vsr): 1: primary_abdicate_timeout reset
2025-12-12 23:09:53.231Z debug(replica): 1N: on_prepare_ok: 1 message(s)
2025-12-12 23:09:53.231Z debug(replica): 1N: on_prepare_ok: waiting for quorum
2025-12-12 23:09:53.231Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.PrepareOk{ .checksum = 332168438849619439583624302812950085790, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 1, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 275713189790845781224572204107528367099, .parent_padding = 0, .prepare_checksum = 221859599298231531114501093791576957971, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 204161290705302669957276092172686812873, .op = 2, .commit_min = 1, .timestamp = 1765580993231150649, .request = 0, .operation = vsr.Operation.register, .reserved = { 0, 0, 0 } }
2025-12-12 23:09:53.231Z debug(vsr): 1: primary_abdicate_timeout reset
2025-12-12 23:09:53.231Z debug(replica): 1N: on_prepare_ok: 2 message(s)
2025-12-12 23:09:53.231Z debug(replica): 1N: on_prepare_ok: quorum received, context=221859599298231531114501093791576957971
2025-12-12 23:09:53.231Z debug(vsr): 1: prepare_timeout stopped
2025-12-12 23:09:53.231Z debug(vsr): 1: primary_abdicate_timeout stopped
2025-12-12 23:09:53.231Z debug(replica): 1N: execute_op: executing view=1 primary=true op=2 checksum=221859599298231531114501093791576957971 (register)
2025-12-12 23:09:53.231Z debug(replica): 1N: execute_op: commit_timestamp=1765580983931588036 prepare.header.timestamp=1765580993231150649
2025-12-12 23:09:53.231Z debug(replica): 1N: execute_op: advancing commit_max=1..2
2025-12-12 23:09:53.231Z debug(replica): 1N: client_table_entry_create: write (client=204161290705302669957276092172686812873 session=2 request=0)
2025-12-12 23:09:53.231Z debug(replica): 1N: execute_op: replying to client: vsr.message_header.Header.Reply{ .checksum = 94993505035280708359129614847081256282, .checksum_padding = 0, .checksum_body = 33380509746930834472700756938017657525, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 320, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 100286166972412602096278910662704428745, .request_checksum_padding = 0, .context = 84862202640841919102126650401924450442, .context_padding = 0, .client = 204161290705302669957276092172686812873, .op = 2, .commit = 2, .timestamp = 1765580993231150649, .request = 0, .operation = vsr.Operation.register, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:09:53.231Z debug(replica): 1N: sending reply to client 204161290705302669957276092172686812873: vsr.message_header.Header.Reply{ .checksum = 94993505035280708359129614847081256282, .checksum_padding = 0, .checksum_body = 33380509746930834472700756938017657525, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 320, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 100286166972412602096278910662704428745, .request_checksum_padding = 0, .context = 84862202640841919102126650401924450442, .context_padding = 0, .client = 204161290705302669957276092172686812873, .op = 2, .commit = 2, .timestamp = 1765580993231150649, .request = 0, .operation = vsr.Operation.register, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:09:53.231Z debug(forest): entering forest.compact() op=2 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
warning(client): 204161290705302669957276092172686812873: on_reply: slow request, request=0 op=2 size=512 register time=92110ms
2025-12-12 23:09:53.232Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 257726315117405451711985239650546488656, .checksum_padding = 0, .checksum_body = 89618358641903479169915062276417095592, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 272, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 84862202640841919102126650401924450442, .parent_padding = 0, .client = 204161290705302669957276092172686812873, .session = 2, .timestamp = 0, .request = 1, .operation = vsr.Operation(141), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 4294967295, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:09:53.232Z debug(replica): 0n: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 257726315117405451711985239650546488656, .checksum_padding = 0, .checksum_body = 89618358641903479169915062276417095592, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 272, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 84862202640841919102126650401924450442, .parent_padding = 0, .client = 204161290705302669957276092172686812873, .session = 2, .timestamp = 0, .request = 1, .operation = vsr.Operation(141), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 4294967295, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:09:53.232Z debug(replica): 1N: on_request: new request
2025-12-12 23:09:53.232Z debug(replica): 1N: primary_pipeline_prepare: request checksum=257726315117405451711985239650546488656 client=204161290705302669957276092172686812873
2025-12-12 23:09:53.232Z debug(replica): 1N: primary_pipeline_prepare: prepare checksum=181322164258747000956055607087193593015 op=3
2025-12-12 23:09:53.232Z debug(vsr): 1: prepare_timeout started
2025-12-12 23:09:53.232Z debug(vsr): 1: primary_abdicate_timeout started
2025-12-12 23:09:53.232Z debug(vsr): 1: pulse_timeout reset
2025-12-12 23:09:53.232Z debug(replica): 1N: replicate: replicating op=3 to replica 0
2025-12-12 23:09:53.232Z debug(replica): 1N: sending prepare to replica 0: vsr.message_header.Header.Prepare{ .checksum = 181322164258747000956055607087193593015, .checksum_padding = 0, .checksum_body = 89618358641903479169915062276417095592, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 272, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 221859599298231531114501093791576957971, .parent_padding = 0, .request_checksum = 257726315117405451711985239650546488656, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 204161290705302669957276092172686812873, .op = 3, .commit = 2, .timestamp = 1765580993232332163, .request = 1, .operation = vsr.Operation(141), .reserved = { 0, 0, 0 } }
2025-12-12 23:09:53.232Z debug(replica): 1N: replicate: replicating op=3 to replica 2
2025-12-12 23:09:53.232Z debug(replica): 1N: sending prepare to replica 2: vsr.message_header.Header.Prepare{ .checksum = 181322164258747000956055607087193593015, .checksum_padding = 0, .checksum_body = 89618358641903479169915062276417095592, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 272, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 221859599298231531114501093791576957971, .parent_padding = 0, .request_checksum = 257726315117405451711985239650546488656, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 204161290705302669957276092172686812873, .op = 3, .commit = 2, .timestamp = 1765580993232332163, .request = 1, .operation = vsr.Operation(141), .reserved = { 0, 0, 0 } }
2025-12-12 23:09:53.232Z debug(replica): 1N: on_prepare: advancing: op=2..3 checksum=221859599298231531114501093791576957971..181322164258747000956055607087193593015
2025-12-12 23:09:53.232Z debug(replica): 0n: on_message: view=1 status=normal vsr.message_header.Header.Prepare{ .checksum = 181322164258747000956055607087193593015, .checksum_padding = 0, .checksum_body = 89618358641903479169915062276417095592, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 272, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 221859599298231531114501093791576957971, .parent_padding = 0, .request_checksum = 257726315117405451711985239650546488656, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 204161290705302669957276092172686812873, .op = 3, .commit = 2, .timestamp = 1765580993232332163, .request = 1, .operation = vsr.Operation(141), .reserved = { 0, 0, 0 } }
2025-12-12 23:09:53.232Z debug(journal): 1: set_header_as_dirty: op=3 checksum=181322164258747000956055607087193593015
2025-12-12 23:09:53.232Z debug(replica): 0n: on_prepare: advancing commit_max=1..2
2025-12-12 23:09:53.232Z debug(replica): 1N: append: appending to journal op=3
2025-12-12 23:09:53.232Z debug(replica): 0n: on_prepare: caching prepare.op=3 (commit_min=1 op=2 commit_max=2 prepare_max=1007)
2025-12-12 23:09:53.232Z debug(journal): 1: write: view=1 slot=3 op=3 len=272: 181322164258747000956055607087193593015 starting
2025-12-12 23:09:53.232Z debug(replica): 0n: on_prepare: advancing: op=2..3 checksum=221859599298231531114501093791576957971..181322164258747000956055607087193593015
2025-12-12 23:09:53.232Z debug(journal): 0: set_header_as_dirty: op=3 checksum=181322164258747000956055607087193593015
2025-12-12 23:09:53.232Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.prepares offset=3145728 len=4096 locked
2025-12-12 23:09:53.232Z debug(replica): 0n: append: appending to journal op=3
2025-12-12 23:09:53.232Z debug(replica): 2n: on_message: view=1 status=normal vsr.message_header.Header.Prepare{ .checksum = 181322164258747000956055607087193593015, .checksum_padding = 0, .checksum_body = 89618358641903479169915062276417095592, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 272, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 221859599298231531114501093791576957971, .parent_padding = 0, .request_checksum = 257726315117405451711985239650546488656, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 204161290705302669957276092172686812873, .op = 3, .commit = 2, .timestamp = 1765580993232332163, .request = 1, .operation = vsr.Operation(141), .reserved = { 0, 0, 0 } }
2025-12-12 23:09:53.232Z debug(journal): 0: write: view=1 slot=3 op=3 len=272: 181322164258747000956055607087193593015 starting
2025-12-12 23:09:53.232Z debug(replica): 2n: on_prepare: advancing commit_max=1..2
2025-12-12 23:09:53.232Z debug(replica): 2n: on_prepare: caching prepare.op=3 (commit_min=1 op=2 commit_max=2 prepare_max=1007)
2025-12-12 23:09:53.232Z debug(journal): 0: write_sectors: ring=vsr.journal.Ring.prepares offset=3145728 len=4096 locked
2025-12-12 23:09:53.232Z debug(replica): 0n: commit_start_journal: cached prepare op=2 checksum=221859599298231531114501093791576957971
2025-12-12 23:09:53.232Z debug(replica): 2n: on_prepare: advancing: op=2..3 checksum=221859599298231531114501093791576957971..181322164258747000956055607087193593015
2025-12-12 23:09:53.232Z debug(journal): 2: set_header_as_dirty: op=3 checksum=181322164258747000956055607087193593015
2025-12-12 23:09:53.232Z debug(replica): 0n: execute_op: executing view=1 primary=false op=2 checksum=221859599298231531114501093791576957971 (register)
2025-12-12 23:09:53.232Z debug(replica): 2n: append: appending to journal op=3
2025-12-12 23:09:53.232Z debug(replica): 0n: execute_op: commit_timestamp=1765580983931588036 prepare.header.timestamp=1765580993231150649
2025-12-12 23:09:53.232Z debug(journal): 2: write: view=1 slot=3 op=3 len=272: 181322164258747000956055607087193593015 starting
2025-12-12 23:09:53.232Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.PrepareOk{ .checksum = 214939693973067032882921163034227835341, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 1, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 275713189790845781224572204107528367099, .parent_padding = 0, .prepare_checksum = 221859599298231531114501093791576957971, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 204161290705302669957276092172686812873, .op = 2, .commit_min = 1, .timestamp = 1765580993231150649, .request = 0, .operation = vsr.Operation.register, .reserved = { 0, 0, 0 } }
2025-12-12 23:09:53.232Z debug(replica): 0n: client_table_entry_create: write (client=204161290705302669957276092172686812873 session=2 request=0)
2025-12-12 23:09:53.232Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.prepares offset=3145728 len=4096 locked
2025-12-12 23:09:53.232Z debug(replica): 1N: on_prepare_ok: not preparing op=2 checksum=221859599298231531114501093791576957971
2025-12-12 23:09:53.232Z debug(replica): 2n: commit_start_journal: cached prepare op=2 checksum=221859599298231531114501093791576957971
2025-12-12 23:09:53.232Z debug(forest): entering forest.compact() op=2 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2025-12-12 23:09:53.232Z debug(replica): 2n: execute_op: executing view=1 primary=false op=2 checksum=221859599298231531114501093791576957971 (register)
2025-12-12 23:09:53.232Z debug(replica): 2n: execute_op: commit_timestamp=1765580983931588036 prepare.header.timestamp=1765580993231150649
2025-12-12 23:09:53.232Z debug(replica): 2n: client_table_entry_create: write (client=204161290705302669957276092172686812873 session=2 request=0)
2025-12-12 23:09:53.232Z debug(replica): 2n: execute_op: replying to client: vsr.message_header.Header.Reply{ .checksum = 94993505035280708359129614847081256282, .checksum_padding = 0, .checksum_body = 33380509746930834472700756938017657525, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 320, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 100286166972412602096278910662704428745, .request_checksum_padding = 0, .context = 84862202640841919102126650401924450442, .context_padding = 0, .client = 204161290705302669957276092172686812873, .op = 2, .commit = 2, .timestamp = 1765580993231150649, .request = 0, .operation = vsr.Operation.register, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:09:53.232Z debug(replica): 0n: repair_prepare: op=3 checksum=181322164258747000956055607087193593015 (already writing)
2025-12-12 23:09:53.232Z debug(replica): 2n: sending reply to client 204161290705302669957276092172686812873: vsr.message_header.Header.Reply{ .checksum = 94993505035280708359129614847081256282, .checksum_padding = 0, .checksum_body = 33380509746930834472700756938017657525, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 320, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 100286166972412602096278910662704428745, .request_checksum_padding = 0, .context = 84862202640841919102126650401924450442, .context_padding = 0, .client = 204161290705302669957276092172686812873, .op = 2, .commit = 2, .timestamp = 1765580993231150649, .request = 0, .operation = vsr.Operation.register, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:09:53.232Z debug(forest): entering forest.compact() op=2 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2025-12-12 23:09:53.232Z debug(replica): 2n: repair_prepare: op=3 checksum=181322164258747000956055607087193593015 (already writing)
2025-12-12 23:09:53.232Z debug(client_replies): 1: write_reply: wrote (client=204161290705302669957276092172686812873 request=0)
2025-12-12 23:09:53.232Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.prepares offset=3145728 len=4096 unlocked
2025-12-12 23:09:53.232Z debug(journal): 0: write_sectors: ring=vsr.journal.Ring.prepares offset=3145728 len=4096 unlocked
2025-12-12 23:09:53.232Z debug(journal): 1: write_header: op=3 sectors[0..4096]
2025-12-12 23:09:53.232Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.headers offset=0 len=4096 locked
2025-12-12 23:09:53.232Z debug(journal): 0: write_header: op=3 sectors[0..4096]
2025-12-12 23:09:53.232Z debug(journal): 0: write_sectors: ring=vsr.journal.Ring.headers offset=0 len=4096 locked
2025-12-12 23:09:53.232Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.headers offset=0 len=4096 unlocked
2025-12-12 23:09:53.232Z debug(journal): 1: write: view=1 slot=3 op=3 len=272: 181322164258747000956055607087193593015 complete, marking clean
2025-12-12 23:09:53.232Z debug(replica): 1N: send_prepare_ok: op=3 checksum=181322164258747000956055607087193593015
2025-12-12 23:09:53.232Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.prepares offset=3145728 len=4096 unlocked
2025-12-12 23:09:53.232Z debug(journal): 2: write_header: op=3 sectors[0..4096]
2025-12-12 23:09:53.232Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.headers offset=0 len=4096 locked
2025-12-12 23:09:53.232Z debug(journal): 0: write_sectors: ring=vsr.journal.Ring.headers offset=0 len=4096 unlocked
2025-12-12 23:09:53.233Z debug(journal): 0: write: view=1 slot=3 op=3 len=272: 181322164258747000956055607087193593015 complete, marking clean
2025-12-12 23:09:53.233Z debug(client_replies): 2: write_reply: wrote (client=204161290705302669957276092172686812873 request=0)
2025-12-12 23:09:53.232Z debug(replica): 1N: sending prepare_ok to replica 1: vsr.message_header.Header.PrepareOk{ .checksum = 22022455683042571321388504069318928069, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 1, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 221859599298231531114501093791576957971, .parent_padding = 0, .prepare_checksum = 181322164258747000956055607087193593015, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 204161290705302669957276092172686812873, .op = 3, .commit_min = 2, .timestamp = 1765580993232332163, .request = 1, .operation = vsr.Operation(141), .reserved = { 0, 0, 0 } }
2025-12-12 23:09:53.233Z debug(replica): 0n: send_prepare_ok: op=3 checksum=181322164258747000956055607087193593015
2025-12-12 23:09:56.309Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.headers offset=0 len=4096 unlocked
2025-12-12 23:09:56.309Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.PrepareOk{ .checksum = 22022455683042571321388504069318928069, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 1, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 221859599298231531114501093791576957971, .parent_padding = 0, .prepare_checksum = 181322164258747000956055607087193593015, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 204161290705302669957276092172686812873, .op = 3, .commit_min = 2, .timestamp = 1765580993232332163, .request = 1, .operation = vsr.Operation(141), .reserved = { 0, 0, 0 } }
2025-12-12 23:09:56.309Z debug(replica): 0n: sending prepare_ok to replica 1: vsr.message_header.Header.PrepareOk{ .checksum = 50741787710822478855825009132451389417, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 1, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 221859599298231531114501093791576957971, .parent_padding = 0, .prepare_checksum = 181322164258747000956055607087193593015, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 204161290705302669957276092172686812873, .op = 3, .commit_min = 2, .timestamp = 1765580993232332163, .request = 1, .operation = vsr.Operation(141), .reserved = { 0, 0, 0 } }
2025-12-12 23:09:56.309Z debug(journal): 2: write: view=1 slot=3 op=3 len=272: 181322164258747000956055607087193593015 complete, marking clean
2025-12-12 23:09:56.309Z debug(vsr): 1: primary_abdicate_timeout reset
2025-12-12 23:09:56.309Z debug(replica): 1N: on_prepare_ok: 1 message(s)
2025-12-12 23:09:56.309Z debug(replica): 2n: send_prepare_ok: op=3 checksum=181322164258747000956055607087193593015
2025-12-12 23:09:56.309Z debug(replica): 1N: on_prepare_ok: waiting for quorum
2025-12-12 23:09:56.309Z debug(replica): 2n: sending prepare_ok to replica 1: vsr.message_header.Header.PrepareOk{ .checksum = 205483678154835151208610023836281717030, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 1, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 221859599298231531114501093791576957971, .parent_padding = 0, .prepare_checksum = 181322164258747000956055607087193593015, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 204161290705302669957276092172686812873, .op = 3, .commit_min = 2, .timestamp = 1765580993232332163, .request = 1, .operation = vsr.Operation(141), .reserved = { 0, 0, 0 } }
2025-12-12 23:09:56.309Z debug(client_replies): 0: write_reply: wrote (client=204161290705302669957276092172686812873 request=0)
2025-12-12 23:09:56.309Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 257726315117405451711985239650546488656, .checksum_padding = 0, .checksum_body = 89618358641903479169915062276417095592, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 272, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 84862202640841919102126650401924450442, .parent_padding = 0, .client = 204161290705302669957276092172686812873, .session = 2, .timestamp = 0, .request = 1, .operation = vsr.Operation(141), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 4294967295, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:09:56.309Z debug(clock): 2: synchronized: truechimers=3/3 clock_offset=0ns..0ns accuracy=0ns
2025-12-12 23:09:56.309Z debug(clock): 2: system time is 70ns behind
2025-12-12 23:09:56.309Z debug(replica): 1N: on_request: new request
2025-12-12 23:09:56.309Z debug(replica): 1N: on_request: ignoring (already preparing)
2025-12-12 23:09:56.309Z debug(replica): 0n: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 257726315117405451711985239650546488656, .checksum_padding = 0, .checksum_body = 89618358641903479169915062276417095592, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 272, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 84862202640841919102126650401924450442, .parent_padding = 0, .client = 204161290705302669957276092172686812873, .session = 2, .timestamp = 0, .request = 1, .operation = vsr.Operation(141), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 4294967295, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:09:56.309Z debug(replica): 0n: on_request: forwarding new request to primary (view=1)
2025-12-12 23:09:56.309Z debug(replica): 0n: sending request to replica 1: vsr.message_header.Header.Request{ .checksum = 257726315117405451711985239650546488656, .checksum_padding = 0, .checksum_body = 89618358641903479169915062276417095592, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 272, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 84862202640841919102126650401924450442, .parent_padding = 0, .client = 204161290705302669957276092172686812873, .session = 2, .timestamp = 0, .request = 1, .operation = vsr.Operation(141), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 4294967295, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:09:56.309Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.PrepareOk{ .checksum = 50741787710822478855825009132451389417, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 1, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 221859599298231531114501093791576957971, .parent_padding = 0, .prepare_checksum = 181322164258747000956055607087193593015, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 204161290705302669957276092172686812873, .op = 3, .commit_min = 2, .timestamp = 1765580993232332163, .request = 1, .operation = vsr.Operation(141), .reserved = { 0, 0, 0 } }
2025-12-12 23:09:56.309Z debug(vsr): 1: primary_abdicate_timeout reset
2025-12-12 23:09:56.309Z debug(replica): 1N: on_prepare_ok: 2 message(s)
2025-12-12 23:09:56.309Z debug(replica): 1N: on_prepare_ok: quorum received, context=181322164258747000956055607087193593015
2025-12-12 23:09:56.309Z debug(vsr): 1: prepare_timeout stopped
2025-12-12 23:09:56.309Z debug(vsr): 1: primary_abdicate_timeout stopped
2025-12-12 23:09:56.309Z debug(clock): 0: synchronized: truechimers=3/3 clock_offset=0ns..0ns accuracy=0ns
2025-12-12 23:09:56.309Z debug(clock): 0: system time is 140ns behind
2025-12-12 23:09:56.310Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.PrepareOk{ .checksum = 205483678154835151208610023836281717030, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 1, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 221859599298231531114501093791576957971, .parent_padding = 0, .prepare_checksum = 181322164258747000956055607087193593015, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 204161290705302669957276092172686812873, .op = 3, .commit_min = 2, .timestamp = 1765580993232332163, .request = 1, .operation = vsr.Operation(141), .reserved = { 0, 0, 0 } }
2025-12-12 23:09:56.310Z debug(replica): 1N: on_prepare_ok: 3 message(s)
2025-12-12 23:09:56.310Z debug(replica): 1N: on_prepare_ok: ignoring (quorum received already)
2025-12-12 23:09:56.310Z debug(replica): 1N: execute_op: executing view=1 primary=true op=3 checksum=181322164258747000956055607087193593015 (lookup_transfers)
2025-12-12 23:09:56.310Z debug(replica): 1N: execute_op: commit_timestamp=1765580993231150649 prepare.header.timestamp=1765580993232332163
2025-12-12 23:09:56.310Z debug(replica): 1N: execute_op: advancing commit_max=2..3
2025-12-12 23:09:56.310Z debug(replica): 1N: client_table_entry_update: client=204161290705302669957276092172686812873 session=2 request=1
2025-12-12 23:09:56.310Z debug(replica): 1N: execute_op: replying to client: vsr.message_header.Header.Reply{ .checksum = 49582223345813643818152195697358833301, .checksum_padding = 0, .checksum_body = 163142189146558185265411974777684875497, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 384, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 257726315117405451711985239650546488656, .request_checksum_padding = 0, .context = 55990259448192735965588433854625213104, .context_padding = 0, .client = 204161290705302669957276092172686812873, .op = 3, .commit = 3, .timestamp = 1765580993232332163, .request = 1, .operation = vsr.Operation(141), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:09:56.310Z debug(replica): 1N: sending reply to client 204161290705302669957276092172686812873: vsr.message_header.Header.Reply{ .checksum = 49582223345813643818152195697358833301, .checksum_padding = 0, .checksum_body = 163142189146558185265411974777684875497, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 384, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 257726315117405451711985239650546488656, .request_checksum_padding = 0, .context = 55990259448192735965588433854625213104, .context_padding = 0, .client = 204161290705302669957276092172686812873, .op = 3, .commit = 3, .timestamp = 1765580993232332163, .request = 1, .operation = vsr.Operation(141), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:09:56.310Z debug(forest): entering forest.compact() op=3 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
warning(client): 204161290705302669957276092172686812873: on_reply: slow request, request=1 op=3 size=272 lookup_transfers time=3078ms
2025-12-12 23:09:56.310Z debug(clock): 1: synchronized: truechimers=3/3 clock_offset=0ns..0ns accuracy=0ns
2025-12-12 23:09:56.310Z debug(clock): 1: system time is 10ns behind
2025-12-12 23:09:56.310Z debug(client_replies): 1: write_reply: wrote (client=204161290705302669957276092172686812873 request=1)
2025-12-12 23:09:56.311Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 3743219772042419751077020331129977229, .checksum_padding = 0, .checksum_body = 89618358641903479169915062276417095592, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 272, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 55990259448192735965588433854625213104, .parent_padding = 0, .client = 204161290705302669957276092172686812873, .session = 2, .timestamp = 0, .request = 2, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 3078252690, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:09:56.311Z debug(replica): 0n: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 3743219772042419751077020331129977229, .checksum_padding = 0, .checksum_body = 89618358641903479169915062276417095592, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 272, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 55990259448192735965588433854625213104, .parent_padding = 0, .client = 204161290705302669957276092172686812873, .session = 2, .timestamp = 0, .request = 2, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 3078252690, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:09:56.311Z debug(replica): 1N: on_request: new request
2025-12-12 23:09:56.311Z debug(replica): 0n: on_request: forwarding new request to primary (view=1)
2025-12-12 23:09:56.311Z debug(replica): 1N: primary_pipeline_prepare: request checksum=3743219772042419751077020331129977229 client=204161290705302669957276092172686812873
2025-12-12 23:09:56.311Z debug(replica): 0n: sending request to replica 1: vsr.message_header.Header.Request{ .checksum = 3743219772042419751077020331129977229, .checksum_padding = 0, .checksum_body = 89618358641903479169915062276417095592, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 272, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 55990259448192735965588433854625213104, .parent_padding = 0, .client = 204161290705302669957276092172686812873, .session = 2, .timestamp = 0, .request = 2, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 3078252690, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:09:56.311Z debug(replica): 1N: primary_pipeline_prepare: prepare checksum=211806948086893540859888426388782723553 op=4
2025-12-12 23:09:56.311Z debug(vsr): 1: prepare_timeout started
2025-12-12 23:09:56.311Z debug(vsr): 1: primary_abdicate_timeout started
2025-12-12 23:09:56.311Z debug(vsr): 1: pulse_timeout reset
2025-12-12 23:09:56.311Z debug(replica): 1N: replicate: replicating op=4 to replica 0
2025-12-12 23:09:56.311Z debug(replica): 1N: sending prepare to replica 0: vsr.message_header.Header.Prepare{ .checksum = 211806948086893540859888426388782723553, .checksum_padding = 0, .checksum_body = 89618358641903479169915062276417095592, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 272, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 181322164258747000956055607087193593015, .parent_padding = 0, .request_checksum = 3743219772042419751077020331129977229, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 204161290705302669957276092172686812873, .op = 4, .commit = 3, .timestamp = 1765580996311061191, .request = 2, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-12-12 23:09:56.311Z debug(replica): 1N: replicate: replicating op=4 to replica 2
2025-12-12 23:09:56.311Z debug(replica): 1N: sending prepare to replica 2: vsr.message_header.Header.Prepare{ .checksum = 211806948086893540859888426388782723553, .checksum_padding = 0, .checksum_body = 89618358641903479169915062276417095592, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 272, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 181322164258747000956055607087193593015, .parent_padding = 0, .request_checksum = 3743219772042419751077020331129977229, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 204161290705302669957276092172686812873, .op = 4, .commit = 3, .timestamp = 1765580996311061191, .request = 2, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-12-12 23:09:56.311Z debug(replica): 1N: on_prepare: advancing: op=3..4 checksum=181322164258747000956055607087193593015..211806948086893540859888426388782723553
2025-12-12 23:09:56.311Z debug(replica): 0n: on_message: view=1 status=normal vsr.message_header.Header.Prepare{ .checksum = 211806948086893540859888426388782723553, .checksum_padding = 0, .checksum_body = 89618358641903479169915062276417095592, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 272, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 181322164258747000956055607087193593015, .parent_padding = 0, .request_checksum = 3743219772042419751077020331129977229, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 204161290705302669957276092172686812873, .op = 4, .commit = 3, .timestamp = 1765580996311061191, .request = 2, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-12-12 23:09:56.311Z debug(journal): 1: set_header_as_dirty: op=4 checksum=211806948086893540859888426388782723553
2025-12-12 23:09:56.311Z debug(replica): 0n: on_prepare: advancing commit_max=2..3
2025-12-12 23:09:56.311Z debug(replica): 1N: append: appending to journal op=4
2025-12-12 23:09:56.311Z debug(replica): 0n: on_prepare: caching prepare.op=4 (commit_min=2 op=3 commit_max=3 prepare_max=1007)
2025-12-12 23:09:56.311Z debug(journal): 1: write: view=1 slot=4 op=4 len=272: 211806948086893540859888426388782723553 starting
2025-12-12 23:09:56.311Z debug(replica): 0n: on_prepare: advancing: op=3..4 checksum=181322164258747000956055607087193593015..211806948086893540859888426388782723553
2025-12-12 23:09:56.311Z debug(journal): 0: set_header_as_dirty: op=4 checksum=211806948086893540859888426388782723553
2025-12-12 23:09:56.311Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.prepares offset=4194304 len=4096 locked
2025-12-12 23:09:56.311Z debug(replica): 0n: append: appending to journal op=4
2025-12-12 23:09:56.311Z debug(replica): 2n: on_message: view=1 status=normal vsr.message_header.Header.Prepare{ .checksum = 211806948086893540859888426388782723553, .checksum_padding = 0, .checksum_body = 89618358641903479169915062276417095592, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 272, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 181322164258747000956055607087193593015, .parent_padding = 0, .request_checksum = 3743219772042419751077020331129977229, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 204161290705302669957276092172686812873, .op = 4, .commit = 3, .timestamp = 1765580996311061191, .request = 2, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-12-12 23:09:56.311Z debug(journal): 0: write: view=1 slot=4 op=4 len=272: 211806948086893540859888426388782723553 starting
2025-12-12 23:09:56.311Z debug(replica): 2n: on_prepare: advancing commit_max=2..3
2025-12-12 23:09:56.311Z debug(replica): 2n: on_prepare: caching prepare.op=4 (commit_min=2 op=3 commit_max=3 prepare_max=1007)
2025-12-12 23:09:56.311Z debug(journal): 0: write_sectors: ring=vsr.journal.Ring.prepares offset=4194304 len=4096 locked
2025-12-12 23:09:56.311Z debug(replica): 2n: on_prepare: advancing: op=3..4 checksum=181322164258747000956055607087193593015..211806948086893540859888426388782723553
2025-12-12 23:09:56.311Z debug(replica): 0n: commit_start_journal: cached prepare op=3 checksum=181322164258747000956055607087193593015
2025-12-12 23:09:56.311Z debug(journal): 2: set_header_as_dirty: op=4 checksum=211806948086893540859888426388782723553
2025-12-12 23:09:56.311Z debug(replica): 2n: append: appending to journal op=4
2025-12-12 23:09:56.311Z debug(journal): 2: write: view=1 slot=4 op=4 len=272: 211806948086893540859888426388782723553 starting
2025-12-12 23:09:56.311Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.prepares offset=4194304 len=4096 locked
2025-12-12 23:09:56.311Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 257726315117405451711985239650546488656, .checksum_padding = 0, .checksum_body = 89618358641903479169915062276417095592, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 272, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 84862202640841919102126650401924450442, .parent_padding = 0, .client = 204161290705302669957276092172686812873, .session = 2, .timestamp = 0, .request = 1, .operation = vsr.Operation(141), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 4294967295, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:09:56.311Z debug(replica): 2n: commit_start_journal: cached prepare op=3 checksum=181322164258747000956055607087193593015
2025-12-12 23:09:56.311Z debug(replica): 1N: on_request: replying to duplicate request
2025-12-12 23:09:56.311Z debug(client_replies): 1: read_reply: start (client=204161290705302669957276092172686812873 reply=49582223345813643818152195697358833301)
2025-12-12 23:09:56.311Z debug(replica): 0n: repair_prepare: op=4 checksum=211806948086893540859888426388782723553 (already writing)
2025-12-12 23:09:56.311Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 3743219772042419751077020331129977229, .checksum_padding = 0, .checksum_body = 89618358641903479169915062276417095592, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 272, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 55990259448192735965588433854625213104, .parent_padding = 0, .client = 204161290705302669957276092172686812873, .session = 2, .timestamp = 0, .request = 2, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 3078252690, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:09:56.311Z debug(replica): 0n: commit_journal: already committing (prefetch; commit_min=2)
2025-12-12 23:09:56.311Z debug(replica): 1N: on_request: new request
2025-12-12 23:09:56.311Z debug(replica): 1N: on_request: ignoring (already preparing)
2025-12-12 23:09:56.311Z debug(replica): 0n: execute_op: executing view=1 primary=false op=3 checksum=181322164258747000956055607087193593015 (lookup_transfers)
2025-12-12 23:09:56.311Z debug(replica): 2n: repair_prepare: op=4 checksum=211806948086893540859888426388782723553 (already writing)
2025-12-12 23:09:56.311Z debug(replica): 0n: execute_op: commit_timestamp=1765580993231150649 prepare.header.timestamp=1765580993232332163
2025-12-12 23:09:56.311Z debug(replica): 0n: client_table_entry_update: client=204161290705302669957276092172686812873 session=2 request=1
2025-12-12 23:09:56.311Z debug(replica): 2n: commit_journal: already committing (prefetch; commit_min=2)
2025-12-12 23:09:56.311Z debug(forest): entering forest.compact() op=3 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2025-12-12 23:09:56.311Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.prepares offset=4194304 len=4096 unlocked
2025-12-12 23:09:56.311Z debug(replica): 2n: execute_op: executing view=1 primary=false op=3 checksum=181322164258747000956055607087193593015 (lookup_transfers)
2025-12-12 23:09:56.311Z debug(journal): 1: write_header: op=4 sectors[0..4096]
2025-12-12 23:09:56.311Z debug(replica): 2n: execute_op: commit_timestamp=1765580993231150649 prepare.header.timestamp=1765580993232332163
2025-12-12 23:09:56.311Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.headers offset=0 len=4096 locked
2025-12-12 23:09:56.311Z debug(replica): 2n: client_table_entry_update: client=204161290705302669957276092172686812873 session=2 request=1
2025-12-12 23:09:56.311Z debug(client_replies): 1: read_reply: done (client=204161290705302669957276092172686812873 reply=49582223345813643818152195697358833301)
2025-12-12 23:09:56.311Z debug(replica): 1N: on_request: repeat reply (client=204161290705302669957276092172686812873 request=1)
2025-12-12 23:09:56.311Z debug(replica): 2n: execute_op: replying to client: vsr.message_header.Header.Reply{ .checksum = 49582223345813643818152195697358833301, .checksum_padding = 0, .checksum_body = 163142189146558185265411974777684875497, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 384, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 257726315117405451711985239650546488656, .request_checksum_padding = 0, .context = 55990259448192735965588433854625213104, .context_padding = 0, .client = 204161290705302669957276092172686812873, .op = 3, .commit = 3, .timestamp = 1765580993232332163, .request = 1, .operation = vsr.Operation(141), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:09:56.311Z debug(replica): 2n: sending reply to client 204161290705302669957276092172686812873: vsr.message_header.Header.Reply{ .checksum = 49582223345813643818152195697358833301, .checksum_padding = 0, .checksum_body = 163142189146558185265411974777684875497, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 384, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 257726315117405451711985239650546488656, .request_checksum_padding = 0, .context = 55990259448192735965588433854625213104, .context_padding = 0, .client = 204161290705302669957276092172686812873, .op = 3, .commit = 3, .timestamp = 1765580993232332163, .request = 1, .operation = vsr.Operation(141), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:09:56.311Z debug(replica): 1N: sending reply to client 204161290705302669957276092172686812873: vsr.message_header.Header.Reply{ .checksum = 49582223345813643818152195697358833301, .checksum_padding = 0, .checksum_body = 163142189146558185265411974777684875497, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 384, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 257726315117405451711985239650546488656, .request_checksum_padding = 0, .context = 55990259448192735965588433854625213104, .context_padding = 0, .client = 204161290705302669957276092172686812873, .op = 3, .commit = 3, .timestamp = 1765580993232332163, .request = 1, .operation = vsr.Operation(141), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:09:56.311Z debug(forest): entering forest.compact() op=3 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2025-12-12 23:09:56.311Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.headers offset=0 len=4096 unlocked
2025-12-12 23:09:56.311Z debug(journal): 1: write: view=1 slot=4 op=4 len=272: 211806948086893540859888426388782723553 complete, marking clean
2025-12-12 23:09:56.311Z debug(client_replies): 0: write_reply: wrote (client=204161290705302669957276092172686812873 request=1)
2025-12-12 23:09:56.311Z debug(replica): 1N: send_prepare_ok: op=4 checksum=211806948086893540859888426388782723553
2025-12-12 23:09:56.311Z debug(journal): 0: write_sectors: ring=vsr.journal.Ring.prepares offset=4194304 len=4096 unlocked
2025-12-12 23:09:56.311Z debug(replica): 1N: sending prepare_ok to replica 1: vsr.message_header.Header.PrepareOk{ .checksum = 308115593982849393546263691056156506618, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 1, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 181322164258747000956055607087193593015, .parent_padding = 0, .prepare_checksum = 211806948086893540859888426388782723553, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 204161290705302669957276092172686812873, .op = 4, .commit_min = 3, .timestamp = 1765580996311061191, .request = 2, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-12-12 23:09:56.311Z debug(journal): 0: write_header: op=4 sectors[0..4096]
2025-12-12 23:09:56.311Z debug(journal): 0: write_sectors: ring=vsr.journal.Ring.headers offset=0 len=4096 locked
2025-12-12 23:09:56.311Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.PrepareOk{ .checksum = 308115593982849393546263691056156506618, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 1, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 181322164258747000956055607087193593015, .parent_padding = 0, .prepare_checksum = 211806948086893540859888426388782723553, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 204161290705302669957276092172686812873, .op = 4, .commit_min = 3, .timestamp = 1765580996311061191, .request = 2, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-12-12 23:09:56.311Z debug(vsr): 1: primary_abdicate_timeout reset
2025-12-12 23:09:56.311Z debug(replica): 1N: on_prepare_ok: 1 message(s)
2025-12-12 23:09:56.311Z debug(replica): 1N: on_prepare_ok: waiting for quorum
2025-12-12 23:09:56.311Z debug(journal): 0: write_sectors: ring=vsr.journal.Ring.headers offset=0 len=4096 unlocked
2025-12-12 23:09:56.311Z debug(journal): 0: write: view=1 slot=4 op=4 len=272: 211806948086893540859888426388782723553 complete, marking clean
2025-12-12 23:09:56.311Z debug(replica): 0n: send_prepare_ok: op=4 checksum=211806948086893540859888426388782723553
2025-12-12 23:09:56.311Z debug(replica): 0n: sending prepare_ok to replica 1: vsr.message_header.Header.PrepareOk{ .checksum = 207449703327518693225129265386983843101, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 1, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 181322164258747000956055607087193593015, .parent_padding = 0, .prepare_checksum = 211806948086893540859888426388782723553, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 204161290705302669957276092172686812873, .op = 4, .commit_min = 3, .timestamp = 1765580996311061191, .request = 2, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-12-12 23:09:56.311Z debug(client_replies): 2: write_reply: wrote (client=204161290705302669957276092172686812873 request=1)
2025-12-12 23:09:56.311Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.prepares offset=4194304 len=4096 unlocked
2025-12-12 23:09:56.311Z debug(journal): 2: write_header: op=4 sectors[0..4096]
2025-12-12 23:09:56.311Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.headers offset=0 len=4096 locked
2025-12-12 23:09:56.311Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.headers offset=0 len=4096 unlocked
2025-12-12 23:09:56.311Z debug(journal): 2: write: view=1 slot=4 op=4 len=272: 211806948086893540859888426388782723553 complete, marking clean
2025-12-12 23:09:56.311Z debug(replica): 2n: send_prepare_ok: op=4 checksum=211806948086893540859888426388782723553
2025-12-12 23:09:56.311Z debug(replica): 2n: sending prepare_ok to replica 1: vsr.message_header.Header.PrepareOk{ .checksum = 120966267582879397325715296382558002515, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 1, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 181322164258747000956055607087193593015, .parent_padding = 0, .prepare_checksum = 211806948086893540859888426388782723553, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 204161290705302669957276092172686812873, .op = 4, .commit_min = 3, .timestamp = 1765580996311061191, .request = 2, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-12-12 23:09:56.311Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.PrepareOk{ .checksum = 120966267582879397325715296382558002515, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 1, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 181322164258747000956055607087193593015, .parent_padding = 0, .prepare_checksum = 211806948086893540859888426388782723553, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 204161290705302669957276092172686812873, .op = 4, .commit_min = 3, .timestamp = 1765580996311061191, .request = 2, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-12-12 23:09:56.311Z debug(vsr): 1: primary_abdicate_timeout reset
2025-12-12 23:09:56.311Z debug(replica): 1N: on_prepare_ok: 2 message(s)
2025-12-12 23:09:56.311Z debug(replica): 1N: on_prepare_ok: quorum received, context=211806948086893540859888426388782723553
2025-12-12 23:09:56.311Z debug(vsr): 1: prepare_timeout stopped
2025-12-12 23:09:56.311Z debug(vsr): 1: primary_abdicate_timeout stopped
2025-12-12 23:09:56.312Z debug(replica): 1N: execute_op: executing view=1 primary=true op=4 checksum=211806948086893540859888426388782723553 (lookup_accounts)
2025-12-12 23:09:56.312Z debug(replica): 1N: execute_op: commit_timestamp=1765580993232332163 prepare.header.timestamp=1765580996311061191
2025-12-12 23:09:56.312Z debug(replica): 1N: execute_op: advancing commit_max=3..4
2025-12-12 23:09:56.312Z debug(replica): 1N: client_table_entry_update: client=204161290705302669957276092172686812873 session=2 request=2
2025-12-12 23:09:56.312Z debug(replica): 1N: execute_op: replying to client: vsr.message_header.Header.Reply{ .checksum = 196897574282506000948337520632138655077, .checksum_padding = 0, .checksum_body = 163142189146558185265411974777684875497, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 384, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 3743219772042419751077020331129977229, .request_checksum_padding = 0, .context = 185548821418314641523184812315704833444, .context_padding = 0, .client = 204161290705302669957276092172686812873, .op = 4, .commit = 4, .timestamp = 1765580996311061191, .request = 2, .operation = vsr.Operation(140), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:09:56.312Z debug(replica): 1N: sending reply to client 204161290705302669957276092172686812873: vsr.message_header.Header.Reply{ .checksum = 196897574282506000948337520632138655077, .checksum_padding = 0, .checksum_body = 163142189146558185265411974777684875497, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 384, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 3743219772042419751077020331129977229, .request_checksum_padding = 0, .context = 185548821418314641523184812315704833444, .context_padding = 0, .client = 204161290705302669957276092172686812873, .op = 4, .commit = 4, .timestamp = 1765580996311061191, .request = 2, .operation = vsr.Operation(140), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:09:56.312Z debug(forest): entering forest.compact() op=4 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2025-12-12 23:09:56.312Z debug(client_replies): 1: write_reply: wrote (client=204161290705302669957276092172686812873 request=2)
2025-12-12 23:09:56.319Z debug(vsr): 2: journal_repair_budget_timeout fired
2025-12-12 23:09:56.319Z debug(vsr): 2: journal_repair_budget_timeout reset
2025-12-12 23:09:56.320Z debug(vsr): 0: journal_repair_budget_timeout fired
2025-12-12 23:09:56.320Z debug(vsr): 0: journal_repair_budget_timeout reset
2025-12-12 23:09:56.320Z debug(vsr): 1: journal_repair_budget_timeout fired
2025-12-12 23:09:56.320Z debug(vsr): 1: journal_repair_budget_timeout reset
2025-12-12 23:09:56.339Z debug(vsr): 2: journal_repair_budget_timeout fired
2025-12-12 23:09:56.339Z debug(vsr): 2: journal_repair_budget_timeout reset
2025-12-12 23:09:56.340Z debug(vsr): 0: journal_repair_budget_timeout fired
2025-12-12 23:09:56.340Z debug(vsr): 0: journal_repair_budget_timeout reset
2025-12-12 23:09:56.340Z debug(vsr): 1: journal_repair_budget_timeout fired
2025-12-12 23:09:56.340Z debug(vsr): 1: journal_repair_budget_timeout reset
2025-12-12 23:09:56.357Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.PrepareOk{ .checksum = 207449703327518693225129265386983843101, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 1, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 181322164258747000956055607087193593015, .parent_padding = 0, .prepare_checksum = 211806948086893540859888426388782723553, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 204161290705302669957276092172686812873, .op = 4, .commit_min = 3, .timestamp = 1765580996311061191, .request = 2, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-12-12 23:09:56.357Z debug(replica): 1N: on_prepare_ok: not preparing op=4 checksum=211806948086893540859888426388782723553
2025-12-12 23:09:56.357Z info(workload): accounts created = 0, transfers = 0, pending transfers = 0, commands run = 1
2025-12-12 23:09:56.358Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 315204885136639407885776589797189005242, .checksum_padding = 0, .checksum_body = 89618358641903479169915062276417095592, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 272, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 185548821418314641523184812315704833444, .parent_padding = 0, .client = 204161290705302669957276092172686812873, .session = 2, .timestamp = 0, .request = 3, .operation = vsr.Operation(141), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 47065562, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:09:56.358Z debug(replica): 0n: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 315204885136639407885776589797189005242, .checksum_padding = 0, .checksum_body = 89618358641903479169915062276417095592, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 272, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 185548821418314641523184812315704833444, .parent_padding = 0, .client = 204161290705302669957276092172686812873, .session = 2, .timestamp = 0, .request = 3, .operation = vsr.Operation(141), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 47065562, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:09:56.358Z debug(replica): 0n: on_request: forwarding new request to primary (view=1)
2025-12-12 23:09:56.358Z debug(replica): 1N: on_request: new request
2025-12-12 23:09:56.358Z debug(replica): 1N: primary_pipeline_prepare: request checksum=315204885136639407885776589797189005242 client=204161290705302669957276092172686812873
2025-12-12 23:09:56.358Z debug(replica): 0n: sending request to replica 1: vsr.message_header.Header.Request{ .checksum = 315204885136639407885776589797189005242, .checksum_padding = 0, .checksum_body = 89618358641903479169915062276417095592, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 272, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 185548821418314641523184812315704833444, .parent_padding = 0, .client = 204161290705302669957276092172686812873, .session = 2, .timestamp = 0, .request = 3, .operation = vsr.Operation(141), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 47065562, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:09:56.358Z debug(replica): 1N: primary_pipeline_prepare: prepare checksum=70167035397459826957528486167735612651 op=5
2025-12-12 23:09:56.358Z debug(vsr): 1: prepare_timeout started
2025-12-12 23:09:56.358Z debug(vsr): 1: primary_abdicate_timeout started
2025-12-12 23:09:56.358Z debug(vsr): 1: pulse_timeout reset
2025-12-12 23:09:56.358Z debug(replica): 1N: replicate: replicating op=5 to replica 0
2025-12-12 23:09:56.358Z debug(replica): 1N: sending prepare to replica 0: vsr.message_header.Header.Prepare{ .checksum = 70167035397459826957528486167735612651, .checksum_padding = 0, .checksum_body = 89618358641903479169915062276417095592, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 272, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 211806948086893540859888426388782723553, .parent_padding = 0, .request_checksum = 315204885136639407885776589797189005242, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 204161290705302669957276092172686812873, .op = 5, .commit = 4, .timestamp = 1765580996358247992, .request = 3, .operation = vsr.Operation(141), .reserved = { 0, 0, 0 } }
2025-12-12 23:09:56.358Z debug(replica): 1N: replicate: replicating op=5 to replica 2
2025-12-12 23:09:56.358Z debug(replica): 1N: sending prepare to replica 2: vsr.message_header.Header.Prepare{ .checksum = 70167035397459826957528486167735612651, .checksum_padding = 0, .checksum_body = 89618358641903479169915062276417095592, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 272, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 211806948086893540859888426388782723553, .parent_padding = 0, .request_checksum = 315204885136639407885776589797189005242, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 204161290705302669957276092172686812873, .op = 5, .commit = 4, .timestamp = 1765580996358247992, .request = 3, .operation = vsr.Operation(141), .reserved = { 0, 0, 0 } }
2025-12-12 23:09:56.358Z debug(replica): 1N: on_prepare: advancing: op=4..5 checksum=211806948086893540859888426388782723553..70167035397459826957528486167735612651
2025-12-12 23:09:56.358Z debug(replica): 0n: on_message: view=1 status=normal vsr.message_header.Header.Prepare{ .checksum = 70167035397459826957528486167735612651, .checksum_padding = 0, .checksum_body = 89618358641903479169915062276417095592, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 272, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 211806948086893540859888426388782723553, .parent_padding = 0, .request_checksum = 315204885136639407885776589797189005242, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 204161290705302669957276092172686812873, .op = 5, .commit = 4, .timestamp = 1765580996358247992, .request = 3, .operation = vsr.Operation(141), .reserved = { 0, 0, 0 } }
2025-12-12 23:09:56.358Z debug(journal): 1: set_header_as_dirty: op=5 checksum=70167035397459826957528486167735612651
2025-12-12 23:09:56.358Z debug(replica): 0n: on_prepare: advancing commit_max=3..4
2025-12-12 23:09:56.358Z debug(replica): 1N: append: appending to journal op=5
2025-12-12 23:09:56.358Z debug(replica): 0n: on_prepare: caching prepare.op=5 (commit_min=3 op=4 commit_max=4 prepare_max=1007)
2025-12-12 23:09:56.358Z debug(journal): 1: write: view=1 slot=5 op=5 len=272: 70167035397459826957528486167735612651 starting
2025-12-12 23:09:56.358Z debug(replica): 0n: on_prepare: advancing: op=4..5 checksum=211806948086893540859888426388782723553..70167035397459826957528486167735612651
2025-12-12 23:09:56.358Z debug(journal): 0: set_header_as_dirty: op=5 checksum=70167035397459826957528486167735612651
2025-12-12 23:09:56.358Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.prepares offset=5242880 len=4096 locked
2025-12-12 23:09:56.358Z debug(replica): 0n: append: appending to journal op=5
2025-12-12 23:09:56.358Z debug(journal): 0: write: view=1 slot=5 op=5 len=272: 70167035397459826957528486167735612651 starting
2025-12-12 23:09:56.358Z debug(replica): 2n: on_message: view=1 status=normal vsr.message_header.Header.Prepare{ .checksum = 70167035397459826957528486167735612651, .checksum_padding = 0, .checksum_body = 89618358641903479169915062276417095592, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 272, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 211806948086893540859888426388782723553, .parent_padding = 0, .request_checksum = 315204885136639407885776589797189005242, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 204161290705302669957276092172686812873, .op = 5, .commit = 4, .timestamp = 1765580996358247992, .request = 3, .operation = vsr.Operation(141), .reserved = { 0, 0, 0 } }
2025-12-12 23:09:56.358Z debug(journal): 0: write_sectors: ring=vsr.journal.Ring.prepares offset=5242880 len=4096 locked
2025-12-12 23:09:56.358Z debug(replica): 2n: on_prepare: advancing commit_max=3..4
2025-12-12 23:09:56.358Z debug(replica): 0n: commit_start_journal: cached prepare op=4 checksum=211806948086893540859888426388782723553
2025-12-12 23:09:56.358Z debug(replica): 2n: on_prepare: caching prepare.op=5 (commit_min=3 op=4 commit_max=4 prepare_max=1007)
2025-12-12 23:09:56.358Z debug(replica): 2n: on_prepare: advancing: op=4..5 checksum=211806948086893540859888426388782723553..70167035397459826957528486167735612651
2025-12-12 23:09:56.358Z debug(journal): 2: set_header_as_dirty: op=5 checksum=70167035397459826957528486167735612651
2025-12-12 23:09:56.358Z debug(replica): 2n: append: appending to journal op=5
2025-12-12 23:09:56.358Z debug(journal): 2: write: view=1 slot=5 op=5 len=272: 70167035397459826957528486167735612651 starting
2025-12-12 23:09:56.358Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.prepares offset=5242880 len=4096 locked
2025-12-12 23:09:56.358Z debug(replica): 2n: commit_start_journal: cached prepare op=4 checksum=211806948086893540859888426388782723553
2025-12-12 23:09:56.358Z debug(replica): 0n: repair_prepare: op=5 checksum=70167035397459826957528486167735612651 (already writing)
2025-12-12 23:09:56.358Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 315204885136639407885776589797189005242, .checksum_padding = 0, .checksum_body = 89618358641903479169915062276417095592, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 272, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 185548821418314641523184812315704833444, .parent_padding = 0, .client = 204161290705302669957276092172686812873, .session = 2, .timestamp = 0, .request = 3, .operation = vsr.Operation(141), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 47065562, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:09:56.358Z debug(replica): 1N: on_request: new request
2025-12-12 23:09:56.358Z debug(replica): 0n: commit_journal: already committing (prefetch; commit_min=3)
2025-12-12 23:09:56.358Z debug(replica): 1N: on_request: ignoring (already preparing)
2025-12-12 23:09:56.358Z debug(replica): 2n: repair_prepare: op=5 checksum=70167035397459826957528486167735612651 (already writing)
2025-12-12 23:09:56.358Z debug(replica): 0n: execute_op: executing view=1 primary=false op=4 checksum=211806948086893540859888426388782723553 (lookup_accounts)
2025-12-12 23:09:56.358Z debug(replica): 0n: execute_op: commit_timestamp=1765580993232332163 prepare.header.timestamp=1765580996311061191
2025-12-12 23:09:56.358Z debug(replica): 2n: commit_journal: already committing (prefetch; commit_min=3)
2025-12-12 23:09:56.358Z debug(replica): 0n: client_table_entry_update: client=204161290705302669957276092172686812873 session=2 request=2
2025-12-12 23:09:56.358Z debug(replica): 2n: execute_op: executing view=1 primary=false op=4 checksum=211806948086893540859888426388782723553 (lookup_accounts)
2025-12-12 23:09:56.358Z debug(replica): 2n: execute_op: commit_timestamp=1765580993232332163 prepare.header.timestamp=1765580996311061191
2025-12-12 23:09:56.358Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.prepares offset=5242880 len=4096 unlocked
2025-12-12 23:09:56.358Z debug(forest): entering forest.compact() op=4 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2025-12-12 23:09:56.358Z debug(journal): 1: write_header: op=5 sectors[0..4096]
2025-12-12 23:09:56.358Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.headers offset=0 len=4096 locked
2025-12-12 23:09:56.358Z debug(replica): 2n: client_table_entry_update: client=204161290705302669957276092172686812873 session=2 request=2
2025-12-12 23:09:56.358Z debug(replica): 2n: execute_op: replying to client: vsr.message_header.Header.Reply{ .checksum = 196897574282506000948337520632138655077, .checksum_padding = 0, .checksum_body = 163142189146558185265411974777684875497, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 384, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 3743219772042419751077020331129977229, .request_checksum_padding = 0, .context = 185548821418314641523184812315704833444, .context_padding = 0, .client = 204161290705302669957276092172686812873, .op = 4, .commit = 4, .timestamp = 1765580996311061191, .request = 2, .operation = vsr.Operation(140), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:09:56.358Z debug(replica): 2n: sending reply to client 204161290705302669957276092172686812873: vsr.message_header.Header.Reply{ .checksum = 196897574282506000948337520632138655077, .checksum_padding = 0, .checksum_body = 163142189146558185265411974777684875497, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 384, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 3743219772042419751077020331129977229, .request_checksum_padding = 0, .context = 185548821418314641523184812315704833444, .context_padding = 0, .client = 204161290705302669957276092172686812873, .op = 4, .commit = 4, .timestamp = 1765580996311061191, .request = 2, .operation = vsr.Operation(140), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:09:56.358Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.headers offset=0 len=4096 unlocked
2025-12-12 23:09:56.358Z debug(journal): 1: write: view=1 slot=5 op=5 len=272: 70167035397459826957528486167735612651 complete, marking clean
2025-12-12 23:09:56.358Z debug(replica): 1N: send_prepare_ok: op=5 checksum=70167035397459826957528486167735612651
2025-12-12 23:09:56.358Z debug(forest): entering forest.compact() op=4 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2025-12-12 23:09:56.358Z debug(replica): 1N: sending prepare_ok to replica 1: vsr.message_header.Header.PrepareOk{ .checksum = 59763420846314417813420552325642900732, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 1, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 211806948086893540859888426388782723553, .parent_padding = 0, .prepare_checksum = 70167035397459826957528486167735612651, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 204161290705302669957276092172686812873, .op = 5, .commit_min = 4, .timestamp = 1765580996358247992, .request = 3, .operation = vsr.Operation(141), .reserved = { 0, 0, 0 } }
2025-12-12 23:09:56.358Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.PrepareOk{ .checksum = 59763420846314417813420552325642900732, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 1, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 211806948086893540859888426388782723553, .parent_padding = 0, .prepare_checksum = 70167035397459826957528486167735612651, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 204161290705302669957276092172686812873, .op = 5, .commit_min = 4, .timestamp = 1765580996358247992, .request = 3, .operation = vsr.Operation(141), .reserved = { 0, 0, 0 } }
2025-12-12 23:09:56.359Z debug(vsr): 1: primary_abdicate_timeout reset
2025-12-12 23:09:56.359Z debug(replica): 1N: on_prepare_ok: 1 message(s)
2025-12-12 23:09:56.359Z debug(replica): 1N: on_prepare_ok: waiting for quorum
2025-12-12 23:09:56.359Z debug(client_replies): 0: write_reply: wrote (client=204161290705302669957276092172686812873 request=2)
2025-12-12 23:09:56.359Z debug(journal): 0: write_sectors: ring=vsr.journal.Ring.prepares offset=5242880 len=4096 unlocked
2025-12-12 23:09:56.359Z debug(journal): 0: write_header: op=5 sectors[0..4096]
2025-12-12 23:09:56.359Z debug(journal): 0: write_sectors: ring=vsr.journal.Ring.headers offset=0 len=4096 locked
2025-12-12 23:09:56.359Z debug(journal): 0: write_sectors: ring=vsr.journal.Ring.headers offset=0 len=4096 unlocked
2025-12-12 23:09:56.359Z debug(journal): 0: write: view=1 slot=5 op=5 len=272: 70167035397459826957528486167735612651 complete, marking clean
2025-12-12 23:09:56.359Z debug(replica): 0n: send_prepare_ok: op=5 checksum=70167035397459826957528486167735612651
2025-12-12 23:09:56.359Z debug(client_replies): 2: write_reply: wrote (client=204161290705302669957276092172686812873 request=2)
2025-12-12 23:09:56.359Z debug(replica): 0n: sending prepare_ok to replica 1: vsr.message_header.Header.PrepareOk{ .checksum = 84123689469483773945368767675374093660, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 1, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 211806948086893540859888426388782723553, .parent_padding = 0, .prepare_checksum = 70167035397459826957528486167735612651, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 204161290705302669957276092172686812873, .op = 5, .commit_min = 4, .timestamp = 1765580996358247992, .request = 3, .operation = vsr.Operation(141), .reserved = { 0, 0, 0 } }
2025-12-12 23:09:56.359Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.prepares offset=5242880 len=4096 unlocked
2025-12-12 23:09:56.359Z debug(journal): 2: write_header: op=5 sectors[0..4096]
2025-12-12 23:09:56.359Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.headers offset=0 len=4096 locked
2025-12-12 23:09:56.359Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.headers offset=0 len=4096 unlocked
2025-12-12 23:09:56.359Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.PrepareOk{ .checksum = 84123689469483773945368767675374093660, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 1, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 211806948086893540859888426388782723553, .parent_padding = 0, .prepare_checksum = 70167035397459826957528486167735612651, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 204161290705302669957276092172686812873, .op = 5, .commit_min = 4, .timestamp = 1765580996358247992, .request = 3, .operation = vsr.Operation(141), .reserved = { 0, 0, 0 } }
2025-12-12 23:09:56.360Z debug(vsr): 0: journal_repair_budget_timeout fired
2025-12-12 23:09:59.078Z debug(journal): 2: write: view=1 slot=5 op=5 len=272: 70167035397459826957528486167735612651 complete, marking clean
2025-12-12 23:09:59.078Z debug(vsr): 1: primary_abdicate_timeout reset
2025-12-12 23:09:59.078Z debug(replica): 2n: send_prepare_ok: op=5 checksum=70167035397459826957528486167735612651
2025-12-12 23:09:59.078Z debug(vsr): 0: journal_repair_budget_timeout reset
2025-12-12 23:09:59.078Z debug(replica): 1N: on_prepare_ok: 2 message(s)
2025-12-12 23:09:59.078Z debug(replica): 1N: on_prepare_ok: quorum received, context=70167035397459826957528486167735612651
2025-12-12 23:09:59.078Z debug(vsr): 1: prepare_timeout stopped
2025-12-12 23:09:59.078Z debug(vsr): 1: primary_abdicate_timeout stopped
2025-12-12 23:09:59.078Z debug(replica): 2n: sending prepare_ok to replica 1: vsr.message_header.Header.PrepareOk{ .checksum = 195202619305483364658069623267756757672, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 1, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 211806948086893540859888426388782723553, .parent_padding = 0, .prepare_checksum = 70167035397459826957528486167735612651, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 204161290705302669957276092172686812873, .op = 5, .commit_min = 4, .timestamp = 1765580996358247992, .request = 3, .operation = vsr.Operation(141), .reserved = { 0, 0, 0 } }
2025-12-12 23:09:59.078Z debug(replica): 0n: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 315204885136639407885776589797189005242, .checksum_padding = 0, .checksum_body = 89618358641903479169915062276417095592, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 272, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 185548821418314641523184812315704833444, .parent_padding = 0, .client = 204161290705302669957276092172686812873, .session = 2, .timestamp = 0, .request = 3, .operation = vsr.Operation(141), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 47065562, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:09:59.078Z debug(replica): 0n: on_request: forwarding new request to primary (view=1)
2025-12-12 23:09:59.078Z debug(replica): 0n: sending request to replica 1: vsr.message_header.Header.Request{ .checksum = 315204885136639407885776589797189005242, .checksum_padding = 0, .checksum_body = 89618358641903479169915062276417095592, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 272, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 185548821418314641523184812315704833444, .parent_padding = 0, .client = 204161290705302669957276092172686812873, .session = 2, .timestamp = 0, .request = 3, .operation = vsr.Operation(141), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 47065562, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:09:59.079Z debug(replica): 1N: execute_op: executing view=1 primary=true op=5 checksum=70167035397459826957528486167735612651 (lookup_transfers)
2025-12-12 23:09:59.079Z debug(replica): 1N: execute_op: commit_timestamp=1765580996311061191 prepare.header.timestamp=1765580996358247992
2025-12-12 23:09:59.079Z debug(replica): 1N: execute_op: advancing commit_max=4..5
2025-12-12 23:09:59.079Z debug(vsr): 2: journal_repair_budget_timeout fired
2025-12-12 23:09:59.079Z debug(vsr): 2: journal_repair_budget_timeout reset
2025-12-12 23:09:59.079Z debug(replica): 1N: client_table_entry_update: client=204161290705302669957276092172686812873 session=2 request=3
2025-12-12 23:09:59.079Z debug(replica): 1N: execute_op: replying to client: vsr.message_header.Header.Reply{ .checksum = 36653470663576830210919545629141926611, .checksum_padding = 0, .checksum_body = 163142189146558185265411974777684875497, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 384, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 315204885136639407885776589797189005242, .request_checksum_padding = 0, .context = 27562119017872210132705278122054339871, .context_padding = 0, .client = 204161290705302669957276092172686812873, .op = 5, .commit = 5, .timestamp = 1765580996358247992, .request = 3, .operation = vsr.Operation(141), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:09:59.079Z debug(replica): 1N: sending reply to client 204161290705302669957276092172686812873: vsr.message_header.Header.Reply{ .checksum = 36653470663576830210919545629141926611, .checksum_padding = 0, .checksum_body = 163142189146558185265411974777684875497, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 384, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 315204885136639407885776589797189005242, .request_checksum_padding = 0, .context = 27562119017872210132705278122054339871, .context_padding = 0, .client = 204161290705302669957276092172686812873, .op = 5, .commit = 5, .timestamp = 1765580996358247992, .request = 3, .operation = vsr.Operation(141), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:09:59.079Z debug(forest): entering forest.compact() op=5 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
warning(client): 204161290705302669957276092172686812873: on_reply: slow request, request=3 op=5 size=272 lookup_transfers time=2721ms
2025-12-12 23:09:59.079Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 315204885136639407885776589797189005242, .checksum_padding = 0, .checksum_body = 89618358641903479169915062276417095592, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 272, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 185548821418314641523184812315704833444, .parent_padding = 0, .client = 204161290705302669957276092172686812873, .session = 2, .timestamp = 0, .request = 3, .operation = vsr.Operation(141), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 47065562, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:09:59.079Z debug(replica): 1N: on_request: replying to duplicate request
2025-12-12 23:09:59.079Z debug(replica): 1N: on_request: repeat reply (client=204161290705302669957276092172686812873 request=3)
2025-12-12 23:09:59.079Z debug(replica): 1N: sending reply to client 204161290705302669957276092172686812873: vsr.message_header.Header.Reply{ .checksum = 36653470663576830210919545629141926611, .checksum_padding = 0, .checksum_body = 163142189146558185265411974777684875497, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 384, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 315204885136639407885776589797189005242, .request_checksum_padding = 0, .context = 27562119017872210132705278122054339871, .context_padding = 0, .client = 204161290705302669957276092172686812873, .op = 5, .commit = 5, .timestamp = 1765580996358247992, .request = 3, .operation = vsr.Operation(141), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:09:59.079Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.PrepareOk{ .checksum = 195202619305483364658069623267756757672, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 1, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 211806948086893540859888426388782723553, .parent_padding = 0, .prepare_checksum = 70167035397459826957528486167735612651, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 204161290705302669957276092172686812873, .op = 5, .commit_min = 4, .timestamp = 1765580996358247992, .request = 3, .operation = vsr.Operation(141), .reserved = { 0, 0, 0 } }
2025-12-12 23:09:59.079Z debug(replica): 1N: on_prepare_ok: not preparing op=5 checksum=70167035397459826957528486167735612651
2025-12-12 23:09:59.079Z debug(replica): 2n: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 296831730601734559943363869710548797178, .checksum_padding = 0, .checksum_body = 89618358641903479169915062276417095592, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 272, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 27562119017872210132705278122054339871, .parent_padding = 0, .client = 204161290705302669957276092172686812873, .session = 2, .timestamp = 0, .request = 4, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 2721210169, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:09:59.079Z debug(replica): 2n: on_request: forwarding new request to primary (view=1)
2025-12-12 23:09:59.079Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 315204885136639407885776589797189005242, .checksum_padding = 0, .checksum_body = 89618358641903479169915062276417095592, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 272, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 185548821418314641523184812315704833444, .parent_padding = 0, .client = 204161290705302669957276092172686812873, .session = 2, .timestamp = 0, .request = 3, .operation = vsr.Operation(141), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 47065562, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:09:59.079Z debug(replica): 1N: on_request: replying to duplicate request
2025-12-12 23:09:59.079Z debug(replica): 1N: on_request: repeat reply (client=204161290705302669957276092172686812873 request=3)
2025-12-12 23:09:59.079Z debug(replica): 2n: sending request to replica 1: vsr.message_header.Header.Request{ .checksum = 296831730601734559943363869710548797178, .checksum_padding = 0, .checksum_body = 89618358641903479169915062276417095592, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 272, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 27562119017872210132705278122054339871, .parent_padding = 0, .client = 204161290705302669957276092172686812873, .session = 2, .timestamp = 0, .request = 4, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 2721210169, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:09:59.079Z debug(replica): 1N: sending reply to client 204161290705302669957276092172686812873: vsr.message_header.Header.Reply{ .checksum = 36653470663576830210919545629141926611, .checksum_padding = 0, .checksum_body = 163142189146558185265411974777684875497, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 384, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 315204885136639407885776589797189005242, .request_checksum_padding = 0, .context = 27562119017872210132705278122054339871, .context_padding = 0, .client = 204161290705302669957276092172686812873, .op = 5, .commit = 5, .timestamp = 1765580996358247992, .request = 3, .operation = vsr.Operation(141), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:09:59.079Z debug(client_replies): 1: write_reply: wrote (client=204161290705302669957276092172686812873 request=3)
2025-12-12 23:09:59.080Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 296831730601734559943363869710548797178, .checksum_padding = 0, .checksum_body = 89618358641903479169915062276417095592, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 272, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 27562119017872210132705278122054339871, .parent_padding = 0, .client = 204161290705302669957276092172686812873, .session = 2, .timestamp = 0, .request = 4, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 2721210169, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:09:59.080Z debug(replica): 1N: on_request: new request
2025-12-12 23:09:59.080Z debug(replica): 1N: primary_pipeline_prepare: request checksum=296831730601734559943363869710548797178 client=204161290705302669957276092172686812873
2025-12-12 23:09:59.080Z debug(replica): 1N: primary_pipeline_prepare: prepare checksum=74643055428510482054259473802849547763 op=6
2025-12-12 23:09:59.080Z debug(vsr): 1: prepare_timeout started
2025-12-12 23:09:59.080Z debug(vsr): 1: primary_abdicate_timeout started
2025-12-12 23:09:59.080Z debug(vsr): 1: pulse_timeout reset
2025-12-12 23:09:59.080Z debug(replica): 1N: replicate: replicating op=6 to replica 0
2025-12-12 23:09:59.080Z debug(replica): 1N: sending prepare to replica 0: vsr.message_header.Header.Prepare{ .checksum = 74643055428510482054259473802849547763, .checksum_padding = 0, .checksum_body = 89618358641903479169915062276417095592, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 272, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 70167035397459826957528486167735612651, .parent_padding = 0, .request_checksum = 296831730601734559943363869710548797178, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 204161290705302669957276092172686812873, .op = 6, .commit = 5, .timestamp = 1765580999080046709, .request = 4, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-12-12 23:09:59.080Z debug(replica): 1N: replicate: replicating op=6 to replica 2
2025-12-12 23:09:59.080Z debug(replica): 1N: sending prepare to replica 2: vsr.message_header.Header.Prepare{ .checksum = 74643055428510482054259473802849547763, .checksum_padding = 0, .checksum_body = 89618358641903479169915062276417095592, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 272, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 70167035397459826957528486167735612651, .parent_padding = 0, .request_checksum = 296831730601734559943363869710548797178, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 204161290705302669957276092172686812873, .op = 6, .commit = 5, .timestamp = 1765580999080046709, .request = 4, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-12-12 23:09:59.080Z debug(replica): 1N: on_prepare: advancing: op=5..6 checksum=70167035397459826957528486167735612651..74643055428510482054259473802849547763
2025-12-12 23:09:59.080Z debug(journal): 1: set_header_as_dirty: op=6 checksum=74643055428510482054259473802849547763
2025-12-12 23:09:59.080Z debug(replica): 1N: append: appending to journal op=6
2025-12-12 23:09:59.080Z debug(replica): 0n: on_message: view=1 status=normal vsr.message_header.Header.Prepare{ .checksum = 74643055428510482054259473802849547763, .checksum_padding = 0, .checksum_body = 89618358641903479169915062276417095592, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 272, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 70167035397459826957528486167735612651, .parent_padding = 0, .request_checksum = 296831730601734559943363869710548797178, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 204161290705302669957276092172686812873, .op = 6, .commit = 5, .timestamp = 1765580999080046709, .request = 4, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-12-12 23:09:59.080Z debug(journal): 1: write: view=1 slot=6 op=6 len=272: 74643055428510482054259473802849547763 starting
2025-12-12 23:09:59.080Z debug(replica): 0n: on_prepare: advancing commit_max=4..5
2025-12-12 23:09:59.080Z debug(replica): 0n: on_prepare: caching prepare.op=6 (commit_min=4 op=5 commit_max=5 prepare_max=1007)
2025-12-12 23:09:59.080Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.prepares offset=6291456 len=4096 locked
2025-12-12 23:09:59.080Z debug(replica): 0n: on_prepare: advancing: op=5..6 checksum=70167035397459826957528486167735612651..74643055428510482054259473802849547763
2025-12-12 23:09:59.080Z debug(replica): 2n: on_message: view=1 status=normal vsr.message_header.Header.Prepare{ .checksum = 74643055428510482054259473802849547763, .checksum_padding = 0, .checksum_body = 89618358641903479169915062276417095592, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 272, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 70167035397459826957528486167735612651, .parent_padding = 0, .request_checksum = 296831730601734559943363869710548797178, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 204161290705302669957276092172686812873, .op = 6, .commit = 5, .timestamp = 1765580999080046709, .request = 4, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-12-12 23:09:59.080Z debug(journal): 0: set_header_as_dirty: op=6 checksum=74643055428510482054259473802849547763
2025-12-12 23:09:59.080Z debug(replica): 0n: append: appending to journal op=6
2025-12-12 23:09:59.080Z debug(replica): 2n: on_prepare: advancing commit_max=4..5
2025-12-12 23:09:59.080Z debug(journal): 0: write: view=1 slot=6 op=6 len=272: 74643055428510482054259473802849547763 starting
2025-12-12 23:09:59.080Z debug(replica): 2n: on_prepare: caching prepare.op=6 (commit_min=4 op=5 commit_max=5 prepare_max=1007)
2025-12-12 23:09:59.080Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 296831730601734559943363869710548797178, .checksum_padding = 0, .checksum_body = 89618358641903479169915062276417095592, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 272, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 27562119017872210132705278122054339871, .parent_padding = 0, .client = 204161290705302669957276092172686812873, .session = 2, .timestamp = 0, .request = 4, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 2721210169, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:09:59.080Z debug(replica): 1N: on_request: new request
2025-12-12 23:09:59.080Z debug(replica): 2n: on_prepare: advancing: op=5..6 checksum=70167035397459826957528486167735612651..74643055428510482054259473802849547763
2025-12-12 23:09:59.080Z debug(journal): 0: write_sectors: ring=vsr.journal.Ring.prepares offset=6291456 len=4096 locked
2025-12-12 23:09:59.080Z debug(replica): 1N: on_request: ignoring (already preparing)
2025-12-12 23:09:59.080Z debug(journal): 2: set_header_as_dirty: op=6 checksum=74643055428510482054259473802849547763
2025-12-12 23:09:59.080Z debug(replica): 2n: append: appending to journal op=6
2025-12-12 23:09:59.080Z debug(replica): 0n: commit_start_journal: cached prepare op=5 checksum=70167035397459826957528486167735612651
2025-12-12 23:09:59.080Z debug(journal): 2: write: view=1 slot=6 op=6 len=272: 74643055428510482054259473802849547763 starting
2025-12-12 23:09:59.080Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.prepares offset=6291456 len=4096 locked
2025-12-12 23:09:59.080Z debug(replica): 2n: commit_start_journal: cached prepare op=5 checksum=70167035397459826957528486167735612651
2025-12-12 23:09:59.080Z debug(vsr): 1: journal_repair_budget_timeout fired
2025-12-12 23:09:59.080Z debug(vsr): 1: journal_repair_budget_timeout reset
2025-12-12 23:09:59.080Z debug(replica): 0n: repair_prepare: op=6 checksum=74643055428510482054259473802849547763 (already writing)
2025-12-12 23:09:59.080Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.prepares offset=6291456 len=4096 unlocked
2025-12-12 23:09:59.080Z debug(journal): 1: write_header: op=6 sectors[0..4096]
2025-12-12 23:09:59.080Z debug(replica): 2n: repair_prepare: op=6 checksum=74643055428510482054259473802849547763 (already writing)
2025-12-12 23:09:59.080Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.headers offset=0 len=4096 locked
2025-12-12 23:09:59.080Z debug(replica): 0n: commit_journal: already committing (prefetch; commit_min=4)
2025-12-12 23:09:59.080Z debug(replica): 2n: commit_journal: already committing (prefetch; commit_min=4)
2025-12-12 23:09:59.080Z debug(replica): 0n: execute_op: executing view=1 primary=false op=5 checksum=70167035397459826957528486167735612651 (lookup_transfers)
2025-12-12 23:09:59.080Z debug(replica): 0n: execute_op: commit_timestamp=1765580996311061191 prepare.header.timestamp=1765580996358247992
2025-12-12 23:09:59.080Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.headers offset=0 len=4096 unlocked
2025-12-12 23:09:59.080Z debug(journal): 1: write: view=1 slot=6 op=6 len=272: 74643055428510482054259473802849547763 complete, marking clean
2025-12-12 23:09:59.080Z debug(replica): 2n: execute_op: executing view=1 primary=false op=5 checksum=70167035397459826957528486167735612651 (lookup_transfers)
2025-12-12 23:09:59.080Z debug(replica): 2n: execute_op: commit_timestamp=1765580996311061191 prepare.header.timestamp=1765580996358247992
2025-12-12 23:09:59.080Z debug(replica): 1N: send_prepare_ok: op=6 checksum=74643055428510482054259473802849547763
2025-12-12 23:09:59.080Z debug(replica): 0n: client_table_entry_update: client=204161290705302669957276092172686812873 session=2 request=3
2025-12-12 23:09:59.080Z debug(replica): 2n: client_table_entry_update: client=204161290705302669957276092172686812873 session=2 request=3
2025-12-12 23:09:59.080Z debug(replica): 1N: sending prepare_ok to replica 1: vsr.message_header.Header.PrepareOk{ .checksum = 24472153515172739193155855550743291274, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 1, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 70167035397459826957528486167735612651, .parent_padding = 0, .prepare_checksum = 74643055428510482054259473802849547763, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 204161290705302669957276092172686812873, .op = 6, .commit_min = 5, .timestamp = 1765580999080046709, .request = 4, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-12-12 23:09:59.080Z debug(forest): entering forest.compact() op=5 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2025-12-12 23:09:59.080Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.PrepareOk{ .checksum = 24472153515172739193155855550743291274, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 1, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 70167035397459826957528486167735612651, .parent_padding = 0, .prepare_checksum = 74643055428510482054259473802849547763, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 204161290705302669957276092172686812873, .op = 6, .commit_min = 5, .timestamp = 1765580999080046709, .request = 4, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-12-12 23:09:59.080Z debug(vsr): 1: primary_abdicate_timeout reset
2025-12-12 23:09:59.080Z debug(replica): 2n: execute_op: replying to client: vsr.message_header.Header.Reply{ .checksum = 36653470663576830210919545629141926611, .checksum_padding = 0, .checksum_body = 163142189146558185265411974777684875497, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 384, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 315204885136639407885776589797189005242, .request_checksum_padding = 0, .context = 27562119017872210132705278122054339871, .context_padding = 0, .client = 204161290705302669957276092172686812873, .op = 5, .commit = 5, .timestamp = 1765580996358247992, .request = 3, .operation = vsr.Operation(141), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:09:59.080Z debug(replica): 1N: on_prepare_ok: 1 message(s)
2025-12-12 23:09:59.080Z debug(replica): 1N: on_prepare_ok: waiting for quorum
2025-12-12 23:09:59.080Z debug(replica): 2n: sending reply to client 204161290705302669957276092172686812873: vsr.message_header.Header.Reply{ .checksum = 36653470663576830210919545629141926611, .checksum_padding = 0, .checksum_body = 163142189146558185265411974777684875497, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 384, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 315204885136639407885776589797189005242, .request_checksum_padding = 0, .context = 27562119017872210132705278122054339871, .context_padding = 0, .client = 204161290705302669957276092172686812873, .op = 5, .commit = 5, .timestamp = 1765580996358247992, .request = 3, .operation = vsr.Operation(141), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:09:59.080Z debug(forest): entering forest.compact() op=5 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2025-12-12 23:09:59.080Z debug(client_replies): 0: write_reply: wrote (client=204161290705302669957276092172686812873 request=3)
2025-12-12 23:09:59.080Z debug(journal): 0: write_sectors: ring=vsr.journal.Ring.prepares offset=6291456 len=4096 unlocked
2025-12-12 23:09:59.080Z debug(journal): 0: write_header: op=6 sectors[0..4096]
2025-12-12 23:09:59.080Z debug(journal): 0: write_sectors: ring=vsr.journal.Ring.headers offset=0 len=4096 locked
2025-12-12 23:09:59.080Z debug(journal): 0: write_sectors: ring=vsr.journal.Ring.headers offset=0 len=4096 unlocked
2025-12-12 23:09:59.080Z debug(client_replies): 2: write_reply: wrote (client=204161290705302669957276092172686812873 request=3)
2025-12-12 23:09:59.080Z debug(journal): 0: write: view=1 slot=6 op=6 len=272: 74643055428510482054259473802849547763 complete, marking clean
2025-12-12 23:09:59.080Z debug(replica): 0n: send_prepare_ok: op=6 checksum=74643055428510482054259473802849547763
2025-12-12 23:09:59.080Z debug(replica): 0n: sending prepare_ok to replica 1: vsr.message_header.Header.PrepareOk{ .checksum = 207060754639299322983171809077123308504, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 1, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 70167035397459826957528486167735612651, .parent_padding = 0, .prepare_checksum = 74643055428510482054259473802849547763, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 204161290705302669957276092172686812873, .op = 6, .commit_min = 5, .timestamp = 1765580999080046709, .request = 4, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-12-12 23:09:59.080Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.prepares offset=6291456 len=4096 unlocked
2025-12-12 23:09:59.080Z debug(journal): 2: write_header: op=6 sectors[0..4096]
2025-12-12 23:09:59.080Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.headers offset=0 len=4096 locked
2025-12-12 23:09:59.080Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.headers offset=0 len=4096 unlocked
2025-12-12 23:09:59.080Z debug(journal): 2: write: view=1 slot=6 op=6 len=272: 74643055428510482054259473802849547763 complete, marking clean
2025-12-12 23:09:59.080Z debug(replica): 2n: send_prepare_ok: op=6 checksum=74643055428510482054259473802849547763
2025-12-12 23:09:59.080Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.PrepareOk{ .checksum = 207060754639299322983171809077123308504, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 1, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 70167035397459826957528486167735612651, .parent_padding = 0, .prepare_checksum = 74643055428510482054259473802849547763, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 204161290705302669957276092172686812873, .op = 6, .commit_min = 5, .timestamp = 1765580999080046709, .request = 4, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-12-12 23:09:59.080Z debug(vsr): 1: primary_abdicate_timeout reset
2025-12-12 23:09:59.080Z debug(replica): 1N: on_prepare_ok: 2 message(s)
2025-12-12 23:09:59.080Z debug(replica): 1N: on_prepare_ok: quorum received, context=74643055428510482054259473802849547763
2025-12-12 23:09:59.080Z debug(replica): 2n: sending prepare_ok to replica 1: vsr.message_header.Header.PrepareOk{ .checksum = 33383437264040915000400861427103379597, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 1, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 70167035397459826957528486167735612651, .parent_padding = 0, .prepare_checksum = 74643055428510482054259473802849547763, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 204161290705302669957276092172686812873, .op = 6, .commit_min = 5, .timestamp = 1765580999080046709, .request = 4, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-12-12 23:09:59.080Z debug(vsr): 1: prepare_timeout stopped
2025-12-12 23:09:59.080Z debug(vsr): 1: primary_abdicate_timeout stopped
2025-12-12 23:09:59.081Z debug(replica): 1N: execute_op: executing view=1 primary=true op=6 checksum=74643055428510482054259473802849547763 (lookup_accounts)
2025-12-12 23:09:59.081Z debug(replica): 1N: execute_op: commit_timestamp=1765580996358247992 prepare.header.timestamp=1765580999080046709
2025-12-12 23:09:59.081Z debug(replica): 1N: execute_op: advancing commit_max=5..6
2025-12-12 23:09:59.081Z debug(replica): 1N: client_table_entry_update: client=204161290705302669957276092172686812873 session=2 request=4
2025-12-12 23:09:59.081Z debug(replica): 1N: execute_op: replying to client: vsr.message_header.Header.Reply{ .checksum = 36208253166119795755731825595282784144, .checksum_padding = 0, .checksum_body = 163142189146558185265411974777684875497, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 384, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 296831730601734559943363869710548797178, .request_checksum_padding = 0, .context = 237963762032600258330237080301214704075, .context_padding = 0, .client = 204161290705302669957276092172686812873, .op = 6, .commit = 6, .timestamp = 1765580999080046709, .request = 4, .operation = vsr.Operation(140), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:09:59.081Z debug(replica): 1N: sending reply to client 204161290705302669957276092172686812873: vsr.message_header.Header.Reply{ .checksum = 36208253166119795755731825595282784144, .checksum_padding = 0, .checksum_body = 163142189146558185265411974777684875497, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 384, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 296831730601734559943363869710548797178, .request_checksum_padding = 0, .context = 237963762032600258330237080301214704075, .context_padding = 0, .client = 204161290705302669957276092172686812873, .op = 6, .commit = 6, .timestamp = 1765580999080046709, .request = 4, .operation = vsr.Operation(140), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:09:59.081Z debug(forest): entering forest.compact() op=6 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2025-12-12 23:09:59.081Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.PrepareOk{ .checksum = 33383437264040915000400861427103379597, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 1, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 70167035397459826957528486167735612651, .parent_padding = 0, .prepare_checksum = 74643055428510482054259473802849547763, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 204161290705302669957276092172686812873, .op = 6, .commit_min = 5, .timestamp = 1765580999080046709, .request = 4, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-12-12 23:09:59.081Z debug(replica): 1N: on_prepare_ok: not preparing op=6 checksum=74643055428510482054259473802849547763
2025-12-12 23:09:59.081Z debug(client_replies): 1: write_reply: wrote (client=204161290705302669957276092172686812873 request=4)
2025-12-12 23:09:59.098Z debug(vsr): 0: journal_repair_budget_timeout fired
2025-12-12 23:09:59.098Z debug(vsr): 0: journal_repair_budget_timeout reset
2025-12-12 23:09:59.099Z debug(vsr): 2: journal_repair_budget_timeout fired
2025-12-12 23:09:59.099Z debug(vsr): 2: journal_repair_budget_timeout reset
2025-12-12 23:09:59.100Z debug(vsr): 1: journal_repair_budget_timeout fired
2025-12-12 23:09:59.100Z debug(vsr): 1: journal_repair_budget_timeout reset
2025-12-12 23:09:59.118Z debug(vsr): 0: journal_repair_budget_timeout fired
2025-12-12 23:09:59.119Z debug(vsr): 0: journal_repair_budget_timeout reset
2025-12-12 23:09:59.119Z debug(vsr): 0: journal_repair_timeout fired
2025-12-12 23:09:59.119Z debug(vsr): 0: journal_repair_timeout reset
2025-12-12 23:09:59.119Z debug(vsr): 2: journal_repair_budget_timeout fired
2025-12-12 23:09:59.119Z debug(vsr): 2: journal_repair_budget_timeout reset
2025-12-12 23:09:59.119Z debug(vsr): 2: journal_repair_timeout fired
2025-12-12 23:09:59.119Z debug(vsr): 2: journal_repair_timeout reset
2025-12-12 23:09:59.120Z debug(vsr): 1: journal_repair_budget_timeout fired
2025-12-12 23:09:59.120Z debug(vsr): 1: journal_repair_budget_timeout reset
2025-12-12 23:09:59.120Z debug(vsr): 1: journal_repair_timeout fired
2025-12-12 23:09:59.120Z debug(vsr): 1: journal_repair_timeout reset
2025-12-12 23:09:59.121Z info(workload): accounts created = 0, transfers = 0, pending transfers = 0, commands run = 2
2025-12-12 23:09:59.122Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 131921637994549118652545016890972672425, .checksum_padding = 0, .checksum_body = 89618358641903479169915062276417095592, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 272, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 237963762032600258330237080301214704075, .parent_padding = 0, .client = 204161290705302669957276092172686812873, .session = 2, .timestamp = 0, .request = 5, .operation = vsr.Operation(141), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 42206896, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:09:59.122Z debug(replica): 1N: on_request: new request
2025-12-12 23:09:59.122Z debug(replica): 1N: primary_pipeline_prepare: request checksum=131921637994549118652545016890972672425 client=204161290705302669957276092172686812873
2025-12-12 23:09:59.122Z debug(replica): 0n: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 131921637994549118652545016890972672425, .checksum_padding = 0, .checksum_body = 89618358641903479169915062276417095592, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 272, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 237963762032600258330237080301214704075, .parent_padding = 0, .client = 204161290705302669957276092172686812873, .session = 2, .timestamp = 0, .request = 5, .operation = vsr.Operation(141), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 42206896, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:09:59.122Z debug(replica): 1N: primary_pipeline_prepare: prepare checksum=313808410211740091743510159279640695682 op=7
2025-12-12 23:09:59.122Z debug(replica): 0n: on_request: forwarding new request to primary (view=1)
2025-12-12 23:09:59.122Z debug(vsr): 1: prepare_timeout started
2025-12-12 23:09:59.122Z debug(vsr): 1: primary_abdicate_timeout started
2025-12-12 23:09:59.122Z debug(vsr): 1: pulse_timeout reset
2025-12-12 23:09:59.122Z debug(replica): 0n: sending request to replica 1: vsr.message_header.Header.Request{ .checksum = 131921637994549118652545016890972672425, .checksum_padding = 0, .checksum_body = 89618358641903479169915062276417095592, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 272, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 237963762032600258330237080301214704075, .parent_padding = 0, .client = 204161290705302669957276092172686812873, .session = 2, .timestamp = 0, .request = 5, .operation = vsr.Operation(141), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 42206896, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:09:59.122Z debug(replica): 1N: replicate: replicating op=7 to replica 0
2025-12-12 23:09:59.122Z debug(replica): 1N: sending prepare to replica 0: vsr.message_header.Header.Prepare{ .checksum = 313808410211740091743510159279640695682, .checksum_padding = 0, .checksum_body = 89618358641903479169915062276417095592, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 272, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 74643055428510482054259473802849547763, .parent_padding = 0, .request_checksum = 131921637994549118652545016890972672425, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 204161290705302669957276092172686812873, .op = 7, .commit = 6, .timestamp = 1765580999122238485, .request = 5, .operation = vsr.Operation(141), .reserved = { 0, 0, 0 } }
2025-12-12 23:09:59.122Z debug(replica): 1N: replicate: replicating op=7 to replica 2
2025-12-12 23:09:59.122Z debug(replica): 1N: sending prepare to replica 2: vsr.message_header.Header.Prepare{ .checksum = 313808410211740091743510159279640695682, .checksum_padding = 0, .checksum_body = 89618358641903479169915062276417095592, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 272, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 74643055428510482054259473802849547763, .parent_padding = 0, .request_checksum = 131921637994549118652545016890972672425, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 204161290705302669957276092172686812873, .op = 7, .commit = 6, .timestamp = 1765580999122238485, .request = 5, .operation = vsr.Operation(141), .reserved = { 0, 0, 0 } }
2025-12-12 23:09:59.122Z debug(replica): 1N: on_prepare: advancing: op=6..7 checksum=74643055428510482054259473802849547763..313808410211740091743510159279640695682
2025-12-12 23:09:59.122Z debug(journal): 1: set_header_as_dirty: op=7 checksum=313808410211740091743510159279640695682
2025-12-12 23:09:59.122Z debug(replica): 0n: on_message: view=1 status=normal vsr.message_header.Header.Prepare{ .checksum = 313808410211740091743510159279640695682, .checksum_padding = 0, .checksum_body = 89618358641903479169915062276417095592, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 272, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 74643055428510482054259473802849547763, .parent_padding = 0, .request_checksum = 131921637994549118652545016890972672425, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 204161290705302669957276092172686812873, .op = 7, .commit = 6, .timestamp = 1765580999122238485, .request = 5, .operation = vsr.Operation(141), .reserved = { 0, 0, 0 } }
2025-12-12 23:09:59.122Z debug(replica): 1N: append: appending to journal op=7
2025-12-12 23:09:59.122Z debug(journal): 1: write: view=1 slot=7 op=7 len=272: 313808410211740091743510159279640695682 starting
2025-12-12 23:09:59.122Z debug(replica): 0n: on_prepare: advancing commit_max=5..6
2025-12-12 23:09:59.122Z debug(replica): 0n: on_prepare: caching prepare.op=7 (commit_min=5 op=6 commit_max=6 prepare_max=1007)
2025-12-12 23:09:59.122Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.prepares offset=7340032 len=4096 locked
2025-12-12 23:09:59.122Z debug(replica): 0n: on_prepare: advancing: op=6..7 checksum=74643055428510482054259473802849547763..313808410211740091743510159279640695682
2025-12-12 23:09:59.122Z debug(journal): 0: set_header_as_dirty: op=7 checksum=313808410211740091743510159279640695682
2025-12-12 23:09:59.122Z debug(replica): 2n: on_message: view=1 status=normal vsr.message_header.Header.Prepare{ .checksum = 313808410211740091743510159279640695682, .checksum_padding = 0, .checksum_body = 89618358641903479169915062276417095592, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 272, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 74643055428510482054259473802849547763, .parent_padding = 0, .request_checksum = 131921637994549118652545016890972672425, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 204161290705302669957276092172686812873, .op = 7, .commit = 6, .timestamp = 1765580999122238485, .request = 5, .operation = vsr.Operation(141), .reserved = { 0, 0, 0 } }
2025-12-12 23:09:59.122Z debug(replica): 0n: append: appending to journal op=7
2025-12-12 23:09:59.122Z debug(replica): 2n: on_prepare: advancing commit_max=5..6
2025-12-12 23:09:59.122Z debug(journal): 0: write: view=1 slot=7 op=7 len=272: 313808410211740091743510159279640695682 starting
2025-12-12 23:09:59.122Z debug(replica): 2n: on_prepare: caching prepare.op=7 (commit_min=5 op=6 commit_max=6 prepare_max=1007)
2025-12-12 23:09:59.122Z debug(journal): 0: write_sectors: ring=vsr.journal.Ring.prepares offset=7340032 len=4096 locked
2025-12-12 23:09:59.122Z debug(replica): 2n: on_prepare: advancing: op=6..7 checksum=74643055428510482054259473802849547763..313808410211740091743510159279640695682
2025-12-12 23:09:59.122Z debug(journal): 2: set_header_as_dirty: op=7 checksum=313808410211740091743510159279640695682
2025-12-12 23:09:59.122Z debug(replica): 0n: commit_start_journal: cached prepare op=6 checksum=74643055428510482054259473802849547763
2025-12-12 23:09:59.122Z debug(replica): 2n: append: appending to journal op=7
2025-12-12 23:09:59.122Z debug(journal): 2: write: view=1 slot=7 op=7 len=272: 313808410211740091743510159279640695682 starting
2025-12-12 23:09:59.122Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.prepares offset=7340032 len=4096 locked
2025-12-12 23:09:59.122Z debug(replica): 2n: commit_start_journal: cached prepare op=6 checksum=74643055428510482054259473802849547763
2025-12-12 23:09:59.122Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 131921637994549118652545016890972672425, .checksum_padding = 0, .checksum_body = 89618358641903479169915062276417095592, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 272, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 237963762032600258330237080301214704075, .parent_padding = 0, .client = 204161290705302669957276092172686812873, .session = 2, .timestamp = 0, .request = 5, .operation = vsr.Operation(141), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 42206896, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:09:59.122Z debug(replica): 1N: on_request: new request
2025-12-12 23:09:59.122Z debug(replica): 1N: on_request: ignoring (already preparing)
2025-12-12 23:09:59.122Z debug(replica): 0n: repair_prepare: op=7 checksum=313808410211740091743510159279640695682 (already writing)
2025-12-12 23:09:59.122Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.prepares offset=7340032 len=4096 unlocked
2025-12-12 23:09:59.122Z debug(replica): 0n: commit_journal: already committing (prefetch; commit_min=5)
2025-12-12 23:09:59.122Z debug(replica): 2n: repair_prepare: op=7 checksum=313808410211740091743510159279640695682 (already writing)
2025-12-12 23:09:59.122Z debug(journal): 1: write_header: op=7 sectors[0..4096]
2025-12-12 23:09:59.122Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.headers offset=0 len=4096 locked
2025-12-12 23:09:59.122Z debug(replica): 0n: execute_op: executing view=1 primary=false op=6 checksum=74643055428510482054259473802849547763 (lookup_accounts)
2025-12-12 23:09:59.122Z debug(replica): 0n: execute_op: commit_timestamp=1765580996358247992 prepare.header.timestamp=1765580999080046709
2025-12-12 23:09:59.122Z debug(replica): 2n: commit_journal: already committing (prefetch; commit_min=5)
2025-12-12 23:09:59.122Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.headers offset=0 len=4096 unlocked
2025-12-12 23:09:59.122Z debug(replica): 0n: client_table_entry_update: client=204161290705302669957276092172686812873 session=2 request=4
2025-12-12 23:09:59.122Z debug(replica): 2n: execute_op: executing view=1 primary=false op=6 checksum=74643055428510482054259473802849547763 (lookup_accounts)
2025-12-12 23:09:59.122Z debug(journal): 1: write: view=1 slot=7 op=7 len=272: 313808410211740091743510159279640695682 complete, marking clean
2025-12-12 23:09:59.122Z debug(replica): 2n: execute_op: commit_timestamp=1765580996358247992 prepare.header.timestamp=1765580999080046709
2025-12-12 23:09:59.122Z debug(replica): 1N: send_prepare_ok: op=7 checksum=313808410211740091743510159279640695682
2025-12-12 23:09:59.122Z debug(replica): 0n: execute_op: replying to client: vsr.message_header.Header.Reply{ .checksum = 36208253166119795755731825595282784144, .checksum_padding = 0, .checksum_body = 163142189146558185265411974777684875497, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 384, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 296831730601734559943363869710548797178, .request_checksum_padding = 0, .context = 237963762032600258330237080301214704075, .context_padding = 0, .client = 204161290705302669957276092172686812873, .op = 6, .commit = 6, .timestamp = 1765580999080046709, .request = 4, .operation = vsr.Operation(140), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:09:59.122Z debug(replica): 2n: client_table_entry_update: client=204161290705302669957276092172686812873 session=2 request=4
2025-12-12 23:09:59.122Z debug(replica): 1N: sending prepare_ok to replica 1: vsr.message_header.Header.PrepareOk{ .checksum = 83868624953327268848675676652985033328, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 1, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 74643055428510482054259473802849547763, .parent_padding = 0, .prepare_checksum = 313808410211740091743510159279640695682, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 204161290705302669957276092172686812873, .op = 7, .commit_min = 6, .timestamp = 1765580999122238485, .request = 5, .operation = vsr.Operation(141), .reserved = { 0, 0, 0 } }
2025-12-12 23:09:59.122Z debug(replica): 0n: sending reply to client 204161290705302669957276092172686812873: vsr.message_header.Header.Reply{ .checksum = 36208253166119795755731825595282784144, .checksum_padding = 0, .checksum_body = 163142189146558185265411974777684875497, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 384, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 296831730601734559943363869710548797178, .request_checksum_padding = 0, .context = 237963762032600258330237080301214704075, .context_padding = 0, .client = 204161290705302669957276092172686812873, .op = 6, .commit = 6, .timestamp = 1765580999080046709, .request = 4, .operation = vsr.Operation(140), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:09:59.122Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.PrepareOk{ .checksum = 83868624953327268848675676652985033328, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 1, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 74643055428510482054259473802849547763, .parent_padding = 0, .prepare_checksum = 313808410211740091743510159279640695682, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 204161290705302669957276092172686812873, .op = 7, .commit_min = 6, .timestamp = 1765580999122238485, .request = 5, .operation = vsr.Operation(141), .reserved = { 0, 0, 0 } }
2025-12-12 23:09:59.122Z debug(forest): entering forest.compact() op=6 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2025-12-12 23:09:59.122Z debug(vsr): 1: primary_abdicate_timeout reset
2025-12-12 23:09:59.122Z debug(replica): 1N: on_prepare_ok: 1 message(s)
2025-12-12 23:09:59.122Z debug(replica): 1N: on_prepare_ok: waiting for quorum
2025-12-12 23:09:59.122Z debug(forest): entering forest.compact() op=6 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2025-12-12 23:09:59.122Z debug(client_replies): 2: write_reply: wrote (client=204161290705302669957276092172686812873 request=4)
2025-12-12 23:09:59.122Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.prepares offset=7340032 len=4096 unlocked
2025-12-12 23:09:59.122Z debug(journal): 2: write_header: op=7 sectors[0..4096]
2025-12-12 23:09:59.122Z debug(client_replies): 0: write_reply: wrote (client=204161290705302669957276092172686812873 request=4)
2025-12-12 23:09:59.122Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.headers offset=0 len=4096 locked
2025-12-12 23:09:59.123Z debug(journal): 0: write_sectors: ring=vsr.journal.Ring.prepares offset=7340032 len=4096 unlocked
2025-12-12 23:09:59.123Z debug(journal): 0: write_header: op=7 sectors[0..4096]
2025-12-12 23:09:59.123Z debug(journal): 0: write_sectors: ring=vsr.journal.Ring.headers offset=0 len=4096 locked
2025-12-12 23:09:59.123Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.headers offset=0 len=4096 unlocked
2025-12-12 23:09:59.123Z debug(journal): 2: write: view=1 slot=7 op=7 len=272: 313808410211740091743510159279640695682 complete, marking clean
2025-12-12 23:09:59.123Z debug(replica): 2n: send_prepare_ok: op=7 checksum=313808410211740091743510159279640695682
2025-12-12 23:09:59.123Z debug(replica): 2n: sending prepare_ok to replica 1: vsr.message_header.Header.PrepareOk{ .checksum = 155114532397481294024166915316267370958, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 1, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 74643055428510482054259473802849547763, .parent_padding = 0, .prepare_checksum = 313808410211740091743510159279640695682, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 204161290705302669957276092172686812873, .op = 7, .commit_min = 6, .timestamp = 1765580999122238485, .request = 5, .operation = vsr.Operation(141), .reserved = { 0, 0, 0 } }
2025-12-12 23:09:59.123Z debug(journal): 0: write_sectors: ring=vsr.journal.Ring.headers offset=0 len=4096 unlocked
2025-12-12 23:09:59.123Z debug(journal): 0: write: view=1 slot=7 op=7 len=272: 313808410211740091743510159279640695682 complete, marking clean
2025-12-12 23:09:59.123Z debug(replica): 0n: send_prepare_ok: op=7 checksum=313808410211740091743510159279640695682
2025-12-12 23:09:59.123Z debug(replica): 0n: sending prepare_ok to replica 1: vsr.message_header.Header.PrepareOk{ .checksum = 95087868312228095609081872705488202527, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 1, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 74643055428510482054259473802849547763, .parent_padding = 0, .prepare_checksum = 313808410211740091743510159279640695682, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 204161290705302669957276092172686812873, .op = 7, .commit_min = 6, .timestamp = 1765580999122238485, .request = 5, .operation = vsr.Operation(141), .reserved = { 0, 0, 0 } }
2025-12-12 23:09:59.123Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.PrepareOk{ .checksum = 155114532397481294024166915316267370958, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 1, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 74643055428510482054259473802849547763, .parent_padding = 0, .prepare_checksum = 313808410211740091743510159279640695682, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 204161290705302669957276092172686812873, .op = 7, .commit_min = 6, .timestamp = 1765580999122238485, .request = 5, .operation = vsr.Operation(141), .reserved = { 0, 0, 0 } }
2025-12-12 23:09:59.123Z debug(vsr): 1: primary_abdicate_timeout reset
2025-12-12 23:09:59.123Z debug(replica): 1N: on_prepare_ok: 2 message(s)
2025-12-12 23:09:59.123Z debug(replica): 1N: on_prepare_ok: quorum received, context=313808410211740091743510159279640695682
2025-12-12 23:09:59.123Z debug(vsr): 1: prepare_timeout stopped
2025-12-12 23:09:59.123Z debug(vsr): 1: primary_abdicate_timeout stopped
2025-12-12 23:09:59.123Z debug(replica): 1N: execute_op: executing view=1 primary=true op=7 checksum=313808410211740091743510159279640695682 (lookup_transfers)
2025-12-12 23:09:59.123Z debug(replica): 1N: execute_op: commit_timestamp=1765580999080046709 prepare.header.timestamp=1765580999122238485
2025-12-12 23:09:59.123Z debug(replica): 1N: execute_op: advancing commit_max=6..7
2025-12-12 23:09:59.123Z debug(replica): 1N: client_table_entry_update: client=204161290705302669957276092172686812873 session=2 request=5
2025-12-12 23:09:59.123Z debug(replica): 1N: execute_op: replying to client: vsr.message_header.Header.Reply{ .checksum = 180836187408286721316226116499192129565, .checksum_padding = 0, .checksum_body = 163142189146558185265411974777684875497, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 384, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 131921637994549118652545016890972672425, .request_checksum_padding = 0, .context = 325156755384226089172033123826201086582, .context_padding = 0, .client = 204161290705302669957276092172686812873, .op = 7, .commit = 7, .timestamp = 1765580999122238485, .request = 5, .operation = vsr.Operation(141), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:09:59.139Z debug(vsr): 0: journal_repair_budget_timeout fired
2025-12-12 23:09:59.139Z debug(vsr): 0: journal_repair_budget_timeout reset
2025-12-12 23:09:59.139Z debug(vsr): 2: journal_repair_budget_timeout fired
2025-12-12 23:09:59.139Z debug(vsr): 2: journal_repair_budget_timeout reset
2025-12-12 23:09:59.159Z debug(vsr): 0: journal_repair_budget_timeout fired
2025-12-12 23:09:59.159Z debug(vsr): 0: journal_repair_budget_timeout reset
2025-12-12 23:09:59.159Z debug(vsr): 2: journal_repair_budget_timeout fired
2025-12-12 23:09:59.123Z debug(replica): 1N: sending reply to client 204161290705302669957276092172686812873: vsr.message_header.Header.Reply{ .checksum = 180836187408286721316226116499192129565, .checksum_padding = 0, .checksum_body = 163142189146558185265411974777684875497, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 384, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 131921637994549118652545016890972672425, .request_checksum_padding = 0, .context = 325156755384226089172033123826201086582, .context_padding = 0, .client = 204161290705302669957276092172686812873, .op = 7, .commit = 7, .timestamp = 1765580999122238485, .request = 5, .operation = vsr.Operation(141), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:09:59.159Z debug(vsr): 2: journal_repair_budget_timeout reset
2025-12-12 23:09:59.179Z debug(vsr): 0: journal_repair_budget_timeout fired
2025-12-12 23:12:40.576Z info(supervisor): sleeping for 2.384s
2025-12-12 23:13:58.856Z debug(forest): entering forest.compact() op=7 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2025-12-12 23:13:58.856Z debug(vsr): 0: journal_repair_budget_timeout reset
2025-12-12 23:13:58.856Z debug(replica): 2n: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 131921637994549118652545016890972672425, .checksum_padding = 0, .checksum_body = 89618358641903479169915062276417095592, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 272, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 237963762032600258330237080301214704075, .parent_padding = 0, .client = 204161290705302669957276092172686812873, .session = 2, .timestamp = 0, .request = 5, .operation = vsr.Operation(141), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 42206896, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:13:58.856Z debug(replica): 2n: on_request: forwarding new request to primary (view=1)
2025-12-12 23:13:58.856Z debug(replica): 0n: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 131921637994549118652545016890972672425, .checksum_padding = 0, .checksum_body = 89618358641903479169915062276417095592, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 272, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 237963762032600258330237080301214704075, .parent_padding = 0, .client = 204161290705302669957276092172686812873, .session = 2, .timestamp = 0, .request = 5, .operation = vsr.Operation(141), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 42206896, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:13:58.856Z debug(replica): 0n: on_request: forwarding new request to primary (view=1)
2025-12-12 23:13:58.856Z debug(replica): 2n: sending request to replica 1: vsr.message_header.Header.Request{ .checksum = 131921637994549118652545016890972672425, .checksum_padding = 0, .checksum_body = 89618358641903479169915062276417095592, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 272, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 237963762032600258330237080301214704075, .parent_padding = 0, .client = 204161290705302669957276092172686812873, .session = 2, .timestamp = 0, .request = 5, .operation = vsr.Operation(141), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 42206896, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:13:58.856Z warning(replica): 1N: commit_dispatch: slow request, request=5 size=272 lookup_transfers time=239733ms
2025-12-12 23:13:58.856Z debug(replica): 0n: sending request to replica 1: vsr.message_header.Header.Request{ .checksum = 131921637994549118652545016890972672425, .checksum_padding = 0, .checksum_body = 89618358641903479169915062276417095592, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 272, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 237963762032600258330237080301214704075, .parent_padding = 0, .client = 204161290705302669957276092172686812873, .session = 2, .timestamp = 0, .request = 5, .operation = vsr.Operation(141), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 42206896, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
warning(client): 204161290705302669957276092172686812873: on_reply: slow request, request=5 op=7 size=272 lookup_transfers time=239734ms
2025-12-12 23:13:58.857Z debug(replica): 2n: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 131921637994549118652545016890972672425, .checksum_padding = 0, .checksum_body = 89618358641903479169915062276417095592, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 272, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 237963762032600258330237080301214704075, .parent_padding = 0, .client = 204161290705302669957276092172686812873, .session = 2, .timestamp = 0, .request = 5, .operation = vsr.Operation(141), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 42206896, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:13:58.857Z debug(replica): 2n: on_request: forwarding new request to primary (view=1)
2025-12-12 23:13:58.857Z debug(replica): 2n: sending request to replica 1: vsr.message_header.Header.Request{ .checksum = 131921637994549118652545016890972672425, .checksum_padding = 0, .checksum_body = 89618358641903479169915062276417095592, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 272, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 237963762032600258330237080301214704075, .parent_padding = 0, .client = 204161290705302669957276092172686812873, .session = 2, .timestamp = 0, .request = 5, .operation = vsr.Operation(141), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 42206896, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:13:58.857Z debug(replica): 2n: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 131921637994549118652545016890972672425, .checksum_padding = 0, .checksum_body = 89618358641903479169915062276417095592, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 272, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 237963762032600258330237080301214704075, .parent_padding = 0, .client = 204161290705302669957276092172686812873, .session = 2, .timestamp = 0, .request = 5, .operation = vsr.Operation(141), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 42206896, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:13:58.857Z debug(replica): 2n: on_request: forwarding new request to primary (view=1)
2025-12-12 23:13:58.857Z debug(replica): 2n: sending request to replica 1: vsr.message_header.Header.Request{ .checksum = 131921637994549118652545016890972672425, .checksum_padding = 0, .checksum_body = 89618358641903479169915062276417095592, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 272, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 237963762032600258330237080301214704075, .parent_padding = 0, .client = 204161290705302669957276092172686812873, .session = 2, .timestamp = 0, .request = 5, .operation = vsr.Operation(141), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 42206896, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:13:58.857Z debug(replica): 2n: on_message: view=1 status=normal vsr.message_header.Header.PingClient{ .checksum = 216874767046572679467723370904134433719, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 0, .release = 0.0.1, .protocol = 0, .command = vsr.Command.ping_client, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .client = 204161290705302669957276092172686812873, .ping_timestamp_monotonic = 37700797936651246, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:13:58.857Z debug(replica): 0n: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 131921637994549118652545016890972672425, .checksum_padding = 0, .checksum_body = 89618358641903479169915062276417095592, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 272, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 237963762032600258330237080301214704075, .parent_padding = 0, .client = 204161290705302669957276092172686812873, .session = 2, .timestamp = 0, .request = 5, .operation = vsr.Operation(141), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 42206896, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:13:58.857Z debug(replica): 0n: on_request: forwarding new request to primary (view=1)
2025-12-12 23:13:58.857Z debug(replica): 2n: sending pong_client to client 204161290705302669957276092172686812873: vsr.message_header.Header.PongClient{ .checksum = 179221424983136612890860463677698573841, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.pong_client, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .ping_timestamp_monotonic = 37700797936651246, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:13:58.857Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.PrepareOk{ .checksum = 95087868312228095609081872705488202527, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 1, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 74643055428510482054259473802849547763, .parent_padding = 0, .prepare_checksum = 313808410211740091743510159279640695682, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 204161290705302669957276092172686812873, .op = 7, .commit_min = 6, .timestamp = 1765580999122238485, .request = 5, .operation = vsr.Operation(141), .reserved = { 0, 0, 0 } }
2025-12-12 23:13:58.857Z debug(replica): 1N: on_prepare_ok: not preparing op=7 checksum=313808410211740091743510159279640695682
2025-12-12 23:13:58.857Z debug(replica): 0n: sending request to replica 1: vsr.message_header.Header.Request{ .checksum = 131921637994549118652545016890972672425, .checksum_padding = 0, .checksum_body = 89618358641903479169915062276417095592, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 272, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 237963762032600258330237080301214704075, .parent_padding = 0, .client = 204161290705302669957276092172686812873, .session = 2, .timestamp = 0, .request = 5, .operation = vsr.Operation(141), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 42206896, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:13:58.857Z debug(replica): 2n: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 131921637994549118652545016890972672425, .checksum_padding = 0, .checksum_body = 89618358641903479169915062276417095592, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 272, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 237963762032600258330237080301214704075, .parent_padding = 0, .client = 204161290705302669957276092172686812873, .session = 2, .timestamp = 0, .request = 5, .operation = vsr.Operation(141), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 42206896, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:13:58.857Z debug(replica): 2n: on_request: forwarding new request to primary (view=1)
2025-12-12 23:13:58.857Z debug(replica): 2n: sending request to replica 1: vsr.message_header.Header.Request{ .checksum = 131921637994549118652545016890972672425, .checksum_padding = 0, .checksum_body = 89618358641903479169915062276417095592, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 272, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 237963762032600258330237080301214704075, .parent_padding = 0, .client = 204161290705302669957276092172686812873, .session = 2, .timestamp = 0, .request = 5, .operation = vsr.Operation(141), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 42206896, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:13:58.857Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 131921637994549118652545016890972672425, .checksum_padding = 0, .checksum_body = 89618358641903479169915062276417095592, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 272, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 237963762032600258330237080301214704075, .parent_padding = 0, .client = 204161290705302669957276092172686812873, .session = 2, .timestamp = 0, .request = 5, .operation = vsr.Operation(141), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 42206896, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:13:58.857Z debug(replica): 0n: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 131921637994549118652545016890972672425, .checksum_padding = 0, .checksum_body = 89618358641903479169915062276417095592, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 272, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 237963762032600258330237080301214704075, .parent_padding = 0, .client = 204161290705302669957276092172686812873, .session = 2, .timestamp = 0, .request = 5, .operation = vsr.Operation(141), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 42206896, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:13:58.857Z debug(replica): 0n: on_request: forwarding new request to primary (view=1)
2025-12-12 23:13:58.857Z debug(replica): 1N: on_request: replying to duplicate request
2025-12-12 23:13:58.857Z debug(replica): 1N: on_request: repeat reply (client=204161290705302669957276092172686812873 request=5)
2025-12-12 23:13:58.857Z debug(replica): 2n: on_message: view=1 status=normal vsr.message_header.Header.PingClient{ .checksum = 203732013210077176772699629991244324379, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 0, .release = 0.0.1, .protocol = 0, .command = vsr.Command.ping_client, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .client = 204161290705302669957276092172686812873, .ping_timestamp_monotonic = 37700828029618898, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:13:58.857Z debug(replica): 0n: sending request to replica 1: vsr.message_header.Header.Request{ .checksum = 131921637994549118652545016890972672425, .checksum_padding = 0, .checksum_body = 89618358641903479169915062276417095592, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 272, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 237963762032600258330237080301214704075, .parent_padding = 0, .client = 204161290705302669957276092172686812873, .session = 2, .timestamp = 0, .request = 5, .operation = vsr.Operation(141), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 42206896, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:13:58.857Z debug(replica): 2n: sending pong_client to client 204161290705302669957276092172686812873: vsr.message_header.Header.PongClient{ .checksum = 182182117629206782462246484497501969354, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.pong_client, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .ping_timestamp_monotonic = 37700828029618898, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:13:58.857Z debug(replica): 1N: sending reply to client 204161290705302669957276092172686812873: vsr.message_header.Header.Reply{ .checksum = 180836187408286721316226116499192129565, .checksum_padding = 0, .checksum_body = 163142189146558185265411974777684875497, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 384, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 131921637994549118652545016890972672425, .request_checksum_padding = 0, .context = 325156755384226089172033123826201086582, .context_padding = 0, .client = 204161290705302669957276092172686812873, .op = 7, .commit = 7, .timestamp = 1765580999122238485, .request = 5, .operation = vsr.Operation(141), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:13:58.857Z debug(replica): 2n: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 131921637994549118652545016890972672425, .checksum_padding = 0, .checksum_body = 89618358641903479169915062276417095592, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 272, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 237963762032600258330237080301214704075, .parent_padding = 0, .client = 204161290705302669957276092172686812873, .session = 2, .timestamp = 0, .request = 5, .operation = vsr.Operation(141), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 42206896, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:13:58.857Z debug(replica): 2n: on_request: forwarding new request to primary (view=1)
2025-12-12 23:13:58.857Z debug(replica): 2n: sending request to replica 1: vsr.message_header.Header.Request{ .checksum = 131921637994549118652545016890972672425, .checksum_padding = 0, .checksum_body = 89618358641903479169915062276417095592, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 272, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 237963762032600258330237080301214704075, .parent_padding = 0, .client = 204161290705302669957276092172686812873, .session = 2, .timestamp = 0, .request = 5, .operation = vsr.Operation(141), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 42206896, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:13:58.857Z debug(replica): 0n: on_message: view=1 status=normal vsr.message_header.Header.PingClient{ .checksum = 216874767046572679467723370904134433719, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 0, .release = 0.0.1, .protocol = 0, .command = vsr.Command.ping_client, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .client = 204161290705302669957276092172686812873, .ping_timestamp_monotonic = 37700797936651246, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:13:58.857Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 131921637994549118652545016890972672425, .checksum_padding = 0, .checksum_body = 89618358641903479169915062276417095592, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 272, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 237963762032600258330237080301214704075, .parent_padding = 0, .client = 204161290705302669957276092172686812873, .session = 2, .timestamp = 0, .request = 5, .operation = vsr.Operation(141), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 42206896, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:13:58.857Z debug(replica): 2n: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 131921637994549118652545016890972672425, .checksum_padding = 0, .checksum_body = 89618358641903479169915062276417095592, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 272, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 237963762032600258330237080301214704075, .parent_padding = 0, .client = 204161290705302669957276092172686812873, .session = 2, .timestamp = 0, .request = 5, .operation = vsr.Operation(141), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 42206896, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:13:58.857Z debug(replica): 2n: on_request: forwarding new request to primary (view=1)
2025-12-12 23:13:58.857Z debug(replica): 1N: on_request: replying to duplicate request
2025-12-12 23:13:58.857Z debug(replica): 1N: on_request: repeat reply (client=204161290705302669957276092172686812873 request=5)
2025-12-12 23:13:58.857Z debug(replica): 2n: sending request to replica 1: vsr.message_header.Header.Request{ .checksum = 131921637994549118652545016890972672425, .checksum_padding = 0, .checksum_body = 89618358641903479169915062276417095592, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 272, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 237963762032600258330237080301214704075, .parent_padding = 0, .client = 204161290705302669957276092172686812873, .session = 2, .timestamp = 0, .request = 5, .operation = vsr.Operation(141), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 42206896, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:13:58.857Z debug(replica): 0n: sending pong_client to client 204161290705302669957276092172686812873: vsr.message_header.Header.PongClient{ .checksum = 108916045578254523854327393760321939719, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.pong_client, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .ping_timestamp_monotonic = 37700797936651246, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:13:58.857Z debug(replica): 1N: sending reply to client 204161290705302669957276092172686812873: vsr.message_header.Header.Reply{ .checksum = 180836187408286721316226116499192129565, .checksum_padding = 0, .checksum_body = 163142189146558185265411974777684875497, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 384, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 131921637994549118652545016890972672425, .request_checksum_padding = 0, .context = 325156755384226089172033123826201086582, .context_padding = 0, .client = 204161290705302669957276092172686812873, .op = 7, .commit = 7, .timestamp = 1765580999122238485, .request = 5, .operation = vsr.Operation(141), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:13:58.857Z debug(replica): 2n: on_message: view=1 status=normal vsr.message_header.Header.PingClient{ .checksum = 18182672945588977481333483900010498112, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 0, .release = 0.0.1, .protocol = 0, .command = vsr.Command.ping_client, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .client = 204161290705302669957276092172686812873, .ping_timestamp_monotonic = 37700858121226738, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:13:58.857Z debug(replica): 2n: sending pong_client to client 204161290705302669957276092172686812873: vsr.message_header.Header.PongClient{ .checksum = 146467230960375545478264017596660818327, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.pong_client, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .ping_timestamp_monotonic = 37700858121226738, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:13:58.857Z warning(clock): 1: synchronization failed, partitioned (sources=1 samples=1)
2025-12-12 23:13:58.857Z error(clock): 1: no agreement on cluster time (partitioned or too many clock faults)
2025-12-12 23:13:58.857Z debug(replica): 2n: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 131921637994549118652545016890972672425, .checksum_padding = 0, .checksum_body = 89618358641903479169915062276417095592, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 272, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 237963762032600258330237080301214704075, .parent_padding = 0, .client = 204161290705302669957276092172686812873, .session = 2, .timestamp = 0, .request = 5, .operation = vsr.Operation(141), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 42206896, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:13:58.857Z debug(replica): 2n: on_request: forwarding new request to primary (view=1)
2025-12-12 23:13:58.857Z debug(replica): 2n: sending request to replica 1: vsr.message_header.Header.Request{ .checksum = 131921637994549118652545016890972672425, .checksum_padding = 0, .checksum_body = 89618358641903479169915062276417095592, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 272, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 237963762032600258330237080301214704075, .parent_padding = 0, .client = 204161290705302669957276092172686812873, .session = 2, .timestamp = 0, .request = 5, .operation = vsr.Operation(141), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 42206896, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:13:58.857Z debug(client_replies): 1: write_reply: wrote (client=204161290705302669957276092172686812873 request=5)
2025-12-12 23:13:58.857Z debug(replica): 0n: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 131921637994549118652545016890972672425, .checksum_padding = 0, .checksum_body = 89618358641903479169915062276417095592, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 272, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 237963762032600258330237080301214704075, .parent_padding = 0, .client = 204161290705302669957276092172686812873, .session = 2, .timestamp = 0, .request = 5, .operation = vsr.Operation(141), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 42206896, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:13:58.858Z debug(replica): 0n: on_request: forwarding new request to primary (view=1)
2025-12-12 23:13:58.858Z debug(replica): 2n: on_message: view=1 status=normal vsr.message_header.Header.PingClient{ .checksum = 218992291249205068388647787579790993482, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 0, .release = 0.0.1, .protocol = 0, .command = vsr.Command.ping_client, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .client = 204161290705302669957276092172686812873, .ping_timestamp_monotonic = 37700888215447074, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:13:58.858Z debug(replica): 0n: sending request to replica 1: vsr.message_header.Header.Request{ .checksum = 131921637994549118652545016890972672425, .checksum_padding = 0, .checksum_body = 89618358641903479169915062276417095592, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 272, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 237963762032600258330237080301214704075, .parent_padding = 0, .client = 204161290705302669957276092172686812873, .session = 2, .timestamp = 0, .request = 5, .operation = vsr.Operation(141), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 42206896, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:13:58.858Z debug(replica): 2n: sending pong_client to client 204161290705302669957276092172686812873: vsr.message_header.Header.PongClient{ .checksum = 298696634416068669338982035272624699483, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.pong_client, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .ping_timestamp_monotonic = 37700888215447074, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:13:58.858Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 131921637994549118652545016890972672425, .checksum_padding = 0, .checksum_body = 89618358641903479169915062276417095592, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 272, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 237963762032600258330237080301214704075, .parent_padding = 0, .client = 204161290705302669957276092172686812873, .session = 2, .timestamp = 0, .request = 5, .operation = vsr.Operation(141), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 42206896, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:13:58.858Z debug(replica): 1N: on_request: replying to duplicate request
2025-12-12 23:13:58.858Z debug(replica): 2n: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 131921637994549118652545016890972672425, .checksum_padding = 0, .checksum_body = 89618358641903479169915062276417095592, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 272, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 237963762032600258330237080301214704075, .parent_padding = 0, .client = 204161290705302669957276092172686812873, .session = 2, .timestamp = 0, .request = 5, .operation = vsr.Operation(141), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 42206896, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:13:58.858Z debug(replica): 2n: on_request: forwarding new request to primary (view=1)
2025-12-12 23:13:58.858Z debug(client_replies): 1: read_reply: start (client=204161290705302669957276092172686812873 reply=180836187408286721316226116499192129565)
2025-12-12 23:13:58.858Z debug(replica): 2n: sending request to replica 1: vsr.message_header.Header.Request{ .checksum = 131921637994549118652545016890972672425, .checksum_padding = 0, .checksum_body = 89618358641903479169915062276417095592, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 272, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 237963762032600258330237080301214704075, .parent_padding = 0, .client = 204161290705302669957276092172686812873, .session = 2, .timestamp = 0, .request = 5, .operation = vsr.Operation(141), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 42206896, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:13:58.858Z debug(replica): 0n: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 131921637994549118652545016890972672425, .checksum_padding = 0, .checksum_body = 89618358641903479169915062276417095592, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 272, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 237963762032600258330237080301214704075, .parent_padding = 0, .client = 204161290705302669957276092172686812873, .session = 2, .timestamp = 0, .request = 5, .operation = vsr.Operation(141), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 42206896, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:13:58.858Z debug(replica): 0n: on_request: forwarding new request to primary (view=1)
2025-12-12 23:13:58.858Z debug(replica): 2n: on_message: view=1 status=normal vsr.message_header.Header.PingClient{ .checksum = 139936347311092830177518826141090531857, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 0, .release = 0.0.1, .protocol = 0, .command = vsr.Command.ping_client, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .client = 204161290705302669957276092172686812873, .ping_timestamp_monotonic = 37700918306348515, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:13:58.858Z debug(replica): 0n: sending request to replica 1: vsr.message_header.Header.Request{ .checksum = 131921637994549118652545016890972672425, .checksum_padding = 0, .checksum_body = 89618358641903479169915062276417095592, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 272, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 237963762032600258330237080301214704075, .parent_padding = 0, .client = 204161290705302669957276092172686812873, .session = 2, .timestamp = 0, .request = 5, .operation = vsr.Operation(141), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 42206896, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:13:58.858Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 131921637994549118652545016890972672425, .checksum_padding = 0, .checksum_body = 89618358641903479169915062276417095592, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 272, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 237963762032600258330237080301214704075, .parent_padding = 0, .client = 204161290705302669957276092172686812873, .session = 2, .timestamp = 0, .request = 5, .operation = vsr.Operation(141), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 42206896, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:13:58.858Z debug(replica): 2n: sending pong_client to client 204161290705302669957276092172686812873: vsr.message_header.Header.PongClient{ .checksum = 338630002692921345102955271328393608450, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.pong_client, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .ping_timestamp_monotonic = 37700918306348515, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:13:58.858Z debug(replica): 1N: on_request: replying to duplicate request
2025-12-12 23:13:58.858Z debug(client_replies): 1: read_reply: busy (client=204161290705302669957276092172686812873 reply=180836187408286721316226116499192129565)
2025-12-12 23:13:58.858Z debug(replica): 1N: on_request: ignoring (client_replies busy)
2025-12-12 23:13:58.858Z debug(replica): 2n: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 131921637994549118652545016890972672425, .checksum_padding = 0, .checksum_body = 89618358641903479169915062276417095592, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 272, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 237963762032600258330237080301214704075, .parent_padding = 0, .client = 204161290705302669957276092172686812873, .session = 2, .timestamp = 0, .request = 5, .operation = vsr.Operation(141), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 42206896, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:13:58.858Z debug(replica): 2n: on_request: forwarding new request to primary (view=1)
2025-12-12 23:13:58.858Z debug(replica): 0n: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 131921637994549118652545016890972672425, .checksum_padding = 0, .checksum_body = 89618358641903479169915062276417095592, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 272, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 237963762032600258330237080301214704075, .parent_padding = 0, .client = 204161290705302669957276092172686812873, .session = 2, .timestamp = 0, .request = 5, .operation = vsr.Operation(141), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 42206896, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:13:58.858Z debug(replica): 2n: sending request to replica 1: vsr.message_header.Header.Request{ .checksum = 131921637994549118652545016890972672425, .checksum_padding = 0, .checksum_body = 89618358641903479169915062276417095592, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 272, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 237963762032600258330237080301214704075, .parent_padding = 0, .client = 204161290705302669957276092172686812873, .session = 2, .timestamp = 0, .request = 5, .operation = vsr.Operation(141), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 42206896, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:13:58.858Z debug(replica): 0n: on_request: forwarding new request to primary (view=1)
2025-12-12 23:13:58.858Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 131921637994549118652545016890972672425, .checksum_padding = 0, .checksum_body = 89618358641903479169915062276417095592, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 272, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 237963762032600258330237080301214704075, .parent_padding = 0, .client = 204161290705302669957276092172686812873, .session = 2, .timestamp = 0, .request = 5, .operation = vsr.Operation(141), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 42206896, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:13:58.858Z debug(replica): 1N: on_request: replying to duplicate request
2025-12-12 23:13:58.858Z debug(client_replies): 1: read_reply: busy (client=204161290705302669957276092172686812873 reply=180836187408286721316226116499192129565)
2025-12-12 23:13:58.858Z debug(replica): 1N: on_request: ignoring (client_replies busy)
2025-12-12 23:13:58.858Z debug(replica): 2n: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 131921637994549118652545016890972672425, .checksum_padding = 0, .checksum_body = 89618358641903479169915062276417095592, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 272, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 237963762032600258330237080301214704075, .parent_padding = 0, .client = 204161290705302669957276092172686812873, .session = 2, .timestamp = 0, .request = 5, .operation = vsr.Operation(141), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 42206896, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:13:58.858Z debug(replica): 0n: sending request to replica 1: vsr.message_header.Header.Request{ .checksum = 131921637994549118652545016890972672425, .checksum_padding = 0, .checksum_body = 89618358641903479169915062276417095592, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 272, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 237963762032600258330237080301214704075, .parent_padding = 0, .client = 204161290705302669957276092172686812873, .session = 2, .timestamp = 0, .request = 5, .operation = vsr.Operation(141), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 42206896, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:13:58.858Z debug(replica): 2n: on_request: forwarding new request to primary (view=1)
2025-12-12 23:13:58.858Z debug(replica): 2n: sending request to replica 1: vsr.message_header.Header.Request{ .checksum = 131921637994549118652545016890972672425, .checksum_padding = 0, .checksum_body = 89618358641903479169915062276417095592, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 272, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 237963762032600258330237080301214704075, .parent_padding = 0, .client = 204161290705302669957276092172686812873, .session = 2, .timestamp = 0, .request = 5, .operation = vsr.Operation(141), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 42206896, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:13:58.858Z debug(replica): 2n: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 131921637994549118652545016890972672425, .checksum_padding = 0, .checksum_body = 89618358641903479169915062276417095592, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 272, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 237963762032600258330237080301214704075, .parent_padding = 0, .client = 204161290705302669957276092172686812873, .session = 2, .timestamp = 0, .request = 5, .operation = vsr.Operation(141), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 42206896, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:13:58.858Z debug(replica): 2n: on_request: forwarding new request to primary (view=1)
2025-12-12 23:13:58.866Z error(supervisor): liveness check: too slow request
2025-12-12 23:13:58.858Z debug(replica): 2n: sending request to replica 1: vsr.message_header.Header.Request{ .checksum = 131921637994549118652545016890972672425, .checksum_padding = 0, .checksum_body = 89618358641903479169915062276417095592, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 272, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 237963762032600258330237080301214704075, .parent_padding = 0, .client = 204161290705302669957276092172686812873, .session = 2, .timestamp = 0, .request = 5, .operation = vsr.Operation(141), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 42206896, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:13:58.858Z debug(replica): 0n: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 131921637994549118652545016890972672425, .checksum_padding = 0, .checksum_body = 89618358641903479169915062276417095592, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 272, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 237963762032600258330237080301214704075, .parent_padding = 0, .client = 204161290705302669957276092172686812873, .session = 2, .timestamp = 0, .request = 5, .operation = vsr.Operation(141), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 42206896, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:13:58.858Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 131921637994549118652545016890972672425, .checksum_padding = 0, .checksum_body = 89618358641903479169915062276417095592, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 272, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 237963762032600258330237080301214704075, .parent_padding = 0, .client = 204161290705302669957276092172686812873, .session = 2, .timestamp = 0, .request = 5, .operation = vsr.Operation(141), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 42206896, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:13:58.867Z info(supervisor): 0: terminating replica
2025-12-12 23:14:03.194Z debug(replica): 0n: on_request: forwarding new request to primary (view=1)
2025-12-12 23:14:03.194Z warning(replica): 2n: on_messages: message count=15 suspended=0
2025-12-12 23:14:03.194Z debug(replica): 1N: on_request: replying to duplicate request
2025-12-12 23:14:03.194Z debug(client_replies): 1: read_reply: busy (client=204161290705302669957276092172686812873 reply=180836187408286721316226116499192129565)
2025-12-12 23:14:03.194Z debug(replica): 1N: on_request: ignoring (client_replies busy)
2025-12-12 23:14:03.194Z debug(replica): 2n: on_message: view=1 status=normal vsr.message_header.Header.PingClient{ .checksum = 83275800637725605036190424358212226180, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 0, .release = 0.0.1, .protocol = 0, .command = vsr.Command.ping_client, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .client = 204161290705302669957276092172686812873, .ping_timestamp_monotonic = 37700948403775436, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:14:03.194Z debug(replica): 2n: sending pong_client to client 204161290705302669957276092172686812873: vsr.message_header.Header.PongClient{ .checksum = 301762384417467470957229503887629234849, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.pong_client, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .ping_timestamp_monotonic = 37700948403775436, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:14:03.194Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 131921637994549118652545016890972672425, .checksum_padding = 0, .checksum_body = 89618358641903479169915062276417095592, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 272, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 237963762032600258330237080301214704075, .parent_padding = 0, .client = 204161290705302669957276092172686812873, .session = 2, .timestamp = 0, .request = 5, .operation = vsr.Operation(141), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 42206896, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:14:03.194Z debug(replica): 1N: on_request: replying to duplicate request
2025-12-12 23:14:03.194Z debug(client_replies): 1: read_reply: busy (client=204161290705302669957276092172686812873 reply=180836187408286721316226116499192129565)
2025-12-12 23:14:03.195Z debug(replica): 1N: on_request: ignoring (client_replies busy)
2025-12-12 23:14:03.195Z debug(replica): 2n: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 131921637994549118652545016890972672425, .checksum_padding = 0, .checksum_body = 89618358641903479169915062276417095592, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 272, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 237963762032600258330237080301214704075, .parent_padding = 0, .client = 204161290705302669957276092172686812873, .session = 2, .timestamp = 0, .request = 5, .operation = vsr.Operation(141), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 42206896, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:14:03.195Z debug(replica): 2n: on_request: forwarding new request to primary (view=1)
2025-12-12 23:14:03.195Z debug(replica): 2n: sending request to replica 1: vsr.message_header.Header.Request{ .checksum = 131921637994549118652545016890972672425, .checksum_padding = 0, .checksum_body = 89618358641903479169915062276417095592, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 272, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 237963762032600258330237080301214704075, .parent_padding = 0, .client = 204161290705302669957276092172686812873, .session = 2, .timestamp = 0, .request = 5, .operation = vsr.Operation(141), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 42206896, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:14:03.195Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 131921637994549118652545016890972672425, .checksum_padding = 0, .checksum_body = 89618358641903479169915062276417095592, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 272, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 237963762032600258330237080301214704075, .parent_padding = 0, .client = 204161290705302669957276092172686812873, .session = 2, .timestamp = 0, .request = 5, .operation = vsr.Operation(141), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 42206896, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:14:03.195Z debug(replica): 1N: on_request: replying to duplicate request
2025-12-12 23:14:03.195Z debug(client_replies): 1: read_reply: busy (client=204161290705302669957276092172686812873 reply=180836187408286721316226116499192129565)
2025-12-12 23:14:03.195Z debug(replica): 1N: on_request: ignoring (client_replies busy)
2025-12-12 23:14:03.195Z debug(replica): 2n: on_message: view=1 status=normal vsr.message_header.Header.PingClient{ .checksum = 171971522165421621245073392118026122689, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 0, .release = 0.0.1, .protocol = 0, .command = vsr.Command.ping_client, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .client = 204161290705302669957276092172686812873, .ping_timestamp_monotonic = 37700978504761420, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:14:03.195Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 131921637994549118652545016890972672425, .checksum_padding = 0, .checksum_body = 89618358641903479169915062276417095592, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 272, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 237963762032600258330237080301214704075, .parent_padding = 0, .client = 204161290705302669957276092172686812873, .session = 2, .timestamp = 0, .request = 5, .operation = vsr.Operation(141), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 42206896, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:14:03.195Z debug(replica): 1N: on_request: replying to duplicate request
2025-12-12 23:14:03.195Z debug(replica): 2n: sending pong_client to client 204161290705302669957276092172686812873: vsr.message_header.Header.PongClient{ .checksum = 131317136605475886721792825822514350359, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.pong_client, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .ping_timestamp_monotonic = 37700978504761420, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:14:03.195Z debug(client_replies): 1: read_reply: busy (client=204161290705302669957276092172686812873 reply=180836187408286721316226116499192129565)
2025-12-12 23:14:03.195Z debug(replica): 1N: on_request: ignoring (client_replies busy)
2025-12-12 23:14:03.195Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 131921637994549118652545016890972672425, .checksum_padding = 0, .checksum_body = 89618358641903479169915062276417095592, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 272, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 237963762032600258330237080301214704075, .parent_padding = 0, .client = 204161290705302669957276092172686812873, .session = 2, .timestamp = 0, .request = 5, .operation = vsr.Operation(141), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 42206896, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:14:03.195Z debug(replica): 1N: on_request: replying to duplicate request
2025-12-12 23:14:03.195Z debug(replica): 2n: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 131921637994549118652545016890972672425, .checksum_padding = 0, .checksum_body = 89618358641903479169915062276417095592, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 272, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 237963762032600258330237080301214704075, .parent_padding = 0, .client = 204161290705302669957276092172686812873, .session = 2, .timestamp = 0, .request = 5, .operation = vsr.Operation(141), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 42206896, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:14:03.195Z debug(replica): 2n: on_request: forwarding new request to primary (view=1)
2025-12-12 23:14:03.195Z debug(client_replies): 1: read_reply: busy (client=204161290705302669957276092172686812873 reply=180836187408286721316226116499192129565)
2025-12-12 23:14:03.195Z debug(replica): 1N: on_request: ignoring (client_replies busy)
2025-12-12 23:14:03.195Z debug(replica): 2n: sending request to replica 1: vsr.message_header.Header.Request{ .checksum = 131921637994549118652545016890972672425, .checksum_padding = 0, .checksum_body = 89618358641903479169915062276417095592, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 272, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 237963762032600258330237080301214704075, .parent_padding = 0, .client = 204161290705302669957276092172686812873, .session = 2, .timestamp = 0, .request = 5, .operation = vsr.Operation(141), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 42206896, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:14:03.195Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.PingClient{ .checksum = 216874767046572679467723370904134433719, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 0, .release = 0.0.1, .protocol = 0, .command = vsr.Command.ping_client, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .client = 204161290705302669957276092172686812873, .ping_timestamp_monotonic = 37700797936651246, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:14:03.195Z debug(replica): 2n: on_message: view=1 status=normal vsr.message_header.Header.PingClient{ .checksum = 294978623810581794057422510225355351885, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 0, .release = 0.0.1, .protocol = 0, .command = vsr.Command.ping_client, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .client = 204161290705302669957276092172686812873, .ping_timestamp_monotonic = 37701008590696156, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:14:03.195Z debug(replica): 2n: sending pong_client to client 204161290705302669957276092172686812873: vsr.message_header.Header.PongClient{ .checksum = 119148534297668946857738930897279488802, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.pong_client, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .ping_timestamp_monotonic = 37701008590696156, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:14:03.195Z debug(replica): 1N: sending pong_client to client 204161290705302669957276092172686812873: vsr.message_header.Header.PongClient{ .checksum = 66083433716778865362713741177243844699, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.pong_client, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .ping_timestamp_monotonic = 37700797936651246, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:14:03.195Z debug(replica): 2n: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 272538097181716609920054383373688758753, .checksum_padding = 0, .checksum_body = 89618358641903479169915062276417095592, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 272, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 325156755384226089172033123826201086582, .parent_padding = 0, .client = 204161290705302669957276092172686812873, .session = 2, .timestamp = 0, .request = 6, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 4294967295, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:14:03.195Z debug(replica): 2n: on_request: forwarding new request to primary (view=1)
2025-12-12 23:14:03.195Z debug(replica): 2n: sending request to replica 1: vsr.message_header.Header.Request{ .checksum = 272538097181716609920054383373688758753, .checksum_padding = 0, .checksum_body = 89618358641903479169915062276417095592, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 272, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 325156755384226089172033123826201086582, .parent_padding = 0, .client = 204161290705302669957276092172686812873, .session = 2, .timestamp = 0, .request = 6, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 4294967295, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:14:03.195Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 131921637994549118652545016890972672425, .checksum_padding = 0, .checksum_body = 89618358641903479169915062276417095592, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 272, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 237963762032600258330237080301214704075, .parent_padding = 0, .client = 204161290705302669957276092172686812873, .session = 2, .timestamp = 0, .request = 5, .operation = vsr.Operation(141), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 42206896, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:14:03.195Z debug(replica): 1N: on_request: replying to duplicate request
2025-12-12 23:14:03.195Z warning(clock): 2: synchronization failed, partitioned (sources=1 samples=1)
2025-12-12 23:14:03.195Z debug(client_replies): 1: read_reply: busy (client=204161290705302669957276092172686812873 reply=180836187408286721316226116499192129565)
2025-12-12 23:14:03.195Z error(clock): 2: no agreement on cluster time (partitioned or too many clock faults)
2025-12-12 23:14:03.195Z debug(replica): 1N: on_request: ignoring (client_replies busy)
2025-12-12 23:14:03.195Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 131921637994549118652545016890972672425, .checksum_padding = 0, .checksum_body = 89618358641903479169915062276417095592, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 272, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 237963762032600258330237080301214704075, .parent_padding = 0, .client = 204161290705302669957276092172686812873, .session = 2, .timestamp = 0, .request = 5, .operation = vsr.Operation(141), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 42206896, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:14:03.195Z debug(replica): 1N: on_request: replying to duplicate request
2025-12-12 23:14:03.195Z debug(client_replies): 1: read_reply: busy (client=204161290705302669957276092172686812873 reply=180836187408286721316226116499192129565)
2025-12-12 23:14:03.195Z debug(replica): 1N: on_request: ignoring (client_replies busy)
2025-12-12 23:14:03.195Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 131921637994549118652545016890972672425, .checksum_padding = 0, .checksum_body = 89618358641903479169915062276417095592, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 272, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 237963762032600258330237080301214704075, .parent_padding = 0, .client = 204161290705302669957276092172686812873, .session = 2, .timestamp = 0, .request = 5, .operation = vsr.Operation(141), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 42206896, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:14:03.196Z debug(replica): 1N: on_request: replying to duplicate request
2025-12-12 23:14:03.196Z debug(client_replies): 1: read_reply: busy (client=204161290705302669957276092172686812873 reply=180836187408286721316226116499192129565)
2025-12-12 23:14:03.196Z debug(replica): 1N: on_request: ignoring (client_replies busy)
2025-12-12 23:14:03.196Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 131921637994549118652545016890972672425, .checksum_padding = 0, .checksum_body = 89618358641903479169915062276417095592, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 272, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 237963762032600258330237080301214704075, .parent_padding = 0, .client = 204161290705302669957276092172686812873, .session = 2, .timestamp = 0, .request = 5, .operation = vsr.Operation(141), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 42206896, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:14:03.196Z debug(replica): 1N: on_request: replying to duplicate request
2025-12-12 23:14:03.196Z debug(client_replies): 1: read_reply: busy (client=204161290705302669957276092172686812873 reply=180836187408286721316226116499192129565)
2025-12-12 23:14:03.196Z debug(replica): 1N: on_request: ignoring (client_replies busy)
2025-12-12 23:14:03.196Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 131921637994549118652545016890972672425, .checksum_padding = 0, .checksum_body = 89618358641903479169915062276417095592, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 272, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 237963762032600258330237080301214704075, .parent_padding = 0, .client = 204161290705302669957276092172686812873, .session = 2, .timestamp = 0, .request = 5, .operation = vsr.Operation(141), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 42206896, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:14:03.196Z debug(replica): 1N: on_request: replying to duplicate request
2025-12-12 23:14:03.196Z debug(client_replies): 1: read_reply: busy (client=204161290705302669957276092172686812873 reply=180836187408286721316226116499192129565)
2025-12-12 23:14:03.196Z debug(replica): 1N: on_request: ignoring (client_replies busy)
2025-12-12 23:14:03.196Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.PingClient{ .checksum = 203732013210077176772699629991244324379, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 0, .release = 0.0.1, .protocol = 0, .command = vsr.Command.ping_client, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .client = 204161290705302669957276092172686812873, .ping_timestamp_monotonic = 37700828029618898, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:14:03.196Z debug(replica): 1N: sending pong_client to client 204161290705302669957276092172686812873: vsr.message_header.Header.PongClient{ .checksum = 50480027039645638948002001929836226177, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.pong_client, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .ping_timestamp_monotonic = 37700828029618898, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:14:03.196Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 131921637994549118652545016890972672425, .checksum_padding = 0, .checksum_body = 89618358641903479169915062276417095592, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 272, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 237963762032600258330237080301214704075, .parent_padding = 0, .client = 204161290705302669957276092172686812873, .session = 2, .timestamp = 0, .request = 5, .operation = vsr.Operation(141), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 42206896, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:14:03.196Z debug(replica): 1N: on_request: replying to duplicate request
2025-12-12 23:14:03.196Z debug(client_replies): 1: read_reply: busy (client=204161290705302669957276092172686812873 reply=180836187408286721316226116499192129565)
2025-12-12 23:14:03.196Z debug(replica): 1N: on_request: ignoring (client_replies busy)
2025-12-12 23:14:03.196Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 131921637994549118652545016890972672425, .checksum_padding = 0, .checksum_body = 89618358641903479169915062276417095592, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 272, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 237963762032600258330237080301214704075, .parent_padding = 0, .client = 204161290705302669957276092172686812873, .session = 2, .timestamp = 0, .request = 5, .operation = vsr.Operation(141), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 42206896, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:14:03.196Z debug(replica): 1N: on_request: replying to duplicate request
2025-12-12 23:14:03.196Z debug(client_replies): 1: read_reply: busy (client=204161290705302669957276092172686812873 reply=180836187408286721316226116499192129565)
2025-12-12 23:14:03.196Z debug(replica): 1N: on_request: ignoring (client_replies busy)
2025-12-12 23:14:03.196Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 131921637994549118652545016890972672425, .checksum_padding = 0, .checksum_body = 89618358641903479169915062276417095592, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 272, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 237963762032600258330237080301214704075, .parent_padding = 0, .client = 204161290705302669957276092172686812873, .session = 2, .timestamp = 0, .request = 5, .operation = vsr.Operation(141), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 42206896, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:14:03.196Z debug(replica): 1N: on_request: replying to duplicate request
2025-12-12 23:14:03.196Z debug(client_replies): 1: read_reply: busy (client=204161290705302669957276092172686812873 reply=180836187408286721316226116499192129565)
2025-12-12 23:14:03.196Z debug(replica): 1N: on_request: ignoring (client_replies busy)
2025-12-12 23:14:03.197Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 131921637994549118652545016890972672425, .checksum_padding = 0, .checksum_body = 89618358641903479169915062276417095592, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 272, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 237963762032600258330237080301214704075, .parent_padding = 0, .client = 204161290705302669957276092172686812873, .session = 2, .timestamp = 0, .request = 5, .operation = vsr.Operation(141), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 42206896, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:14:03.197Z debug(replica): 1N: on_request: replying to duplicate request
2025-12-12 23:14:03.197Z debug(client_replies): 1: read_reply: busy (client=204161290705302669957276092172686812873 reply=180836187408286721316226116499192129565)
2025-12-12 23:14:03.197Z debug(replica): 1N: on_request: ignoring (client_replies busy)
2025-12-12 23:14:03.197Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.PingClient{ .checksum = 18182672945588977481333483900010498112, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 0, .release = 0.0.1, .protocol = 0, .command = vsr.Command.ping_client, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .client = 204161290705302669957276092172686812873, .ping_timestamp_monotonic = 37700858121226738, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:14:03.197Z debug(replica): 1N: sending pong_client to client 204161290705302669957276092172686812873: vsr.message_header.Header.PongClient{ .checksum = 229606095677672550992416335288137025686, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.pong_client, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .ping_timestamp_monotonic = 37700858121226738, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:14:03.197Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 131921637994549118652545016890972672425, .checksum_padding = 0, .checksum_body = 89618358641903479169915062276417095592, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 272, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 237963762032600258330237080301214704075, .parent_padding = 0, .client = 204161290705302669957276092172686812873, .session = 2, .timestamp = 0, .request = 5, .operation = vsr.Operation(141), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 42206896, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:14:03.197Z debug(replica): 1N: on_request: replying to duplicate request
2025-12-12 23:14:03.197Z debug(client_replies): 1: read_reply: busy (client=204161290705302669957276092172686812873 reply=180836187408286721316226116499192129565)
2025-12-12 23:14:03.197Z debug(replica): 1N: on_request: ignoring (client_replies busy)
2025-12-12 23:14:03.197Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 131921637994549118652545016890972672425, .checksum_padding = 0, .checksum_body = 89618358641903479169915062276417095592, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 272, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 237963762032600258330237080301214704075, .parent_padding = 0, .client = 204161290705302669957276092172686812873, .session = 2, .timestamp = 0, .request = 5, .operation = vsr.Operation(141), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 42206896, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:14:03.197Z debug(replica): 1N: on_request: replying to duplicate request
2025-12-12 23:14:03.197Z debug(client_replies): 1: read_reply: busy (client=204161290705302669957276092172686812873 reply=180836187408286721316226116499192129565)
2025-12-12 23:14:03.197Z debug(replica): 1N: on_request: ignoring (client_replies busy)
2025-12-12 23:14:03.197Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 131921637994549118652545016890972672425, .checksum_padding = 0, .checksum_body = 89618358641903479169915062276417095592, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 272, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 237963762032600258330237080301214704075, .parent_padding = 0, .client = 204161290705302669957276092172686812873, .session = 2, .timestamp = 0, .request = 5, .operation = vsr.Operation(141), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 42206896, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:14:03.197Z debug(replica): 1N: on_request: replying to duplicate request
2025-12-12 23:14:03.197Z debug(client_replies): 1: read_reply: busy (client=204161290705302669957276092172686812873 reply=180836187408286721316226116499192129565)
2025-12-12 23:14:03.197Z debug(replica): 1N: on_request: ignoring (client_replies busy)
2025-12-12 23:14:03.197Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.PingClient{ .checksum = 218992291249205068388647787579790993482, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 0, .release = 0.0.1, .protocol = 0, .command = vsr.Command.ping_client, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .client = 204161290705302669957276092172686812873, .ping_timestamp_monotonic = 37700888215447074, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:14:03.197Z debug(replica): 1N: sending pong_client to client 204161290705302669957276092172686812873: vsr.message_header.Header.PongClient{ .checksum = 22695702872363296153019453988992794798, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.pong_client, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .ping_timestamp_monotonic = 37700888215447074, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:14:03.198Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 131921637994549118652545016890972672425, .checksum_padding = 0, .checksum_body = 89618358641903479169915062276417095592, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 272, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 237963762032600258330237080301214704075, .parent_padding = 0, .client = 204161290705302669957276092172686812873, .session = 2, .timestamp = 0, .request = 5, .operation = vsr.Operation(141), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 42206896, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:14:03.198Z debug(replica): 1N: on_request: replying to duplicate request
2025-12-12 23:14:03.198Z debug(client_replies): 1: read_reply: busy (client=204161290705302669957276092172686812873 reply=180836187408286721316226116499192129565)
2025-12-12 23:14:03.198Z debug(replica): 1N: on_request: ignoring (client_replies busy)
2025-12-12 23:14:03.198Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 131921637994549118652545016890972672425, .checksum_padding = 0, .checksum_body = 89618358641903479169915062276417095592, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 272, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 237963762032600258330237080301214704075, .parent_padding = 0, .client = 204161290705302669957276092172686812873, .session = 2, .timestamp = 0, .request = 5, .operation = vsr.Operation(141), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 42206896, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:14:03.198Z debug(replica): 1N: on_request: replying to duplicate request
2025-12-12 23:14:03.198Z debug(client_replies): 1: read_reply: busy (client=204161290705302669957276092172686812873 reply=180836187408286721316226116499192129565)
2025-12-12 23:14:03.198Z debug(replica): 1N: on_request: ignoring (client_replies busy)
2025-12-12 23:14:03.198Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 131921637994549118652545016890972672425, .checksum_padding = 0, .checksum_body = 89618358641903479169915062276417095592, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 272, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 237963762032600258330237080301214704075, .parent_padding = 0, .client = 204161290705302669957276092172686812873, .session = 2, .timestamp = 0, .request = 5, .operation = vsr.Operation(141), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 42206896, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:14:03.198Z debug(replica): 1N: on_request: replying to duplicate request
2025-12-12 23:14:03.198Z debug(client_replies): 1: read_reply: busy (client=204161290705302669957276092172686812873 reply=180836187408286721316226116499192129565)
2025-12-12 23:14:03.198Z debug(replica): 1N: on_request: ignoring (client_replies busy)
2025-12-12 23:14:03.198Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.PingClient{ .checksum = 139936347311092830177518826141090531857, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 0, .release = 0.0.1, .protocol = 0, .command = vsr.Command.ping_client, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .client = 204161290705302669957276092172686812873, .ping_timestamp_monotonic = 37700918306348515, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:14:03.198Z debug(replica): 1N: sending pong_client to client 204161290705302669957276092172686812873: vsr.message_header.Header.PongClient{ .checksum = 120506250107212495438984948122128955407, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.pong_client, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .ping_timestamp_monotonic = 37700918306348515, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:14:03.198Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 131921637994549118652545016890972672425, .checksum_padding = 0, .checksum_body = 89618358641903479169915062276417095592, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 272, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 237963762032600258330237080301214704075, .parent_padding = 0, .client = 204161290705302669957276092172686812873, .session = 2, .timestamp = 0, .request = 5, .operation = vsr.Operation(141), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 42206896, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:14:03.198Z debug(replica): 1N: on_request: replying to duplicate request
2025-12-12 23:14:03.198Z debug(client_replies): 1: read_reply: busy (client=204161290705302669957276092172686812873 reply=180836187408286721316226116499192129565)
2025-12-12 23:14:03.198Z debug(replica): 1N: on_request: ignoring (client_replies busy)
2025-12-12 23:14:03.198Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 131921637994549118652545016890972672425, .checksum_padding = 0, .checksum_body = 89618358641903479169915062276417095592, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 272, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 237963762032600258330237080301214704075, .parent_padding = 0, .client = 204161290705302669957276092172686812873, .session = 2, .timestamp = 0, .request = 5, .operation = vsr.Operation(141), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 42206896, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:14:03.198Z debug(replica): 1N: on_request: replying to duplicate request
2025-12-12 23:14:03.198Z debug(client_replies): 1: read_reply: busy (client=204161290705302669957276092172686812873 reply=180836187408286721316226116499192129565)
2025-12-12 23:14:03.198Z debug(replica): 1N: on_request: ignoring (client_replies busy)
2025-12-12 23:14:03.198Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 131921637994549118652545016890972672425, .checksum_padding = 0, .checksum_body = 89618358641903479169915062276417095592, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 272, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 237963762032600258330237080301214704075, .parent_padding = 0, .client = 204161290705302669957276092172686812873, .session = 2, .timestamp = 0, .request = 5, .operation = vsr.Operation(141), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 42206896, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:14:03.198Z debug(replica): 1N: on_request: replying to duplicate request
2025-12-12 23:14:03.198Z debug(client_replies): 1: read_reply: busy (client=204161290705302669957276092172686812873 reply=180836187408286721316226116499192129565)
2025-12-12 23:14:03.198Z debug(replica): 1N: on_request: ignoring (client_replies busy)
2025-12-12 23:14:03.199Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 131921637994549118652545016890972672425, .checksum_padding = 0, .checksum_body = 89618358641903479169915062276417095592, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 272, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 237963762032600258330237080301214704075, .parent_padding = 0, .client = 204161290705302669957276092172686812873, .session = 2, .timestamp = 0, .request = 5, .operation = vsr.Operation(141), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 42206896, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:14:03.199Z debug(replica): 1N: on_request: replying to duplicate request
2025-12-12 23:14:03.199Z debug(client_replies): 1: read_reply: busy (client=204161290705302669957276092172686812873 reply=180836187408286721316226116499192129565)
2025-12-12 23:14:03.199Z debug(replica): 1N: on_request: ignoring (client_replies busy)
2025-12-12 23:14:03.199Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.PingClient{ .checksum = 83275800637725605036190424358212226180, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 0, .release = 0.0.1, .protocol = 0, .command = vsr.Command.ping_client, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .client = 204161290705302669957276092172686812873, .ping_timestamp_monotonic = 37700948403775436, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 23:14:03.205Z debug(vsr): 2: journal_repair_budget_timeout fired
2025-12-12 23:14:03.205Z debug(vsr): 2: journal_repair_budget_timeout reset
2025-12-12 23:14:03.207Z info(supervisor): 1: terminating replica
2025-12-12 23:14:03.219Z info(supervisor): 2: terminating replica
2025-12-12 23:14:03.275Z error: TestFailed
/root/tigerbeetle/working/main/src/testing/vortex/supervisor.zig:295:21: 0x1307eb0 in run (vortex)
                    return error.TestFailed;
                    ^
/root/tigerbeetle/working/main/src/testing/vortex/supervisor.zig:207:5: 0x130ca73 in main (vortex)
    try supervisor.run();
    ^
/root/tigerbeetle/working/main/src/vortex.zig:61:42: 0x13216d4 in main (vortex)
        .supervisor => |supervisor_args| try Supervisor.main(allocator, supervisor_args),
                                         ^
