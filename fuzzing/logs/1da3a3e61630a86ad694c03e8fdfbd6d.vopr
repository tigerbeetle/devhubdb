on_prepare: advancing commit_max=75..76
2025-12-12 18:42:39.801Z debug(replica): 1n: on_prepare: caching prepare.op=77 (commit_min=75 op=76 commit_max=76 prepare_max=1007)
2025-12-12 18:42:39.801Z debug(replica): 2N: on_message: view=2 status=normal vsr.message_header.Header.Request{ .checksum = 309799047143092972233297483117665828805, .checksum_padding = 0, .checksum_body = 115145659962858292186797920771916199226, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 819456, .epoch = 0, .view = 2, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 232177095567659046659678431227227467738, .parent_padding = 0, .client = 129800060941563857535569923226995055452, .session = 2, .timestamp = 0, .request = 75, .operation = vsr.Operation(139), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 45727713, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 18:42:39.801Z debug(replica): 1n: on_prepare: advancing: op=76..77 checksum=50171195367199191013598993173721660374..101835763928779581347929029942247644699
2025-12-12 18:42:39.801Z debug(journal): 1: set_header_as_dirty: op=77 checksum=101835763928779581347929029942247644699
2025-12-12 18:42:39.801Z debug(replica): 2N: on_request: new request
2025-12-12 18:42:39.801Z debug(replica): 1n: append: appending to journal op=77
2025-12-12 18:42:39.801Z debug(replica): 2N: on_request: ignoring (already preparing)
2025-12-12 18:42:39.801Z debug(journal): 1: write: view=2 slot=77 op=77 len=819456: 101835763928779581347929029942247644699 starting
2025-12-12 18:42:39.801Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.prepares offset=80740352 len=823296 locked
2025-12-12 18:42:39.801Z debug(replica): 1n: commit_start_journal: cached prepare op=76 checksum=50171195367199191013598993173721660374
2025-12-12 18:42:39.801Z debug(replica): 1n: repair_prepare: op=77 checksum=101835763928779581347929029942247644699 (already writing)
2025-12-12 18:42:39.801Z debug(replica): 1n: commit_journal: already committing (prefetch; commit_min=75)
2025-12-12 18:42:39.801Z debug(replica): 1n: execute_op: executing view=2 primary=false op=76 checksum=50171195367199191013598993173721660374 (lookup_accounts)
2025-12-12 18:42:39.801Z debug(replica): 1n: execute_op: commit_timestamp=1765564953572708328 prepare.header.timestamp=1765564956586890030
2025-12-12 18:42:39.801Z debug(replica): 1n: client_table_entry_update: client=129800060941563857535569923226995055452 session=2 request=74
2025-12-12 18:42:39.801Z debug(replica): 1n: execute_op: replying to client: vsr.message_header.Header.Reply{ .checksum = 112572242570900881626521146477409531827, .checksum_padding = 0, .checksum_body = 318359880942421289578672087623306813703, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 14720, .epoch = 0, .view = 2, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 244701026119310533347082000144020525205, .request_checksum_padding = 0, .context = 232177095567659046659678431227227467738, .context_padding = 0, .client = 129800060941563857535569923226995055452, .op = 76, .commit = 76, .timestamp = 1765564956586890030, .request = 74, .operation = vsr.Operation(140), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 18:42:39.801Z debug(replica): 1n: sending reply to client 129800060941563857535569923226995055452: vsr.message_header.Header.Reply{ .checksum = 112572242570900881626521146477409531827, .checksum_padding = 0, .checksum_body = 318359880942421289578672087623306813703, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 14720, .epoch = 0, .view = 2, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 244701026119310533347082000144020525205, .request_checksum_padding = 0, .context = 232177095567659046659678431227227467738, .context_padding = 0, .client = 129800060941563857535569923226995055452, .op = 76, .commit = 76, .timestamp = 1765564956586890030, .request = 74, .operation = vsr.Operation(140), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 18:42:39.801Z debug(forest): entering forest.compact() op=76 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2025-12-12 18:42:39.802Z debug(client_replies): 1: write_reply: wrote (client=129800060941563857535569923226995055452 request=74)
2025-12-12 18:42:39.802Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.prepares offset=80740352 len=823296 unlocked
2025-12-12 18:42:39.802Z debug(journal): 1: write_header: op=77 sectors[16384..20480]
2025-12-12 18:42:39.802Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.headers offset=16384 len=4096 locked
2025-12-12 18:42:39.802Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.headers offset=16384 len=4096 unlocked
2025-12-12 18:42:39.802Z debug(journal): 1: write: view=2 slot=77 op=77 len=819456: 101835763928779581347929029942247644699 complete, marking clean
2025-12-12 18:42:39.802Z debug(replica): 1n: send_prepare_ok: op=77 checksum=101835763928779581347929029942247644699
2025-12-12 18:42:39.802Z debug(replica): 1n: sending prepare_ok to replica 2: vsr.message_header.Header.PrepareOk{ .checksum = 25112869173185654804672094082142008420, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 2, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 50171195367199191013598993173721660374, .parent_padding = 0, .prepare_checksum = 101835763928779581347929029942247644699, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 129800060941563857535569923226995055452, .op = 77, .commit_min = 76, .timestamp = 1765564959793115706, .request = 75, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-12-12 18:42:39.804Z debug(replica): 2N: on_message: view=2 status=normal vsr.message_header.Header.Request{ .checksum = 309799047143092972233297483117665828805, .checksum_padding = 0, .checksum_body = 115145659962858292186797920771916199226, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 819456, .epoch = 0, .view = 2, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 232177095567659046659678431227227467738, .parent_padding = 0, .client = 129800060941563857535569923226995055452, .session = 2, .timestamp = 0, .request = 75, .operation = vsr.Operation(139), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 45727713, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 18:42:39.804Z debug(replica): 2N: on_request: new request
2025-12-12 18:42:39.804Z debug(replica): 2N: on_request: ignoring (already preparing)
2025-12-12 18:42:39.805Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.prepares offset=80740352 len=823296 unlocked
2025-12-12 18:42:39.805Z debug(journal): 2: write_header: op=77 sectors[16384..20480]
2025-12-12 18:42:39.805Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.headers offset=16384 len=4096 locked
2025-12-12 18:42:39.806Z debug(replica): 0n: execute_op: executing view=2 primary=false op=37 checksum=26889165326429776525032733986417163889 (create_transfers)
2025-12-12 18:42:39.806Z debug(replica): 0n: execute_op: commit_timestamp=1765564866703148063 prepare.header.timestamp=1765564866760074301
2025-12-12 18:42:39.808Z debug(replica): 2N: on_message: view=2 status=normal vsr.message_header.Header.Request{ .checksum = 309799047143092972233297483117665828805, .checksum_padding = 0, .checksum_body = 115145659962858292186797920771916199226, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 819456, .epoch = 0, .view = 2, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 232177095567659046659678431227227467738, .parent_padding = 0, .client = 129800060941563857535569923226995055452, .session = 2, .timestamp = 0, .request = 75, .operation = vsr.Operation(139), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 45727713, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 18:42:39.808Z debug(replica): 2N: on_request: new request
2025-12-12 18:42:39.808Z debug(replica): 2N: on_request: ignoring (already preparing)
2025-12-12 18:42:39.808Z debug(vsr): 2: journal_repair_budget_timeout fired
2025-12-12 18:42:39.808Z debug(vsr): 2: journal_repair_budget_timeout reset
2025-12-12 18:42:39.808Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.headers offset=16384 len=4096 unlocked
2025-12-12 18:42:39.808Z debug(journal): 2: write: view=2 slot=77 op=77 len=819456: 101835763928779581347929029942247644699 complete, marking clean
2025-12-12 18:42:39.808Z debug(replica): 2N: send_prepare_ok: op=77 checksum=101835763928779581347929029942247644699
2025-12-12 18:42:39.808Z debug(replica): 2N: sending prepare_ok to replica 2: vsr.message_header.Header.PrepareOk{ .checksum = 188044307919483469946592748860997480103, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 2, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 50171195367199191013598993173721660374, .parent_padding = 0, .prepare_checksum = 101835763928779581347929029942247644699, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 129800060941563857535569923226995055452, .op = 77, .commit_min = 76, .timestamp = 1765564959793115706, .request = 75, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-12-12 18:42:39.808Z debug(replica): 2N: on_message: view=2 status=normal vsr.message_header.Header.PrepareOk{ .checksum = 188044307919483469946592748860997480103, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 2, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 50171195367199191013598993173721660374, .parent_padding = 0, .prepare_checksum = 101835763928779581347929029942247644699, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 129800060941563857535569923226995055452, .op = 77, .commit_min = 76, .timestamp = 1765564959793115706, .request = 75, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-12-12 18:42:39.808Z debug(vsr): 2: primary_abdicate_timeout reset
2025-12-12 18:42:39.808Z debug(replica): 2N: on_prepare_ok: 1 message(s)
2025-12-12 18:42:39.808Z debug(replica): 2N: on_prepare_ok: waiting for quorum
2025-12-12 18:42:39.812Z debug(vsr): 1: journal_repair_budget_timeout fired
2025-12-12 18:42:39.812Z debug(vsr): 1: journal_repair_budget_timeout reset
2025-12-12 18:42:39.828Z debug(vsr): 2: journal_repair_budget_timeout fired
2025-12-12 18:42:39.828Z debug(vsr): 2: journal_repair_budget_timeout reset
2025-12-12 18:42:39.832Z debug(vsr): 1: journal_repair_budget_timeout fired
2025-12-12 18:42:39.832Z debug(vsr): 1: journal_repair_budget_timeout reset
2025-12-12 18:42:39.832Z debug(vsr): 1: journal_repair_timeout fired
2025-12-12 18:42:39.832Z debug(vsr): 1: journal_repair_timeout reset
2025-12-12 18:42:39.833Z debug(replica): 0n: client_table_entry_update: client=129800060941563857535569923226995055452 session=2 request=35
2025-12-12 18:42:39.833Z debug(forest): entering forest.compact() op=37 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2025-12-12 18:42:39.844Z debug(replica): 2N: on_message: view=2 status=normal vsr.message_header.Header.PrepareOk{ .checksum = 25112869173185654804672094082142008420, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 2, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 50171195367199191013598993173721660374, .parent_padding = 0, .prepare_checksum = 101835763928779581347929029942247644699, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 129800060941563857535569923226995055452, .op = 77, .commit_min = 76, .timestamp = 1765564959793115706, .request = 75, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-12-12 18:42:39.844Z debug(vsr): 2: primary_abdicate_timeout reset
2025-12-12 18:42:39.844Z debug(replica): 2N: on_prepare_ok: 2 message(s)
2025-12-12 18:42:39.844Z debug(replica): 2N: on_prepare_ok: quorum received, context=101835763928779581347929029942247644699
2025-12-12 18:42:39.844Z debug(vsr): 2: prepare_timeout stopped
2025-12-12 18:42:39.844Z debug(vsr): 2: primary_abdicate_timeout stopped
2025-12-12 18:42:39.847Z debug(client_replies): 0: write_reply: wrote (client=129800060941563857535569923226995055452 request=35)
2025-12-12 18:42:39.847Z debug(replica): 0n: execute_op: executing view=2 primary=false op=38 checksum=212518679201431008357927820176806289419 (lookup_accounts)
2025-12-12 18:42:39.847Z debug(replica): 0n: execute_op: commit_timestamp=1765564866760074301 prepare.header.timestamp=1765564869043711606
2025-12-12 18:42:39.847Z debug(replica): 0n: client_table_entry_update: client=129800060941563857535569923226995055452 session=2 request=36
2025-12-12 18:42:39.847Z debug(replica): 2N: execute_op: executing view=2 primary=true op=77 checksum=101835763928779581347929029942247644699 (create_transfers)
2025-12-12 18:42:39.847Z debug(forest): entering forest.compact() op=38 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2025-12-12 18:42:39.847Z debug(replica): 2N: execute_op: commit_timestamp=1765564956586890030 prepare.header.timestamp=1765564959793115706
2025-12-12 18:42:39.847Z debug(client_replies): 0: write_reply: wrote (client=129800060941563857535569923226995055452 request=36)
2025-12-12 18:42:39.852Z debug(vsr): 1: journal_repair_budget_timeout fired
2025-12-12 18:42:39.852Z debug(vsr): 1: journal_repair_budget_timeout reset
2025-12-12 18:42:39.854Z debug(replica): 0n: execute_op: executing view=2 primary=false op=39 checksum=133843236647749920105601245213684968557 (create_transfers)
2025-12-12 18:42:39.854Z debug(replica): 0n: execute_op: commit_timestamp=1765564869043711606 prepare.header.timestamp=1765564871821925975
2025-12-12 18:42:39.871Z debug(replica): 2N: execute_op: advancing commit_max=76..77
2025-12-12 18:42:39.872Z debug(replica): 2N: client_table_entry_update: client=129800060941563857535569923226995055452 session=2 request=75
2025-12-12 18:42:39.872Z debug(replica): 2N: execute_op: replying to client: vsr.message_header.Header.Reply{ .checksum = 317489432491163695941499283033090917089, .checksum_padding = 0, .checksum_body = 281711844982843542114175711130321012796, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 400, .epoch = 0, .view = 2, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 309799047143092972233297483117665828805, .request_checksum_padding = 0, .context = 2389995664003248079491962550587178037, .context_padding = 0, .client = 129800060941563857535569923226995055452, .op = 77, .commit = 77, .timestamp = 1765564959793115706, .request = 75, .operation = vsr.Operation(139), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 18:42:39.872Z debug(replica): 2N: sending reply to client 129800060941563857535569923226995055452: vsr.message_header.Header.Reply{ .checksum = 317489432491163695941499283033090917089, .checksum_padding = 0, .checksum_body = 281711844982843542114175711130321012796, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 400, .epoch = 0, .view = 2, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 309799047143092972233297483117665828805, .request_checksum_padding = 0, .context = 2389995664003248079491962550587178037, .context_padding = 0, .client = 129800060941563857535569923226995055452, .op = 77, .commit = 77, .timestamp = 1765564959793115706, .request = 75, .operation = vsr.Operation(139), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 18:42:39.872Z debug(forest): entering forest.compact() op=77 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
warning(client): 129800060941563857535569923226995055452: on_reply: slow request, request=75 op=77 size=819456 create_transfers time=3234ms
2025-12-12 18:42:39.872Z debug(vsr): 1: journal_repair_budget_timeout fired
2025-12-12 18:42:39.872Z debug(vsr): 1: journal_repair_budget_timeout reset
2025-12-12 18:42:39.880Z debug(replica): 0n: client_table_entry_update: client=129800060941563857535569923226995055452 session=2 request=37
2025-12-12 18:42:39.880Z debug(forest): entering forest.compact() op=39 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2025-12-12 18:42:39.884Z debug(vsr): 2: ping_timeout fired
2025-12-12 18:42:39.884Z debug(vsr): 2: ping_timeout reset
2025-12-12 18:42:39.884Z debug(replica): 2N: sending ping to replica 0: vsr.message_header.Header.Ping{ .checksum = 78672035594363665220604630332189568824, .checksum_padding = 0, .checksum_body = 154787626362930377789479683857780696253, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 512, .epoch = 0, .view = 2, .release = 0.0.1, .protocol = 0, .command = vsr.Command.ping, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .checkpoint_id = 321854455202207724029466302309042662424, .checkpoint_op = 0, .ping_timestamp_monotonic = 37680523404224117, .release_count = 1, .route_padding = { 0, 0, 0, 0, 0, 0 }, .route = 18446744073692840448, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 18:42:39.884Z debug(message_bus): 2: send_message_to_replica: no connection to=0 header=vsr.message_header.Header.Ping{ .checksum = 78672035594363665220604630332189568824, .checksum_padding = 0, .checksum_body = 154787626362930377789479683857780696253, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 512, .epoch = 0, .view = 2, .release = 0.0.1, .protocol = 0, .command = vsr.Command.ping, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .checkpoint_id = 321854455202207724029466302309042662424, .checkpoint_op = 0, .ping_timestamp_monotonic = 37680523404224117, .release_count = 1, .route_padding = { 0, 0, 0, 0, 0, 0 }, .route = 18446744073692840448, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 18:42:39.884Z debug(replica): 2N: sending ping to replica 1: vsr.message_header.Header.Ping{ .checksum = 78672035594363665220604630332189568824, .checksum_padding = 0, .checksum_body = 154787626362930377789479683857780696253, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 512, .epoch = 0, .view = 2, .release = 0.0.1, .protocol = 0, .command = vsr.Command.ping, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .checkpoint_id = 321854455202207724029466302309042662424, .checkpoint_op = 0, .ping_timestamp_monotonic = 37680523404224117, .release_count = 1, .route_padding = { 0, 0, 0, 0, 0, 0 }, .route = 18446744073692840448, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 18:42:39.884Z debug(vsr): 2: commit_message_timeout fired
2025-12-12 18:42:39.884Z debug(vsr): 2: commit_message_timeout reset
2025-12-12 18:42:39.884Z debug(replica): 2N: sending commit to replica 0: vsr.message_header.Header.Commit{ .checksum = 255017581405432029578298916943541880337, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 2, .release = 0.0.0, .protocol = 0, .command = vsr.Command.commit, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .commit_checksum = 101835763928779581347929029942247644699, .commit_checksum_padding = 0, .checkpoint_id = 321854455202207724029466302309042662424, .checkpoint_op = 0, .commit = 77, .timestamp_monotonic = 37680523404378317, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 18:42:39.884Z debug(message_bus): 2: send_message_to_replica: no connection to=0 header=vsr.message_header.Header.Commit{ .checksum = 255017581405432029578298916943541880337, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 2, .release = 0.0.0, .protocol = 0, .command = vsr.Command.commit, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .commit_checksum = 101835763928779581347929029942247644699, .commit_checksum_padding = 0, .checkpoint_id = 321854455202207724029466302309042662424, .checkpoint_op = 0, .commit = 77, .timestamp_monotonic = 37680523404378317, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 18:42:39.884Z debug(replica): 1n: on_message: view=2 status=normal vsr.message_header.Header.Ping{ .checksum = 78672035594363665220604630332189568824, .checksum_padding = 0, .checksum_body = 154787626362930377789479683857780696253, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 512, .epoch = 0, .view = 2, .release = 0.0.1, .protocol = 0, .command = vsr.Command.ping, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .checkpoint_id = 321854455202207724029466302309042662424, .checkpoint_op = 0, .ping_timestamp_monotonic = 37680523404224117, .release_count = 1, .route_padding = { 0, 0, 0, 0, 0, 0 }, .route = 18446744073692840448, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 18:42:39.884Z debug(replica): 2N: sending commit to replica 1: vsr.message_header.Header.Commit{ .checksum = 255017581405432029578298916943541880337, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 2, .release = 0.0.0, .protocol = 0, .command = vsr.Command.commit, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .commit_checksum = 101835763928779581347929029942247644699, .commit_checksum_padding = 0, .checkpoint_id = 321854455202207724029466302309042662424, .checkpoint_op = 0, .commit = 77, .timestamp_monotonic = 37680523404378317, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 18:42:39.884Z debug(replica): 1n: sending pong to replica 2: vsr.message_header.Header.Pong{ .checksum = 105392196846999774392513162479225012561, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 2, .release = 0.0.1, .protocol = 0, .command = vsr.Command.pong, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .ping_timestamp_monotonic = 37680523404224117, .pong_timestamp_wall = 1765564959884599365, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 18:42:39.884Z debug(vsr): 2: start_view_change_message_timeout fired
2025-12-12 18:42:39.884Z debug(vsr): 2: start_view_change_message_timeout reset
2025-12-12 18:42:39.884Z debug(vsr): 2: journal_repair_budget_timeout fired
2025-12-12 18:42:39.884Z debug(vsr): 2: journal_repair_budget_timeout reset
2025-12-12 18:42:39.884Z debug(vsr): 2: journal_repair_timeout fired
2025-12-12 18:42:39.884Z debug(vsr): 2: journal_repair_timeout reset
2025-12-12 18:42:39.884Z debug(replica): 1n: on_message: view=2 status=normal vsr.message_header.Header.Commit{ .checksum = 255017581405432029578298916943541880337, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 2, .release = 0.0.0, .protocol = 0, .command = vsr.Command.commit, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .commit_checksum = 101835763928779581347929029942247644699, .commit_checksum_padding = 0, .checkpoint_id = 321854455202207724029466302309042662424, .checkpoint_op = 0, .commit = 77, .timestamp_monotonic = 37680523404378317, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 18:42:39.884Z debug(vsr): 2: grid_repair_budget_timeout fired
2025-12-12 18:42:39.884Z debug(vsr): 2: grid_repair_budget_timeout reset
2025-12-12 18:42:39.884Z debug(vsr): 1: normal_heartbeat_timeout reset
2025-12-12 18:42:39.884Z debug(replica): 1n: on_commit: checksum verified
2025-12-12 18:42:39.884Z debug(replica): 1n: on_commit: advancing commit_max=76..77
2025-12-12 18:42:39.884Z debug(replica): 1n: commit_start_journal: cached prepare op=77 checksum=101835763928779581347929029942247644699
2025-12-12 18:42:39.884Z debug(client_replies): 2: write_reply: wrote (client=129800060941563857535569923226995055452 request=75)
2025-12-12 18:42:39.884Z debug(replica): 2N: on_message: view=2 status=normal vsr.message_header.Header.Pong{ .checksum = 105392196846999774392513162479225012561, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 2, .release = 0.0.1, .protocol = 0, .command = vsr.Command.pong, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .ping_timestamp_monotonic = 37680523404224117, .pong_timestamp_wall = 1765564959884599365, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 18:42:39.884Z debug(clock): 2: learn: replica=1 m0=37680523404224117 t1=1765564959884599365 m2=37680523404743067 t2=1765564959884900115 one_way_delay=259475 asymmetric_delay=0 clock_offset=-41275
2025-12-12 18:42:39.888Z debug(replica): 1n: execute_op: executing view=2 primary=false op=77 checksum=101835763928779581347929029942247644699 (create_transfers)
2025-12-12 18:42:39.888Z debug(replica): 1n: execute_op: commit_timestamp=1765564956586890030 prepare.header.timestamp=1765564959793115706
2025-12-12 18:42:39.893Z debug(vsr): 0: journal_repair_budget_timeout fired
2025-12-12 18:42:39.893Z debug(vsr): 0: journal_repair_budget_timeout reset
2025-12-12 18:42:39.893Z debug(client_replies): 0: write_reply: wrote (client=129800060941563857535569923226995055452 request=37)
2025-12-12 18:42:39.893Z debug(replica): 0n: execute_op: executing view=2 primary=false op=40 checksum=155725186495140672961683952478122400623 (lookup_accounts)
2025-12-12 18:42:39.893Z debug(replica): 0n: execute_op: commit_timestamp=1765564871821925975 prepare.header.timestamp=1765564874139361331
2025-12-12 18:42:39.893Z debug(replica): 0n: client_table_entry_update: client=129800060941563857535569923226995055452 session=2 request=38
2025-12-12 18:42:39.893Z debug(forest): entering forest.compact() op=40 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2025-12-12 18:42:39.893Z debug(client_replies): 0: write_reply: wrote (client=129800060941563857535569923226995055452 request=38)
2025-12-12 18:42:39.894Z debug(clock): 2: synchronized: truechimers=2/3 clock_offset=0ns..0ns accuracy=0ns
2025-12-12 18:42:39.894Z debug(clock): 2: system time is 140ns behind
2025-12-12 18:42:39.895Z debug(replica): 2N: on_message: view=2 status=normal vsr.message_header.Header.Request{ .checksum = 222018071360485593436269594250421467889, .checksum_padding = 0, .checksum_body = 8534786181244049314008013070841583767, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2064, .epoch = 0, .view = 2, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 2389995664003248079491962550587178037, .parent_padding = 0, .client = 129800060941563857535569923226995055452, .session = 2, .timestamp = 0, .request = 76, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 3235067822, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 18:42:39.895Z debug(replica): 2N: on_request: new request
2025-12-12 18:42:39.895Z debug(replica): 2N: primary_pipeline_prepare: request checksum=222018071360485593436269594250421467889 client=129800060941563857535569923226995055452
2025-12-12 18:42:39.895Z debug(replica): 2N: primary_pipeline_prepare: prepare checksum=46115641683022957382704522545044726900 op=78
2025-12-12 18:42:39.895Z debug(vsr): 2: prepare_timeout started
2025-12-12 18:42:39.895Z debug(vsr): 2: primary_abdicate_timeout started
2025-12-12 18:42:39.895Z debug(vsr): 2: pulse_timeout reset
2025-12-12 18:42:39.895Z debug(replica): 2N: replicate: replicating op=78 to replica 0
2025-12-12 18:42:39.895Z debug(replica): 2N: sending prepare to replica 0: vsr.message_header.Header.Prepare{ .checksum = 46115641683022957382704522545044726900, .checksum_padding = 0, .checksum_body = 8534786181244049314008013070841583767, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2064, .epoch = 0, .view = 2, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 101835763928779581347929029942247644699, .parent_padding = 0, .request_checksum = 222018071360485593436269594250421467889, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 129800060941563857535569923226995055452, .op = 78, .commit = 77, .timestamp = 1765564959895449179, .request = 76, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-12-12 18:42:39.913Z debug(replica): 1n: client_table_entry_update: client=129800060941563857535569923226995055452 session=2 request=75
2025-12-12 18:42:39.895Z debug(message_bus): 2: send_message_to_replica: no connection to=0 header=vsr.message_header.Header.Prepare{ .checksum = 46115641683022957382704522545044726900, .checksum_padding = 0, .checksum_body = 8534786181244049314008013070841583767, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2064, .epoch = 0, .view = 2, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 101835763928779581347929029942247644699, .parent_padding = 0, .request_checksum = 222018071360485593436269594250421467889, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 129800060941563857535569923226995055452, .op = 78, .commit = 77, .timestamp = 1765564959895449179, .request = 76, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-12-12 18:42:39.898Z debug(replica): 0n: execute_op: executing view=2 primary=false op=41 checksum=313933083824253185809696232442301052167 (create_transfers)
2025-12-12 18:42:39.913Z debug(replica): 1n: execute_op: replying to client: vsr.message_header.Header.Reply{ .checksum = 317489432491163695941499283033090917089, .checksum_padding = 0, .checksum_body = 281711844982843542114175711130321012796, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 400, .epoch = 0, .view = 2, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 309799047143092972233297483117665828805, .request_checksum_padding = 0, .context = 2389995664003248079491962550587178037, .context_padding = 0, .client = 129800060941563857535569923226995055452, .op = 77, .commit = 77, .timestamp = 1765564959793115706, .request = 75, .operation = vsr.Operation(139), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 18:42:42.996Z debug(replica): 2N: replicate: replicating op=78 to replica 1
2025-12-12 18:42:42.996Z debug(replica): 0n: execute_op: commit_timestamp=1765564874139361331 prepare.header.timestamp=1765564874192112921
2025-12-12 18:42:42.996Z debug(replica): 2N: sending prepare to replica 1: vsr.message_header.Header.Prepare{ .checksum = 46115641683022957382704522545044726900, .checksum_padding = 0, .checksum_body = 8534786181244049314008013070841583767, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2064, .epoch = 0, .view = 2, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 101835763928779581347929029942247644699, .parent_padding = 0, .request_checksum = 222018071360485593436269594250421467889, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 129800060941563857535569923226995055452, .op = 78, .commit = 77, .timestamp = 1765564959895449179, .request = 76, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-12-12 18:42:42.996Z debug(replica): 1n: sending reply to client 129800060941563857535569923226995055452: vsr.message_header.Header.Reply{ .checksum = 317489432491163695941499283033090917089, .checksum_padding = 0, .checksum_body = 281711844982843542114175711130321012796, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 400, .epoch = 0, .view = 2, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 309799047143092972233297483117665828805, .request_checksum_padding = 0, .context = 2389995664003248079491962550587178037, .context_padding = 0, .client = 129800060941563857535569923226995055452, .op = 77, .commit = 77, .timestamp = 1765564959793115706, .request = 75, .operation = vsr.Operation(139), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 18:42:42.996Z debug(forest): entering forest.compact() op=77 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2025-12-12 18:42:42.996Z debug(replica): 2N: on_prepare: advancing: op=77..78 checksum=101835763928779581347929029942247644699..46115641683022957382704522545044726900
2025-12-12 18:42:42.996Z debug(journal): 2: set_header_as_dirty: op=78 checksum=46115641683022957382704522545044726900
2025-12-12 18:42:42.996Z debug(replica): 2N: append: appending to journal op=78
2025-12-12 18:42:42.996Z debug(journal): 2: write: view=2 slot=78 op=78 len=2064: 46115641683022957382704522545044726900 starting
2025-12-12 18:42:42.996Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.prepares offset=81788928 len=4096 locked
2025-12-12 18:42:42.997Z debug(replica): 2N: on_message: view=2 status=normal vsr.message_header.Header.Request{ .checksum = 222018071360485593436269594250421467889, .checksum_padding = 0, .checksum_body = 8534786181244049314008013070841583767, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2064, .epoch = 0, .view = 2, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 2389995664003248079491962550587178037, .parent_padding = 0, .client = 129800060941563857535569923226995055452, .session = 2, .timestamp = 0, .request = 76, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 3235067822, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 18:42:42.997Z debug(replica): 2N: on_request: new request
2025-12-12 18:42:42.997Z debug(replica): 2N: on_request: ignoring (already preparing)
2025-12-12 18:42:42.997Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.prepares offset=81788928 len=4096 unlocked
2025-12-12 18:42:42.997Z debug(journal): 2: write_header: op=78 sectors[16384..20480]
2025-12-12 18:42:42.997Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.headers offset=16384 len=4096 locked
2025-12-12 18:42:42.997Z debug(vsr): 2: journal_repair_budget_timeout fired
2025-12-12 18:42:42.997Z debug(vsr): 2: journal_repair_budget_timeout reset
2025-12-12 18:42:42.997Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.headers offset=16384 len=4096 unlocked
2025-12-12 18:42:42.997Z debug(journal): 2: write: view=2 slot=78 op=78 len=2064: 46115641683022957382704522545044726900 complete, marking clean
2025-12-12 18:42:42.997Z debug(replica): 2N: send_prepare_ok: op=78 checksum=46115641683022957382704522545044726900
2025-12-12 18:42:42.997Z debug(replica): 2N: sending prepare_ok to replica 2: vsr.message_header.Header.PrepareOk{ .checksum = 197960089349385150244634103778349688043, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 2, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 101835763928779581347929029942247644699, .parent_padding = 0, .prepare_checksum = 46115641683022957382704522545044726900, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 129800060941563857535569923226995055452, .op = 78, .commit_min = 77, .timestamp = 1765564959895449179, .request = 76, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-12-12 18:42:42.997Z debug(replica): 2N: on_message: view=2 status=normal vsr.message_header.Header.PrepareOk{ .checksum = 197960089349385150244634103778349688043, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 2, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 101835763928779581347929029942247644699, .parent_padding = 0, .prepare_checksum = 46115641683022957382704522545044726900, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 129800060941563857535569923226995055452, .op = 78, .commit_min = 77, .timestamp = 1765564959895449179, .request = 76, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-12-12 18:42:42.997Z debug(vsr): 2: primary_abdicate_timeout reset
2025-12-12 18:42:42.997Z debug(replica): 2N: on_prepare_ok: 1 message(s)
2025-12-12 18:42:42.997Z debug(replica): 2N: on_prepare_ok: waiting for quorum
2025-12-12 18:42:43.008Z warning(replica): 1n: commit_dispatch: slow request, request=75 size=819456 create_transfers time=3123ms
2025-12-12 18:42:43.008Z debug(replica): 1n: on_message: view=2 status=normal vsr.message_header.Header.Prepare{ .checksum = 46115641683022957382704522545044726900, .checksum_padding = 0, .checksum_body = 8534786181244049314008013070841583767, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2064, .epoch = 0, .view = 2, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 101835763928779581347929029942247644699, .parent_padding = 0, .request_checksum = 222018071360485593436269594250421467889, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 129800060941563857535569923226995055452, .op = 78, .commit = 77, .timestamp = 1765564959895449179, .request = 76, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-12-12 18:42:43.008Z debug(replica): 1n: on_prepare: caching prepare.op=78 (commit_min=77 op=77 commit_max=77 prepare_max=1007)
2025-12-12 18:42:43.008Z debug(replica): 1n: on_prepare: advancing: op=77..78 checksum=101835763928779581347929029942247644699..46115641683022957382704522545044726900
2025-12-12 18:42:43.008Z debug(journal): 1: set_header_as_dirty: op=78 checksum=46115641683022957382704522545044726900
2025-12-12 18:42:43.008Z debug(replica): 1n: append: appending to journal op=78
2025-12-12 18:42:43.008Z debug(journal): 1: write: view=2 slot=78 op=78 len=2064: 46115641683022957382704522545044726900 starting
2025-12-12 18:42:43.008Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.prepares offset=81788928 len=4096 locked
2025-12-12 18:42:43.008Z debug(replica): 1n: repair_prepare: op=78 checksum=46115641683022957382704522545044726900 (already writing)
2025-12-12 18:42:43.009Z debug(client_replies): 1: write_reply: wrote (client=129800060941563857535569923226995055452 request=75)
2025-12-12 18:42:43.009Z warning(clock): 1: synchronization failed, partitioned (sources=1 samples=1)
2025-12-12 18:42:43.009Z debug(vsr): 1: journal_repair_budget_timeout fired
2025-12-12 18:42:43.009Z debug(vsr): 1: journal_repair_budget_timeout reset
2025-12-12 18:42:43.009Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.prepares offset=81788928 len=4096 unlocked
2025-12-12 18:42:43.009Z debug(journal): 1: write_header: op=78 sectors[16384..20480]
2025-12-12 18:42:43.009Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.headers offset=16384 len=4096 locked
2025-12-12 18:42:43.009Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.headers offset=16384 len=4096 unlocked
2025-12-12 18:42:43.009Z debug(journal): 1: write: view=2 slot=78 op=78 len=2064: 46115641683022957382704522545044726900 complete, marking clean
2025-12-12 18:42:43.009Z debug(replica): 1n: send_prepare_ok: op=78 checksum=46115641683022957382704522545044726900
2025-12-12 18:42:43.009Z debug(replica): 1n: sending prepare_ok to replica 2: vsr.message_header.Header.PrepareOk{ .checksum = 223736406924101654602942303172475903893, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 2, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 101835763928779581347929029942247644699, .parent_padding = 0, .prepare_checksum = 46115641683022957382704522545044726900, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 129800060941563857535569923226995055452, .op = 78, .commit_min = 77, .timestamp = 1765564959895449179, .request = 76, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-12-12 18:42:43.010Z debug(replica): 2N: on_message: view=2 status=normal vsr.message_header.Header.PrepareOk{ .checksum = 223736406924101654602942303172475903893, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 2, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 101835763928779581347929029942247644699, .parent_padding = 0, .prepare_checksum = 46115641683022957382704522545044726900, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 129800060941563857535569923226995055452, .op = 78, .commit_min = 77, .timestamp = 1765564959895449179, .request = 76, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-12-12 18:42:43.010Z debug(vsr): 2: primary_abdicate_timeout reset
2025-12-12 18:42:43.010Z debug(replica): 2N: on_prepare_ok: 2 message(s)
2025-12-12 18:42:43.010Z debug(replica): 2N: on_prepare_ok: quorum received, context=46115641683022957382704522545044726900
2025-12-12 18:42:43.010Z debug(vsr): 2: prepare_timeout stopped
2025-12-12 18:42:43.010Z debug(vsr): 2: primary_abdicate_timeout stopped
2025-12-12 18:42:43.011Z debug(replica): 2N: execute_op: executing view=2 primary=true op=78 checksum=46115641683022957382704522545044726900 (lookup_accounts)
2025-12-12 18:42:43.011Z debug(replica): 2N: execute_op: commit_timestamp=1765564959793115706 prepare.header.timestamp=1765564959895449179
2025-12-12 18:42:43.011Z debug(replica): 2N: execute_op: advancing commit_max=77..78
2025-12-12 18:42:43.011Z debug(replica): 2N: client_table_entry_update: client=129800060941563857535569923226995055452 session=2 request=76
2025-12-12 18:42:43.011Z debug(replica): 2N: execute_op: replying to client: vsr.message_header.Header.Reply{ .checksum = 192802211311154397628432765459808932228, .checksum_padding = 0, .checksum_body = 26981266217336085848273889805535514864, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 14720, .epoch = 0, .view = 2, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 222018071360485593436269594250421467889, .request_checksum_padding = 0, .context = 52163284225307700928990644246979232354, .context_padding = 0, .client = 129800060941563857535569923226995055452, .op = 78, .commit = 78, .timestamp = 1765564959895449179, .request = 76, .operation = vsr.Operation(140), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 18:42:43.011Z debug(replica): 2N: sending reply to client 129800060941563857535569923226995055452: vsr.message_header.Header.Reply{ .checksum = 192802211311154397628432765459808932228, .checksum_padding = 0, .checksum_body = 26981266217336085848273889805535514864, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 14720, .epoch = 0, .view = 2, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 222018071360485593436269594250421467889, .request_checksum_padding = 0, .context = 52163284225307700928990644246979232354, .context_padding = 0, .client = 129800060941563857535569923226995055452, .op = 78, .commit = 78, .timestamp = 1765564959895449179, .request = 76, .operation = vsr.Operation(140), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 18:42:43.011Z debug(forest): entering forest.compact() op=78 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
warning(client): 129800060941563857535569923226995055452: on_reply: slow request, request=76 op=78 size=2064 lookup_accounts time=3116ms
2025-12-12 18:42:43.011Z info(workload): accounts created = 112, transfers = 126362, pending transfers = 0, commands run = 38
2025-12-12 18:42:43.012Z debug(client_replies): 2: write_reply: wrote (client=129800060941563857535569923226995055452 request=76)
2025-12-12 18:42:43.014Z debug(replica): 0n: client_table_entry_update: client=129800060941563857535569923226995055452 session=2 request=39
2025-12-12 18:42:43.014Z debug(forest): entering forest.compact() op=41 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2025-12-12 18:42:43.017Z debug(vsr): 2: journal_repair_budget_timeout fired
2025-12-12 18:42:43.017Z debug(vsr): 2: journal_repair_budget_timeout reset
2025-12-12 18:42:43.022Z warning(replica): 0n: commit_dispatch: slow request, request=39 size=526592 create_transfers time=3126ms
2025-12-12 18:42:43.022Z debug(replica): 0n: on_message: view=2 status=normal vsr.message_header.Header.Request{ .checksum = 222018071360485593436269594250421467889, .checksum_padding = 0, .checksum_body = 8534786181244049314008013070841583767, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2064, .epoch = 0, .view = 2, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 2389995664003248079491962550587178037, .parent_padding = 0, .client = 129800060941563857535569923226995055452, .session = 2, .timestamp = 0, .request = 76, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 3235067822, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 18:42:43.022Z debug(replica): 0n: on_request: forwarding new request to primary (view=2)
2025-12-12 18:42:43.022Z debug(replica): 0n: sending request to replica 2: vsr.message_header.Header.Request{ .checksum = 222018071360485593436269594250421467889, .checksum_padding = 0, .checksum_body = 8534786181244049314008013070841583767, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2064, .epoch = 0, .view = 2, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 2389995664003248079491962550587178037, .parent_padding = 0, .client = 129800060941563857535569923226995055452, .session = 2, .timestamp = 0, .request = 76, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 3235067822, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 18:42:43.023Z debug(client_replies): 0: write_reply: wrote (client=129800060941563857535569923226995055452 request=39)
2025-12-12 18:42:43.023Z debug(replica): 2N: on_message: view=2 status=normal vsr.message_header.Header.Request{ .checksum = 222018071360485593436269594250421467889, .checksum_padding = 0, .checksum_body = 8534786181244049314008013070841583767, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2064, .epoch = 0, .view = 2, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 2389995664003248079491962550587178037, .parent_padding = 0, .client = 129800060941563857535569923226995055452, .session = 2, .timestamp = 0, .request = 76, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 3235067822, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 18:42:43.023Z debug(replica): 2N: on_request: replying to duplicate request
2025-12-12 18:42:43.023Z debug(client_replies): 2: read_reply: start (client=129800060941563857535569923226995055452 reply=192802211311154397628432765459808932228)
2025-12-12 18:42:43.023Z debug(replica): 0n: on_message: view=2 status=normal vsr.message_header.Header.Request{ .checksum = 222018071360485593436269594250421467889, .checksum_padding = 0, .checksum_body = 8534786181244049314008013070841583767, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2064, .epoch = 0, .view = 2, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 2389995664003248079491962550587178037, .parent_padding = 0, .client = 129800060941563857535569923226995055452, .session = 2, .timestamp = 0, .request = 76, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 3235067822, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 18:42:43.023Z debug(replica): 0n: on_request: forwarding new request to primary (view=2)
2025-12-12 18:42:43.023Z debug(replica): 0n: sending request to replica 2: vsr.message_header.Header.Request{ .checksum = 222018071360485593436269594250421467889, .checksum_padding = 0, .checksum_body = 8534786181244049314008013070841583767, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2064, .epoch = 0, .view = 2, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 2389995664003248079491962550587178037, .parent_padding = 0, .client = 129800060941563857535569923226995055452, .session = 2, .timestamp = 0, .request = 76, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 3235067822, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 18:42:43.023Z debug(replica): 2N: on_message: view=2 status=normal vsr.message_header.Header.Request{ .checksum = 222018071360485593436269594250421467889, .checksum_padding = 0, .checksum_body = 8534786181244049314008013070841583767, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2064, .epoch = 0, .view = 2, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 2389995664003248079491962550587178037, .parent_padding = 0, .client = 129800060941563857535569923226995055452, .session = 2, .timestamp = 0, .request = 76, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 3235067822, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 18:42:43.023Z debug(replica): 2N: on_request: replying to duplicate request
2025-12-12 18:42:43.023Z debug(client_replies): 2: read_reply: busy (client=129800060941563857535569923226995055452 reply=192802211311154397628432765459808932228)
2025-12-12 18:42:43.023Z debug(replica): 2N: on_request: ignoring (client_replies busy)
2025-12-12 18:42:43.023Z debug(client_replies): 2: read_reply: done (client=129800060941563857535569923226995055452 reply=192802211311154397628432765459808932228)
2025-12-12 18:42:43.023Z debug(replica): 2N: on_request: repeat reply (client=129800060941563857535569923226995055452 request=76)
2025-12-12 18:42:43.023Z debug(replica): 2N: sending reply to client 129800060941563857535569923226995055452: vsr.message_header.Header.Reply{ .checksum = 192802211311154397628432765459808932228, .checksum_padding = 0, .checksum_body = 26981266217336085848273889805535514864, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 14720, .epoch = 0, .view = 2, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 222018071360485593436269594250421467889, .request_checksum_padding = 0, .context = 52163284225307700928990644246979232354, .context_padding = 0, .client = 129800060941563857535569923226995055452, .op = 78, .commit = 78, .timestamp = 1765564959895449179, .request = 76, .operation = vsr.Operation(140), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 18:42:43.027Z debug(replica): 2N: on_message: view=2 status=normal vsr.message_header.Header.Request{ .checksum = 259907725549595238925131762988644609507, .checksum_padding = 0, .checksum_body = 127212965177050289868558095111329653171, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 811392, .epoch = 0, .view = 2, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 52163284225307700928990644246979232354, .parent_padding = 0, .client = 129800060941563857535569923226995055452, .session = 2, .timestamp = 0, .request = 77, .operation = vsr.Operation(139), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 3116486090, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 18:42:43.027Z debug(replica): 1n: on_message: view=2 status=normal vsr.message_header.Header.Request{ .checksum = 259907725549595238925131762988644609507, .checksum_padding = 0, .checksum_body = 127212965177050289868558095111329653171, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 811392, .epoch = 0, .view = 2, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 52163284225307700928990644246979232354, .parent_padding = 0, .client = 129800060941563857535569923226995055452, .session = 2, .timestamp = 0, .request = 77, .operation = vsr.Operation(139), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 3116486090, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 18:42:43.027Z debug(replica): 2N: on_request: new request
2025-12-12 18:42:43.027Z debug(replica): 1n: on_request: forwarding new request to primary (view=2)
2025-12-12 18:42:43.027Z debug(replica): 2N: primary_pipeline_prepare: request checksum=259907725549595238925131762988644609507 client=129800060941563857535569923226995055452
2025-12-12 18:42:43.027Z debug(replica): 1n: sending request to replica 2: vsr.message_header.Header.Request{ .checksum = 259907725549595238925131762988644609507, .checksum_padding = 0, .checksum_body = 127212965177050289868558095111329653171, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 811392, .epoch = 0, .view = 2, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 52163284225307700928990644246979232354, .parent_padding = 0, .client = 129800060941563857535569923226995055452, .session = 2, .timestamp = 0, .request = 77, .operation = vsr.Operation(139), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 3116486090, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 18:42:43.029Z debug(vsr): 1: journal_repair_budget_timeout fired
2025-12-12 18:42:43.029Z debug(vsr): 1: journal_repair_budget_timeout reset
2025-12-12 18:42:43.031Z debug(replica): 2N: primary_pipeline_prepare: prepare checksum=278798001163306172812375157407290329283 op=79
2025-12-12 18:42:43.031Z debug(vsr): 2: prepare_timeout started
2025-12-12 18:42:43.031Z debug(vsr): 2: primary_abdicate_timeout started
2025-12-12 18:42:43.031Z debug(vsr): 2: pulse_timeout reset
2025-12-12 18:42:43.031Z debug(replica): 2N: replicate: replicating op=79 to replica 0
2025-12-12 18:42:43.031Z debug(replica): 2N: sending prepare to replica 0: vsr.message_header.Header.Prepare{ .checksum = 278798001163306172812375157407290329283, .checksum_padding = 0, .checksum_body = 127212965177050289868558095111329653171, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 811392, .epoch = 0, .view = 2, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 46115641683022957382704522545044726900, .parent_padding = 0, .request_checksum = 259907725549595238925131762988644609507, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 129800060941563857535569923226995055452, .op = 79, .commit = 78, .timestamp = 1765564963027427105, .request = 77, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-12-12 18:42:43.031Z debug(message_bus): 2: send_message_to_replica: no connection to=0 header=vsr.message_header.Header.Prepare{ .checksum = 278798001163306172812375157407290329283, .checksum_padding = 0, .checksum_body = 127212965177050289868558095111329653171, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 811392, .epoch = 0, .view = 2, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 46115641683022957382704522545044726900, .parent_padding = 0, .request_checksum = 259907725549595238925131762988644609507, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 129800060941563857535569923226995055452, .op = 79, .commit = 78, .timestamp = 1765564963027427105, .request = 77, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-12-12 18:42:43.031Z debug(replica): 2N: replicate: replicating op=79 to replica 1
2025-12-12 18:42:43.031Z debug(replica): 2N: sending prepare to replica 1: vsr.message_header.Header.Prepare{ .checksum = 278798001163306172812375157407290329283, .checksum_padding = 0, .checksum_body = 127212965177050289868558095111329653171, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 811392, .epoch = 0, .view = 2, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 46115641683022957382704522545044726900, .parent_padding = 0, .request_checksum = 259907725549595238925131762988644609507, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 129800060941563857535569923226995055452, .op = 79, .commit = 78, .timestamp = 1765564963027427105, .request = 77, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-12-12 18:42:43.031Z debug(replica): 2N: on_prepare: advancing: op=78..79 checksum=46115641683022957382704522545044726900..278798001163306172812375157407290329283
2025-12-12 18:42:43.031Z debug(journal): 2: set_header_as_dirty: op=79 checksum=278798001163306172812375157407290329283
2025-12-12 18:42:43.031Z debug(replica): 2N: append: appending to journal op=79
2025-12-12 18:42:43.031Z debug(journal): 2: write: view=2 slot=79 op=79 len=811392: 278798001163306172812375157407290329283 starting
2025-12-12 18:42:43.031Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.prepares offset=82837504 len=815104 locked
2025-12-12 18:42:43.033Z debug(vsr): 0: journal_repair_budget_timeout fired
2025-12-12 18:42:43.033Z debug(vsr): 0: journal_repair_budget_timeout reset
2025-12-12 18:42:43.035Z debug(replica): 1n: on_message: view=2 status=normal vsr.message_header.Header.Prepare{ .checksum = 278798001163306172812375157407290329283, .checksum_padding = 0, .checksum_body = 127212965177050289868558095111329653171, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 811392, .epoch = 0, .view = 2, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 46115641683022957382704522545044726900, .parent_padding = 0, .request_checksum = 259907725549595238925131762988644609507, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 129800060941563857535569923226995055452, .op = 79, .commit = 78, .timestamp = 1765564963027427105, .request = 77, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-12-12 18:42:43.035Z debug(replica): 1n: on_prepare: advancing commit_max=77..78
2025-12-12 18:42:43.035Z debug(replica): 1n: on_prepare: caching prepare.op=79 (commit_min=77 op=78 commit_max=78 prepare_max=1007)
2025-12-12 18:42:43.035Z debug(replica): 1n: on_prepare: advancing: op=78..79 checksum=46115641683022957382704522545044726900..278798001163306172812375157407290329283
2025-12-12 18:42:43.035Z debug(journal): 1: set_header_as_dirty: op=79 checksum=278798001163306172812375157407290329283
2025-12-12 18:42:43.035Z debug(replica): 1n: append: appending to journal op=79
2025-12-12 18:42:43.035Z debug(journal): 1: write: view=2 slot=79 op=79 len=811392: 278798001163306172812375157407290329283 starting
2025-12-12 18:42:43.035Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.prepares offset=82837504 len=815104 locked
2025-12-12 18:42:43.035Z debug(replica): 1n: commit_start_journal: cached prepare op=78 checksum=46115641683022957382704522545044726900
2025-12-12 18:42:43.035Z debug(replica): 1n: repair_prepare: op=79 checksum=278798001163306172812375157407290329283 (already writing)
2025-12-12 18:42:43.035Z debug(replica): 1n: commit_journal: already committing (prefetch; commit_min=77)
2025-12-12 18:42:43.035Z debug(replica): 1n: execute_op: executing view=2 primary=false op=78 checksum=46115641683022957382704522545044726900 (lookup_accounts)
2025-12-12 18:42:43.035Z debug(replica): 1n: execute_op: commit_timestamp=1765564959793115706 prepare.header.timestamp=1765564959895449179
2025-12-12 18:42:43.035Z debug(replica): 2N: on_message: view=2 status=normal vsr.message_header.Header.Request{ .checksum = 259907725549595238925131762988644609507, .checksum_padding = 0, .checksum_body = 127212965177050289868558095111329653171, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 811392, .epoch = 0, .view = 2, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 52163284225307700928990644246979232354, .parent_padding = 0, .client = 129800060941563857535569923226995055452, .session = 2, .timestamp = 0, .request = 77, .operation = vsr.Operation(139), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 3116486090, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 18:42:43.035Z debug(replica): 1n: client_table_entry_update: client=129800060941563857535569923226995055452 session=2 request=76
2025-12-12 18:42:43.035Z debug(forest): entering forest.compact() op=78 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2025-12-12 18:42:43.035Z debug(replica): 2N: on_request: new request
2025-12-12 18:42:43.035Z debug(replica): 2N: on_request: ignoring (already preparing)
2025-12-12 18:42:43.035Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.prepares offset=82837504 len=815104 unlocked
2025-12-12 18:42:43.035Z debug(journal): 2: write_header: op=79 sectors[16384..20480]
2025-12-12 18:42:43.035Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.headers offset=16384 len=4096 locked
2025-12-12 18:42:43.035Z debug(client_replies): 1: write_reply: wrote (client=129800060941563857535569923226995055452 request=76)
2025-12-12 18:42:43.036Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.prepares offset=82837504 len=815104 unlocked
2025-12-12 18:42:43.036Z debug(journal): 1: write_header: op=79 sectors[16384..20480]
2025-12-12 18:42:43.036Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.headers offset=16384 len=4096 locked
2025-12-12 18:42:43.036Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.headers offset=16384 len=4096 unlocked
2025-12-12 18:42:43.036Z debug(journal): 1: write: view=2 slot=79 op=79 len=811392: 278798001163306172812375157407290329283 complete, marking clean
2025-12-12 18:42:43.036Z debug(replica): 1n: send_prepare_ok: op=79 checksum=278798001163306172812375157407290329283
2025-12-12 18:42:43.036Z debug(replica): 1n: sending prepare_ok to replica 2: vsr.message_header.Header.PrepareOk{ .checksum = 17997161744864128781538992078944372760, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 2, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 46115641683022957382704522545044726900, .parent_padding = 0, .prepare_checksum = 278798001163306172812375157407290329283, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 129800060941563857535569923226995055452, .op = 79, .commit_min = 78, .timestamp = 1765564963027427105, .request = 77, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-12-12 18:42:43.045Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.headers offset=16384 len=4096 unlocked
2025-12-12 18:42:43.045Z debug(journal): 2: write: view=2 slot=79 op=79 len=811392: 278798001163306172812375157407290329283 complete, marking clean
2025-12-12 18:42:43.045Z debug(replica): 2N: send_prepare_ok: op=79 checksum=278798001163306172812375157407290329283
2025-12-12 18:42:43.046Z debug(replica): 2N: sending prepare_ok to replica 2: vsr.message_header.Header.PrepareOk{ .checksum = 207104623018271658605040954923824132720, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 2, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 46115641683022957382704522545044726900, .parent_padding = 0, .prepare_checksum = 278798001163306172812375157407290329283, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 129800060941563857535569923226995055452, .op = 79, .commit_min = 78, .timestamp = 1765564963027427105, .request = 77, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-12-12 18:42:43.046Z debug(replica): 2N: on_message: view=2 status=normal vsr.message_header.Header.PrepareOk{ .checksum = 207104623018271658605040954923824132720, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 2, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 46115641683022957382704522545044726900, .parent_padding = 0, .prepare_checksum = 278798001163306172812375157407290329283, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 129800060941563857535569923226995055452, .op = 79, .commit_min = 78, .timestamp = 1765564963027427105, .request = 77, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-12-12 18:42:43.046Z debug(vsr): 2: primary_abdicate_timeout reset
2025-12-12 18:42:43.046Z debug(replica): 2N: on_prepare_ok: 1 message(s)
2025-12-12 18:42:43.046Z debug(replica): 2N: on_prepare_ok: waiting for quorum
2025-12-12 18:42:43.046Z debug(vsr): 2: journal_repair_budget_timeout fired
2025-12-12 18:42:43.046Z debug(vsr): 2: journal_repair_budget_timeout reset
2025-12-12 18:42:43.049Z debug(vsr): 1: start_view_change_message_timeout fired
2025-12-12 18:42:43.049Z debug(vsr): 1: start_view_change_message_timeout reset
2025-12-12 18:42:43.049Z debug(vsr): 1: journal_repair_budget_timeout fired
2025-12-12 18:42:43.049Z debug(vsr): 1: journal_repair_budget_timeout reset
2025-12-12 18:42:43.049Z debug(vsr): 1: journal_repair_timeout fired
2025-12-12 18:42:43.049Z debug(vsr): 1: journal_repair_timeout reset
2025-12-12 18:42:43.049Z debug(vsr): 1: grid_repair_budget_timeout fired
2025-12-12 18:42:43.049Z debug(vsr): 1: grid_repair_budget_timeout reset
2025-12-12 18:42:43.053Z debug(vsr): 0: journal_repair_budget_timeout fired
2025-12-12 18:42:43.053Z debug(vsr): 0: journal_repair_budget_timeout reset
2025-12-12 18:42:43.053Z debug(vsr): 0: journal_repair_timeout fired
2025-12-12 18:42:43.053Z debug(vsr): 0: journal_repair_timeout reset
2025-12-12 18:42:43.066Z debug(vsr): 2: journal_repair_budget_timeout fired
2025-12-12 18:42:43.066Z debug(vsr): 2: journal_repair_budget_timeout reset
2025-12-12 18:42:43.069Z debug(vsr): 1: journal_repair_budget_timeout fired
2025-12-12 18:42:43.069Z debug(vsr): 1: journal_repair_budget_timeout reset
2025-12-12 18:42:43.072Z debug(replica): 2N: on_message: view=2 status=normal vsr.message_header.Header.PrepareOk{ .checksum = 17997161744864128781538992078944372760, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 2, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 46115641683022957382704522545044726900, .parent_padding = 0, .prepare_checksum = 278798001163306172812375157407290329283, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 129800060941563857535569923226995055452, .op = 79, .commit_min = 78, .timestamp = 1765564963027427105, .request = 77, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-12-12 18:42:43.072Z debug(vsr): 2: primary_abdicate_timeout reset
2025-12-12 18:42:43.072Z debug(replica): 2N: on_prepare_ok: 2 message(s)
2025-12-12 18:42:43.072Z debug(replica): 2N: on_prepare_ok: quorum received, context=278798001163306172812375157407290329283
2025-12-12 18:42:43.072Z debug(vsr): 2: prepare_timeout stopped
2025-12-12 18:42:43.072Z debug(vsr): 2: primary_abdicate_timeout stopped
2025-12-12 18:42:43.073Z debug(vsr): 0: journal_repair_budget_timeout fired
2025-12-12 18:42:43.073Z debug(vsr): 0: journal_repair_budget_timeout reset
2025-12-12 18:42:43.075Z debug(replica): 2N: execute_op: executing view=2 primary=true op=79 checksum=278798001163306172812375157407290329283 (create_transfers)
2025-12-12 18:42:43.075Z debug(replica): 2N: execute_op: commit_timestamp=1765564959895449179 prepare.header.timestamp=1765564963027427105
2025-12-12 18:42:43.089Z debug(vsr): 1: journal_repair_budget_timeout fired
2025-12-12 18:42:43.089Z debug(vsr): 1: journal_repair_budget_timeout reset
2025-12-12 18:42:43.093Z debug(vsr): 0: journal_repair_budget_timeout fired
2025-12-12 18:42:43.093Z debug(vsr): 0: journal_repair_budget_timeout reset
2025-12-12 18:42:43.101Z debug(replica): 2N: execute_op: advancing commit_max=78..79
2025-12-12 18:42:43.101Z debug(replica): 2N: client_table_entry_update: client=129800060941563857535569923226995055452 session=2 request=77
2025-12-12 18:42:43.101Z debug(replica): 2N: execute_op: replying to client: vsr.message_header.Header.Reply{ .checksum = 260994595275693577425366555167592702421, .checksum_padding = 0, .checksum_body = 123952473893376277661007810235207256912, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 536, .epoch = 0, .view = 2, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 259907725549595238925131762988644609507, .request_checksum_padding = 0, .context = 263132283239105641758566867392209782006, .context_padding = 0, .client = 129800060941563857535569923226995055452, .op = 79, .commit = 79, .timestamp = 1765564963027427105, .request = 77, .operation = vsr.Operation(139), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 18:42:43.101Z debug(replica): 2N: sending reply to client 129800060941563857535569923226995055452: vsr.message_header.Header.Reply{ .checksum = 260994595275693577425366555167592702421, .checksum_padding = 0, .checksum_body = 123952473893376277661007810235207256912, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 536, .epoch = 0, .view = 2, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 259907725549595238925131762988644609507, .request_checksum_padding = 0, .context = 263132283239105641758566867392209782006, .context_padding = 0, .client = 129800060941563857535569923226995055452, .op = 79, .commit = 79, .timestamp = 1765564963027427105, .request = 77, .operation = vsr.Operation(139), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 18:42:43.101Z debug(forest): entering forest.compact() op=79 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=true half_beat=false last_beat=false
2025-12-12 18:42:43.101Z debug(manifest_log): 2: flush: writing 0 block(s)
2025-12-12 18:42:43.109Z debug(vsr): 1: journal_repair_budget_timeout fired
2025-12-12 18:42:43.109Z debug(vsr): 1: journal_repair_budget_timeout reset
2025-12-12 18:42:43.113Z debug(vsr): 0: journal_repair_budget_timeout fired
2025-12-12 18:42:43.113Z debug(vsr): 0: journal_repair_budget_timeout reset
2025-12-12 18:42:43.114Z debug(client_replies): 2: write_reply: wrote (client=129800060941563857535569923226995055452 request=77)
2025-12-12 18:42:43.124Z debug(vsr): 2: journal_repair_budget_timeout fired
2025-12-12 18:42:43.124Z debug(vsr): 2: journal_repair_budget_timeout reset
2025-12-12 18:42:43.124Z debug(vsr): 2: journal_repair_timeout fired
2025-12-12 18:42:43.124Z debug(vsr): 2: journal_repair_timeout reset
2025-12-12 18:42:43.129Z debug(vsr): 1: journal_repair_budget_timeout fired
2025-12-12 18:42:43.129Z debug(vsr): 1: journal_repair_budget_timeout reset
2025-12-12 18:42:43.130Z debug(replica): 2N: on_message: view=2 status=normal vsr.message_header.Header.Request{ .checksum = 220267228703775834723431662919395147223, .checksum_padding = 0, .checksum_body = 8534786181244049314008013070841583767, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2064, .epoch = 0, .view = 2, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 263132283239105641758566867392209782006, .parent_padding = 0, .client = 129800060941563857535569923226995055452, .session = 2, .timestamp = 0, .request = 78, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 83277593, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 18:42:43.130Z debug(replica): 0n: on_message: view=2 status=normal vsr.message_header.Header.Request{ .checksum = 220267228703775834723431662919395147223, .checksum_padding = 0, .checksum_body = 8534786181244049314008013070841583767, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2064, .epoch = 0, .view = 2, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 263132283239105641758566867392209782006, .parent_padding = 0, .client = 129800060941563857535569923226995055452, .session = 2, .timestamp = 0, .request = 78, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 83277593, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 18:42:43.130Z debug(replica): 0n: on_request: forwarding new request to primary (view=2)
2025-12-12 18:42:43.130Z debug(replica): 2N: on_request: new request
2025-12-12 18:42:43.130Z debug(replica): 2N: primary_pipeline_prepare: request checksum=220267228703775834723431662919395147223 client=129800060941563857535569923226995055452
2025-12-12 18:42:43.130Z debug(replica): 0n: sending request to replica 2: vsr.message_header.Header.Request{ .checksum = 220267228703775834723431662919395147223, .checksum_padding = 0, .checksum_body = 8534786181244049314008013070841583767, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2064, .epoch = 0, .view = 2, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 263132283239105641758566867392209782006, .parent_padding = 0, .client = 129800060941563857535569923226995055452, .session = 2, .timestamp = 0, .request = 78, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 83277593, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 18:42:43.130Z debug(replica): 2N: primary_pipeline_prepare: prepare checksum=190906259201884426279323688639025730549 op=80
2025-12-12 18:42:43.130Z debug(vsr): 2: prepare_timeout started
2025-12-12 18:42:43.130Z debug(vsr): 2: primary_abdicate_timeout started
2025-12-12 18:42:43.130Z debug(vsr): 2: pulse_timeout reset
2025-12-12 18:42:43.130Z debug(replica): 2N: replicate: replicating op=80 to replica 0
2025-12-12 18:42:43.130Z debug(replica): 2N: sending prepare to replica 0: vsr.message_header.Header.Prepare{ .checksum = 190906259201884426279323688639025730549, .checksum_padding = 0, .checksum_body = 8534786181244049314008013070841583767, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2064, .epoch = 0, .view = 2, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 278798001163306172812375157407290329283, .parent_padding = 0, .request_checksum = 220267228703775834723431662919395147223, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 129800060941563857535569923226995055452, .op = 80, .commit = 79, .timestamp = 1765564963130383380, .request = 78, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-12-12 18:42:43.130Z debug(message_bus): 2: send_message_to_replica: no connection to=0 header=vsr.message_header.Header.Prepare{ .checksum = 190906259201884426279323688639025730549, .checksum_padding = 0, .checksum_body = 8534786181244049314008013070841583767, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2064, .epoch = 0, .view = 2, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 278798001163306172812375157407290329283, .parent_padding = 0, .request_checksum = 220267228703775834723431662919395147223, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 129800060941563857535569923226995055452, .op = 80, .commit = 79, .timestamp = 1765564963130383380, .request = 78, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-12-12 18:42:43.130Z debug(replica): 2N: replicate: replicating op=80 to replica 1
2025-12-12 18:42:43.130Z debug(replica): 2N: sending prepare to replica 1: vsr.message_header.Header.Prepare{ .checksum = 190906259201884426279323688639025730549, .checksum_padding = 0, .checksum_body = 8534786181244049314008013070841583767, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2064, .epoch = 0, .view = 2, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 278798001163306172812375157407290329283, .parent_padding = 0, .request_checksum = 220267228703775834723431662919395147223, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 129800060941563857535569923226995055452, .op = 80, .commit = 79, .timestamp = 1765564963130383380, .request = 78, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-12-12 18:42:43.130Z debug(replica): 2N: on_prepare: advancing: op=79..80 checksum=278798001163306172812375157407290329283..190906259201884426279323688639025730549
2025-12-12 18:42:43.130Z debug(journal): 2: set_header_as_dirty: op=80 checksum=190906259201884426279323688639025730549
2025-12-12 18:42:43.130Z debug(replica): 2N: append: appending to journal op=80
2025-12-12 18:42:43.130Z debug(journal): 2: write: view=2 slot=80 op=80 len=2064: 190906259201884426279323688639025730549 starting
2025-12-12 18:42:43.130Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.prepares offset=83886080 len=4096 locked
2025-12-12 18:42:43.130Z debug(replica): 1n: on_message: view=2 status=normal vsr.message_header.Header.Prepare{ .checksum = 190906259201884426279323688639025730549, .checksum_padding = 0, .checksum_body = 8534786181244049314008013070841583767, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2064, .epoch = 0, .view = 2, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 278798001163306172812375157407290329283, .parent_padding = 0, .request_checksum = 220267228703775834723431662919395147223, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 129800060941563857535569923226995055452, .op = 80, .commit = 79, .timestamp = 1765564963130383380, .request = 78, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-12-12 18:42:43.130Z debug(replica): 1n: on_prepare: advancing commit_max=78..79
2025-12-12 18:42:43.130Z debug(replica): 1n: on_prepare: caching prepare.op=80 (commit_min=78 op=79 commit_max=79 prepare_max=1007)
2025-12-12 18:42:43.130Z debug(replica): 1n: on_prepare: advancing: op=79..80 checksum=278798001163306172812375157407290329283..190906259201884426279323688639025730549
2025-12-12 18:42:43.130Z debug(journal): 1: set_header_as_dirty: op=80 checksum=190906259201884426279323688639025730549
2025-12-12 18:42:43.130Z debug(replica): 1n: append: appending to journal op=80
2025-12-12 18:42:43.130Z debug(journal): 1: write: view=2 slot=80 op=80 len=2064: 190906259201884426279323688639025730549 starting
2025-12-12 18:42:43.130Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.prepares offset=83886080 len=4096 locked
2025-12-12 18:42:43.130Z debug(replica): 1n: commit_start_journal: cached prepare op=79 checksum=278798001163306172812375157407290329283
2025-12-12 18:42:43.130Z debug(replica): 2N: on_message: view=2 status=normal vsr.message_header.Header.Request{ .checksum = 220267228703775834723431662919395147223, .checksum_padding = 0, .checksum_body = 8534786181244049314008013070841583767, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2064, .epoch = 0, .view = 2, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 263132283239105641758566867392209782006, .parent_padding = 0, .client = 129800060941563857535569923226995055452, .session = 2, .timestamp = 0, .request = 78, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 83277593, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 18:42:43.130Z debug(replica): 2N: on_request: new request
2025-12-12 18:42:43.130Z debug(replica): 2N: on_request: ignoring (already preparing)
2025-12-12 18:42:43.130Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.prepares offset=83886080 len=4096 unlocked
2025-12-12 18:42:43.130Z debug(journal): 2: write_header: op=80 sectors[20480..24576]
2025-12-12 18:42:43.130Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.headers offset=20480 len=4096 locked
2025-12-12 18:42:43.130Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.headers offset=20480 len=4096 unlocked
2025-12-12 18:42:43.130Z debug(journal): 2: write: view=2 slot=80 op=80 len=2064: 190906259201884426279323688639025730549 complete, marking clean
2025-12-12 18:42:43.130Z debug(replica): 2N: send_prepare_ok: op=80 checksum=190906259201884426279323688639025730549
2025-12-12 18:42:43.130Z debug(replica): 2N: sending prepare_ok to replica 2: vsr.message_header.Header.PrepareOk{ .checksum = 178940999935069735771090776901567115381, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 2, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 278798001163306172812375157407290329283, .parent_padding = 0, .prepare_checksum = 190906259201884426279323688639025730549, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 129800060941563857535569923226995055452, .op = 80, .commit_min = 79, .timestamp = 1765564963130383380, .request = 78, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-12-12 18:42:43.130Z debug(replica): 2N: on_message: view=2 status=normal vsr.message_header.Header.PrepareOk{ .checksum = 178940999935069735771090776901567115381, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 2, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 278798001163306172812375157407290329283, .parent_padding = 0, .prepare_checksum = 190906259201884426279323688639025730549, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 129800060941563857535569923226995055452, .op = 80, .commit_min = 79, .timestamp = 1765564963130383380, .request = 78, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-12-12 18:42:43.130Z debug(vsr): 2: primary_abdicate_timeout reset
2025-12-12 18:42:43.130Z debug(replica): 2N: on_prepare_ok: 1 message(s)
2025-12-12 18:42:43.130Z debug(replica): 2N: on_prepare_ok: waiting for quorum
2025-12-12 18:42:43.133Z debug(vsr): 0: journal_repair_budget_timeout fired
2025-12-12 18:42:43.131Z debug(replica): 1n: repair_prepare: op=80 checksum=190906259201884426279323688639025730549 (already writing)
2025-12-12 18:42:43.144Z debug(vsr): 2: journal_repair_budget_timeout fired
2025-12-12 18:42:43.133Z debug(vsr): 0: journal_repair_budget_timeout reset
2025-12-12 18:42:45.669Z debug(vsr): 2: journal_repair_budget_timeout reset
2025-12-12 18:42:45.669Z debug(replica): 1n: commit_journal: already committing (prefetch; commit_min=78)
2025-12-12 18:42:45.669Z debug(replica): 2N: on_message: view=2 status=normal vsr.message_header.Header.Request{ .checksum = 220267228703775834723431662919395147223, .checksum_padding = 0, .checksum_body = 8534786181244049314008013070841583767, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2064, .epoch = 0, .view = 2, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 263132283239105641758566867392209782006, .parent_padding = 0, .client = 129800060941563857535569923226995055452, .session = 2, .timestamp = 0, .request = 78, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 83277593, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 18:42:45.669Z debug(replica): 0n: on_message: view=2 status=normal vsr.message_header.Header.Request{ .checksum = 220267228703775834723431662919395147223, .checksum_padding = 0, .checksum_body = 8534786181244049314008013070841583767, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2064, .epoch = 0, .view = 2, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 263132283239105641758566867392209782006, .parent_padding = 0, .client = 129800060941563857535569923226995055452, .session = 2, .timestamp = 0, .request = 78, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 83277593, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 18:42:45.669Z debug(replica): 0n: on_request: forwarding new request to primary (view=2)
2025-12-12 18:42:45.669Z debug(replica): 2N: on_request: new request
2025-12-12 18:42:45.669Z debug(replica): 2N: on_request: ignoring (already preparing)
2025-12-12 18:42:45.669Z debug(replica): 0n: sending request to replica 2: vsr.message_header.Header.Request{ .checksum = 220267228703775834723431662919395147223, .checksum_padding = 0, .checksum_body = 8534786181244049314008013070841583767, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2064, .epoch = 0, .view = 2, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 263132283239105641758566867392209782006, .parent_padding = 0, .client = 129800060941563857535569923226995055452, .session = 2, .timestamp = 0, .request = 78, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 83277593, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 18:42:45.670Z debug(replica): 2N: on_message: view=2 status=normal vsr.message_header.Header.Request{ .checksum = 220267228703775834723431662919395147223, .checksum_padding = 0, .checksum_body = 8534786181244049314008013070841583767, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2064, .epoch = 0, .view = 2, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 263132283239105641758566867392209782006, .parent_padding = 0, .client = 129800060941563857535569923226995055452, .session = 2, .timestamp = 0, .request = 78, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 83277593, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 18:42:45.670Z debug(replica): 2N: on_request: new request
2025-12-12 18:42:45.670Z debug(replica): 2N: on_request: ignoring (already preparing)
2025-12-12 18:42:45.672Z debug(replica): 1n: execute_op: executing view=2 primary=false op=79 checksum=278798001163306172812375157407290329283 (create_transfers)
2025-12-12 18:42:45.672Z debug(replica): 1n: execute_op: commit_timestamp=1765564959895449179 prepare.header.timestamp=1765564963027427105
2025-12-12 18:42:45.689Z debug(vsr): 2: journal_repair_budget_timeout fired
2025-12-12 18:42:45.689Z debug(vsr): 2: journal_repair_budget_timeout reset
2025-12-12 18:42:45.689Z debug(vsr): 0: journal_repair_budget_timeout fired
2025-12-12 18:42:45.689Z debug(vsr): 0: journal_repair_budget_timeout reset
2025-12-12 18:42:45.689Z debug(vsr): 0: journal_repair_timeout fired
2025-12-12 18:42:45.689Z debug(vsr): 0: journal_repair_timeout reset
2025-12-12 18:42:45.708Z debug(replica): 1n: client_table_entry_update: client=129800060941563857535569923226995055452 session=2 request=77
2025-12-12 18:42:45.708Z debug(replica): 1n: execute_op: replying to client: vsr.message_header.Header.Reply{ .checksum = 260994595275693577425366555167592702421, .checksum_padding = 0, .checksum_body = 123952473893376277661007810235207256912, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 536, .epoch = 0, .view = 2, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 259907725549595238925131762988644609507, .request_checksum_padding = 0, .context = 263132283239105641758566867392209782006, .context_padding = 0, .client = 129800060941563857535569923226995055452, .op = 79, .commit = 79, .timestamp = 1765564963027427105, .request = 77, .operation = vsr.Operation(139), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 18:42:45.708Z debug(replica): 1n: sending reply to client 129800060941563857535569923226995055452: vsr.message_header.Header.Reply{ .checksum = 260994595275693577425366555167592702421, .checksum_padding = 0, .checksum_body = 123952473893376277661007810235207256912, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 536, .epoch = 0, .view = 2, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 259907725549595238925131762988644609507, .request_checksum_padding = 0, .context = 263132283239105641758566867392209782006, .context_padding = 0, .client = 129800060941563857535569923226995055452, .op = 79, .commit = 79, .timestamp = 1765564963027427105, .request = 77, .operation = vsr.Operation(139), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 18:42:45.708Z debug(forest): entering forest.compact() op=79 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=true half_beat=false last_beat=false
2025-12-12 18:42:45.708Z debug(manifest_log): 1: flush: writing 0 block(s)
2025-12-12 18:42:45.709Z debug(vsr): 2: journal_repair_budget_timeout fired
2025-12-12 18:42:45.709Z debug(vsr): 2: journal_repair_budget_timeout reset
2025-12-12 18:42:45.710Z debug(vsr): 0: journal_repair_budget_timeout fired
2025-12-12 18:42:45.710Z debug(vsr): 0: journal_repair_budget_timeout reset
2025-12-12 18:42:45.724Z warning(replica): 1n: commit_dispatch: slow request, request=77 size=811392 create_transfers time=2593ms
2025-12-12 18:42:45.724Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.prepares offset=83886080 len=4096 unlocked
2025-12-12 18:42:45.724Z debug(journal): 1: write_header: op=80 sectors[20480..24576]
2025-12-12 18:42:45.724Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.headers offset=20480 len=4096 locked
2025-12-12 18:42:45.724Z debug(client_replies): 1: write_reply: wrote (client=129800060941563857535569923226995055452 request=77)
2025-12-12 18:42:45.724Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.headers offset=20480 len=4096 unlocked
2025-12-12 18:42:45.724Z debug(journal): 1: write: view=2 slot=80 op=80 len=2064: 190906259201884426279323688639025730549 complete, marking clean
2025-12-12 18:42:45.724Z debug(replica): 1n: send_prepare_ok: op=80 checksum=190906259201884426279323688639025730549
2025-12-12 18:42:45.724Z debug(replica): 1n: sending prepare_ok to replica 2: vsr.message_header.Header.PrepareOk{ .checksum = 265741023256998121765515491171116118027, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 2, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 278798001163306172812375157407290329283, .parent_padding = 0, .prepare_checksum = 190906259201884426279323688639025730549, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 129800060941563857535569923226995055452, .op = 80, .commit_min = 79, .timestamp = 1765564963130383380, .request = 78, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-12-12 18:42:45.725Z debug(replica): 2N: on_message: view=2 status=normal vsr.message_header.Header.PrepareOk{ .checksum = 265741023256998121765515491171116118027, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 2, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 278798001163306172812375157407290329283, .parent_padding = 0, .prepare_checksum = 190906259201884426279323688639025730549, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 129800060941563857535569923226995055452, .op = 80, .commit_min = 79, .timestamp = 1765564963130383380, .request = 78, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-12-12 18:42:45.725Z debug(vsr): 2: primary_abdicate_timeout reset
2025-12-12 18:42:45.725Z debug(replica): 2N: on_prepare_ok: 2 message(s)
2025-12-12 18:42:45.725Z debug(replica): 2N: on_prepare_ok: quorum received, context=190906259201884426279323688639025730549
2025-12-12 18:42:45.725Z debug(vsr): 2: prepare_timeout stopped
2025-12-12 18:42:45.725Z debug(vsr): 2: primary_abdicate_timeout stopped
2025-12-12 18:42:45.725Z debug(replica): 2N: execute_op: executing view=2 primary=true op=80 checksum=190906259201884426279323688639025730549 (lookup_accounts)
2025-12-12 18:42:45.725Z debug(replica): 2N: execute_op: commit_timestamp=1765564963027427105 prepare.header.timestamp=1765564963130383380
2025-12-12 18:42:45.725Z debug(replica): 2N: execute_op: advancing commit_max=79..80
2025-12-12 18:42:45.725Z debug(replica): 2N: client_table_entry_update: client=129800060941563857535569923226995055452 session=2 request=78
2025-12-12 18:42:45.725Z debug(replica): 2N: execute_op: replying to client: vsr.message_header.Header.Reply{ .checksum = 59940488084520228387887405527261541593, .checksum_padding = 0, .checksum_body = 211901166049784168839814566194890595140, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 14720, .epoch = 0, .view = 2, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 220267228703775834723431662919395147223, .request_checksum_padding = 0, .context = 102223299795980850673429666419134149757, .context_padding = 0, .client = 129800060941563857535569923226995055452, .op = 80, .commit = 80, .timestamp = 1765564963130383380, .request = 78, .operation = vsr.Operation(140), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 18:42:45.725Z debug(replica): 2N: sending reply to client 129800060941563857535569923226995055452: vsr.message_header.Header.Reply{ .checksum = 59940488084520228387887405527261541593, .checksum_padding = 0, .checksum_body = 211901166049784168839814566194890595140, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 14720, .epoch = 0, .view = 2, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 220267228703775834723431662919395147223, .request_checksum_padding = 0, .context = 102223299795980850673429666419134149757, .context_padding = 0, .client = 129800060941563857535569923226995055452, .op = 80, .commit = 80, .timestamp = 1765564963130383380, .request = 78, .operation = vsr.Operation(140), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 18:42:45.725Z debug(forest): entering forest.compact() op=80 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=true last_beat=false
2025-12-12 18:42:45.725Z debug(compaction): Account.id:0: bar_commence: immutable table flush skipped (112+0+131040  262080)
2025-12-12 18:42:45.725Z debug(compaction): Account.user_data_128:0: bar_commence: immutable table flushed
2025-12-12 18:42:45.725Z debug(compaction): Account.user_data_64:0: bar_commence: immutable table flushed
2025-12-12 18:42:45.725Z debug(compaction): Account.user_data_32:0: bar_commence: immutable table flushed
2025-12-12 18:42:45.725Z debug(compaction): Account.ledger:0: bar_commence: immutable table flush skipped (112+0+131040  262080)
2025-12-12 18:42:45.725Z debug(compaction): Account.code:0: bar_commence: immutable table flush skipped (112+0+131040  262080)
2025-12-12 18:42:45.725Z debug(compaction): Account:0: bar_commence: immutable table flush skipped (112+784+262080  524160)
2025-12-12 18:42:45.725Z debug(compaction): Transfer.id:0: bar_commence: quota_bar_done=0 quota_bar=93158
2025-12-12 18:42:45.725Z debug(compaction): Transfer.debit_account_id:0: bar_commence: quota_bar_done=0 quota_bar=92840
2025-12-12 18:42:45.725Z debug(compaction): Transfer.credit_account_id:0: bar_commence: quota_bar_done=0 quota_bar=92840
2025-12-12 18:42:45.725Z debug(compaction): Transfer.amount:0: bar_commence: quota_bar_done=0 quota_bar=92840
2025-12-12 18:42:45.725Z debug(compaction): Transfer.pending_id:0: bar_commence: immutable table flushed
2025-12-12 18:42:45.725Z debug(compaction): Transfer.user_data_128:0: bar_commence: immutable table flushed
2025-12-12 18:42:45.725Z debug(compaction): Transfer.user_data_64:0: bar_commence: immutable table flushed
2025-12-12 18:42:45.725Z debug(compaction): Transfer.user_data_32:0: bar_commence: immutable table flushed
2025-12-12 18:42:45.725Z debug(compaction): Transfer.ledger:0: bar_commence: quota_bar_done=0 quota_bar=92840
2025-12-12 18:42:45.725Z debug(compaction): Transfer.code:0: bar_commence: quota_bar_done=0 quota_bar=92840
2025-12-12 18:42:45.725Z debug(compaction): Transfer:0: bar_commence: quota_bar_done=0 quota_bar=92840
2025-12-12 18:42:45.725Z debug(compaction): Transfer.expires_at:0: bar_commence: immutable table flushed
2025-12-12 18:42:45.725Z debug(compaction): TransferPending:0: bar_commence: immutable table flushed
2025-12-12 18:42:45.725Z debug(compaction): TransferPending.status:0: bar_commence: immutable table flushed
2025-12-12 18:42:45.725Z debug(compaction): AccountEvent:0: bar_commence: quota_bar_done=0 quota_bar=92840
2025-12-12 18:42:45.725Z debug(compaction): Account.imported:0: bar_commence: immutable table flushed
2025-12-12 18:42:45.725Z debug(compaction): Transfer.imported:0: bar_commence: immutable table flushed
2025-12-12 18:42:45.725Z debug(compaction): Account.closed:0: bar_commence: immutable table flushed
2025-12-12 18:42:45.725Z debug(compaction): Transfer.closing:0: bar_commence: immutable table flushed
warning(client): 129800060941563857535569923226995055452: on_reply: slow request, request=78 op=80 size=2064 lookup_accounts time=2595ms
2025-12-12 18:42:45.725Z debug(compaction): AccountEvent.account_timestamp:0: bar_commence: immutable table flush skipped (11487+4245+262080  524160)
2025-12-12 18:42:45.725Z debug(compaction): AccountEvent.transfer_pending_status:0: bar_commence: quota_bar_done=0 quota_bar=92840
2025-12-12 18:42:45.725Z debug(compaction): AccountEvent.dr_account_id_expired:0: bar_commence: immutable table flushed
2025-12-12 18:42:45.725Z debug(compaction): AccountEvent.cr_account_id_expired:0: bar_commence: immutable table flushed
2025-12-12 18:42:45.725Z debug(compaction): AccountEvent.transfer_pending_id_expired:0: bar_commence: immutable table flushed
2025-12-12 18:42:45.725Z debug(compaction): AccountEvent.ledger_expired:0: bar_commence: immutable table flushed
2025-12-12 18:42:45.725Z debug(compaction): AccountEvent.prunable:0: bar_commence: immutable table flush skipped (81699+35323+131040  262080)
2025-12-12 18:42:45.725Z debug(compaction): Account.id:2: bar_commence: nothing to compact
2025-12-12 18:42:45.725Z debug(compaction): Account.user_data_128:2: bar_commence: nothing to compact
2025-12-12 18:42:45.725Z debug(compaction): Account.user_data_64:2: bar_commence: nothing to compact
2025-12-12 18:42:45.725Z debug(compaction): Account.user_data_32:2: bar_commence: nothing to compact
2025-12-12 18:42:45.725Z debug(compaction): Account.ledger:2: bar_commence: nothing to compact
2025-12-12 18:42:45.725Z debug(compaction): Account.code:2: bar_commence: nothing to compact
2025-12-12 18:42:45.725Z debug(compaction): Account:2: bar_commence: nothing to compact
2025-12-12 18:42:45.725Z debug(compaction): Transfer.id:2: bar_commence: nothing to compact
2025-12-12 18:42:45.725Z debug(compaction): Transfer.debit_account_id:2: bar_commence: nothing to compact
2025-12-12 18:42:45.725Z debug(compaction): Transfer.credit_account_id:2: bar_commence: nothing to compact
2025-12-12 18:42:45.725Z debug(compaction): Transfer.amount:2: bar_commence: nothing to compact
2025-12-12 18:42:45.725Z debug(compaction): Transfer.pending_id:2: bar_commence: nothing to compact
2025-12-12 18:42:45.725Z debug(compaction): Transfer.user_data_128:2: bar_commence: nothing to compact
2025-12-12 18:42:45.725Z debug(compaction): Transfer.user_data_64:2: bar_commence: nothing to compact
2025-12-12 18:42:45.725Z debug(compaction): Transfer.user_data_32:2: bar_commence: nothing to compact
2025-12-12 18:42:45.725Z debug(compaction): Transfer.ledger:2: bar_commence: nothing to compact
2025-12-12 18:42:45.725Z debug(compaction): Transfer.code:2: bar_commence: nothing to compact
2025-12-12 18:42:45.725Z debug(compaction): Transfer:2: bar_commence: nothing to compact
2025-12-12 18:42:45.725Z debug(compaction): Transfer.expires_at:2: bar_commence: nothing to compact
2025-12-12 18:42:45.725Z debug(compaction): TransferPending:2: bar_commence: nothing to compact
2025-12-12 18:42:45.725Z debug(compaction): TransferPending.status:2: bar_commence: nothing to compact
2025-12-12 18:42:45.725Z debug(compaction): AccountEvent:2: bar_commence: nothing to compact
2025-12-12 18:42:45.725Z debug(compaction): Account.imported:2: bar_commence: nothing to compact
2025-12-12 18:42:45.725Z debug(compaction): Transfer.imported:2: bar_commence: nothing to compact
2025-12-12 18:42:45.725Z debug(compaction): Account.closed:2: bar_commence: nothing to compact
2025-12-12 18:42:45.725Z debug(compaction): Transfer.closing:2: bar_commence: nothing to compact
2025-12-12 18:42:45.725Z debug(compaction): AccountEvent.account_timestamp:2: bar_commence: nothing to compact
2025-12-12 18:42:45.725Z debug(compaction): AccountEvent.transfer_pending_status:2: bar_commence: nothing to compact
2025-12-12 18:42:45.725Z debug(compaction): AccountEvent.dr_account_id_expired:2: bar_commence: nothing to compact
2025-12-12 18:42:45.725Z info(workload): accounts created = 112, transfers = 132698, pending transfers = 0, commands run = 39
2025-12-12 18:42:45.725Z debug(compaction): AccountEvent.cr_account_id_expired:2: bar_commence: nothing to compact
2025-12-12 18:42:45.725Z debug(compaction): AccountEvent.transfer_pending_id_expired:2: bar_commence: nothing to compact
2025-12-12 18:42:45.725Z debug(compaction): AccountEvent.ledger_expired:2: bar_commence: nothing to compact
2025-12-12 18:42:45.725Z debug(compaction): AccountEvent.prunable:2: bar_commence: nothing to compact
2025-12-12 18:42:45.725Z debug(compaction): Account.id:4: bar_commence: nothing to compact
2025-12-12 18:42:45.725Z debug(compaction): Account.user_data_128:4: bar_commence: nothing to compact
2025-12-12 18:42:45.725Z debug(compaction): Account.user_data_64:4: bar_commence: nothing to compact
2025-12-12 18:42:45.725Z debug(compaction): Account.user_data_32:4: bar_commence: nothing to compact
2025-12-12 18:42:45.725Z debug(compaction): Account.ledger:4: bar_commence: nothing to compact
2025-12-12 18:42:45.725Z debug(compaction): Account.code:4: bar_commence: nothing to compact
2025-12-12 18:42:45.725Z debug(compaction): Account:4: bar_commence: nothing to compact
2025-12-12 18:42:45.725Z debug(compaction): Transfer.id:4: bar_commence: nothing to compact
2025-12-12 18:42:45.725Z debug(compaction): Transfer.debit_account_id:4: bar_commence: nothing to compact
2025-12-12 18:42:45.725Z debug(compaction): Transfer.credit_account_id:4: bar_commence: nothing to compact
2025-12-12 18:42:45.725Z debug(compaction): Transfer.amount:4: bar_commence: nothing to compact
2025-12-12 18:42:45.725Z debug(compaction): Transfer.pending_id:4: bar_commence: nothing to compact
2025-12-12 18:42:45.725Z debug(compaction): Transfer.user_data_128:4: bar_commence: nothing to compact
2025-12-12 18:42:45.725Z debug(compaction): Transfer.user_data_64:4: bar_commence: nothing to compact
2025-12-12 18:42:45.725Z debug(compaction): Transfer.user_data_32:4: bar_commence: nothing to compact
2025-12-12 18:42:45.725Z debug(compaction): Transfer.ledger:4: bar_commence: nothing to compact
2025-12-12 18:42:45.726Z debug(compaction): Transfer.code:4: bar_commence: nothing to compact
2025-12-12 18:42:45.726Z debug(compaction): Transfer:4: bar_commence: nothing to compact
2025-12-12 18:42:45.726Z debug(compaction): Transfer.expires_at:4: bar_commence: nothing to compact
2025-12-12 18:42:45.726Z debug(compaction): TransferPending:4: bar_commence: nothing to compact
2025-12-12 18:42:45.726Z debug(compaction): TransferPending.status:4: bar_commence: nothing to compact
2025-12-12 18:42:45.726Z debug(compaction): AccountEvent:4: bar_commence: nothing to compact
2025-12-12 18:42:45.726Z debug(compaction): Account.imported:4: bar_commence: nothing to compact
2025-12-12 18:42:45.726Z debug(compaction): Transfer.imported:4: bar_commence: nothing to compact
2025-12-12 18:42:45.726Z debug(compaction): Account.closed:4: bar_commence: nothing to compact
2025-12-12 18:42:45.726Z debug(compaction): Transfer.closing:4: bar_commence: nothing to compact
2025-12-12 18:42:45.726Z debug(compaction): AccountEvent.account_timestamp:4: bar_commence: nothing to compact
2025-12-12 18:42:45.726Z debug(compaction): AccountEvent.transfer_pending_status:4: bar_commence: nothing to compact
2025-12-12 18:42:45.726Z debug(compaction): AccountEvent.dr_account_id_expired:4: bar_commence: nothing to compact
2025-12-12 18:42:45.726Z debug(compaction): AccountEvent.cr_account_id_expired:4: bar_commence: nothing to compact
2025-12-12 18:42:45.726Z debug(compaction): AccountEvent.transfer_pending_id_expired:4: bar_commence: nothing to compact
2025-12-12 18:42:45.726Z debug(compaction): AccountEvent.ledger_expired:4: bar_commence: nothing to compact
2025-12-12 18:42:45.726Z debug(compaction): AccountEvent.prunable:4: bar_commence: nothing to compact
2025-12-12 18:42:45.726Z debug(compaction): Account.id:6: bar_commence: nothing to compact
2025-12-12 18:42:45.726Z debug(compaction): Account.user_data_128:6: bar_commence: nothing to compact
2025-12-12 18:42:45.726Z debug(compaction): Account.user_data_64:6: bar_commence: nothing to compact
2025-12-12 18:42:45.726Z debug(compaction): Account.user_data_32:6: bar_commence: nothing to compact
2025-12-12 18:42:45.726Z debug(compaction): Account.ledger:6: bar_commence: nothing to compact
2025-12-12 18:42:45.726Z debug(compaction): Account.code:6: bar_commence: nothing to compact
2025-12-12 18:42:45.726Z debug(compaction): Account:6: bar_commence: nothing to compact
2025-12-12 18:42:45.726Z debug(compaction): Transfer.id:6: bar_commence: nothing to compact
2025-12-12 18:42:45.726Z debug(compaction): Transfer.debit_account_id:6: bar_commence: nothing to compact
2025-12-12 18:42:45.726Z debug(compaction): Transfer.credit_account_id:6: bar_commence: nothing to compact
2025-12-12 18:42:45.726Z debug(compaction): Transfer.amount:6: bar_commence: nothing to compact
2025-12-12 18:42:45.726Z debug(compaction): Transfer.pending_id:6: bar_commence: nothing to compact
2025-12-12 18:42:45.726Z debug(compaction): Transfer.user_data_128:6: bar_commence: nothing to compact
2025-12-12 18:42:45.726Z debug(compaction): Transfer.user_data_64:6: bar_commence: nothing to compact
2025-12-12 18:42:45.726Z debug(compaction): Transfer.user_data_32:6: bar_commence: nothing to compact
2025-12-12 18:42:45.726Z debug(compaction): Transfer.ledger:6: bar_commence: nothing to compact
2025-12-12 18:42:45.726Z debug(compaction): Transfer.code:6: bar_commence: nothing to compact
2025-12-12 18:42:45.726Z debug(compaction): Transfer:6: bar_commence: nothing to compact
2025-12-12 18:42:45.726Z debug(compaction): Transfer.expires_at:6: bar_commence: nothing to compact
2025-12-12 18:42:45.726Z debug(compaction): TransferPending:6: bar_commence: nothing to compact
2025-12-12 18:42:45.726Z debug(compaction): TransferPending.status:6: bar_commence: nothing to compact
2025-12-12 18:42:45.726Z debug(compaction): AccountEvent:6: bar_commence: nothing to compact
2025-12-12 18:42:45.726Z debug(compaction): Account.imported:6: bar_commence: nothing to compact
2025-12-12 18:42:45.726Z debug(compaction): Transfer.imported:6: bar_commence: nothing to compact
2025-12-12 18:42:45.726Z debug(compaction): Account.closed:6: bar_commence: nothing to compact
2025-12-12 18:42:45.726Z debug(compaction): Transfer.closing:6: bar_commence: nothing to compact
2025-12-12 18:42:45.726Z debug(compaction): AccountEvent.account_timestamp:6: bar_commence: nothing to compact
2025-12-12 18:42:45.726Z debug(compaction): AccountEvent.transfer_pending_status:6: bar_commence: nothing to compact
2025-12-12 18:42:45.726Z debug(compaction): AccountEvent.dr_account_id_expired:6: bar_commence: nothing to compact
2025-12-12 18:42:45.726Z debug(compaction): AccountEvent.cr_account_id_expired:6: bar_commence: nothing to compact
2025-12-12 18:42:45.726Z debug(compaction): AccountEvent.transfer_pending_id_expired:6: bar_commence: nothing to compact
2025-12-12 18:42:45.726Z debug(compaction): AccountEvent.ledger_expired:6: bar_commence: nothing to compact
2025-12-12 18:42:45.726Z debug(compaction): AccountEvent.prunable:6: bar_commence: nothing to compact
2025-12-12 18:42:45.726Z debug(compaction): 2: Account.id:0: beat_commence: bar quota=0 fulfilled, done=0
2025-12-12 18:42:45.726Z debug(compaction): 2: Account.user_data_128:0: beat_commence: bar quota=0 fulfilled, done=0
2025-12-12 18:42:45.726Z debug(compaction): 2: Account.user_data_64:0: beat_commence: bar quota=0 fulfilled, done=0
2025-12-12 18:42:45.726Z debug(compaction): 2: Account.user_data_32:0: beat_commence: bar quota=0 fulfilled, done=0
2025-12-12 18:42:45.726Z debug(compaction): 2: Account.ledger:0: beat_commence: bar quota=0 fulfilled, done=0
2025-12-12 18:42:45.726Z debug(compaction): 2: Account.code:0: beat_commence: bar quota=0 fulfilled, done=0
2025-12-12 18:42:45.726Z debug(compaction): 2: Account:0: beat_commence: bar quota=0 fulfilled, done=0
2025-12-12 18:42:45.728Z debug(replica): 0n: on_message: view=2 status=normal vsr.message_header.Header.Request{ .checksum = 206965483952788878501331448987007267279, .checksum_padding = 0, .checksum_body = 186100930357175022436291576967370647900, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 121088, .epoch = 0, .view = 2, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 102223299795980850673429666419134149757, .parent_padding = 0, .client = 129800060941563857535569923226995055452, .session = 2, .timestamp = 0, .request = 79, .operation = vsr.Operation(139), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 2595635519, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 18:42:45.728Z debug(replica): 0n: on_request: forwarding new request to primary (view=2)
2025-12-12 18:42:45.728Z debug(replica): 0n: sending request to replica 2: vsr.message_header.Header.Request{ .checksum = 206965483952788878501331448987007267279, .checksum_padding = 0, .checksum_body = 186100930357175022436291576967370647900, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 121088, .epoch = 0, .view = 2, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 102223299795980850673429666419134149757, .parent_padding = 0, .client = 129800060941563857535569923226995055452, .session = 2, .timestamp = 0, .request = 79, .operation = vsr.Operation(139), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 2595635519, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 18:42:45.730Z debug(vsr): 0: journal_repair_budget_timeout fired
2025-12-12 18:42:45.730Z debug(vsr): 0: journal_repair_budget_timeout reset
2025-12-12 18:42:45.734Z debug(vsr): 1: journal_repair_budget_timeout fired
2025-12-12 18:42:45.734Z debug(vsr): 1: journal_repair_budget_timeout reset
2025-12-12 18:42:45.734Z debug(vsr): 1: journal_repair_timeout fired
2025-12-12 18:42:45.734Z debug(vsr): 1: journal_repair_timeout reset
2025-12-12 18:42:45.741Z debug(client_replies): 2: write_reply: wrote (client=129800060941563857535569923226995055452 request=78)
2025-12-12 18:42:45.742Z debug(vsr): 2: journal_repair_budget_timeout fired
2025-12-12 18:42:45.742Z debug(vsr): 2: journal_repair_budget_timeout reset
2025-12-12 18:42:45.742Z debug(replica): 2N: on_message: view=2 status=normal vsr.message_header.Header.Request{ .checksum = 206965483952788878501331448987007267279, .checksum_padding = 0, .checksum_body = 186100930357175022436291576967370647900, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 121088, .epoch = 0, .view = 2, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 102223299795980850673429666419134149757, .parent_padding = 0, .client = 129800060941563857535569923226995055452, .session = 2, .timestamp = 0, .request = 79, .operation = vsr.Operation(139), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 2595635519, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 18:42:45.742Z debug(replica): 2N: on_request: new request
2025-12-12 18:42:45.742Z debug(replica): 2N: primary_pipeline_prepare: request checksum=206965483952788878501331448987007267279 client=129800060941563857535569923226995055452
2025-12-12 18:42:45.743Z debug(replica): 2N: primary_pipeline_prepare: prepare checksum=75307684776007077891113995186346302623 op=81
2025-12-12 18:42:45.743Z debug(vsr): 2: prepare_timeout started
2025-12-12 18:42:45.743Z debug(vsr): 2: primary_abdicate_timeout started
2025-12-12 18:42:45.743Z debug(vsr): 2: pulse_timeout reset
2025-12-12 18:42:45.743Z debug(replica): 2N: replicate: replicating op=81 to replica 0
2025-12-12 18:42:45.743Z debug(replica): 2N: sending prepare to replica 0: vsr.message_header.Header.Prepare{ .checksum = 75307684776007077891113995186346302623, .checksum_padding = 0, .checksum_body = 186100930357175022436291576967370647900, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 121088, .epoch = 0, .view = 2, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 190906259201884426279323688639025730549, .parent_padding = 0, .request_checksum = 206965483952788878501331448987007267279, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 129800060941563857535569923226995055452, .op = 81, .commit = 80, .timestamp = 1765564965742697463, .request = 79, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-12-12 18:42:45.743Z debug(message_bus): 2: send_message_to_replica: no connection to=0 header=vsr.message_header.Header.Prepare{ .checksum = 75307684776007077891113995186346302623, .checksum_padding = 0, .checksum_body = 186100930357175022436291576967370647900, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 121088, .epoch = 0, .view = 2, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 190906259201884426279323688639025730549, .parent_padding = 0, .request_checksum = 206965483952788878501331448987007267279, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 129800060941563857535569923226995055452, .op = 81, .commit = 80, .timestamp = 1765564965742697463, .request = 79, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-12-12 18:42:45.743Z debug(replica): 2N: replicate: replicating op=81 to replica 1
2025-12-12 18:42:45.743Z debug(replica): 2N: sending prepare to replica 1: vsr.message_header.Header.Prepare{ .checksum = 75307684776007077891113995186346302623, .checksum_padding = 0, .checksum_body = 186100930357175022436291576967370647900, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 121088, .epoch = 0, .view = 2, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 190906259201884426279323688639025730549, .parent_padding = 0, .request_checksum = 206965483952788878501331448987007267279, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 129800060941563857535569923226995055452, .op = 81, .commit = 80, .timestamp = 1765564965742697463, .request = 79, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-12-12 18:42:45.743Z debug(replica): 2N: on_prepare: advancing: op=80..81 checksum=190906259201884426279323688639025730549..75307684776007077891113995186346302623
2025-12-12 18:42:45.743Z debug(journal): 2: set_header_as_dirty: op=81 checksum=75307684776007077891113995186346302623
2025-12-12 18:42:45.743Z debug(replica): 2N: append: appending to journal op=81
2025-12-12 18:42:45.743Z debug(journal): 2: write: view=2 slot=81 op=81 len=121088: 75307684776007077891113995186346302623 starting
2025-12-12 18:42:45.743Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.prepares offset=84934656 len=122880 locked
2025-12-12 18:42:45.744Z debug(replica): 2N: on_message: view=2 status=normal vsr.message_header.Header.Request{ .checksum = 206965483952788878501331448987007267279, .checksum_padding = 0, .checksum_body = 186100930357175022436291576967370647900, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 121088, .epoch = 0, .view = 2, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 102223299795980850673429666419134149757, .parent_padding = 0, .client = 129800060941563857535569923226995055452, .session = 2, .timestamp = 0, .request = 79, .operation = vsr.Operation(139), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 2595635519, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 18:42:45.744Z debug(replica): 2N: on_request: new request
2025-12-12 18:42:45.744Z debug(replica): 2N: on_request: ignoring (already preparing)
2025-12-12 18:42:45.744Z debug(compaction): Transfer.id:0: beat_complete: quota_beat_done=93158 quota_beat=93158 quota_bar_done=93158 quota_bar=93158
2025-12-12 18:42:45.744Z debug(compaction): 2: Account.id:0: beat_commence: bar quota=0 fulfilled, done=0
2025-12-12 18:42:45.744Z debug(compaction): 2: Account.user_data_128:0: beat_commence: bar quota=0 fulfilled, done=0
2025-12-12 18:42:45.744Z debug(compaction): 2: Account.user_data_64:0: beat_commence: bar quota=0 fulfilled, done=0
2025-12-12 18:42:45.744Z debug(compaction): 2: Account.user_data_32:0: beat_commence: bar quota=0 fulfilled, done=0
2025-12-12 18:42:45.744Z debug(compaction): 2: Account.ledger:0: beat_commence: bar quota=0 fulfilled, done=0
2025-12-12 18:42:45.744Z debug(compaction): 2: Account.code:0: beat_commence: bar quota=0 fulfilled, done=0
2025-12-12 18:42:45.744Z debug(compaction): 2: Account:0: beat_commence: bar quota=0 fulfilled, done=0
2025-12-12 18:42:45.744Z debug(compaction): 2: Transfer.id:0: beat_commence: bar quota=93158 fulfilled, done=93158
2025-12-12 18:42:45.744Z debug(replica): 1n: on_message: view=2 status=normal vsr.message_header.Header.Prepare{ .checksum = 75307684776007077891113995186346302623, .checksum_padding = 0, .checksum_body = 186100930357175022436291576967370647900, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 121088, .epoch = 0, .view = 2, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 190906259201884426279323688639025730549, .parent_padding = 0, .request_checksum = 206965483952788878501331448987007267279, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 129800060941563857535569923226995055452, .op = 81, .commit = 80, .timestamp = 1765564965742697463, .request = 79, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-12-12 18:42:45.744Z debug(replica): 1n: on_prepare: advancing commit_max=79..80
2025-12-12 18:42:45.744Z debug(replica): 1n: on_prepare: caching prepare.op=81 (commit_min=79 op=80 commit_max=80 prepare_max=1007)
2025-12-12 18:42:45.744Z debug(replica): 1n: on_prepare: advancing: op=80..81 checksum=190906259201884426279323688639025730549..75307684776007077891113995186346302623
2025-12-12 18:42:45.744Z debug(journal): 1: set_header_as_dirty: op=81 checksum=75307684776007077891113995186346302623
2025-12-12 18:42:45.744Z debug(replica): 1n: append: appending to journal op=81
2025-12-12 18:42:45.744Z debug(journal): 1: write: view=2 slot=81 op=81 len=121088: 75307684776007077891113995186346302623 starting
2025-12-12 18:42:45.744Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.prepares offset=84934656 len=122880 locked
2025-12-12 18:42:45.744Z debug(replica): 1n: commit_start_journal: cached prepare op=80 checksum=190906259201884426279323688639025730549
2025-12-12 18:42:45.745Z debug(replica): 1n: repair_prepare: op=81 checksum=75307684776007077891113995186346302623 (already writing)
2025-12-12 18:42:45.745Z debug(replica): 1n: commit_journal: already committing (prefetch; commit_min=79)
2025-12-12 18:42:45.745Z debug(replica): 1n: execute_op: executing view=2 primary=false op=80 checksum=190906259201884426279323688639025730549 (lookup_accounts)
2025-12-12 18:42:45.745Z debug(replica): 1n: execute_op: commit_timestamp=1765564963027427105 prepare.header.timestamp=1765564963130383380
2025-12-12 18:42:45.745Z debug(replica): 1n: client_table_entry_update: client=129800060941563857535569923226995055452 session=2 request=78
2025-12-12 18:42:45.745Z debug(forest): entering forest.compact() op=80 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=true last_beat=false
2025-12-12 18:42:45.745Z debug(compaction): Account.id:0: bar_commence: immutable table flush skipped (112+0+131040  262080)
2025-12-12 18:42:45.745Z debug(compaction): Account.user_data_128:0: bar_commence: immutable table flushed
2025-12-12 18:42:45.745Z debug(compaction): Account.user_data_64:0: bar_commence: immutable table flushed
2025-12-12 18:42:45.745Z debug(compaction): Account.user_data_32:0: bar_commence: immutable table flushed
2025-12-12 18:42:45.745Z debug(compaction): Account.ledger:0: bar_commence: immutable table flush skipped (112+0+131040  262080)
2025-12-12 18:42:45.745Z debug(compaction): Account.code:0: bar_commence: immutable table flush skipped (112+0+131040  262080)
2025-12-12 18:42:45.745Z debug(compaction): Account:0: bar_commence: immutable table flush skipped (112+784+262080  524160)
2025-12-12 18:42:45.745Z debug(compaction): Transfer.id:0: bar_commence: quota_bar_done=0 quota_bar=93158
2025-12-12 18:42:45.745Z debug(compaction): Transfer.debit_account_id:0: bar_commence: quota_bar_done=0 quota_bar=92840
2025-12-12 18:42:45.745Z debug(compaction): Transfer.credit_account_id:0: bar_commence: quota_bar_done=0 quota_bar=92840
2025-12-12 18:42:45.745Z debug(compaction): Transfer.amount:0: bar_commence: quota_bar_done=0 quota_bar=92840
2025-12-12 18:42:45.745Z debug(compaction): Transfer.pending_id:0: bar_commence: immutable table flushed
2025-12-12 18:42:45.745Z debug(compaction): Transfer.user_data_128:0: bar_commence: immutable table flushed
2025-12-12 18:42:45.745Z debug(compaction): Transfer.user_data_64:0: bar_commence: immutable table flushed
2025-12-12 18:42:45.745Z debug(compaction): Transfer.user_data_32:0: bar_commence: immutable table flushed
2025-12-12 18:42:45.745Z debug(compaction): Transfer.ledger:0: bar_commence: quota_bar_done=0 quota_bar=92840
2025-12-12 18:42:45.745Z debug(compaction): Transfer.code:0: bar_commence: quota_bar_done=0 quota_bar=92840
2025-12-12 18:42:45.745Z debug(compaction): Transfer:0: bar_commence: quota_bar_done=0 quota_bar=92840
2025-12-12 18:42:45.745Z debug(compaction): Transfer.expires_at:0: bar_commence: immutable table flushed
2025-12-12 18:42:45.745Z debug(compaction): TransferPending:0: bar_commence: immutable table flushed
2025-12-12 18:42:45.745Z debug(compaction): TransferPending.status:0: bar_commence: immutable table flushed
2025-12-12 18:42:45.745Z debug(compaction): AccountEvent:0: bar_commence: quota_bar_done=0 quota_bar=92840
2025-12-12 18:42:45.745Z debug(compaction): Account.imported:0: bar_commence: immutable table flushed
2025-12-12 18:42:45.745Z debug(compaction): Transfer.imported:0: bar_commence: immutable table flushed
2025-12-12 18:42:45.745Z debug(compaction): Account.closed:0: bar_commence: immutable table flushed
2025-12-12 18:42:45.745Z debug(compaction): Transfer.closing:0: bar_commence: immutable table flushed
2025-12-12 18:42:45.745Z debug(compaction): AccountEvent.account_timestamp:0: bar_commence: immutable table flush skipped (11487+4245+262080  524160)
2025-12-12 18:42:45.745Z debug(compaction): AccountEvent.transfer_pending_status:0: bar_commence: quota_bar_done=0 quota_bar=92840
2025-12-12 18:42:45.745Z debug(compaction): AccountEvent.dr_account_id_expired:0: bar_commence: immutable table flushed
2025-12-12 18:42:45.745Z debug(compaction): AccountEvent.cr_account_id_expired:0: bar_commence: immutable table flushed
2025-12-12 18:42:45.745Z debug(compaction): AccountEvent.transfer_pending_id_expired:0: bar_commence: immutable table flushed
2025-12-12 18:42:45.745Z debug(compaction): AccountEvent.ledger_expired:0: bar_commence: immutable table flushed
2025-12-12 18:42:45.745Z debug(compaction): AccountEvent.prunable:0: bar_commence: immutable table flush skipped (81699+35323+131040  262080)
2025-12-12 18:42:45.745Z debug(compaction): Account.id:2: bar_commence: nothing to compact
2025-12-12 18:42:45.745Z debug(compaction): Account.user_data_128:2: bar_commence: nothing to compact
2025-12-12 18:42:45.745Z debug(compaction): Account.user_data_64:2: bar_commence: nothing to compact
2025-12-12 18:42:45.745Z debug(compaction): Account.user_data_32:2: bar_commence: nothing to compact
2025-12-12 18:42:45.745Z debug(compaction): Account.ledger:2: bar_commence: nothing to compact
2025-12-12 18:42:45.745Z debug(compaction): Account.code:2: bar_commence: nothing to compact
2025-12-12 18:42:45.745Z debug(compaction): Account:2: bar_commence: nothing to compact
2025-12-12 18:42:45.745Z debug(compaction): Transfer.id:2: bar_commence: nothing to compact
2025-12-12 18:42:45.745Z debug(compaction): Transfer.debit_account_id:2: bar_commence: nothing to compact
2025-12-12 18:42:45.745Z debug(compaction): Transfer.credit_account_id:2: bar_commence: nothing to compact
2025-12-12 18:42:45.745Z debug(compaction): Transfer.amount:2: bar_commence: nothing to compact
2025-12-12 18:42:45.745Z debug(compaction): Transfer.pending_id:2: bar_commence: nothing to compact
2025-12-12 18:42:45.745Z debug(compaction): Transfer.user_data_128:2: bar_commence: nothing to compact
2025-12-12 18:42:45.745Z debug(compaction): Transfer.user_data_64:2: bar_commence: nothing to compact
2025-12-12 18:42:45.745Z debug(compaction): Transfer.user_data_32:2: bar_commence: nothing to compact
2025-12-12 18:42:45.745Z debug(compaction): Transfer.ledger:2: bar_commence: nothing to compact
2025-12-12 18:42:45.745Z debug(compaction): Transfer.code:2: bar_commence: nothing to compact
2025-12-12 18:42:45.745Z debug(compaction): Transfer:2: bar_commence: nothing to compact
2025-12-12 18:42:45.745Z debug(compaction): Transfer.expires_at:2: bar_commence: nothing to compact
2025-12-12 18:42:45.745Z debug(compaction): TransferPending:2: bar_commence: nothing to compact
2025-12-12 18:42:45.745Z debug(compaction): TransferPending.status:2: bar_commence: nothing to compact
2025-12-12 18:42:45.745Z debug(compaction): AccountEvent:2: bar_commence: nothing to compact
2025-12-12 18:42:45.745Z debug(compaction): Account.imported:2: bar_commence: nothing to compact
2025-12-12 18:42:45.745Z debug(compaction): Transfer.imported:2: bar_commence: nothing to compact
2025-12-12 18:42:45.745Z debug(compaction): Account.closed:2: bar_commence: nothing to compact
2025-12-12 18:42:45.745Z debug(compaction): Transfer.closing:2: bar_commence: nothing to compact
2025-12-12 18:42:45.745Z debug(compaction): AccountEvent.account_timestamp:2: bar_commence: nothing to compact
2025-12-12 18:42:45.745Z debug(compaction): AccountEvent.transfer_pending_status:2: bar_commence: nothing to compact
2025-12-12 18:42:45.745Z debug(compaction): AccountEvent.dr_account_id_expired:2: bar_commence: nothing to compact
2025-12-12 18:42:45.745Z debug(compaction): AccountEvent.cr_account_id_expired:2: bar_commence: nothing to compact
2025-12-12 18:42:45.745Z debug(compaction): AccountEvent.transfer_pending_id_expired:2: bar_commence: nothing to compact
2025-12-12 18:42:45.745Z debug(compaction): AccountEvent.ledger_expired:2: bar_commence: nothing to compact
2025-12-12 18:42:45.745Z debug(compaction): AccountEvent.prunable:2: bar_commence: nothing to compact
2025-12-12 18:42:45.745Z debug(compaction): Account.id:4: bar_commence: nothing to compact
2025-12-12 18:42:45.746Z debug(compaction): Account.user_data_128:4: bar_commence: nothing to compact
2025-12-12 18:42:45.746Z debug(compaction): Account.user_data_64:4: bar_commence: nothing to compact
2025-12-12 18:42:45.746Z debug(compaction): Account.user_data_32:4: bar_commence: nothing to compact
2025-12-12 18:42:45.746Z debug(compaction): Account.ledger:4: bar_commence: nothing to compact
2025-12-12 18:42:45.746Z debug(compaction): Account.code:4: bar_commence: nothing to compact
2025-12-12 18:42:45.746Z debug(compaction): Account:4: bar_commence: nothing to compact
2025-12-12 18:42:45.746Z debug(compaction): Transfer.id:4: bar_commence: nothing to compact
2025-12-12 18:42:45.746Z debug(compaction): Transfer.debit_account_id:4: bar_commence: nothing to compact
2025-12-12 18:42:45.746Z debug(compaction): Transfer.credit_account_id:4: bar_commence: nothing to compact
2025-12-12 18:42:45.746Z debug(compaction): Transfer.amount:4: bar_commence: nothing to compact
2025-12-12 18:42:45.746Z debug(compaction): Transfer.pending_id:4: bar_commence: nothing to compact
2025-12-12 18:42:45.746Z debug(compaction): Transfer.user_data_128:4: bar_commence: nothing to compact
2025-12-12 18:42:45.746Z debug(compaction): Transfer.user_data_64:4: bar_commence: nothing to compact
2025-12-12 18:42:45.746Z debug(compaction): Transfer.user_data_32:4: bar_commence: nothing to compact
2025-12-12 18:42:45.746Z debug(compaction): Transfer.ledger:4: bar_commence: nothing to compact
2025-12-12 18:42:45.746Z debug(compaction): Transfer.code:4: bar_commence: nothing to compact
2025-12-12 18:42:45.746Z debug(compaction): Transfer:4: bar_commence: nothing to compact
2025-12-12 18:42:45.746Z debug(compaction): Transfer.expires_at:4: bar_commence: nothing to compact
2025-12-12 18:42:45.746Z debug(compaction): TransferPending:4: bar_commence: nothing to compact
2025-12-12 18:42:45.746Z debug(compaction): TransferPending.status:4: bar_commence: nothing to compact
2025-12-12 18:42:45.746Z debug(compaction): AccountEvent:4: bar_commence: nothing to compact
2025-12-12 18:42:45.746Z debug(compaction): Account.imported:4: bar_commence: nothing to compact
2025-12-12 18:42:45.746Z debug(compaction): Transfer.imported:4: bar_commence: nothing to compact
2025-12-12 18:42:45.746Z debug(compaction): Account.closed:4: bar_commence: nothing to compact
2025-12-12 18:42:45.746Z debug(compaction): Transfer.closing:4: bar_commence: nothing to compact
2025-12-12 18:42:45.746Z debug(compaction): AccountEvent.account_timestamp:4: bar_commence: nothing to compact
2025-12-12 18:42:45.746Z debug(compaction): AccountEvent.transfer_pending_status:4: bar_commence: nothing to compact
2025-12-12 18:42:45.746Z debug(compaction): AccountEvent.dr_account_id_expired:4: bar_commence: nothing to compact
2025-12-12 18:42:45.746Z debug(compaction): AccountEvent.cr_account_id_expired:4: bar_commence: nothing to compact
2025-12-12 18:42:45.746Z debug(compaction): AccountEvent.transfer_pending_id_expired:4: bar_commence: nothing to compact
2025-12-12 18:42:45.746Z debug(compaction): AccountEvent.ledger_expired:4: bar_commence: nothing to compact
2025-12-12 18:42:45.746Z debug(compaction): AccountEvent.prunable:4: bar_commence: nothing to compact
2025-12-12 18:42:45.746Z debug(compaction): Account.id:6: bar_commence: nothing to compact
2025-12-12 18:42:45.746Z debug(compaction): Account.user_data_128:6: bar_commence: nothing to compact
2025-12-12 18:42:45.746Z debug(compaction): Account.user_data_64:6: bar_commence: nothing to compact
2025-12-12 18:42:45.746Z debug(compaction): Account.user_data_32:6: bar_commence: nothing to compact
2025-12-12 18:42:45.746Z debug(compaction): Account.ledger:6: bar_commence: nothing to compact
2025-12-12 18:42:45.746Z debug(compaction): Account.code:6: bar_commence: nothing to compact
2025-12-12 18:42:45.746Z debug(compaction): Account:6: bar_commence: nothing to compact
2025-12-12 18:42:45.746Z debug(compaction): Transfer.id:6: bar_commence: nothing to compact
2025-12-12 18:42:45.746Z debug(compaction): Transfer.debit_account_id:6: bar_commence: nothing to compact
2025-12-12 18:42:45.746Z debug(compaction): Transfer.credit_account_id:6: bar_commence: nothing to compact
2025-12-12 18:42:45.746Z debug(compaction): Transfer.amount:6: bar_commence: nothing to compact
2025-12-12 18:42:45.746Z debug(compaction): Transfer.pending_id:6: bar_commence: nothing to compact
2025-12-12 18:42:45.746Z debug(compaction): Transfer.user_data_128:6: bar_commence: nothing to compact
2025-12-12 18:42:45.746Z debug(compaction): Transfer.user_data_64:6: bar_commence: nothing to compact
2025-12-12 18:42:45.746Z debug(compaction): Transfer.user_data_32:6: bar_commence: nothing to compact
2025-12-12 18:42:45.746Z debug(compaction): Transfer.ledger:6: bar_commence: nothing to compact
2025-12-12 18:42:45.746Z debug(compaction): Transfer.code:6: bar_commence: nothing to compact
2025-12-12 18:42:45.746Z debug(compaction): Transfer:6: bar_commence: nothing to compact
2025-12-12 18:42:45.746Z debug(compaction): Transfer.expires_at:6: bar_commence: nothing to compact
2025-12-12 18:42:45.746Z debug(compaction): TransferPending:6: bar_commence: nothing to compact
2025-12-12 18:42:45.746Z debug(compaction): TransferPending.status:6: bar_commence: nothing to compact
2025-12-12 18:42:45.746Z debug(compaction): AccountEvent:6: bar_commence: nothing to compact
2025-12-12 18:42:45.746Z debug(compaction): Account.imported:6: bar_commence: nothing to compact
2025-12-12 18:42:45.746Z debug(compaction): Transfer.imported:6: bar_commence: nothing to compact
2025-12-12 18:42:45.746Z debug(compaction): Account.closed:6: bar_commence: nothing to compact
2025-12-12 18:42:45.746Z debug(compaction): Transfer.closing:6: bar_commence: nothing to compact
2025-12-12 18:42:45.746Z debug(compaction): AccountEvent.account_timestamp:6: bar_commence: nothing to compact
2025-12-12 18:42:45.746Z debug(compaction): AccountEvent.transfer_pending_status:6: bar_commence: nothing to compact
2025-12-12 18:42:45.746Z debug(compaction): AccountEvent.dr_account_id_expired:6: bar_commence: nothing to compact
2025-12-12 18:42:45.746Z debug(compaction): AccountEvent.cr_account_id_expired:6: bar_commence: nothing to compact
2025-12-12 18:42:45.746Z debug(compaction): AccountEvent.transfer_pending_id_expired:6: bar_commence: nothing to compact
2025-12-12 18:42:45.746Z debug(compaction): AccountEvent.ledger_expired:6: bar_commence: nothing to compact
2025-12-12 18:42:45.746Z debug(compaction): AccountEvent.prunable:6: bar_commence: nothing to compact
2025-12-12 18:42:45.746Z debug(compaction): 1: Account.id:0: beat_commence: bar quota=0 fulfilled, done=0
2025-12-12 18:42:45.746Z debug(compaction): 1: Account.user_data_128:0: beat_commence: bar quota=0 fulfilled, done=0
2025-12-12 18:42:45.746Z debug(compaction): 1: Account.user_data_64:0: beat_commence: bar quota=0 fulfilled, done=0
2025-12-12 18:42:45.746Z debug(compaction): 1: Account.user_data_32:0: beat_commence: bar quota=0 fulfilled, done=0
2025-12-12 18:42:45.746Z debug(compaction): 1: Account.ledger:0: beat_commence: bar quota=0 fulfilled, done=0
2025-12-12 18:42:45.746Z debug(compaction): 1: Account.code:0: beat_commence: bar quota=0 fulfilled, done=0
2025-12-12 18:42:45.746Z debug(compaction): 1: Account:0: beat_commence: bar quota=0 fulfilled, done=0
2025-12-12 18:42:45.747Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.prepares offset=84934656 len=122880 unlocked
2025-12-12 18:42:45.747Z debug(journal): 2: write_header: op=81 sectors[20480..24576]
2025-12-12 18:42:45.747Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.headers offset=20480 len=4096 locked
2025-12-12 18:42:45.748Z debug(compaction): Transfer.debit_account_id:0: beat_complete: quota_beat_done=16376 quota_beat=8406 quota_bar_done=16376 quota_bar=92840
2025-12-12 18:42:45.748Z debug(replica): 2N: commit_start_pipeline: waiting for quorum
2025-12-12 18:42:45.748Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.headers offset=20480 len=4096 unlocked
2025-12-12 18:42:45.748Z debug(journal): 2: write: view=2 slot=81 op=81 len=121088: 75307684776007077891113995186346302623 complete, marking clean
2025-12-12 18:42:45.748Z debug(replica): 2N: send_prepare_ok: op=81 checksum=75307684776007077891113995186346302623
2025-12-12 18:42:45.748Z debug(replica): 2N: sending prepare_ok to replica 2: vsr.message_header.Header.PrepareOk{ .checksum = 161892780636968307497380861031418419545, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 2, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 190906259201884426279323688639025730549, .parent_padding = 0, .prepare_checksum = 75307684776007077891113995186346302623, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 129800060941563857535569923226995055452, .op = 81, .commit_min = 80, .timestamp = 1765564965742697463, .request = 79, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-12-12 18:42:45.748Z debug(replica): 2N: on_message: view=2 status=normal vsr.message_header.Header.PrepareOk{ .checksum = 161892780636968307497380861031418419545, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 2, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 190906259201884426279323688639025730549, .parent_padding = 0, .prepare_checksum = 75307684776007077891113995186346302623, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 129800060941563857535569923226995055452, .op = 81, .commit_min = 80, .timestamp = 1765564965742697463, .request = 79, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-12-12 18:42:45.748Z debug(vsr): 2: primary_abdicate_timeout reset
2025-12-12 18:42:45.748Z debug(replica): 2N: on_prepare_ok: 1 message(s)
2025-12-12 18:42:45.748Z debug(replica): 2N: on_prepare_ok: waiting for quorum
2025-12-12 18:42:45.750Z debug(vsr): 0: journal_repair_budget_timeout fired
2025-12-12 18:42:45.750Z debug(vsr): 0: journal_repair_budget_timeout reset
2025-12-12 18:42:45.767Z debug(client_replies): 1: write_reply: wrote (client=129800060941563857535569923226995055452 request=78)
2025-12-12 18:42:45.762Z debug(vsr): 2: journal_repair_budget_timeout fired
2025-12-12 18:42:48.393Z debug(vsr): 2: journal_repair_budget_timeout reset
2025-12-12 18:42:48.393Z debug(vsr): 2: journal_repair_timeout fired
2025-12-12 18:42:48.393Z debug(vsr): 2: journal_repair_timeout reset
2025-12-12 18:42:48.393Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.prepares offset=84934656 len=122880 unlocked
2025-12-12 18:42:48.394Z debug(journal): 1: write_header: op=81 sectors[20480..24576]
2025-12-12 18:42:48.394Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.headers offset=20480 len=4096 locked
2025-12-12 18:42:48.394Z debug(compaction): Transfer.id:0: beat_complete: quota_beat_done=93158 quota_beat=93158 quota_bar_done=93158 quota_bar=93158
2025-12-12 18:42:48.394Z debug(compaction): 1: Account.id:0: beat_commence: bar quota=0 fulfilled, done=0
2025-12-12 18:42:48.394Z debug(compaction): 1: Account.user_data_128:0: beat_commence: bar quota=0 fulfilled, done=0
2025-12-12 18:42:48.394Z debug(compaction): 1: Account.user_data_64:0: beat_commence: bar quota=0 fulfilled, done=0
2025-12-12 18:42:48.394Z debug(compaction): 1: Account.user_data_32:0: beat_commence: bar quota=0 fulfilled, done=0
2025-12-12 18:42:48.394Z debug(compaction): 1: Account.ledger:0: beat_commence: bar quota=0 fulfilled, done=0
2025-12-12 18:42:48.394Z debug(compaction): 1: Account.code:0: beat_commence: bar quota=0 fulfilled, done=0
2025-12-12 18:42:48.394Z debug(compaction): 1: Account:0: beat_commence: bar quota=0 fulfilled, done=0
2025-12-12 18:42:48.394Z debug(compaction): 1: Transfer.id:0: beat_commence: bar quota=93158 fulfilled, done=93158
2025-12-12 18:42:48.394Z debug(replica): 2N: on_message: view=2 status=normal vsr.message_header.Header.Request{ .checksum = 206965483952788878501331448987007267279, .checksum_padding = 0, .checksum_body = 186100930357175022436291576967370647900, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 121088, .epoch = 0, .view = 2, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 102223299795980850673429666419134149757, .parent_padding = 0, .client = 129800060941563857535569923226995055452, .session = 2, .timestamp = 0, .request = 79, .operation = vsr.Operation(139), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 2595635519, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 18:42:48.394Z debug(replica): 2N: on_request: new request
2025-12-12 18:42:48.394Z debug(replica): 2N: on_request: ignoring (already preparing)
2025-12-12 18:42:48.397Z debug(replica): 1n: on_message: view=2 status=normal vsr.message_header.Header.Request{ .checksum = 206965483952788878501331448987007267279, .checksum_padding = 0, .checksum_body = 186100930357175022436291576967370647900, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 121088, .epoch = 0, .view = 2, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 102223299795980850673429666419134149757, .parent_padding = 0, .client = 129800060941563857535569923226995055452, .session = 2, .timestamp = 0, .request = 79, .operation = vsr.Operation(139), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 2595635519, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 18:42:48.397Z debug(replica): 1n: on_request: forwarding new request to primary (view=2)
2025-12-12 18:42:48.397Z debug(replica): 1n: sending request to replica 2: vsr.message_header.Header.Request{ .checksum = 206965483952788878501331448987007267279, .checksum_padding = 0, .checksum_body = 186100930357175022436291576967370647900, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 121088, .epoch = 0, .view = 2, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 102223299795980850673429666419134149757, .parent_padding = 0, .client = 129800060941563857535569923226995055452, .session = 2, .timestamp = 0, .request = 79, .operation = vsr.Operation(139), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 2595635519, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 18:42:48.398Z debug(vsr): 1: journal_repair_budget_timeout fired
2025-12-12 18:42:48.398Z debug(vsr): 1: journal_repair_budget_timeout reset
2025-12-12 18:42:48.398Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.headers offset=20480 len=4096 unlocked
2025-12-12 18:42:48.398Z debug(journal): 1: write: view=2 slot=81 op=81 len=121088: 75307684776007077891113995186346302623 complete, marking clean
2025-12-12 18:42:48.398Z debug(replica): 1n: send_prepare_ok: op=81 checksum=75307684776007077891113995186346302623
2025-12-12 18:42:48.398Z debug(replica): 1n: sending prepare_ok to replica 2: vsr.message_header.Header.PrepareOk{ .checksum = 77493422515034970027406496368158695469, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 2, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 190906259201884426279323688639025730549, .parent_padding = 0, .prepare_checksum = 75307684776007077891113995186346302623, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 129800060941563857535569923226995055452, .op = 81, .commit_min = 80, .timestamp = 1765564965742697463, .request = 79, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-12-12 18:42:48.398Z debug(compaction): Transfer.debit_account_id:0: beat_complete: quota_beat_done=16376 quota_beat=8406 quota_bar_done=16376 quota_bar=92840
2025-12-12 18:42:48.398Z warning(replica): 1n: commit_dispatch: slow request, request=78 size=2064 lookup_accounts time=2653ms
2025-12-12 18:42:48.398Z debug(replica): 2N: on_message: view=2 status=normal vsr.message_header.Header.Request{ .checksum = 206965483952788878501331448987007267279, .checksum_padding = 0, .checksum_body = 186100930357175022436291576967370647900, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 121088, .epoch = 0, .view = 2, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 102223299795980850673429666419134149757, .parent_padding = 0, .client = 129800060941563857535569923226995055452, .session = 2, .timestamp = 0, .request = 79, .operation = vsr.Operation(139), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 2595635519, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 18:42:48.398Z debug(replica): 2N: on_request: new request
2025-12-12 18:42:48.398Z debug(replica): 2N: on_request: ignoring (already preparing)
2025-12-12 18:42:48.398Z debug(replica): 2N: on_message: view=2 status=normal vsr.message_header.Header.PrepareOk{ .checksum = 77493422515034970027406496368158695469, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 2, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 190906259201884426279323688639025730549, .parent_padding = 0, .prepare_checksum = 75307684776007077891113995186346302623, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 129800060941563857535569923226995055452, .op = 81, .commit_min = 80, .timestamp = 1765564965742697463, .request = 79, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-12-12 18:42:48.399Z debug(vsr): 2: primary_abdicate_timeout reset
2025-12-12 18:42:48.399Z debug(replica): 2N: on_prepare_ok: 2 message(s)
2025-12-12 18:42:48.399Z debug(replica): 2N: on_prepare_ok: quorum received, context=75307684776007077891113995186346302623
2025-12-12 18:42:48.399Z debug(vsr): 2: prepare_timeout stopped
2025-12-12 18:42:48.399Z debug(vsr): 2: primary_abdicate_timeout stopped
2025-12-12 18:42:48.399Z debug(replica): 2N: execute_op: executing view=2 primary=true op=81 checksum=75307684776007077891113995186346302623 (create_transfers)
2025-12-12 18:42:48.399Z debug(replica): 2N: execute_op: commit_timestamp=1765564963130383380 prepare.header.timestamp=1765564965742697463
2025-12-12 18:42:48.403Z debug(replica): 2N: execute_op: advancing commit_max=80..81
2025-12-12 18:42:48.403Z debug(replica): 2N: client_table_entry_update: client=129800060941563857535569923226995055452 session=2 request=79
2025-12-12 18:42:48.403Z debug(replica): 2N: execute_op: replying to client: vsr.message_header.Header.Reply{ .checksum = 105147828771690831464791649331242073263, .checksum_padding = 0, .checksum_body = 24562775496979689271572808536896432243, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 296, .epoch = 0, .view = 2, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 206965483952788878501331448987007267279, .request_checksum_padding = 0, .context = 143857196813019442212290607245469996569, .context_padding = 0, .client = 129800060941563857535569923226995055452, .op = 81, .commit = 81, .timestamp = 1765564965742697463, .request = 79, .operation = vsr.Operation(139), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 18:42:48.403Z debug(replica): 2N: sending reply to client 129800060941563857535569923226995055452: vsr.message_header.Header.Reply{ .checksum = 105147828771690831464791649331242073263, .checksum_padding = 0, .checksum_body = 24562775496979689271572808536896432243, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 296, .epoch = 0, .view = 2, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 206965483952788878501331448987007267279, .request_checksum_padding = 0, .context = 143857196813019442212290607245469996569, .context_padding = 0, .client = 129800060941563857535569923226995055452, .op = 81, .commit = 81, .timestamp = 1765564965742697463, .request = 79, .operation = vsr.Operation(139), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 18:42:48.403Z debug(forest): entering forest.compact() op=81 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
warning(client): 129800060941563857535569923226995055452: on_reply: slow request, request=79 op=81 size=121088 create_transfers time=2676ms
2025-12-12 18:42:48.403Z debug(compaction): 2: Account.id:0: beat_commence: bar quota=0 fulfilled, done=0
2025-12-12 18:42:48.403Z debug(compaction): 2: Account.user_data_128:0: beat_commence: bar quota=0 fulfilled, done=0
2025-12-12 18:42:48.403Z debug(compaction): 2: Account.user_data_64:0: beat_commence: bar quota=0 fulfilled, done=0
2025-12-12 18:42:48.403Z debug(compaction): 2: Account.user_data_32:0: beat_commence: bar quota=0 fulfilled, done=0
2025-12-12 18:42:48.403Z debug(compaction): 2: Account.ledger:0: beat_commence: bar quota=0 fulfilled, done=0
2025-12-12 18:42:48.403Z debug(compaction): 2: Account.code:0: beat_commence: bar quota=0 fulfilled, done=0
2025-12-12 18:42:48.403Z debug(compaction): 2: Account:0: beat_commence: bar quota=0 fulfilled, done=0
2025-12-12 18:42:48.403Z debug(compaction): 2: Transfer.id:0: beat_commence: bar quota=93158 fulfilled, done=93158
2025-12-12 18:42:48.403Z warning(clock): 0: synchronization failed, partitioned (sources=1 samples=1)
2025-12-12 18:42:48.407Z debug(replica): 1n: on_message: view=2 status=normal vsr.message_header.Header.Request{ .checksum = 365909904073293281432199028363919757, .checksum_padding = 0, .checksum_body = 8534786181244049314008013070841583767, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2064, .epoch = 0, .view = 2, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 143857196813019442212290607245469996569, .parent_padding = 0, .client = 129800060941563857535569923226995055452, .session = 2, .timestamp = 0, .request = 80, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 2676807762, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 18:42:48.407Z debug(replica): 1n: on_request: forwarding new request to primary (view=2)
2025-12-12 18:42:48.407Z debug(replica): 1n: sending request to replica 2: vsr.message_header.Header.Request{ .checksum = 365909904073293281432199028363919757, .checksum_padding = 0, .checksum_body = 8534786181244049314008013070841583767, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2064, .epoch = 0, .view = 2, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 143857196813019442212290607245469996569, .parent_padding = 0, .client = 129800060941563857535569923226995055452, .session = 2, .timestamp = 0, .request = 80, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 2676807762, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 18:42:48.413Z debug(vsr): 0: journal_repair_budget_timeout fired
2025-12-12 18:42:48.413Z debug(vsr): 0: journal_repair_budget_timeout reset
2025-12-12 18:42:48.417Z debug(replica): 2N: on_message: view=2 status=normal vsr.message_header.Header.Request{ .checksum = 365909904073293281432199028363919757, .checksum_padding = 0, .checksum_body = 8534786181244049314008013070841583767, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2064, .epoch = 0, .view = 2, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 143857196813019442212290607245469996569, .parent_padding = 0, .client = 129800060941563857535569923226995055452, .session = 2, .timestamp = 0, .request = 80, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 2676807762, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 18:42:48.417Z debug(replica): 2N: on_request: new request
2025-12-12 18:42:48.417Z debug(replica): 2N: primary_pipeline_prepare: request checksum=365909904073293281432199028363919757 client=129800060941563857535569923226995055452
2025-12-12 18:42:48.417Z debug(replica): 2N: primary_pipeline_prepare: prepare checksum=162127257168752911751447890883838318903 op=82
2025-12-12 18:42:48.417Z debug(vsr): 2: prepare_timeout started
2025-12-12 18:42:48.417Z debug(vsr): 2: primary_abdicate_timeout started
2025-12-12 18:42:48.417Z debug(vsr): 2: pulse_timeout reset
2025-12-12 18:42:48.417Z debug(replica): 2N: replicate: replicating op=82 to replica 0
2025-12-12 18:42:48.417Z debug(replica): 2N: sending prepare to replica 0: vsr.message_header.Header.Prepare{ .checksum = 162127257168752911751447890883838318903, .checksum_padding = 0, .checksum_body = 8534786181244049314008013070841583767, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2064, .epoch = 0, .view = 2, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 75307684776007077891113995186346302623, .parent_padding = 0, .request_checksum = 365909904073293281432199028363919757, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 129800060941563857535569923226995055452, .op = 82, .commit = 81, .timestamp = 1765564968417197214, .request = 80, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-12-12 18:42:48.417Z debug(message_bus): 2: send_message_to_replica: no connection to=0 header=vsr.message_header.Header.Prepare{ .checksum = 162127257168752911751447890883838318903, .checksum_padding = 0, .checksum_body = 8534786181244049314008013070841583767, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2064, .epoch = 0, .view = 2, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 75307684776007077891113995186346302623, .parent_padding = 0, .request_checksum = 365909904073293281432199028363919757, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 129800060941563857535569923226995055452, .op = 82, .commit = 81, .timestamp = 1765564968417197214, .request = 80, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-12-12 18:42:48.417Z debug(replica): 2N: replicate: replicating op=82 to replica 1
2025-12-12 18:42:48.417Z debug(replica): 2N: sending prepare to replica 1: vsr.message_header.Header.Prepare{ .checksum = 162127257168752911751447890883838318903, .checksum_padding = 0, .checksum_body = 8534786181244049314008013070841583767, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2064, .epoch = 0, .view = 2, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 75307684776007077891113995186346302623, .parent_padding = 0, .request_checksum = 365909904073293281432199028363919757, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 129800060941563857535569923226995055452, .op = 82, .commit = 81, .timestamp = 1765564968417197214, .request = 80, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-12-12 18:42:48.417Z debug(replica): 2N: on_prepare: advancing: op=81..82 checksum=75307684776007077891113995186346302623..162127257168752911751447890883838318903
2025-12-12 18:42:48.417Z debug(journal): 2: set_header_as_dirty: op=82 checksum=162127257168752911751447890883838318903
2025-12-12 18:42:48.417Z debug(replica): 2N: append: appending to journal op=82
2025-12-12 18:42:48.417Z debug(journal): 2: write: view=2 slot=82 op=82 len=2064: 162127257168752911751447890883838318903 starting
2025-12-12 18:42:48.417Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.prepares offset=85983232 len=4096 locked
2025-12-12 18:42:48.417Z debug(client_replies): 2: write_reply: wrote (client=129800060941563857535569923226995055452 request=79)
2025-12-12 18:42:48.417Z debug(replica): 1n: on_message: view=2 status=normal vsr.message_header.Header.Prepare{ .checksum = 162127257168752911751447890883838318903, .checksum_padding = 0, .checksum_body = 8534786181244049314008013070841583767, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2064, .epoch = 0, .view = 2, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 75307684776007077891113995186346302623, .parent_padding = 0, .request_checksum = 365909904073293281432199028363919757, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 129800060941563857535569923226995055452, .op = 82, .commit = 81, .timestamp = 1765564968417197214, .request = 80, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-12-12 18:42:48.417Z debug(replica): 1n: on_prepare: advancing commit_max=80..81
2025-12-12 18:42:48.417Z debug(replica): 1n: on_prepare: caching prepare.op=82 (commit_min=80 op=81 commit_max=81 prepare_max=1007)
2025-12-12 18:42:48.417Z debug(replica): 2N: on_message: view=2 status=normal vsr.message_header.Header.Request{ .checksum = 365909904073293281432199028363919757, .checksum_padding = 0, .checksum_body = 8534786181244049314008013070841583767, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2064, .epoch = 0, .view = 2, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 143857196813019442212290607245469996569, .parent_padding = 0, .client = 129800060941563857535569923226995055452, .session = 2, .timestamp = 0, .request = 80, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 2676807762, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 18:42:48.417Z debug(replica): 2N: on_request: new request
2025-12-12 18:42:48.417Z debug(replica): 1n: on_prepare: advancing: op=81..82 checksum=75307684776007077891113995186346302623..162127257168752911751447890883838318903
2025-12-12 18:42:48.417Z debug(replica): 2N: on_request: ignoring (already preparing)
2025-12-12 18:42:48.417Z debug(journal): 1: set_header_as_dirty: op=82 checksum=162127257168752911751447890883838318903
2025-12-12 18:42:48.417Z debug(replica): 1n: append: appending to journal op=82
2025-12-12 18:42:48.417Z debug(journal): 1: write: view=2 slot=82 op=82 len=2064: 162127257168752911751447890883838318903 starting
2025-12-12 18:42:48.417Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.prepares offset=85983232 len=4096 locked
2025-12-12 18:42:48.417Z debug(replica): 1n: commit_start_journal: cached prepare op=81 checksum=75307684776007077891113995186346302623
2025-12-12 18:42:48.417Z debug(replica): 1n: repair_prepare: op=82 checksum=162127257168752911751447890883838318903 (already writing)
2025-12-12 18:42:48.417Z debug(replica): 1n: commit_journal: already committing (prefetch; commit_min=80)
2025-12-12 18:42:48.418Z debug(replica): 1n: execute_op: executing view=2 primary=false op=81 checksum=75307684776007077891113995186346302623 (create_transfers)
2025-12-12 18:42:48.418Z debug(replica): 1n: execute_op: commit_timestamp=1765564963130383380 prepare.header.timestamp=1765564965742697463
2025-12-12 18:42:48.418Z debug(compaction): Transfer.debit_account_id:0: beat_complete: quota_beat_done=76464 quota_beat=76464 quota_bar_done=92840 quota_bar=92840
2025-12-12 18:42:48.418Z debug(compaction): 2: Account.id:0: beat_commence: bar quota=0 fulfilled, done=0
2025-12-12 18:42:48.418Z debug(compaction): 2: Account.user_data_128:0: beat_commence: bar quota=0 fulfilled, done=0
2025-12-12 18:42:48.418Z debug(compaction): 2: Account.user_data_64:0: beat_commence: bar quota=0 fulfilled, done=0
2025-12-12 18:42:48.418Z debug(compaction): 2: Account.user_data_32:0: beat_commence: bar quota=0 fulfilled, done=0
2025-12-12 18:42:48.418Z debug(compaction): 2: Account.ledger:0: beat_commence: bar quota=0 fulfilled, done=0
2025-12-12 18:42:48.418Z debug(compaction): 2: Account.code:0: beat_commence: bar quota=0 fulfilled, done=0
2025-12-12 18:42:48.418Z debug(compaction): 2: Account:0: beat_commence: bar quota=0 fulfilled, done=0
2025-12-12 18:42:48.418Z debug(compaction): 2: Transfer.id:0: beat_commence: bar quota=93158 fulfilled, done=93158
2025-12-12 18:42:48.418Z debug(compaction): 2: Transfer.debit_account_id:0: beat_commence: bar quota=92840 fulfilled, done=92840
2025-12-12 18:42:48.421Z debug(replica): 1n: client_table_entry_update: client=129800060941563857535569923226995055452 session=2 request=79
2025-12-12 18:42:48.421Z debug(replica): 1n: execute_op: replying to client: vsr.message_header.Header.Reply{ .checksum = 105147828771690831464791649331242073263, .checksum_padding = 0, .checksum_body = 24562775496979689271572808536896432243, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 296, .epoch = 0, .view = 2, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 206965483952788878501331448987007267279, .request_checksum_padding = 0, .context = 143857196813019442212290607245469996569, .context_padding = 0, .client = 129800060941563857535569923226995055452, .op = 81, .commit = 81, .timestamp = 1765564965742697463, .request = 79, .operation = vsr.Operation(139), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 18:42:48.421Z debug(replica): 1n: sending reply to client 129800060941563857535569923226995055452: vsr.message_header.Header.Reply{ .checksum = 105147828771690831464791649331242073263, .checksum_padding = 0, .checksum_body = 24562775496979689271572808536896432243, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 296, .epoch = 0, .view = 2, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 206965483952788878501331448987007267279, .request_checksum_padding = 0, .context = 143857196813019442212290607245469996569, .context_padding = 0, .client = 129800060941563857535569923226995055452, .op = 81, .commit = 81, .timestamp = 1765564965742697463, .request = 79, .operation = vsr.Operation(139), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 18:42:48.422Z debug(forest): entering forest.compact() op=81 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2025-12-12 18:42:48.422Z debug(compaction): 1: Account.id:0: beat_commence: bar quota=0 fulfilled, done=0
2025-12-12 18:42:48.422Z debug(compaction): 1: Account.user_data_128:0: beat_commence: bar quota=0 fulfilled, done=0
2025-12-12 18:42:48.422Z debug(compaction): 1: Account.user_data_64:0: beat_commence: bar quota=0 fulfilled, done=0
2025-12-12 18:42:48.422Z debug(compaction): 1: Account.user_data_32:0: beat_commence: bar quota=0 fulfilled, done=0
2025-12-12 18:42:48.422Z debug(compaction): 1: Account.ledger:0: beat_commence: bar quota=0 fulfilled, done=0
2025-12-12 18:42:48.422Z debug(compaction): 1: Account.code:0: beat_commence: bar quota=0 fulfilled, done=0
2025-12-12 18:42:48.422Z debug(compaction): 1: Account:0: beat_commence: bar quota=0 fulfilled, done=0
2025-12-12 18:42:48.422Z debug(compaction): 1: Transfer.id:0: beat_commence: bar quota=93158 fulfilled, done=93158
2025-12-12 18:42:48.424Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.prepares offset=85983232 len=4096 unlocked
2025-12-12 18:42:48.424Z debug(journal): 2: write_header: op=82 sectors[20480..24576]
2025-12-12 18:42:48.424Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.headers offset=20480 len=4096 locked
2025-12-12 18:42:48.425Z debug(compaction): Transfer.credit_account_id:0: beat_complete: quota_beat_done=32752 quota_beat=24569 quota_bar_done=32752 quota_bar=92840
2025-12-12 18:42:48.427Z debug(replica): 2N: commit_start_pipeline: waiting for quorum
2025-12-12 18:42:48.427Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.headers offset=20480 len=4096 unlocked
2025-12-12 18:42:48.427Z debug(journal): 2: write: view=2 slot=82 op=82 len=2064: 162127257168752911751447890883838318903 complete, marking clean
2025-12-12 18:42:48.427Z debug(replica): 2N: send_prepare_ok: op=82 checksum=162127257168752911751447890883838318903
2025-12-12 18:42:48.427Z debug(replica): 2N: sending prepare_ok to replica 2: vsr.message_header.Header.PrepareOk{ .checksum = 193166938807295469315087628328086900646, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 2, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 75307684776007077891113995186346302623, .parent_padding = 0, .prepare_checksum = 162127257168752911751447890883838318903, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 129800060941563857535569923226995055452, .op = 82, .commit_min = 81, .timestamp = 1765564968417197214, .request = 80, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-12-12 18:42:48.427Z debug(replica): 2N: on_message: view=2 status=normal vsr.message_header.Header.PrepareOk{ .checksum = 193166938807295469315087628328086900646, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 2, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 75307684776007077891113995186346302623, .parent_padding = 0, .prepare_checksum = 162127257168752911751447890883838318903, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 129800060941563857535569923226995055452, .op = 82, .commit_min = 81, .timestamp = 1765564968417197214, .request = 80, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-12-12 18:42:48.427Z debug(vsr): 2: primary_abdicate_timeout reset
2025-12-12 18:42:48.427Z debug(replica): 2N: on_prepare_ok: 1 message(s)
2025-12-12 18:42:48.427Z debug(replica): 2N: on_prepare_ok: waiting for quorum
2025-12-12 18:42:48.427Z debug(vsr): 2: journal_repair_budget_timeout fired
2025-12-12 18:42:48.427Z debug(vsr): 2: journal_repair_budget_timeout reset
2025-12-12 18:42:48.434Z debug(vsr): 0: journal_repair_budget_timeout fired
2025-12-12 18:42:48.434Z debug(vsr): 0: journal_repair_budget_timeout reset
2025-12-12 18:42:48.434Z debug(vsr): 0: journal_repair_timeout fired
2025-12-12 18:42:48.434Z debug(vsr): 0: journal_repair_timeout reset
2025-12-12 18:42:48.436Z debug(vsr): 1: journal_repair_budget_timeout fired
2025-12-12 18:42:48.436Z debug(vsr): 1: journal_repair_budget_timeout reset
2025-12-12 18:42:48.436Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.prepares offset=85983232 len=4096 unlocked
2025-12-12 18:42:48.436Z debug(journal): 1: write_header: op=82 sectors[20480..24576]
2025-12-12 18:42:48.436Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.headers offset=20480 len=4096 locked
2025-12-12 18:42:48.436Z debug(client_replies): 1: write_reply: wrote (client=129800060941563857535569923226995055452 request=79)
2025-12-12 18:42:48.437Z debug(compaction): Transfer.debit_account_id:0: beat_complete: quota_beat_done=76464 quota_beat=76464 quota_bar_done=92840 quota_bar=92840
2025-12-12 18:42:48.437Z debug(compaction): 1: Account.id:0: beat_commence: bar quota=0 fulfilled, done=0
2025-12-12 18:42:48.437Z debug(compaction): 1: Account.user_data_128:0: beat_commence: bar quota=0 fulfilled, done=0
2025-12-12 18:42:48.437Z debug(compaction): 1: Account.user_data_64:0: beat_commence: bar quota=0 fulfilled, done=0
2025-12-12 18:42:48.437Z debug(compaction): 1: Account.user_data_32:0: beat_commence: bar quota=0 fulfilled, done=0
2025-12-12 18:42:48.437Z debug(compaction): 1: Account.ledger:0: beat_commence: bar quota=0 fulfilled, done=0
2025-12-12 18:42:48.437Z debug(compaction): 1: Account.code:0: beat_commence: bar quota=0 fulfilled, done=0
2025-12-12 18:42:48.437Z debug(compaction): 1: Account:0: beat_commence: bar quota=0 fulfilled, done=0
2025-12-12 18:42:48.437Z debug(compaction): 1: Transfer.id:0: beat_commence: bar quota=93158 fulfilled, done=93158
2025-12-12 18:42:48.437Z debug(compaction): 1: Transfer.debit_account_id:0: beat_commence: bar quota=92840 fulfilled, done=92840
2025-12-12 18:42:48.443Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.headers offset=20480 len=4096 unlocked
2025-12-12 18:42:48.443Z debug(journal): 1: write: view=2 slot=82 op=82 len=2064: 162127257168752911751447890883838318903 complete, marking clean
2025-12-12 18:42:48.443Z debug(replica): 1n: send_prepare_ok: op=82 checksum=162127257168752911751447890883838318903
2025-12-12 18:42:48.443Z debug(replica): 1n: sending prepare_ok to replica 2: vsr.message_header.Header.PrepareOk{ .checksum = 295077714667068529441972610882565748413, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 2, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 75307684776007077891113995186346302623, .parent_padding = 0, .prepare_checksum = 162127257168752911751447890883838318903, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 129800060941563857535569923226995055452, .op = 82, .commit_min = 81, .timestamp = 1765564968417197214, .request = 80, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-12-12 18:42:48.444Z debug(compaction): Transfer.credit_account_id:0: beat_complete: quota_beat_done=32752 quota_beat=24569 quota_bar_done=32752 quota_bar=92840
2025-12-12 18:42:48.447Z debug(vsr): 2: journal_repair_budget_timeout fired
2025-12-12 18:42:48.447Z debug(vsr): 2: journal_repair_budget_timeout reset
2025-12-12 18:42:48.454Z debug(vsr): 0: journal_repair_budget_timeout fired
2025-12-12 18:42:48.454Z debug(vsr): 0: journal_repair_budget_timeout reset
2025-12-12 18:42:48.456Z debug(vsr): 1: journal_repair_budget_timeout fired
2025-12-12 18:42:48.456Z debug(vsr): 1: journal_repair_budget_timeout reset
2025-12-12 18:42:48.464Z debug(replica): 2N: on_message: view=2 status=normal vsr.message_header.Header.PrepareOk{ .checksum = 295077714667068529441972610882565748413, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 2, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 75307684776007077891113995186346302623, .parent_padding = 0, .prepare_checksum = 162127257168752911751447890883838318903, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 129800060941563857535569923226995055452, .op = 82, .commit_min = 81, .timestamp = 1765564968417197214, .request = 80, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-12-12 18:42:48.464Z debug(vsr): 2: primary_abdicate_timeout reset
2025-12-12 18:42:48.464Z debug(replica): 2N: on_prepare_ok: 2 message(s)
2025-12-12 18:42:48.464Z debug(replica): 2N: on_prepare_ok: quorum received, context=162127257168752911751447890883838318903
2025-12-12 18:42:48.464Z debug(vsr): 2: prepare_timeout stopped
2025-12-12 18:42:48.464Z debug(vsr): 2: primary_abdicate_timeout stopped
2025-12-12 18:42:48.464Z debug(replica): 2N: execute_op: executing view=2 primary=true op=82 checksum=162127257168752911751447890883838318903 (lookup_accounts)
2025-12-12 18:42:48.464Z debug(replica): 2N: execute_op: commit_timestamp=1765564965742697463 prepare.header.timestamp=1765564968417197214
2025-12-12 18:42:48.464Z debug(replica): 2N: execute_op: advancing commit_max=81..82
2025-12-12 18:42:48.464Z debug(replica): 2N: client_table_entry_update: client=129800060941563857535569923226995055452 session=2 request=80
2025-12-12 18:42:48.464Z debug(replica): 2N: execute_op: replying to client: vsr.message_header.Header.Reply{ .checksum = 297810883317257275998524263504804999002, .checksum_padding = 0, .checksum_body = 53633611036230836637116873376307580091, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 14720, .epoch = 0, .view = 2, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 365909904073293281432199028363919757, .request_checksum_padding = 0, .context = 329773723757090566204971058525184476939, .context_padding = 0, .client = 129800060941563857535569923226995055452, .op = 82, .commit = 82, .timestamp = 1765564968417197214, .request = 80, .operation = vsr.Operation(140), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 18:42:48.464Z debug(replica): 2N: sending reply to client 129800060941563857535569923226995055452: vsr.message_header.Header.Reply{ .checksum = 297810883317257275998524263504804999002, .checksum_padding = 0, .checksum_body = 53633611036230836637116873376307580091, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 14720, .epoch = 0, .view = 2, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 365909904073293281432199028363919757, .request_checksum_padding = 0, .context = 329773723757090566204971058525184476939, .context_padding = 0, .client = 129800060941563857535569923226995055452, .op = 82, .commit = 82, .timestamp = 1765564968417197214, .request = 80, .operation = vsr.Operation(140), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 18:42:48.464Z debug(forest): entering forest.compact() op=82 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2025-12-12 18:42:48.464Z debug(compaction): 2: Account.id:0: beat_commence: bar quota=0 fulfilled, done=0
2025-12-12 18:42:48.464Z debug(compaction): 2: Account.user_data_128:0: beat_commence: bar quota=0 fulfilled, done=0
2025-12-12 18:42:48.464Z debug(compaction): 2: Account.user_data_64:0: beat_commence: bar quota=0 fulfilled, done=0
2025-12-12 18:42:48.464Z debug(compaction): 2: Account.user_data_32:0: beat_commence: bar quota=0 fulfilled, done=0
2025-12-12 18:42:48.464Z debug(compaction): 2: Account.ledger:0: beat_commence: bar quota=0 fulfilled, done=0
2025-12-12 18:42:48.464Z debug(compaction): 2: Account.code:0: beat_commence: bar quota=0 fulfilled, done=0
2025-12-12 18:42:48.464Z debug(compaction): 2: Account:0: beat_commence: bar quota=0 fulfilled, done=0
2025-12-12 18:42:48.464Z debug(compaction): 2: Transfer.id:0: beat_commence: bar quota=93158 fulfilled, done=93158
2025-12-12 18:42:48.464Z debug(compaction): 2: Transfer.debit_account_id:0: beat_commence: bar quota=92840 fulfilled, done=92840
2025-12-12 18:42:48.465Z info(workload): accounts created = 112, transfers = 133641, pending transfers = 0, commands run = 40
2025-12-12 18:42:48.475Z debug(vsr): 2: journal_repair_budget_timeout fired
2025-12-12 18:42:48.475Z debug(vsr): 2: journal_repair_budget_timeout reset
2025-12-12 18:42:48.475Z debug(client_replies): 2: write_reply: wrote (client=129800060941563857535569923226995055452 request=80)
2025-12-12 18:42:48.476Z debug(vsr): 1: journal_repair_budget_timeout fired
2025-12-12 18:42:48.476Z debug(vsr): 1: journal_repair_budget_timeout reset
2025-12-12 18:42:48.476Z debug(replica): 0n: on_message: view=2 status=normal vsr.message_header.Header.Request{ .checksum = 39792972214874618568501445663341288247, .checksum_padding = 0, .checksum_body = 281034154456906138187476354491563389195, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 665600, .epoch = 0, .view = 2, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 329773723757090566204971058525184476939, .parent_padding = 0, .client = 129800060941563857535569923226995055452, .session = 2, .timestamp = 0, .request = 81, .operation = vsr.Operation(139), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 57838157, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 18:42:48.476Z debug(replica): 0n: on_request: forwarding new request to primary (view=2)
2025-12-12 18:42:48.476Z debug(replica): 0n: sending request to replica 2: vsr.message_header.Header.Request{ .checksum = 39792972214874618568501445663341288247, .checksum_padding = 0, .checksum_body = 281034154456906138187476354491563389195, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 665600, .epoch = 0, .view = 2, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 329773723757090566204971058525184476939, .parent_padding = 0, .client = 129800060941563857535569923226995055452, .session = 2, .timestamp = 0, .request = 81, .operation = vsr.Operation(139), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 57838157, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 18:42:48.477Z debug(vsr): 0: journal_repair_budget_timeout fired
2025-12-12 18:42:48.477Z debug(vsr): 0: journal_repair_budget_timeout reset
2025-12-12 18:42:48.478Z debug(replica): 2N: on_message: view=2 status=normal vsr.message_header.Header.Request{ .checksum = 39792972214874618568501445663341288247, .checksum_padding = 0, .checksum_body = 281034154456906138187476354491563389195, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 665600, .epoch = 0, .view = 2, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 329773723757090566204971058525184476939, .parent_padding = 0, .client = 129800060941563857535569923226995055452, .session = 2, .timestamp = 0, .request = 81, .operation = vsr.Operation(139), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 57838157, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 18:42:48.478Z debug(replica): 2N: on_request: new request
2025-12-12 18:42:48.478Z debug(replica): 2N: primary_pipeline_prepare: request checksum=39792972214874618568501445663341288247 client=129800060941563857535569923226995055452
2025-12-12 18:42:48.481Z debug(replica): 2N: primary_pipeline_prepare: prepare checksum=57018800251387350987699266840338142777 op=83
2025-12-12 18:42:48.481Z debug(vsr): 2: prepare_timeout started
2025-12-12 18:42:48.481Z debug(vsr): 2: primary_abdicate_timeout started
2025-12-12 18:42:48.481Z debug(vsr): 2: pulse_timeout reset
2025-12-12 18:42:48.481Z debug(replica): 2N: replicate: replicating op=83 to replica 0
2025-12-12 18:42:48.481Z debug(replica): 2N: sending prepare to replica 0: vsr.message_header.Header.Prepare{ .checksum = 57018800251387350987699266840338142777, .checksum_padding = 0, .checksum_body = 281034154456906138187476354491563389195, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 665600, .epoch = 0, .view = 2, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 162127257168752911751447890883838318903, .parent_padding = 0, .request_checksum = 39792972214874618568501445663341288247, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 129800060941563857535569923226995055452, .op = 83, .commit = 82, .timestamp = 1765564968478784265, .request = 81, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-12-12 18:42:48.481Z debug(message_bus): 2: send_message_to_replica: no connection to=0 header=vsr.message_header.Header.Prepare{ .checksum = 57018800251387350987699266840338142777, .checksum_padding = 0, .checksum_body = 281034154456906138187476354491563389195, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 665600, .epoch = 0, .view = 2, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 162127257168752911751447890883838318903, .parent_padding = 0, .request_checksum = 39792972214874618568501445663341288247, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 129800060941563857535569923226995055452, .op = 83, .commit = 82, .timestamp = 1765564968478784265, .request = 81, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-12-12 18:42:48.481Z debug(replica): 2N: replicate: replicating op=83 to replica 1
2025-12-12 18:42:48.481Z debug(replica): 2N: sending prepare to replica 1: vsr.message_header.Header.Prepare{ .checksum = 57018800251387350987699266840338142777, .checksum_padding = 0, .checksum_body = 281034154456906138187476354491563389195, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 665600, .epoch = 0, .view = 2, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 162127257168752911751447890883838318903, .parent_padding = 0, .request_checksum = 39792972214874618568501445663341288247, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 129800060941563857535569923226995055452, .op = 83, .commit = 82, .timestamp = 1765564968478784265, .request = 81, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-12-12 18:42:48.481Z debug(replica): 2N: on_prepare: advancing: op=82..83 checksum=162127257168752911751447890883838318903..57018800251387350987699266840338142777
2025-12-12 18:42:48.481Z debug(journal): 2: set_header_as_dirty: op=83 checksum=57018800251387350987699266840338142777
2025-12-12 18:42:48.481Z debug(replica): 2N: append: appending to journal op=83
2025-12-12 18:42:48.481Z debug(journal): 2: write: view=2 slot=83 op=83 len=665600: 57018800251387350987699266840338142777 starting
2025-12-12 18:42:48.481Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.prepares offset=87031808 len=667648 locked
2025-12-12 18:42:48.482Z debug(compaction): Transfer.credit_account_id:0: beat_complete: quota_beat_done=60088 quota_beat=60088 quota_bar_done=92840 quota_bar=92840
2025-12-12 18:42:48.482Z debug(compaction): 2: Account.id:0: beat_commence: bar quota=0 fulfilled, done=0
2025-12-12 18:42:48.482Z debug(compaction): 2: Account.user_data_128:0: beat_commence: bar quota=0 fulfilled, done=0
2025-12-12 18:42:48.482Z debug(compaction): 2: Account.user_data_64:0: beat_commence: bar quota=0 fulfilled, done=0
2025-12-12 18:42:48.482Z debug(compaction): 2: Account.user_data_32:0: beat_commence: bar quota=0 fulfilled, done=0
2025-12-12 18:42:48.482Z debug(compaction): 2: Account.ledger:0: beat_commence: bar quota=0 fulfilled, done=0
2025-12-12 18:42:48.482Z debug(compaction): 2: Account.code:0: beat_commence: bar quota=0 fulfilled, done=0
2025-12-12 18:42:48.482Z debug(compaction): 2: Account:0: beat_commence: bar quota=0 fulfilled, done=0
2025-12-12 18:42:48.482Z debug(compaction): 2: Transfer.id:0: beat_commence: bar quota=93158 fulfilled, done=93158
2025-12-12 18:42:48.482Z debug(compaction): 2: Transfer.debit_account_id:0: beat_commence: bar quota=92840 fulfilled, done=92840
2025-12-12 18:42:48.482Z debug(compaction): 2: Transfer.credit_account_id:0: beat_commence: bar quota=92840 fulfilled, done=92840
2025-12-12 18:42:48.485Z debug(replica): 1n: on_message: view=2 status=normal vsr.message_header.Header.Prepare{ .checksum = 57018800251387350987699266840338142777, .checksum_padding = 0, .checksum_body = 281034154456906138187476354491563389195, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 665600, .epoch = 0, .view = 2, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 162127257168752911751447890883838318903, .parent_padding = 0, .request_checksum = 39792972214874618568501445663341288247, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 129800060941563857535569923226995055452, .op = 83, .commit = 82, .timestamp = 1765564968478784265, .request = 81, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-12-12 18:42:48.485Z debug(replica): 1n: on_prepare: advancing commit_max=81..82
2025-12-12 18:42:48.485Z debug(replica): 1n: on_prepare: caching prepare.op=83 (commit_min=81 op=82 commit_max=82 prepare_max=1007)
2025-12-12 18:42:48.485Z debug(replica): 1n: on_prepare: advancing: op=82..83 checksum=162127257168752911751447890883838318903..57018800251387350987699266840338142777
2025-12-12 18:42:48.485Z debug(journal): 1: set_header_as_dirty: op=83 checksum=57018800251387350987699266840338142777
2025-12-12 18:42:48.485Z debug(replica): 1n: append: appending to journal op=83
2025-12-12 18:42:48.485Z debug(journal): 1: write: view=2 slot=83 op=83 len=665600: 57018800251387350987699266840338142777 starting
2025-12-12 18:42:48.485Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.prepares offset=87031808 len=667648 locked
2025-12-12 18:42:48.485Z debug(replica): 1n: commit_start_journal: cached prepare op=82 checksum=162127257168752911751447890883838318903
2025-12-12 18:42:48.485Z debug(replica): 1n: repair_prepare: op=83 checksum=57018800251387350987699266840338142777 (already writing)
2025-12-12 18:42:48.485Z debug(replica): 1n: commit_journal: already committing (prefetch; commit_min=81)
2025-12-12 18:42:48.485Z debug(replica): 1n: execute_op: executing view=2 primary=false op=82 checksum=162127257168752911751447890883838318903 (lookup_accounts)
2025-12-12 18:42:48.485Z debug(replica): 1n: execute_op: commit_timestamp=1765564965742697463 prepare.header.timestamp=1765564968417197214
2025-12-12 18:42:48.485Z debug(replica): 1n: client_table_entry_update: client=129800060941563857535569923226995055452 session=2 request=80
2025-12-12 18:42:48.485Z debug(forest): entering forest.compact() op=82 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2025-12-12 18:42:48.486Z debug(compaction): 1: Account.id:0: beat_commence: bar quota=0 fulfilled, done=0
2025-12-12 18:42:48.486Z debug(compaction): 1: Account.user_data_128:0: beat_commence: bar quota=0 fulfilled, done=0
2025-12-12 18:42:48.486Z debug(compaction): 1: Account.user_data_64:0: beat_commence: bar quota=0 fulfilled, done=0
2025-12-12 18:42:48.486Z debug(compaction): 1: Account.user_data_32:0: beat_commence: bar quota=0 fulfilled, done=0
2025-12-12 18:42:48.486Z debug(compaction): 1: Account.ledger:0: beat_commence: bar quota=0 fulfilled, done=0
2025-12-12 18:42:48.486Z debug(compaction): 1: Account.code:0: beat_commence: bar quota=0 fulfilled, done=0
2025-12-12 18:42:48.486Z debug(compaction): 1: Account:0: beat_commence: bar quota=0 fulfilled, done=0
2025-12-12 18:42:48.486Z debug(compaction): 1: Transfer.id:0: beat_commence: bar quota=93158 fulfilled, done=93158
2025-12-12 18:42:48.486Z debug(compaction): 1: Transfer.debit_account_id:0: beat_commence: bar quota=92840 fulfilled, done=92840
2025-12-12 18:42:48.490Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.prepares offset=87031808 len=667648 unlocked
2025-12-12 18:42:48.490Z debug(journal): 2: write_header: op=83 sectors[20480..24576]
2025-12-12 18:42:48.490Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.headers offset=20480 len=4096 locked
2025-12-12 18:42:48.493Z debug(replica): 2N: on_message: view=2 status=normal vsr.message_header.Header.Request{ .checksum = 39792972214874618568501445663341288247, .checksum_padding = 0, .checksum_body = 281034154456906138187476354491563389195, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 665600, .epoch = 0, .view = 2, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 329773723757090566204971058525184476939, .parent_padding = 0, .client = 129800060941563857535569923226995055452, .session = 2, .timestamp = 0, .request = 81, .operation = vsr.Operation(139), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 57838157, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 18:42:48.494Z debug(replica): 2N: on_request: new request
2025-12-12 18:42:48.494Z debug(replica): 2N: on_request: ignoring (already preparing)
2025-12-12 18:42:48.494Z debug(compaction): Transfer.amount:0: beat_complete: quota_beat_done=49128 quota_beat=40360 quota_bar_done=49128 quota_bar=92840
2025-12-12 18:42:48.494Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.headers offset=20480 len=4096 unlocked
2025-12-12 18:42:48.494Z debug(journal): 2: write: view=2 slot=83 op=83 len=665600: 57018800251387350987699266840338142777 complete, marking clean
2025-12-12 18:42:48.494Z debug(replica): 2N: send_prepare_ok: op=83 checksum=57018800251387350987699266840338142777
2025-12-12 18:42:48.494Z debug(replica): 2N: sending prepare_ok to replica 2: vsr.message_header.Header.PrepareOk{ .checksum = 247308698070960143890807440780038154088, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 2, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 162127257168752911751447890883838318903, .parent_padding = 0, .prepare_checksum = 57018800251387350987699266840338142777, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 129800060941563857535569923226995055452, .op = 83, .commit_min = 82, .timestamp = 1765564968478784265, .request = 81, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-12-12 18:42:48.494Z debug(replica): 2N: on_message: view=2 status=normal vsr.message_header.Header.PrepareOk{ .checksum = 247308698070960143890807440780038154088, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 2, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 162127257168752911751447890883838318903, .parent_padding = 0, .prepare_checksum = 57018800251387350987699266840338142777, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 129800060941563857535569923226995055452, .op = 83, .commit_min = 82, .timestamp = 1765564968478784265, .request = 81, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-12-12 18:42:48.494Z debug(vsr): 2: primary_abdicate_timeout reset
2025-12-12 18:42:48.494Z debug(replica): 2N: on_prepare_ok: 1 message(s)
2025-12-12 18:42:48.494Z debug(replica): 2N: on_prepare_ok: waiting for quorum
2025-12-12 18:42:48.494Z debug(replica): 2N: commit_start_pipeline: waiting for quorum
2025-12-12 18:42:48.497Z debug(client_replies): 1: write_reply: wrote (client=129800060941563857535569923226995055452 request=80)
2025-12-12 18:42:48.497Z debug(vsr): 0: journal_repair_budget_timeout fired
2025-12-12 18:42:48.497Z debug(vsr): 0: journal_repair_budget_timeout reset
2025-12-12 18:42:48.497Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.prepares offset=87031808 len=667648 unlocked
2025-12-12 18:42:48.497Z debug(journal): 1: write_header: op=83 sectors[20480..24576]
2025-12-12 18:42:48.497Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.headers offset=20480 len=4096 locked
2025-12-12 18:42:48.498Z debug(compaction): Transfer.credit_account_id:0: beat_complete: quota_beat_done=60088 quota_beat=60088 quota_bar_done=92840 quota_bar=92840
2025-12-12 18:42:48.498Z debug(compaction): 1: Account.id:0: beat_commence: bar quota=0 fulfilled, done=0
2025-12-12 18:42:48.498Z debug(compaction): 1: Account.user_data_128:0: beat_commence: bar quota=0 fulfilled, done=0
2025-12-12 18:42:48.498Z debug(compaction): 1: Account.user_data_64:0: beat_commence: bar quota=0 fulfilled, done=0
2025-12-12 18:42:48.498Z debug(compaction): 1: Account.user_data_32:0: beat_commence: bar quota=0 fulfilled, done=0
2025-12-12 18:42:48.498Z debug(compaction): 1: Account.ledger:0: beat_commence: bar quota=0 fulfilled, done=0
2025-12-12 18:42:48.498Z debug(compaction): 1: Account.code:0: beat_commence: bar quota=0 fulfilled, done=0
2025-12-12 18:42:48.498Z debug(compaction): 1: Account:0: beat_commence: bar quota=0 fulfilled, done=0
2025-12-12 18:42:48.498Z debug(compaction): 1: Transfer.id:0: beat_commence: bar quota=93158 fulfilled, done=93158
2025-12-12 18:42:48.498Z debug(compaction): 1: Transfer.debit_account_id:0: beat_commence: bar quota=92840 fulfilled, done=92840
2025-12-12 18:42:48.498Z debug(compaction): 1: Transfer.credit_account_id:0: beat_commence: bar quota=92840 fulfilled, done=92840
2025-12-12 18:42:48.504Z debug(vsr): 2: journal_repair_budget_timeout fired
2025-12-12 18:42:48.504Z debug(vsr): 2: journal_repair_budget_timeout reset
2025-12-12 18:42:48.507Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.headers offset=20480 len=4096 unlocked
2025-12-12 18:42:48.507Z debug(journal): 1: write: view=2 slot=83 op=83 len=665600: 57018800251387350987699266840338142777 complete, marking clean
2025-12-12 18:42:48.507Z debug(replica): 1n: send_prepare_ok: op=83 checksum=57018800251387350987699266840338142777
2025-12-12 18:42:48.507Z debug(replica): 1n: sending prepare_ok to replica 2: vsr.message_header.Header.PrepareOk{ .checksum = 169898015352376057962739835080239467969, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 2, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 162127257168752911751447890883838318903, .parent_padding = 0, .prepare_checksum = 57018800251387350987699266840338142777, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 129800060941563857535569923226995055452, .op = 83, .commit_min = 82, .timestamp = 1765564968478784265, .request = 81, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-12-12 18:42:48.507Z debug(vsr): 1: journal_repair_budget_timeout fired
2025-12-12 18:42:48.507Z debug(vsr): 1: journal_repair_budget_timeout reset
2025-12-12 18:42:48.507Z debug(vsr): 1: journal_repair_timeout fired
2025-12-12 18:42:48.507Z debug(vsr): 1: journal_repair_timeout reset
2025-12-12 18:42:48.508Z debug(compaction): Transfer.amount:0: beat_complete: quota_beat_done=49128 quota_beat=40360 quota_bar_done=49128 quota_bar=92840
2025-12-12 18:42:48.517Z debug(vsr): 0: journal_repair_budget_timeout fired
2025-12-12 18:42:48.517Z debug(vsr): 0: journal_repair_budget_timeout reset
2025-12-12 18:42:48.507Z debug(replica): 2N: on_message: view=2 status=normal vsr.message_header.Header.PrepareOk{ .checksum = 169898015352376057962739835080239467969, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 2, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 162127257168752911751447890883838318903, .parent_padding = 0, .prepare_checksum = 57018800251387350987699266840338142777, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 129800060941563857535569923226995055452, .op = 83, .commit_min = 82, .timestamp = 1765564968478784265, .request = 81, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-12-12 18:42:48.527Z debug(vsr): 1: journal_repair_budget_timeout fired
2025-12-12 18:46:45.652Z debug(vsr): 2: primary_abdicate_timeout reset
2025-12-12 18:46:45.652Z debug(replica): 2N: on_prepare_ok: 2 message(s)
2025-12-12 18:46:45.652Z debug(replica): 2N: on_prepare_ok: quorum received, context=57018800251387350987699266840338142777
2025-12-12 18:46:45.652Z debug(vsr): 2: prepare_timeout stopped
2025-12-12 18:42:48.537Z debug(vsr): 0: start_view_change_message_timeout fired
2025-12-12 18:46:45.652Z debug(vsr): 2: primary_abdicate_timeout stopped
2025-12-12 18:46:45.652Z debug(vsr): 1: journal_repair_budget_timeout reset
warning(message_bus): 129800060941563857535569923226995055452: on_recv: from=vsr.Peer{ .replica = 2 } error.ConnectionTimedOut
2025-12-12 18:46:45.652Z debug(vsr): 0: start_view_change_message_timeout reset
2025-12-12 18:46:45.652Z debug(vsr): 0: journal_repair_budget_timeout fired
2025-12-12 18:46:45.652Z debug(vsr): 0: journal_repair_budget_timeout reset
2025-12-12 18:46:45.652Z debug(vsr): 0: journal_repair_timeout fired
2025-12-12 18:46:45.652Z debug(vsr): 0: journal_repair_timeout reset
2025-12-12 18:45:05.987Z info(supervisor): 1: terminating replica
2025-12-12 18:46:45.652Z debug(vsr): 0: grid_repair_budget_timeout fired
2025-12-12 18:46:45.652Z debug(vsr): 0: grid_repair_budget_timeout reset
2025-12-12 18:46:45.652Z debug(vsr): 0: grid_scrub_timeout fired
2025-12-12 18:46:45.652Z debug(vsr): 0: grid_scrub_timeout reset
2025-12-12 18:46:45.654Z debug(replica): 2N: execute_op: executing view=2 primary=true op=83 checksum=57018800251387350987699266840338142777 (create_transfers)
2025-12-12 18:46:45.654Z debug(replica): 2N: execute_op: commit_timestamp=1765564968417197214 prepare.header.timestamp=1765564968478784265
2025-12-12 18:46:45.656Z debug(grid_scrubber): 0: tour_next: cycle done (toured_blocks=0)
2025-12-12 18:46:45.657Z debug(replica): 0n: on_message: view=2 status=normal vsr.message_header.Header.PingClient{ .checksum = 285760366593963311673437646980741004075, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 0, .release = 0.0.1, .protocol = 0, .command = vsr.Command.ping_client, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .client = 129800060941563857535569923226995055452, .ping_timestamp_monotonic = 37680533716498693, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 18:46:45.657Z debug(replica): 0n: sending pong_client to client 129800060941563857535569923226995055452: vsr.message_header.Header.PongClient{ .checksum = 62528391624723649628377389106191381981, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 2, .release = 0.0.1, .protocol = 0, .command = vsr.Command.pong_client, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .ping_timestamp_monotonic = 37680533716498693, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 18:46:45.657Z debug(replica): 0n: on_message: view=2 status=normal vsr.message_header.Header.PingClient{ .checksum = 175235626067961786175651527908430031732, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 0, .release = 0.0.1, .protocol = 0, .command = vsr.Command.ping_client, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .client = 129800060941563857535569923226995055452, .ping_timestamp_monotonic = 37680563851531731, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 18:46:45.657Z debug(replica): 0n: sending pong_client to client 129800060941563857535569923226995055452: vsr.message_header.Header.PongClient{ .checksum = 316963141015149918322981463622586767466, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 2, .release = 0.0.1, .protocol = 0, .command = vsr.Command.pong_client, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .ping_timestamp_monotonic = 37680563851531731, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 18:46:45.664Z warning(faulty_network): recv error (1,4): error.ConnectionResetByPeer
2025-12-12 18:46:45.666Z debug(replica): 0n: on_message: view=2 status=normal vsr.message_header.Header.Request{ .checksum = 39792972214874618568501445663341288247, .checksum_padding = 0, .checksum_body = 281034154456906138187476354491563389195, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 665600, .epoch = 0, .view = 2, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 329773723757090566204971058525184476939, .parent_padding = 0, .client = 129800060941563857535569923226995055452, .session = 2, .timestamp = 0, .request = 81, .operation = vsr.Operation(139), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 57838157, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 18:46:45.666Z debug(replica): 0n: on_request: forwarding new request to primary (view=2)
2025-12-12 18:46:45.666Z debug(replica): 0n: sending request to replica 2: vsr.message_header.Header.Request{ .checksum = 39792972214874618568501445663341288247, .checksum_padding = 0, .checksum_body = 281034154456906138187476354491563389195, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 665600, .epoch = 0, .view = 2, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 329773723757090566204971058525184476939, .parent_padding = 0, .client = 129800060941563857535569923226995055452, .session = 2, .timestamp = 0, .request = 81, .operation = vsr.Operation(139), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 57838157, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 18:46:45.666Z debug(replica): 0n: on_message: view=2 status=normal vsr.message_header.Header.PingClient{ .checksum = 108362733724462948199764203479937006651, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 0, .release = 0.0.1, .protocol = 0, .command = vsr.Command.ping_client, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .client = 129800060941563857535569923226995055452, .ping_timestamp_monotonic = 37680593934260911, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 18:46:45.666Z debug(replica): 0n: sending pong_client to client 129800060941563857535569923226995055452: vsr.message_header.Header.PongClient{ .checksum = 79625109733306471315973117114072781126, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 2, .release = 0.0.1, .protocol = 0, .command = vsr.Command.pong_client, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .ping_timestamp_monotonic = 37680593934260911, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 18:46:45.667Z info(message_bus): 0: on_recv: from=vsr.Peer{ .replica = 1 } orderly shutdown
2025-12-12 18:46:45.668Z debug(replica): 2N: execute_op: advancing commit_max=82..83
2025-12-12 18:46:45.668Z debug(replica): 2N: client_table_entry_update: client=129800060941563857535569923226995055452 session=2 request=81
2025-12-12 18:46:45.668Z debug(replica): 2N: execute_op: replying to client: vsr.message_header.Header.Reply{ .checksum = 103690446315152096921846066664885933595, .checksum_padding = 0, .checksum_body = 225737336253671706644003115993621428625, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 288, .epoch = 0, .view = 2, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 39792972214874618568501445663341288247, .request_checksum_padding = 0, .context = 71238269653775673709592736076580168263, .context_padding = 0, .client = 129800060941563857535569923226995055452, .op = 83, .commit = 83, .timestamp = 1765564968478784265, .request = 81, .operation = vsr.Operation(139), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 18:46:45.668Z debug(replica): 2N: sending reply to client 129800060941563857535569923226995055452: vsr.message_header.Header.Reply{ .checksum = 103690446315152096921846066664885933595, .checksum_padding = 0, .checksum_body = 225737336253671706644003115993621428625, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 288, .epoch = 0, .view = 2, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 39792972214874618568501445663341288247, .request_checksum_padding = 0, .context = 71238269653775673709592736076580168263, .context_padding = 0, .client = 129800060941563857535569923226995055452, .op = 83, .commit = 83, .timestamp = 1765564968478784265, .request = 81, .operation = vsr.Operation(139), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 18:46:45.668Z debug(forest): entering forest.compact() op=83 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2025-12-12 18:46:45.668Z debug(compaction): 2: Account.id:0: beat_commence: bar quota=0 fulfilled, done=0
2025-12-12 18:46:45.668Z debug(compaction): 2: Account.user_data_128:0: beat_commence: bar quota=0 fulfilled, done=0
2025-12-12 18:46:45.668Z debug(compaction): 2: Account.user_data_64:0: beat_commence: bar quota=0 fulfilled, done=0
2025-12-12 18:46:45.668Z debug(compaction): 2: Account.user_data_32:0: beat_commence: bar quota=0 fulfilled, done=0
2025-12-12 18:46:45.668Z debug(compaction): 2: Account.ledger:0: beat_commence: bar quota=0 fulfilled, done=0
2025-12-12 18:46:45.668Z debug(compaction): 2: Account.code:0: beat_commence: bar quota=0 fulfilled, done=0
2025-12-12 18:46:45.668Z debug(compaction): 2: Account:0: beat_commence: bar quota=0 fulfilled, done=0
2025-12-12 18:46:45.668Z debug(compaction): 2: Transfer.id:0: beat_commence: bar quota=93158 fulfilled, done=93158
2025-12-12 18:46:45.668Z debug(compaction): 2: Transfer.debit_account_id:0: beat_commence: bar quota=92840 fulfilled, done=92840
2025-12-12 18:46:45.668Z debug(compaction): 2: Transfer.credit_account_id:0: beat_commence: bar quota=92840 fulfilled, done=92840
2025-12-12 18:46:45.673Z debug(replica): 0n: on_message: view=2 status=normal vsr.message_header.Header.Request{ .checksum = 39792972214874618568501445663341288247, .checksum_padding = 0, .checksum_body = 281034154456906138187476354491563389195, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 665600, .epoch = 0, .view = 2, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 329773723757090566204971058525184476939, .parent_padding = 0, .client = 129800060941563857535569923226995055452, .session = 2, .timestamp = 0, .request = 81, .operation = vsr.Operation(139), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 57838157, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 18:46:45.674Z debug(replica): 0n: on_request: forwarding new request to primary (view=2)
2025-12-12 18:46:45.674Z debug(replica): 0n: sending request to replica 2: vsr.message_header.Header.Request{ .checksum = 39792972214874618568501445663341288247, .checksum_padding = 0, .checksum_body = 281034154456906138187476354491563389195, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 665600, .epoch = 0, .view = 2, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 329773723757090566204971058525184476939, .parent_padding = 0, .client = 129800060941563857535569923226995055452, .session = 2, .timestamp = 0, .request = 81, .operation = vsr.Operation(139), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 57838157, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 18:46:45.674Z info(supervisor): 1: starting replica
2025-12-12 18:46:45.675Z info(message_bus): 2: on_recv: from=vsr.Peer{ .replica = 1 } orderly shutdown
2025-12-12 18:46:45.675Z debug(client_replies): 2: write_reply: wrote (client=129800060941563857535569923226995055452 request=81)
2025-12-12 18:46:45.677Z debug(replica): 2N: on_message: view=2 status=normal vsr.message_header.Header.Request{ .checksum = 39792972214874618568501445663341288247, .checksum_padding = 0, .checksum_body = 281034154456906138187476354491563389195, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 665600, .epoch = 0, .view = 2, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 329773723757090566204971058525184476939, .parent_padding = 0, .client = 129800060941563857535569923226995055452, .session = 2, .timestamp = 0, .request = 81, .operation = vsr.Operation(139), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 57838157, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 18:46:45.677Z debug(replica): 2N: on_request: replying to duplicate request
2025-12-12 18:46:45.677Z debug(client_replies): 2: read_reply: start (client=129800060941563857535569923226995055452 reply=103690446315152096921846066664885933595)
2025-12-12 18:46:45.677Z debug(replica): 2N: on_message: view=2 status=normal vsr.message_header.Header.PingClient{ .checksum = 285760366593963311673437646980741004075, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 0, .release = 0.0.1, .protocol = 0, .command = vsr.Command.ping_client, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .client = 129800060941563857535569923226995055452, .ping_timestamp_monotonic = 37680533716498693, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 18:46:45.677Z debug(replica): 2N: sending pong_client to client 129800060941563857535569923226995055452: vsr.message_header.Header.PongClient{ .checksum = 338245670935707982910747414953405712232, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 2, .release = 0.0.1, .protocol = 0, .command = vsr.Command.pong_client, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .ping_timestamp_monotonic = 37680533716498693, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 18:46:45.677Z warning(faulty_network): send error (2,7): error.ConnectionResetByPeer
2025-12-12 18:46:45.678Z info(io): opening "0_1.tigerbeetle"...
2025-12-12 18:46:45.678Z debug(compaction): Transfer.amount:0: beat_complete: quota_beat_done=43712 quota_beat=43712 quota_bar_done=92840 quota_bar=92840
2025-12-12 18:46:45.678Z debug(compaction): 2: Account.id:0: beat_commence: bar quota=0 fulfilled, done=0
2025-12-12 18:46:45.678Z debug(compaction): 2: Account.user_data_128:0: beat_commence: bar quota=0 fulfilled, done=0
2025-12-12 18:46:45.678Z debug(compaction): 2: Account.user_data_64:0: beat_commence: bar quota=0 fulfilled, done=0
2025-12-12 18:46:45.678Z debug(compaction): 2: Account.user_data_32:0: beat_commence: bar quota=0 fulfilled, done=0
2025-12-12 18:46:45.678Z debug(compaction): 2: Account.ledger:0: beat_commence: bar quota=0 fulfilled, done=0
2025-12-12 18:46:45.678Z debug(compaction): 2: Account.code:0: beat_commence: bar quota=0 fulfilled, done=0
2025-12-12 18:46:45.678Z debug(compaction): 2: Account:0: beat_commence: bar quota=0 fulfilled, done=0
2025-12-12 18:46:45.678Z debug(compaction): 2: Transfer.id:0: beat_commence: bar quota=93158 fulfilled, done=93158
2025-12-12 18:46:45.678Z debug(compaction): 2: Transfer.debit_account_id:0: beat_commence: bar quota=92840 fulfilled, done=92840
2025-12-12 18:46:45.678Z debug(compaction): 2: Transfer.credit_account_id:0: beat_commence: bar quota=92840 fulfilled, done=92840
2025-12-12 18:46:45.678Z debug(compaction): 2: Transfer.amount:0: beat_commence: bar quota=92840 fulfilled, done=92840
2025-12-12 18:46:45.678Z debug(compaction): 2: Transfer.pending_id:0: beat_commence: bar quota=0 fulfilled, done=0
2025-12-12 18:46:45.678Z debug(compaction): 2: Transfer.user_data_128:0: beat_commence: bar quota=0 fulfilled, done=0
2025-12-12 18:46:45.678Z debug(compaction): 2: Transfer.user_data_64:0: beat_commence: bar quota=0 fulfilled, done=0
2025-12-12 18:46:45.678Z debug(compaction): 2: Transfer.user_data_32:0: beat_commence: bar quota=0 fulfilled, done=0
2025-12-12 18:46:45.680Z debug(replica): 2N: on_message: view=2 status=normal vsr.message_header.Header.Request{ .checksum = 39792972214874618568501445663341288247, .checksum_padding = 0, .checksum_body = 281034154456906138187476354491563389195, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 665600, .epoch = 0, .view = 2, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 329773723757090566204971058525184476939, .parent_padding = 0, .client = 129800060941563857535569923226995055452, .session = 2, .timestamp = 0, .request = 81, .operation = vsr.Operation(139), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 57838157, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 18:46:45.680Z debug(replica): 2N: on_request: replying to duplicate request
2025-12-12 18:46:45.680Z debug(client_replies): 2: read_reply: busy (client=129800060941563857535569923226995055452 reply=103690446315152096921846066664885933595)
2025-12-12 18:46:45.680Z debug(replica): 2N: on_request: ignoring (client_replies busy)
2025-12-12 18:46:45.681Z debug(replica): 0n: on_message: view=2 status=normal vsr.message_header.Header.Request{ .checksum = 39792972214874618568501445663341288247, .checksum_padding = 0, .checksum_body = 281034154456906138187476354491563389195, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 665600, .epoch = 0, .view = 2, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 329773723757090566204971058525184476939, .parent_padding = 0, .client = 129800060941563857535569923226995055452, .session = 2, .timestamp = 0, .request = 81, .operation = vsr.Operation(139), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 57838157, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 18:46:45.681Z debug(replica): 0n: on_request: forwarding new request to primary (view=2)
2025-12-12 18:46:45.681Z debug(replica): 0n: sending request to replica 2: vsr.message_header.Header.Request{ .checksum = 39792972214874618568501445663341288247, .checksum_padding = 0, .checksum_body = 281034154456906138187476354491563389195, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 665600, .epoch = 0, .view = 2, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 329773723757090566204971058525184476939, .parent_padding = 0, .client = 129800060941563857535569923226995055452, .session = 2, .timestamp = 0, .request = 81, .operation = vsr.Operation(139), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 57838157, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 18:46:45.682Z debug(replica): 0n: on_message: view=2 status=normal vsr.message_header.Header.PingClient{ .checksum = 166104436884021871433419392732450592531, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 0, .release = 0.0.1, .protocol = 0, .command = vsr.Command.ping_client, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .client = 129800060941563857535569923226995055452, .ping_timestamp_monotonic = 37680624004279949, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 18:46:45.682Z debug(replica): 0n: sending pong_client to client 129800060941563857535569923226995055452: vsr.message_header.Header.PongClient{ .checksum = 212079398333754337009474505467762780310, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 2, .release = 0.0.1, .protocol = 0, .command = vsr.Command.pong_client, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .ping_timestamp_monotonic = 37680624004279949, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 18:46:45.682Z warning(clock): 0: synchronization failed, partitioned (sources=1 samples=1)
2025-12-12 18:46:45.682Z error(clock): 0: no agreement on cluster time (partitioned or too many clock faults)
2025-12-12 18:46:45.682Z debug(message_bus): 0: connect_to_replica: connecting to=1 after=68ms
2025-12-12 18:46:45.685Z debug(replica): 0n: on_message: view=2 status=normal vsr.message_header.Header.Request{ .checksum = 39792972214874618568501445663341288247, .checksum_padding = 0, .checksum_body = 281034154456906138187476354491563389195, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 665600, .epoch = 0, .view = 2, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 329773723757090566204971058525184476939, .parent_padding = 0, .client = 129800060941563857535569923226995055452, .session = 2, .timestamp = 0, .request = 81, .operation = vsr.Operation(139), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 57838157, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 18:46:45.685Z debug(replica): 0n: on_request: forwarding new request to primary (view=2)
2025-12-12 18:46:45.685Z debug(replica): 0n: sending request to replica 2: vsr.message_header.Header.Request{ .checksum = 39792972214874618568501445663341288247, .checksum_padding = 0, .checksum_body = 281034154456906138187476354491563389195, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 665600, .epoch = 0, .view = 2, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 329773723757090566204971058525184476939, .parent_padding = 0, .client = 129800060941563857535569923226995055452, .session = 2, .timestamp = 0, .request = 81, .operation = vsr.Operation(139), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 57838157, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 18:46:45.685Z info(supervisor): 2: pausing replica
2025-12-12 18:46:45.692Z debug(vsr): 0: journal_repair_budget_timeout fired
2025-12-12 18:46:45.692Z debug(vsr): 0: journal_repair_budget_timeout reset
2025-12-12 18:46:45.695Z info(supervisor): sleeping for 123.737ms
2025-12-12 18:46:45.699Z info(main): multiversioning: upgrades disabled for development (0.0.1) release.
2025-12-12 18:46:45.699Z info(main): release=0.0.1
2025-12-12 18:46:45.699Z info(main): release_client_min=0.0.1
2025-12-12 18:46:45.699Z info(main): releases_bundled={ 0.0.1 }
2025-12-12 18:46:45.699Z info(main): git_commit=e54041e91171cbaa2d2d274b165643b81af9b4df
2025-12-12 18:46:45.699Z debug(superblock): null: open: started
2025-12-12 18:46:45.699Z debug(superblock): null: open: read_header: copy=0 size=8192 offset=0
2025-12-12 18:46:45.699Z debug(superblock): null: open: read_header: copy=1 size=8192 offset=24576
2025-12-12 18:46:45.699Z debug(superblock): null: open: read_header: copy=2 size=8192 offset=49152
2025-12-12 18:46:45.699Z debug(superblock): null: open: read_header: copy=3 size=8192 offset=73728
2025-12-12 18:46:45.699Z debug(superblock_quorums): copy: 0/4: checksum=8c7994041376ed4b5bf9863b898912a parent=5bb84f585fde4660831f6ba1176047a9 sequence=5
2025-12-12 18:46:45.699Z debug(superblock_quorums): copy: 1/4: checksum=8c7994041376ed4b5bf9863b898912a parent=5bb84f585fde4660831f6ba1176047a9 sequence=5
2025-12-12 18:46:45.699Z debug(superblock_quorums): copy: 2/4: checksum=8c7994041376ed4b5bf9863b898912a parent=5bb84f585fde4660831f6ba1176047a9 sequence=5
2025-12-12 18:46:45.699Z debug(superblock_quorums): copy: 3/4: checksum=8c7994041376ed4b5bf9863b898912a parent=5bb84f585fde4660831f6ba1176047a9 sequence=5
2025-12-12 18:46:45.700Z debug(superblock_quorums): quorum: checksum=8c7994041376ed4b5bf9863b898912a parent=5bb84f585fde4660831f6ba1176047a9 sequence=5 count=4 valid=true
2025-12-12 18:46:45.700Z debug(superblock): null: open: installed working superblock: checksum=08c7994041376ed4b5bf9863b898912a sequence=5 release=0.0.1 cluster=00000000000000000000000000000000 replica_id=308943487097555535311203420603596972560 size=1141374976 free_set_blocks_acquired_size=0 free_set_blocks_released_size=0 client_sessions_size=0 checkpoint_id=f222e9ce156b309eaeb4af665242ac18 commit_min_checksum=108034676951432761169128540124443993015 commit_min=0 commit_max=1 log_view=2 view=2 sync_op_min=0 sync_op_max=0 manifest_oldest_checksum=0 manifest_oldest_address=0 manifest_newest_checksum=0 manifest_newest_address=0 manifest_block_count=0 snapshots_block_checksum=0 snapshots_block_address=0
2025-12-12 18:46:45.700Z debug(superblock): null: open: vsr_header: op=2 checksum=59832958509027325364042851603777938826
2025-12-12 18:46:45.700Z debug(superblock): null: open: vsr_header: op=1 checksum=142915995575080760694841867488751614987
2025-12-12 18:46:45.700Z debug(superblock): null: open: vsr_header: op=0 checksum=108034676951432761169128540124443993015
2025-12-12 18:46:45.700Z debug(superblock): null: open: complete
2025-12-12 18:46:45.700Z debug(journal): 1: slot_count=1024 size=1.000244140625GiB headers_size=256KiB prepares_size=1GiB
2025-12-12 18:46:45.712Z debug(vsr): 0: journal_repair_budget_timeout fired
2025-12-12 18:46:45.712Z debug(vsr): 0: journal_repair_budget_timeout reset
2025-12-12 18:46:45.732Z debug(vsr): 0: journal_repair_budget_timeout fired
2025-12-12 18:46:45.732Z debug(vsr): 0: journal_repair_budget_timeout reset
2025-12-12 18:46:45.750Z debug(message_bus): 0: on_connect_with_exponential_backoff: to=1
2025-12-12 18:46:45.750Z info(message_bus): 0: on_connect: connected to=1
2025-12-12 18:46:45.750Z warning(faulty_network): connect failed (1,6): error.ConnectionRefused
2025-12-12 18:46:45.750Z info(message_bus): 0: on_recv: from=vsr.Peer{ .replica = 1 } orderly shutdown
2025-12-12 18:46:45.752Z debug(message_bus): 0: connect_to_replica: connecting to=1 after=50ms
2025-12-12 18:46:45.752Z debug(vsr): 0: journal_repair_budget_timeout fired
2025-12-12 18:46:45.752Z debug(vsr): 0: journal_repair_budget_timeout reset
2025-12-12 18:46:45.758Z warning(faulty_network): connect failed (1,7): error.ConnectionRefused
2025-12-12 18:46:45.772Z debug(vsr): 0: journal_repair_budget_timeout fired
2025-12-12 18:46:45.772Z debug(vsr): 0: journal_repair_budget_timeout reset
2025-12-12 18:46:45.772Z debug(vsr): 0: journal_repair_timeout fired
2025-12-12 18:46:45.772Z debug(vsr): 0: journal_repair_timeout reset
2025-12-12 18:46:45.793Z debug(vsr): 0: journal_repair_budget_timeout fired
2025-12-12 18:46:45.793Z debug(vsr): 0: journal_repair_budget_timeout reset
2025-12-12 18:46:45.802Z debug(message_bus): 0: on_connect_with_exponential_backoff: to=1
2025-12-12 18:46:45.802Z info(message_bus): 0: on_connect: connected to=1
2025-12-12 18:46:45.803Z warning(faulty_network): connect failed (1,8): error.ConnectionRefused
2025-12-12 18:46:45.803Z info(message_bus): 0: on_recv: from=vsr.Peer{ .replica = 1 } orderly shutdown
2025-12-12 18:46:45.803Z debug(message_bus): 0: connect_to_replica: connecting to=1 after=75ms
2025-12-12 18:46:45.813Z debug(vsr): 0: journal_repair_budget_timeout fired
2025-12-12 18:46:45.813Z debug(vsr): 0: journal_repair_budget_timeout reset
2025-12-12 18:46:45.822Z debug(manifest_log): 1: Manifest.Pace.half_bar_append_blocks_max = 1
2025-12-12 18:46:45.822Z debug(manifest_log): 1: Manifest.Pace.half_bar_compact_blocks_max = 2
2025-12-12 18:46:45.822Z debug(manifest_log): 1: Manifest.Pace.log_blocks_full_max = 586
2025-12-12 18:46:45.822Z debug(manifest_log): 1: Manifest.Pace.log_blocks_cycle_max = 1172
2025-12-12 18:46:45.822Z debug(manifest_log): 1: Manifest.Pace.log_blocks_max = 1466
2025-12-12 18:46:45.822Z debug(manifest_log): 1: Manifest.Pace.tables_max = 2396744
2025-12-12 18:46:45.826Z info(supervisor): 2: unpausing replica
2025-12-12 18:46:45.826Z info(supervisor): going into 3m42s quiescence (no faults)
2025-12-12 18:46:45.827Z debug(client_replies): 2: read_reply: done (client=129800060941563857535569923226995055452 reply=103690446315152096921846066664885933595)
2025-12-12 18:46:45.827Z debug(replica): 2N: on_request: repeat reply (client=129800060941563857535569923226995055452 request=81)
2025-12-12 18:46:45.827Z debug(replica): 2N: sending reply to client 129800060941563857535569923226995055452: vsr.message_header.Header.Reply{ .checksum = 103690446315152096921846066664885933595, .checksum_padding = 0, .checksum_body = 225737336253671706644003115993621428625, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 288, .epoch = 0, .view = 2, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 39792972214874618568501445663341288247, .request_checksum_padding = 0, .context = 71238269653775673709592736076580168263, .context_padding = 0, .client = 129800060941563857535569923226995055452, .op = 83, .commit = 83, .timestamp = 1765564968478784265, .request = 81, .operation = vsr.Operation(139), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 18:46:45.830Z debug(replica): 2N: on_message: view=2 status=normal vsr.message_header.Header.Request{ .checksum = 39792972214874618568501445663341288247, .checksum_padding = 0, .checksum_body = 281034154456906138187476354491563389195, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 665600, .epoch = 0, .view = 2, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 329773723757090566204971058525184476939, .parent_padding = 0, .client = 129800060941563857535569923226995055452, .session = 2, .timestamp = 0, .request = 81, .operation = vsr.Operation(139), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 57838157, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 18:46:45.830Z debug(replica): 2N: on_request: replying to duplicate request
2025-12-12 18:46:45.830Z debug(client_replies): 2: read_reply: start (client=129800060941563857535569923226995055452 reply=103690446315152096921846066664885933595)
2025-12-12 18:46:45.830Z debug(compaction): Transfer.ledger:0: beat_complete: quota_beat_done=92840 quota_beat=92840 quota_bar_done=92840 quota_bar=92840
2025-12-12 18:46:45.830Z debug(compaction): 2: Account.id:0: beat_commence: bar quota=0 fulfilled, done=0
2025-12-12 18:46:45.830Z debug(compaction): 2: Account.user_data_128:0: beat_commence: bar quota=0 fulfilled, done=0
2025-12-12 18:46:45.830Z debug(compaction): 2: Account.user_data_64:0: beat_commence: bar quota=0 fulfilled, done=0
2025-12-12 18:46:45.830Z debug(compaction): 2: Account.user_data_32:0: beat_commence: bar quota=0 fulfilled, done=0
2025-12-12 18:46:45.830Z debug(compaction): 2: Account.ledger:0: beat_commence: bar quota=0 fulfilled, done=0
2025-12-12 18:46:45.830Z debug(compaction): 2: Account.code:0: beat_commence: bar quota=0 fulfilled, done=0
2025-12-12 18:46:45.830Z debug(compaction): 2: Account:0: beat_commence: bar quota=0 fulfilled, done=0
2025-12-12 18:46:45.830Z debug(compaction): 2: Transfer.id:0: beat_commence: bar quota=93158 fulfilled, done=93158
2025-12-12 18:46:45.830Z debug(compaction): 2: Transfer.debit_account_id:0: beat_commence: bar quota=92840 fulfilled, done=92840
2025-12-12 18:46:45.830Z debug(compaction): 2: Transfer.credit_account_id:0: beat_commence: bar quota=92840 fulfilled, done=92840
2025-12-12 18:46:45.830Z debug(compaction): 2: Transfer.amount:0: beat_commence: bar quota=92840 fulfilled, done=92840
2025-12-12 18:46:45.830Z debug(compaction): 2: Transfer.pending_id:0: beat_commence: bar quota=0 fulfilled, done=0
2025-12-12 18:46:45.830Z debug(compaction): 2: Transfer.user_data_128:0: beat_commence: bar quota=0 fulfilled, done=0
2025-12-12 18:46:45.830Z debug(compaction): 2: Transfer.user_data_64:0: beat_commence: bar quota=0 fulfilled, done=0
2025-12-12 18:46:45.830Z debug(compaction): 2: Transfer.user_data_32:0: beat_commence: bar quota=0 fulfilled, done=0
2025-12-12 18:46:45.830Z debug(compaction): 2: Transfer.ledger:0: beat_commence: bar quota=92840 fulfilled, done=92840
2025-12-12 18:46:45.832Z debug(client_replies): 2: read_reply: done (client=129800060941563857535569923226995055452 reply=103690446315152096921846066664885933595)
2025-12-12 18:46:45.832Z debug(replica): 2N: on_request: repeat reply (client=129800060941563857535569923226995055452 request=81)
2025-12-12 18:46:45.832Z debug(replica): 2N: sending reply to client 129800060941563857535569923226995055452: vsr.message_header.Header.Reply{ .checksum = 103690446315152096921846066664885933595, .checksum_padding = 0, .checksum_body = 225737336253671706644003115993621428625, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 288, .epoch = 0, .view = 2, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 39792972214874618568501445663341288247, .request_checksum_padding = 0, .context = 71238269653775673709592736076580168263, .context_padding = 0, .client = 129800060941563857535569923226995055452, .op = 83, .commit = 83, .timestamp = 1765564968478784265, .request = 81, .operation = vsr.Operation(139), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 18:46:45.832Z warning(message_bus): 2: on_recv: from=vsr.Peer{ .client = 129800060941563857535569923226995055452 } error.ConnectionResetByPeer
2025-12-12 18:46:45.833Z debug(vsr): 0: journal_repair_budget_timeout fired
2025-12-12 18:46:45.833Z debug(vsr): 0: journal_repair_budget_timeout reset
2025-12-12 18:46:45.835Z debug(replica): 2N: on_message: view=2 status=normal vsr.message_header.Header.Request{ .checksum = 39792972214874618568501445663341288247, .checksum_padding = 0, .checksum_body = 281034154456906138187476354491563389195, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 665600, .epoch = 0, .view = 2, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 329773723757090566204971058525184476939, .parent_padding = 0, .client = 129800060941563857535569923226995055452, .session = 2, .timestamp = 0, .request = 81, .operation = vsr.Operation(139), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 57838157, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 18:46:45.835Z debug(replica): 2N: on_request: replying to duplicate request
2025-12-12 18:46:45.835Z debug(client_replies): 2: read_reply: start (client=129800060941563857535569923226995055452 reply=103690446315152096921846066664885933595)
2025-12-12 18:46:45.835Z debug(compaction): Transfer.code:0: beat_complete: quota_beat_done=32752 quota_beat=19283 quota_bar_done=32752 quota_bar=92840
2025-12-12 18:46:45.837Z info(message_bus): 2: set_and_verify_peer connection from client_likely=129800060941563857535569923226995055452
2025-12-12 18:46:45.837Z debug(replica): 2N: on_message: view=2 status=normal vsr.message_header.Header.Request{ .checksum = 39792972214874618568501445663341288247, .checksum_padding = 0, .checksum_body = 281034154456906138187476354491563389195, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 665600, .epoch = 0, .view = 2, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 329773723757090566204971058525184476939, .parent_padding = 0, .client = 129800060941563857535569923226995055452, .session = 2, .timestamp = 0, .request = 81, .operation = vsr.Operation(139), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 57838157, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 18:46:45.837Z debug(replica): 2N: on_request: replying to duplicate request
2025-12-12 18:46:45.837Z debug(client_replies): 2: read_reply: busy (client=129800060941563857535569923226995055452 reply=103690446315152096921846066664885933595)
2025-12-12 18:46:45.837Z debug(replica): 2N: on_request: ignoring (client_replies busy)
2025-12-12 18:46:45.843Z debug(client_replies): 2: read_reply: done (client=129800060941563857535569923226995055452 reply=103690446315152096921846066664885933595)
2025-12-12 18:46:45.843Z debug(replica): 2N: on_request: repeat reply (client=129800060941563857535569923226995055452 request=81)
2025-12-12 18:46:45.843Z debug(replica): 2N: sending reply to client 129800060941563857535569923226995055452: vsr.message_header.Header.Reply{ .checksum = 103690446315152096921846066664885933595, .checksum_padding = 0, .checksum_body = 225737336253671706644003115993621428625, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 288, .epoch = 0, .view = 2, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 39792972214874618568501445663341288247, .request_checksum_padding = 0, .context = 71238269653775673709592736076580168263, .context_padding = 0, .client = 129800060941563857535569923226995055452, .op = 83, .commit = 83, .timestamp = 1765564968478784265, .request = 81, .operation = vsr.Operation(139), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
warning(client): 129800060941563857535569923226995055452: on_reply: slow request, request=81 op=83 size=665600 create_transfers time=237374ms
2025-12-12 18:46:45.845Z debug(replica): 2N: on_message: view=2 status=normal vsr.message_header.Header.Request{ .checksum = 39792972214874618568501445663341288247, .checksum_padding = 0, .checksum_body = 281034154456906138187476354491563389195, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 665600, .epoch = 0, .view = 2, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 329773723757090566204971058525184476939, .parent_padding = 0, .client = 129800060941563857535569923226995055452, .session = 2, .timestamp = 0, .request = 81, .operation = vsr.Operation(139), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 57838157, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 18:46:45.845Z debug(replica): 2N: on_request: replying to duplicate request
2025-12-12 18:46:45.845Z debug(client_replies): 2: read_reply: start (client=129800060941563857535569923226995055452 reply=103690446315152096921846066664885933595)
2025-12-12 18:46:45.848Z debug(replica): 2N: on_message: view=2 status=normal vsr.message_header.Header.Request{ .checksum = 39792972214874618568501445663341288247, .checksum_padding = 0, .checksum_body = 281034154456906138187476354491563389195, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 665600, .epoch = 0, .view = 2, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 329773723757090566204971058525184476939, .parent_padding = 0, .client = 129800060941563857535569923226995055452, .session = 2, .timestamp = 0, .request = 81, .operation = vsr.Operation(139), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 57838157, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 18:46:45.848Z debug(replica): 2N: on_request: replying to duplicate request
2025-12-12 18:46:45.848Z debug(client_replies): 2: read_reply: busy (client=129800060941563857535569923226995055452 reply=103690446315152096921846066664885933595)
2025-12-12 18:46:45.848Z debug(replica): 2N: on_request: ignoring (client_replies busy)
2025-12-12 18:46:45.848Z debug(client_replies): 2: read_reply: done (client=129800060941563857535569923226995055452 reply=103690446315152096921846066664885933595)
2025-12-12 18:46:45.848Z debug(replica): 2N: on_request: repeat reply (client=129800060941563857535569923226995055452 request=81)
2025-12-12 18:46:45.848Z debug(replica): 2N: sending reply to client 129800060941563857535569923226995055452: vsr.message_header.Header.Reply{ .checksum = 103690446315152096921846066664885933595, .checksum_padding = 0, .checksum_body = 225737336253671706644003115993621428625, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 288, .epoch = 0, .view = 2, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 39792972214874618568501445663341288247, .request_checksum_padding = 0, .context = 71238269653775673709592736076580168263, .context_padding = 0, .client = 129800060941563857535569923226995055452, .op = 83, .commit = 83, .timestamp = 1765564968478784265, .request = 81, .operation = vsr.Operation(139), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 18:46:45.848Z warning(clock): 2: synchronization failed, partitioned (sources=1 samples=1)
2025-12-12 18:46:45.848Z error(clock): 2: no agreement on cluster time (partitioned or too many clock faults)
2025-12-12 18:46:45.853Z debug(vsr): 0: journal_repair_budget_timeout fired
2025-12-12 18:46:45.853Z debug(vsr): 0: journal_repair_budget_timeout reset
2025-12-12 18:46:45.854Z warning(faulty_network): connect failed (1,9): error.ConnectionRefused
2025-12-12 18:46:45.858Z debug(vsr): 2: journal_repair_budget_timeout fired
2025-12-12 18:46:45.858Z debug(vsr): 2: journal_repair_budget_timeout reset
2025-12-12 18:46:45.858Z debug(vsr): 2: journal_repair_timeout fired
2025-12-12 18:46:45.858Z debug(vsr): 2: journal_repair_timeout reset
2025-12-12 18:46:45.873Z debug(vsr): 0: journal_repair_budget_timeout fired
2025-12-12 18:46:45.873Z debug(vsr): 0: journal_repair_budget_timeout reset
2025-12-12 18:46:45.873Z debug(vsr): 0: journal_repair_timeout fired
2025-12-12 18:46:45.873Z debug(vsr): 0: journal_repair_timeout reset
2025-12-12 18:46:45.878Z debug(message_bus): 0: on_connect_with_exponential_backoff: to=1
2025-12-12 18:46:45.878Z info(message_bus): 0: on_connect: connected to=1
2025-12-12 18:46:45.878Z warning(faulty_network): connect failed (1,0): error.ConnectionRefused
2025-12-12 18:46:45.878Z info(message_bus): 0: on_recv: from=vsr.Peer{ .replica = 1 } orderly shutdown
2025-12-12 18:46:45.878Z debug(vsr): 2: journal_repair_budget_timeout fired
2025-12-12 18:46:45.878Z debug(vsr): 2: journal_repair_budget_timeout reset
2025-12-12 18:46:45.881Z debug(replica): 2N: on_message: view=2 status=normal vsr.message_header.Header.Request{ .checksum = 288586371519641091125190937893974958814, .checksum_padding = 0, .checksum_body = 8534786181244049314008013070841583767, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2064, .epoch = 0, .view = 2, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 71238269653775673709592736076580168263, .parent_padding = 0, .client = 129800060941563857535569923226995055452, .session = 2, .timestamp = 0, .request = 82, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 4294967295, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 18:46:45.881Z debug(replica): 2N: on_request: new request
2025-12-12 18:46:45.881Z debug(vsr): 2: primary_abdicate_timeout started
2025-12-12 18:46:45.881Z warning(replica): 2N: on_request: dropping (clock not synchronized)
2025-12-12 18:46:45.883Z debug(message_bus): 0: connect_to_replica: connecting to=1 after=51ms
2025-12-12 18:46:45.886Z error(supervisor): liveness check: too slow request
2025-12-12 18:46:45.887Z info(supervisor): 0: terminating replica
2025-12-12 18:46:45.898Z info(supervisor): 1: terminating replica
2025-12-12 18:46:45.898Z debug(vsr): 2: journal_repair_budget_timeout fired
2025-12-12 18:46:45.903Z info(supervisor): 2: terminating replica
2025-12-12 18:46:52.954Z error: TestFailed
/root/tigerbeetle/working/main/src/testing/vortex/supervisor.zig:295:21: 0x1307eb0 in run (vortex)
                    return error.TestFailed;
                    ^
/root/tigerbeetle/working/main/src/testing/vortex/supervisor.zig:207:5: 0x130ca73 in main (vortex)
    try supervisor.run();
    ^
/root/tigerbeetle/working/main/src/vortex.zig:61:42: 0x13216d4 in main (vortex)
        .supervisor => |supervisor_args| try Supervisor.main(allocator, supervisor_args),
                                         ^
