twork): connect failed (0,8): error.ConnectionRefused
2025-12-12 19:32:52.425Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.PrepareOk{ .checksum = 294892681469990602241518419976773652458, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 1, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 292152104040010765586508344441647526974, .parent_padding = 0, .prepare_checksum = 254621069411020878571499031314218057024, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 298802811082733066315345031472557842243, .op = 68, .commit_min = 67, .timestamp = 1765567969616500339, .request = 66, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-12-12 19:32:52.425Z debug(vsr): 1: primary_abdicate_timeout reset
2025-12-12 19:32:52.425Z debug(replica): 1N: on_prepare_ok: 2 message(s)
2025-12-12 19:32:52.425Z debug(replica): 1N: on_prepare_ok: quorum received, context=254621069411020878571499031314218057024
2025-12-12 19:32:52.425Z debug(vsr): 1: prepare_timeout stopped
2025-12-12 19:32:52.425Z debug(vsr): 1: primary_abdicate_timeout stopped
2025-12-12 19:32:52.425Z debug(replica): 1N: execute_op: executing view=1 primary=true op=68 checksum=254621069411020878571499031314218057024 (lookup_accounts)
2025-12-12 19:32:52.425Z debug(replica): 1N: execute_op: commit_timestamp=1765567969597326073 prepare.header.timestamp=1765567969616500339
2025-12-12 19:32:52.425Z debug(replica): 1N: execute_op: advancing commit_max=67..68
2025-12-12 19:32:52.425Z debug(replica): 1N: client_table_entry_update: client=298802811082733066315345031472557842243 session=2 request=66
2025-12-12 19:32:52.425Z debug(replica): 1N: execute_op: replying to client: vsr.message_header.Header.Reply{ .checksum = 130312037553736945253180887569933739938, .checksum_padding = 0, .checksum_body = 137410363270625320649863753735505304076, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 13952, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 59456445820815361377554668893218860422, .request_checksum_padding = 0, .context = 279621773868689303076656576656182315510, .context_padding = 0, .client = 298802811082733066315345031472557842243, .op = 68, .commit = 68, .timestamp = 1765567969616500339, .request = 66, .operation = vsr.Operation(140), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 19:32:52.425Z debug(replica): 1N: sending reply to client 298802811082733066315345031472557842243: vsr.message_header.Header.Reply{ .checksum = 130312037553736945253180887569933739938, .checksum_padding = 0, .checksum_body = 137410363270625320649863753735505304076, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 13952, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 59456445820815361377554668893218860422, .request_checksum_padding = 0, .context = 279621773868689303076656576656182315510, .context_padding = 0, .client = 298802811082733066315345031472557842243, .op = 68, .commit = 68, .timestamp = 1765567969616500339, .request = 66, .operation = vsr.Operation(140), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 19:32:52.425Z debug(forest): entering forest.compact() op=68 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
warning(client): 298802811082733066315345031472557842243: on_reply: slow request, request=66 op=68 size=1968 lookup_accounts time=2809ms
2025-12-12 19:32:52.426Z info(workload): accounts created = 106, transfers = 56088, pending transfers = 0, commands run = 33
2025-12-12 19:32:52.426Z debug(replica): 2n: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 59456445820815361377554668893218860422, .checksum_padding = 0, .checksum_body = 335087834777102016521472518441542458906, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 1968, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 209017490373420912112241679223052205354, .parent_padding = 0, .client = 298802811082733066315345031472557842243, .session = 2, .timestamp = 0, .request = 66, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 19008048, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 19:32:52.426Z debug(replica): 2n: on_request: forwarding new request to primary (view=1)
2025-12-12 19:32:52.426Z debug(replica): 2n: sending request to replica 1: vsr.message_header.Header.Request{ .checksum = 59456445820815361377554668893218860422, .checksum_padding = 0, .checksum_body = 335087834777102016521472518441542458906, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 1968, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 209017490373420912112241679223052205354, .parent_padding = 0, .client = 298802811082733066315345031472557842243, .session = 2, .timestamp = 0, .request = 66, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 19008048, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 19:32:52.426Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 59456445820815361377554668893218860422, .checksum_padding = 0, .checksum_body = 335087834777102016521472518441542458906, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 1968, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 209017490373420912112241679223052205354, .parent_padding = 0, .client = 298802811082733066315345031472557842243, .session = 2, .timestamp = 0, .request = 66, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 19008048, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 19:32:52.426Z debug(replica): 1N: on_request: replying to duplicate request
2025-12-12 19:32:52.426Z debug(replica): 1N: on_request: repeat reply (client=298802811082733066315345031472557842243 request=66)
2025-12-12 19:32:52.426Z debug(replica): 1N: sending reply to client 298802811082733066315345031472557842243: vsr.message_header.Header.Reply{ .checksum = 130312037553736945253180887569933739938, .checksum_padding = 0, .checksum_body = 137410363270625320649863753735505304076, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 13952, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 59456445820815361377554668893218860422, .request_checksum_padding = 0, .context = 279621773868689303076656576656182315510, .context_padding = 0, .client = 298802811082733066315345031472557842243, .op = 68, .commit = 68, .timestamp = 1765567969616500339, .request = 66, .operation = vsr.Operation(140), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 19:32:52.426Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.Pong{ .checksum = 289562660162215216024715081744086164174, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.pong, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .ping_timestamp_monotonic = 37683542166843664, .pong_timestamp_wall = 1765567969647417587, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 19:32:52.426Z debug(clock): 1: learn: replica=2 m0=37683542166843664 t1=1765567969647417587 m2=37683544946436706 t2=1765567972426783761 one_way_delay=1389796521 asymmetric_delay=579104277 clock_offset=-810465376
2025-12-12 19:32:52.426Z debug(client_replies): 1: write_reply: wrote (client=298802811082733066315345031472557842243 request=66)
2025-12-12 19:32:52.427Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 309708843580175873406880645705114276647, .checksum_padding = 0, .checksum_body = 317761732507965300148573685979367616643, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 42624, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 279621773868689303076656576656182315510, .parent_padding = 0, .client = 298802811082733066315345031472557842243, .session = 2, .timestamp = 0, .request = 67, .operation = vsr.Operation(139), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 2809659665, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 19:32:52.427Z debug(replica): 1N: on_request: new request
2025-12-12 19:32:52.427Z debug(replica): 1N: primary_pipeline_prepare: request checksum=309708843580175873406880645705114276647 client=298802811082733066315345031472557842243
2025-12-12 19:32:52.427Z debug(replica): 1N: primary_pipeline_prepare: prepare checksum=170534008775123555095776752934506378491 op=69
2025-12-12 19:32:52.427Z debug(vsr): 1: prepare_timeout started
2025-12-12 19:32:52.427Z debug(vsr): 1: primary_abdicate_timeout started
2025-12-12 19:32:52.427Z debug(vsr): 1: pulse_timeout reset
2025-12-12 19:32:52.427Z debug(replica): 1N: replicate: replicating op=69 to replica 0
2025-12-12 19:32:52.427Z debug(replica): 1N: sending prepare to replica 0: vsr.message_header.Header.Prepare{ .checksum = 170534008775123555095776752934506378491, .checksum_padding = 0, .checksum_body = 317761732507965300148573685979367616643, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 42624, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 254621069411020878571499031314218057024, .parent_padding = 0, .request_checksum = 309708843580175873406880645705114276647, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 298802811082733066315345031472557842243, .op = 69, .commit = 68, .timestamp = 1765567972427266629, .request = 67, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-12-12 19:32:52.427Z debug(message_bus): 1: send_message_to_replica: no connection to=0 header=vsr.message_header.Header.Prepare{ .checksum = 170534008775123555095776752934506378491, .checksum_padding = 0, .checksum_body = 317761732507965300148573685979367616643, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 42624, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 254621069411020878571499031314218057024, .parent_padding = 0, .request_checksum = 309708843580175873406880645705114276647, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 298802811082733066315345031472557842243, .op = 69, .commit = 68, .timestamp = 1765567972427266629, .request = 67, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-12-12 19:32:52.427Z debug(replica): 1N: replicate: replicating op=69 to replica 2
2025-12-12 19:32:52.427Z debug(replica): 1N: sending prepare to replica 2: vsr.message_header.Header.Prepare{ .checksum = 170534008775123555095776752934506378491, .checksum_padding = 0, .checksum_body = 317761732507965300148573685979367616643, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 42624, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 254621069411020878571499031314218057024, .parent_padding = 0, .request_checksum = 309708843580175873406880645705114276647, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 298802811082733066315345031472557842243, .op = 69, .commit = 68, .timestamp = 1765567972427266629, .request = 67, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-12-12 19:32:52.427Z debug(replica): 1N: on_prepare: advancing: op=68..69 checksum=254621069411020878571499031314218057024..170534008775123555095776752934506378491
2025-12-12 19:32:52.427Z debug(journal): 1: set_header_as_dirty: op=69 checksum=170534008775123555095776752934506378491
2025-12-12 19:32:52.427Z debug(replica): 1N: append: appending to journal op=69
2025-12-12 19:32:52.427Z debug(journal): 1: write: view=1 slot=69 op=69 len=42624: 170534008775123555095776752934506378491 starting
2025-12-12 19:32:52.427Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.prepares offset=72351744 len=45056 locked
2025-12-12 19:32:52.427Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 59456445820815361377554668893218860422, .checksum_padding = 0, .checksum_body = 335087834777102016521472518441542458906, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 1968, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 209017490373420912112241679223052205354, .parent_padding = 0, .client = 298802811082733066315345031472557842243, .session = 2, .timestamp = 0, .request = 66, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 19008048, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 19:32:52.427Z debug(replica): 1N: on_request: replying to duplicate request
2025-12-12 19:32:52.427Z debug(client_replies): 1: read_reply: start (client=298802811082733066315345031472557842243 reply=130312037553736945253180887569933739938)
2025-12-12 19:32:52.427Z debug(replica): 2n: on_message: view=1 status=normal vsr.message_header.Header.Prepare{ .checksum = 170534008775123555095776752934506378491, .checksum_padding = 0, .checksum_body = 317761732507965300148573685979367616643, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 42624, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 254621069411020878571499031314218057024, .parent_padding = 0, .request_checksum = 309708843580175873406880645705114276647, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 298802811082733066315345031472557842243, .op = 69, .commit = 68, .timestamp = 1765567972427266629, .request = 67, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-12-12 19:32:52.428Z debug(replica): 2n: on_prepare: advancing commit_max=67..68
2025-12-12 19:32:52.428Z debug(replica): 2n: on_prepare: caching prepare.op=69 (commit_min=67 op=68 commit_max=68 prepare_max=1007)
2025-12-12 19:32:52.428Z debug(replica): 2n: on_prepare: advancing: op=68..69 checksum=254621069411020878571499031314218057024..170534008775123555095776752934506378491
2025-12-12 19:32:52.428Z debug(journal): 2: set_header_as_dirty: op=69 checksum=170534008775123555095776752934506378491
2025-12-12 19:32:52.428Z debug(client_replies): 1: read_reply: done (client=298802811082733066315345031472557842243 reply=130312037553736945253180887569933739938)
2025-12-12 19:32:52.428Z debug(replica): 2n: append: appending to journal op=69
2025-12-12 19:32:52.428Z debug(replica): 1N: on_request: repeat reply (client=298802811082733066315345031472557842243 request=66)
2025-12-12 19:32:52.428Z debug(journal): 2: write: view=1 slot=69 op=69 len=42624: 170534008775123555095776752934506378491 starting
2025-12-12 19:32:52.428Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.prepares offset=72351744 len=45056 locked
2025-12-12 19:32:52.428Z debug(replica): 1N: sending reply to client 298802811082733066315345031472557842243: vsr.message_header.Header.Reply{ .checksum = 130312037553736945253180887569933739938, .checksum_padding = 0, .checksum_body = 137410363270625320649863753735505304076, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 13952, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 59456445820815361377554668893218860422, .request_checksum_padding = 0, .context = 279621773868689303076656576656182315510, .context_padding = 0, .client = 298802811082733066315345031472557842243, .op = 68, .commit = 68, .timestamp = 1765567969616500339, .request = 66, .operation = vsr.Operation(140), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 19:32:52.428Z debug(replica): 2n: commit_start_journal: cached prepare op=68 checksum=254621069411020878571499031314218057024
2025-12-12 19:32:52.428Z debug(replica): 2n: repair_prepare: op=69 checksum=170534008775123555095776752934506378491 (already writing)
2025-12-12 19:32:52.428Z debug(replica): 2n: commit_journal: already committing (prefetch; commit_min=67)
2025-12-12 19:32:52.428Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.prepares offset=72351744 len=45056 unlocked
2025-12-12 19:32:52.428Z debug(replica): 2n: execute_op: executing view=1 primary=false op=68 checksum=254621069411020878571499031314218057024 (lookup_accounts)
2025-12-12 19:32:52.428Z debug(replica): 2n: execute_op: commit_timestamp=1765567969597326073 prepare.header.timestamp=1765567969616500339
2025-12-12 19:32:52.428Z debug(journal): 1: write_header: op=69 sectors[16384..20480]
2025-12-12 19:32:52.428Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.headers offset=16384 len=4096 locked
2025-12-12 19:32:52.428Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.headers offset=16384 len=4096 unlocked
2025-12-12 19:32:52.428Z debug(replica): 2n: client_table_entry_update: client=298802811082733066315345031472557842243 session=2 request=66
2025-12-12 19:32:52.428Z debug(journal): 1: write: view=1 slot=69 op=69 len=42624: 170534008775123555095776752934506378491 complete, marking clean
2025-12-12 19:32:52.428Z debug(forest): entering forest.compact() op=68 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2025-12-12 19:32:52.428Z debug(replica): 1N: send_prepare_ok: op=69 checksum=170534008775123555095776752934506378491
2025-12-12 19:32:52.428Z debug(replica): 1N: sending prepare_ok to replica 1: vsr.message_header.Header.PrepareOk{ .checksum = 318601892255873703809787880676981916142, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 1, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 254621069411020878571499031314218057024, .parent_padding = 0, .prepare_checksum = 170534008775123555095776752934506378491, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 298802811082733066315345031472557842243, .op = 69, .commit_min = 68, .timestamp = 1765567972427266629, .request = 67, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-12-12 19:32:52.428Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.PrepareOk{ .checksum = 318601892255873703809787880676981916142, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 1, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 254621069411020878571499031314218057024, .parent_padding = 0, .prepare_checksum = 170534008775123555095776752934506378491, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 298802811082733066315345031472557842243, .op = 69, .commit_min = 68, .timestamp = 1765567972427266629, .request = 67, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-12-12 19:32:52.428Z debug(vsr): 1: primary_abdicate_timeout reset
2025-12-12 19:32:52.428Z debug(replica): 1N: on_prepare_ok: 1 message(s)
2025-12-12 19:32:52.428Z debug(replica): 1N: on_prepare_ok: waiting for quorum
2025-12-12 19:32:52.428Z debug(client_replies): 2: write_reply: wrote (client=298802811082733066315345031472557842243 request=66)
2025-12-12 19:32:52.429Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.prepares offset=72351744 len=45056 unlocked
2025-12-12 19:32:52.429Z debug(journal): 2: write_header: op=69 sectors[16384..20480]
2025-12-12 19:32:52.429Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.headers offset=16384 len=4096 locked
2025-12-12 19:32:52.429Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.headers offset=16384 len=4096 unlocked
2025-12-12 19:32:52.429Z debug(journal): 2: write: view=1 slot=69 op=69 len=42624: 170534008775123555095776752934506378491 complete, marking clean
2025-12-12 19:32:52.429Z debug(replica): 2n: send_prepare_ok: op=69 checksum=170534008775123555095776752934506378491
2025-12-12 19:32:52.429Z debug(replica): 2n: sending prepare_ok to replica 1: vsr.message_header.Header.PrepareOk{ .checksum = 82992156624244201161170766300262144690, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 1, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 254621069411020878571499031314218057024, .parent_padding = 0, .prepare_checksum = 170534008775123555095776752934506378491, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 298802811082733066315345031472557842243, .op = 69, .commit_min = 68, .timestamp = 1765567972427266629, .request = 67, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-12-12 19:32:52.429Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.PrepareOk{ .checksum = 82992156624244201161170766300262144690, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 1, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 254621069411020878571499031314218057024, .parent_padding = 0, .prepare_checksum = 170534008775123555095776752934506378491, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 298802811082733066315345031472557842243, .op = 69, .commit_min = 68, .timestamp = 1765567972427266629, .request = 67, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-12-12 19:32:52.429Z debug(vsr): 1: primary_abdicate_timeout reset
2025-12-12 19:32:52.429Z debug(replica): 1N: on_prepare_ok: 2 message(s)
2025-12-12 19:32:52.429Z debug(replica): 1N: on_prepare_ok: quorum received, context=170534008775123555095776752934506378491
2025-12-12 19:32:52.429Z debug(vsr): 1: prepare_timeout stopped
2025-12-12 19:32:52.429Z debug(vsr): 1: primary_abdicate_timeout stopped
2025-12-12 19:32:52.429Z debug(replica): 1N: execute_op: executing view=1 primary=true op=69 checksum=170534008775123555095776752934506378491 (create_transfers)
2025-12-12 19:32:52.429Z debug(replica): 1N: execute_op: commit_timestamp=1765567969616500339 prepare.header.timestamp=1765567972427266629
2025-12-12 19:32:52.430Z debug(replica): 1N: execute_op: advancing commit_max=68..69
2025-12-12 19:32:52.430Z debug(replica): 1N: client_table_entry_update: client=298802811082733066315345031472557842243 session=2 request=67
2025-12-12 19:32:52.430Z debug(replica): 1N: execute_op: replying to client: vsr.message_header.Header.Reply{ .checksum = 173930406226730142556683230039082006904, .checksum_padding = 0, .checksum_body = 311752944233308762869332694583075543730, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 264, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 309708843580175873406880645705114276647, .request_checksum_padding = 0, .context = 155994709511669089776429598020177368265, .context_padding = 0, .client = 298802811082733066315345031472557842243, .op = 69, .commit = 69, .timestamp = 1765567972427266629, .request = 67, .operation = vsr.Operation(139), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 19:32:52.430Z debug(replica): 1N: sending reply to client 298802811082733066315345031472557842243: vsr.message_header.Header.Reply{ .checksum = 173930406226730142556683230039082006904, .checksum_padding = 0, .checksum_body = 311752944233308762869332694583075543730, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 264, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 309708843580175873406880645705114276647, .request_checksum_padding = 0, .context = 155994709511669089776429598020177368265, .context_padding = 0, .client = 298802811082733066315345031472557842243, .op = 69, .commit = 69, .timestamp = 1765567972427266629, .request = 67, .operation = vsr.Operation(139), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 19:32:52.430Z debug(forest): entering forest.compact() op=69 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2025-12-12 19:32:52.432Z debug(client_replies): 1: write_reply: wrote (client=298802811082733066315345031472557842243 request=67)
2025-12-12 19:32:52.435Z debug(clock): 1: synchronized: truechimers=2/3 clock_offset=0ns..0ns accuracy=0ns
2025-12-12 19:32:52.435Z debug(clock): 1: system time is 20ns behind
2025-12-12 19:32:52.436Z debug(vsr): 2: journal_repair_budget_timeout fired
2025-12-12 19:32:52.436Z debug(vsr): 2: journal_repair_budget_timeout reset
2025-12-12 19:32:52.445Z debug(vsr): 1: journal_repair_budget_timeout fired
2025-12-12 19:32:52.445Z debug(vsr): 1: journal_repair_budget_timeout reset
2025-12-12 19:32:52.456Z debug(vsr): 2: journal_repair_budget_timeout fired
2025-12-12 19:32:52.456Z debug(vsr): 2: journal_repair_budget_timeout reset
2025-12-12 19:32:52.456Z debug(vsr): 2: journal_repair_timeout fired
2025-12-12 19:32:52.456Z debug(vsr): 2: journal_repair_timeout reset
2025-12-12 19:32:52.465Z debug(vsr): 1: journal_repair_budget_timeout fired
2025-12-12 19:32:52.465Z debug(vsr): 1: journal_repair_budget_timeout reset
2025-12-12 19:32:52.470Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 222172428920323671581066988600153093999, .checksum_padding = 0, .checksum_body = 335087834777102016521472518441542458906, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 1968, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 155994709511669089776429598020177368265, .parent_padding = 0, .client = 298802811082733066315345031472557842243, .session = 2, .timestamp = 0, .request = 68, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 42235822, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 19:32:52.470Z debug(replica): 2n: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 222172428920323671581066988600153093999, .checksum_padding = 0, .checksum_body = 335087834777102016521472518441542458906, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 1968, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 155994709511669089776429598020177368265, .parent_padding = 0, .client = 298802811082733066315345031472557842243, .session = 2, .timestamp = 0, .request = 68, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 42235822, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 19:32:52.470Z debug(replica): 2n: on_request: forwarding new request to primary (view=1)
2025-12-12 19:32:52.470Z debug(replica): 1N: on_request: new request
2025-12-12 19:32:52.470Z debug(replica): 1N: primary_pipeline_prepare: request checksum=222172428920323671581066988600153093999 client=298802811082733066315345031472557842243
2025-12-12 19:32:52.470Z debug(replica): 2n: sending request to replica 1: vsr.message_header.Header.Request{ .checksum = 222172428920323671581066988600153093999, .checksum_padding = 0, .checksum_body = 335087834777102016521472518441542458906, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 1968, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 155994709511669089776429598020177368265, .parent_padding = 0, .client = 298802811082733066315345031472557842243, .session = 2, .timestamp = 0, .request = 68, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 42235822, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 19:32:52.470Z debug(replica): 1N: primary_pipeline_prepare: prepare checksum=220734229818176377738523995150353688483 op=70
2025-12-12 19:32:52.470Z debug(vsr): 1: prepare_timeout started
2025-12-12 19:32:52.470Z debug(vsr): 1: primary_abdicate_timeout started
2025-12-12 19:32:52.470Z debug(vsr): 1: pulse_timeout reset
2025-12-12 19:32:52.470Z debug(replica): 1N: replicate: replicating op=70 to replica 0
2025-12-12 19:32:52.470Z debug(replica): 1N: sending prepare to replica 0: vsr.message_header.Header.Prepare{ .checksum = 220734229818176377738523995150353688483, .checksum_padding = 0, .checksum_body = 335087834777102016521472518441542458906, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 1968, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 170534008775123555095776752934506378491, .parent_padding = 0, .request_checksum = 222172428920323671581066988600153093999, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 298802811082733066315345031472557842243, .op = 70, .commit = 69, .timestamp = 1765567972470227176, .request = 68, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-12-12 19:32:52.470Z debug(message_bus): 1: send_message_to_replica: no connection to=0 header=vsr.message_header.Header.Prepare{ .checksum = 220734229818176377738523995150353688483, .checksum_padding = 0, .checksum_body = 335087834777102016521472518441542458906, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 1968, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 170534008775123555095776752934506378491, .parent_padding = 0, .request_checksum = 222172428920323671581066988600153093999, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 298802811082733066315345031472557842243, .op = 70, .commit = 69, .timestamp = 1765567972470227176, .request = 68, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-12-12 19:32:52.470Z debug(replica): 1N: replicate: replicating op=70 to replica 2
2025-12-12 19:32:52.470Z debug(replica): 1N: sending prepare to replica 2: vsr.message_header.Header.Prepare{ .checksum = 220734229818176377738523995150353688483, .checksum_padding = 0, .checksum_body = 335087834777102016521472518441542458906, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 1968, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 170534008775123555095776752934506378491, .parent_padding = 0, .request_checksum = 222172428920323671581066988600153093999, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 298802811082733066315345031472557842243, .op = 70, .commit = 69, .timestamp = 1765567972470227176, .request = 68, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-12-12 19:32:52.470Z debug(replica): 1N: on_prepare: advancing: op=69..70 checksum=170534008775123555095776752934506378491..220734229818176377738523995150353688483
2025-12-12 19:32:52.470Z debug(journal): 1: set_header_as_dirty: op=70 checksum=220734229818176377738523995150353688483
2025-12-12 19:32:52.470Z debug(replica): 1N: append: appending to journal op=70
2025-12-12 19:32:52.470Z debug(journal): 1: write: view=1 slot=70 op=70 len=1968: 220734229818176377738523995150353688483 starting
2025-12-12 19:32:52.470Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.prepares offset=73400320 len=4096 locked
2025-12-12 19:32:52.470Z debug(replica): 2n: on_message: view=1 status=normal vsr.message_header.Header.Prepare{ .checksum = 220734229818176377738523995150353688483, .checksum_padding = 0, .checksum_body = 335087834777102016521472518441542458906, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 1968, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 170534008775123555095776752934506378491, .parent_padding = 0, .request_checksum = 222172428920323671581066988600153093999, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 298802811082733066315345031472557842243, .op = 70, .commit = 69, .timestamp = 1765567972470227176, .request = 68, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-12-12 19:32:52.470Z debug(replica): 2n: on_prepare: advancing commit_max=68..69
2025-12-12 19:32:52.470Z debug(replica): 2n: on_prepare: caching prepare.op=70 (commit_min=68 op=69 commit_max=69 prepare_max=1007)
2025-12-12 19:32:52.470Z debug(replica): 2n: on_prepare: advancing: op=69..70 checksum=170534008775123555095776752934506378491..220734229818176377738523995150353688483
2025-12-12 19:32:52.470Z debug(journal): 2: set_header_as_dirty: op=70 checksum=220734229818176377738523995150353688483
2025-12-12 19:32:52.470Z debug(replica): 2n: append: appending to journal op=70
2025-12-12 19:32:52.470Z debug(journal): 2: write: view=1 slot=70 op=70 len=1968: 220734229818176377738523995150353688483 starting
2025-12-12 19:32:52.470Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.prepares offset=73400320 len=4096 locked
2025-12-12 19:32:52.470Z debug(replica): 2n: commit_start_journal: cached prepare op=69 checksum=170534008775123555095776752934506378491
2025-12-12 19:32:52.470Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 222172428920323671581066988600153093999, .checksum_padding = 0, .checksum_body = 335087834777102016521472518441542458906, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 1968, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 155994709511669089776429598020177368265, .parent_padding = 0, .client = 298802811082733066315345031472557842243, .session = 2, .timestamp = 0, .request = 68, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 42235822, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 19:32:52.470Z debug(replica): 1N: on_request: new request
2025-12-12 19:32:52.470Z debug(replica): 1N: on_request: ignoring (already preparing)
2025-12-12 19:32:52.470Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.prepares offset=73400320 len=4096 unlocked
2025-12-12 19:32:52.470Z debug(journal): 1: write_header: op=70 sectors[16384..20480]
2025-12-12 19:32:52.470Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.headers offset=16384 len=4096 locked
2025-12-12 19:32:52.470Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.headers offset=16384 len=4096 unlocked
2025-12-12 19:32:52.470Z debug(journal): 1: write: view=1 slot=70 op=70 len=1968: 220734229818176377738523995150353688483 complete, marking clean
2025-12-12 19:32:52.470Z debug(replica): 1N: send_prepare_ok: op=70 checksum=220734229818176377738523995150353688483
2025-12-12 19:32:52.470Z debug(replica): 2n: repair_prepare: op=70 checksum=220734229818176377738523995150353688483 (already writing)
2025-12-12 19:32:52.470Z debug(replica): 1N: sending prepare_ok to replica 1: vsr.message_header.Header.PrepareOk{ .checksum = 327410757960348729078725207067593293988, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 1, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 170534008775123555095776752934506378491, .parent_padding = 0, .prepare_checksum = 220734229818176377738523995150353688483, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 298802811082733066315345031472557842243, .op = 70, .commit_min = 69, .timestamp = 1765567972470227176, .request = 68, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-12-12 19:32:52.470Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.PrepareOk{ .checksum = 327410757960348729078725207067593293988, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 1, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 170534008775123555095776752934506378491, .parent_padding = 0, .prepare_checksum = 220734229818176377738523995150353688483, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 298802811082733066315345031472557842243, .op = 70, .commit_min = 69, .timestamp = 1765567972470227176, .request = 68, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-12-12 19:32:52.470Z debug(replica): 2n: commit_journal: already committing (prefetch; commit_min=68)
2025-12-12 19:32:52.470Z debug(vsr): 1: primary_abdicate_timeout reset
2025-12-12 19:32:52.470Z debug(replica): 1N: on_prepare_ok: 1 message(s)
2025-12-12 19:32:52.470Z debug(replica): 1N: on_prepare_ok: waiting for quorum
2025-12-12 19:32:52.470Z debug(replica): 2n: execute_op: executing view=1 primary=false op=69 checksum=170534008775123555095776752934506378491 (create_transfers)
2025-12-12 19:32:52.470Z debug(replica): 2n: execute_op: commit_timestamp=1765567969616500339 prepare.header.timestamp=1765567972427266629
2025-12-12 19:32:52.472Z debug(replica): 2n: client_table_entry_update: client=298802811082733066315345031472557842243 session=2 request=67
2025-12-12 19:32:52.472Z debug(forest): entering forest.compact() op=69 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2025-12-12 19:32:52.473Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.prepares offset=73400320 len=4096 unlocked
2025-12-12 19:32:52.473Z debug(journal): 2: write_header: op=70 sectors[16384..20480]
2025-12-12 19:32:52.473Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.headers offset=16384 len=4096 locked
2025-12-12 19:32:52.473Z debug(client_replies): 2: write_reply: wrote (client=298802811082733066315345031472557842243 request=67)
2025-12-12 19:32:52.474Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.headers offset=16384 len=4096 unlocked
2025-12-12 19:32:52.474Z debug(journal): 2: write: view=1 slot=70 op=70 len=1968: 220734229818176377738523995150353688483 complete, marking clean
2025-12-12 19:32:52.474Z debug(replica): 2n: send_prepare_ok: op=70 checksum=220734229818176377738523995150353688483
2025-12-12 19:32:52.474Z debug(replica): 2n: sending prepare_ok to replica 1: vsr.message_header.Header.PrepareOk{ .checksum = 339924807213617231813302181855836368463, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 1, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 170534008775123555095776752934506378491, .parent_padding = 0, .prepare_checksum = 220734229818176377738523995150353688483, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 298802811082733066315345031472557842243, .op = 70, .commit_min = 69, .timestamp = 1765567972470227176, .request = 68, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-12-12 19:32:52.476Z debug(vsr): 2: journal_repair_budget_timeout fired
2025-12-12 19:32:52.476Z debug(vsr): 2: journal_repair_budget_timeout reset
2025-12-12 19:32:52.485Z debug(vsr): 1: journal_repair_budget_timeout fired
2025-12-12 19:32:52.485Z debug(vsr): 1: journal_repair_budget_timeout reset
2025-12-12 19:32:52.492Z warning(faulty_network): connect failed (0,9): error.ConnectionRefused
2025-12-12 19:32:52.496Z debug(vsr): 2: journal_repair_budget_timeout fired
2025-12-12 19:32:52.496Z debug(vsr): 2: journal_repair_budget_timeout reset
2025-12-12 19:32:52.505Z debug(vsr): 1: journal_repair_budget_timeout fired
2025-12-12 19:32:52.505Z debug(vsr): 1: journal_repair_budget_timeout reset
2025-12-12 19:32:52.512Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.PrepareOk{ .checksum = 339924807213617231813302181855836368463, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 1, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 170534008775123555095776752934506378491, .parent_padding = 0, .prepare_checksum = 220734229818176377738523995150353688483, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 298802811082733066315345031472557842243, .op = 70, .commit_min = 69, .timestamp = 1765567972470227176, .request = 68, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-12-12 19:32:52.512Z debug(vsr): 1: primary_abdicate_timeout reset
2025-12-12 19:32:52.512Z debug(replica): 1N: on_prepare_ok: 2 message(s)
2025-12-12 19:32:52.512Z debug(replica): 1N: on_prepare_ok: quorum received, context=220734229818176377738523995150353688483
2025-12-12 19:32:52.512Z debug(vsr): 1: prepare_timeout stopped
2025-12-12 19:32:52.512Z debug(vsr): 1: primary_abdicate_timeout stopped
2025-12-12 19:32:52.512Z debug(replica): 1N: execute_op: executing view=1 primary=true op=70 checksum=220734229818176377738523995150353688483 (lookup_accounts)
2025-12-12 19:32:52.512Z debug(replica): 1N: execute_op: commit_timestamp=1765567972427266629 prepare.header.timestamp=1765567972470227176
2025-12-12 19:32:52.512Z debug(replica): 1N: execute_op: advancing commit_max=69..70
2025-12-12 19:32:52.512Z debug(replica): 1N: client_table_entry_update: client=298802811082733066315345031472557842243 session=2 request=68
2025-12-12 19:32:52.512Z debug(replica): 1N: execute_op: replying to client: vsr.message_header.Header.Reply{ .checksum = 119333095016839772262324112906378663467, .checksum_padding = 0, .checksum_body = 93161375402133554763691420682393406203, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 13952, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 222172428920323671581066988600153093999, .request_checksum_padding = 0, .context = 149014631894753246485525663021895623833, .context_padding = 0, .client = 298802811082733066315345031472557842243, .op = 70, .commit = 70, .timestamp = 1765567972470227176, .request = 68, .operation = vsr.Operation(140), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 19:32:52.512Z debug(replica): 1N: sending reply to client 298802811082733066315345031472557842243: vsr.message_header.Header.Reply{ .checksum = 119333095016839772262324112906378663467, .checksum_padding = 0, .checksum_body = 93161375402133554763691420682393406203, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 13952, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 222172428920323671581066988600153093999, .request_checksum_padding = 0, .context = 149014631894753246485525663021895623833, .context_padding = 0, .client = 298802811082733066315345031472557842243, .op = 70, .commit = 70, .timestamp = 1765567972470227176, .request = 68, .operation = vsr.Operation(140), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 19:32:52.512Z debug(forest): entering forest.compact() op=70 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2025-12-12 19:32:52.513Z info(workload): accounts created = 106, transfers = 56418, pending transfers = 0, commands run = 34
2025-12-12 19:32:52.513Z debug(client_replies): 1: write_reply: wrote (client=298802811082733066315345031472557842243 request=68)
2025-12-12 19:32:52.514Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 163012970321548452669911212396019818280, .checksum_padding = 0, .checksum_body = 310805550105796871911859957523491538008, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 111184, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 149014631894753246485525663021895623833, .parent_padding = 0, .client = 298802811082733066315345031472557842243, .session = 2, .timestamp = 0, .request = 69, .operation = vsr.Operation(141), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 43188566, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 19:32:52.514Z debug(replica): 1N: on_request: new request
2025-12-12 19:32:52.514Z debug(replica): 1N: primary_pipeline_prepare: request checksum=163012970321548452669911212396019818280 client=298802811082733066315345031472557842243
2025-12-12 19:32:52.515Z debug(replica): 1N: primary_pipeline_prepare: prepare checksum=19453193703364400330890009371414682004 op=71
2025-12-12 19:32:52.515Z debug(vsr): 1: prepare_timeout started
2025-12-12 19:32:52.515Z debug(vsr): 1: primary_abdicate_timeout started
2025-12-12 19:32:52.515Z debug(vsr): 1: pulse_timeout reset
2025-12-12 19:32:52.515Z debug(replica): 1N: replicate: replicating op=71 to replica 0
2025-12-12 19:32:52.515Z debug(replica): 1N: sending prepare to replica 0: vsr.message_header.Header.Prepare{ .checksum = 19453193703364400330890009371414682004, .checksum_padding = 0, .checksum_body = 310805550105796871911859957523491538008, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 111184, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 220734229818176377738523995150353688483, .parent_padding = 0, .request_checksum = 163012970321548452669911212396019818280, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 298802811082733066315345031472557842243, .op = 71, .commit = 70, .timestamp = 1765567972514904993, .request = 69, .operation = vsr.Operation(141), .reserved = { 0, 0, 0 } }
2025-12-12 19:32:52.515Z debug(message_bus): 1: send_message_to_replica: no connection to=0 header=vsr.message_header.Header.Prepare{ .checksum = 19453193703364400330890009371414682004, .checksum_padding = 0, .checksum_body = 310805550105796871911859957523491538008, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 111184, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 220734229818176377738523995150353688483, .parent_padding = 0, .request_checksum = 163012970321548452669911212396019818280, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 298802811082733066315345031472557842243, .op = 71, .commit = 70, .timestamp = 1765567972514904993, .request = 69, .operation = vsr.Operation(141), .reserved = { 0, 0, 0 } }
2025-12-12 19:32:52.515Z debug(replica): 1N: replicate: replicating op=71 to replica 2
2025-12-12 19:32:52.515Z debug(replica): 1N: sending prepare to replica 2: vsr.message_header.Header.Prepare{ .checksum = 19453193703364400330890009371414682004, .checksum_padding = 0, .checksum_body = 310805550105796871911859957523491538008, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 111184, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 220734229818176377738523995150353688483, .parent_padding = 0, .request_checksum = 163012970321548452669911212396019818280, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 298802811082733066315345031472557842243, .op = 71, .commit = 70, .timestamp = 1765567972514904993, .request = 69, .operation = vsr.Operation(141), .reserved = { 0, 0, 0 } }
2025-12-12 19:32:52.515Z debug(replica): 1N: on_prepare: advancing: op=70..71 checksum=220734229818176377738523995150353688483..19453193703364400330890009371414682004
2025-12-12 19:32:52.515Z debug(journal): 1: set_header_as_dirty: op=71 checksum=19453193703364400330890009371414682004
2025-12-12 19:32:52.515Z debug(replica): 1N: append: appending to journal op=71
2025-12-12 19:32:52.515Z debug(journal): 1: write: view=1 slot=71 op=71 len=111184: 19453193703364400330890009371414682004 starting
2025-12-12 19:32:52.515Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.prepares offset=74448896 len=114688 locked
2025-12-12 19:32:52.516Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.prepares offset=74448896 len=114688 unlocked
2025-12-12 19:32:52.516Z debug(journal): 1: write_header: op=71 sectors[16384..20480]
2025-12-12 19:32:52.516Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.headers offset=16384 len=4096 locked
2025-12-12 19:32:52.516Z debug(replica): 2n: on_message: view=1 status=normal vsr.message_header.Header.Prepare{ .checksum = 19453193703364400330890009371414682004, .checksum_padding = 0, .checksum_body = 310805550105796871911859957523491538008, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 111184, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 220734229818176377738523995150353688483, .parent_padding = 0, .request_checksum = 163012970321548452669911212396019818280, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 298802811082733066315345031472557842243, .op = 71, .commit = 70, .timestamp = 1765567972514904993, .request = 69, .operation = vsr.Operation(141), .reserved = { 0, 0, 0 } }
2025-12-12 19:32:52.549Z warning(faulty_network): connect failed (0,0): error.ConnectionRefused
2025-12-12 19:32:55.202Z debug(replica): 2n: on_prepare: advancing commit_max=69..70
2025-12-12 19:32:55.202Z debug(replica): 2n: on_prepare: caching prepare.op=71 (commit_min=69 op=70 commit_max=70 prepare_max=1007)
2025-12-12 19:32:55.202Z debug(replica): 2n: on_prepare: advancing: op=70..71 checksum=220734229818176377738523995150353688483..19453193703364400330890009371414682004
2025-12-12 19:32:55.202Z debug(journal): 2: set_header_as_dirty: op=71 checksum=19453193703364400330890009371414682004
2025-12-12 19:32:55.202Z debug(replica): 2n: append: appending to journal op=71
2025-12-12 19:32:55.202Z debug(journal): 2: write: view=1 slot=71 op=71 len=111184: 19453193703364400330890009371414682004 starting
2025-12-12 19:32:55.202Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.prepares offset=74448896 len=114688 locked
2025-12-12 19:32:55.202Z debug(replica): 2n: commit_start_journal: cached prepare op=70 checksum=220734229818176377738523995150353688483
warning(message_bus): 298802811082733066315345031472557842243: on_recv: from=vsr.Peer{ .replica = 0 } error.ConnectionResetByPeer
2025-12-12 19:32:55.203Z debug(replica): 2n: repair_prepare: op=71 checksum=19453193703364400330890009371414682004 (already writing)
2025-12-12 19:32:55.203Z debug(replica): 2n: commit_journal: already committing (prefetch; commit_min=69)
2025-12-12 19:32:55.203Z debug(replica): 2n: execute_op: executing view=1 primary=false op=70 checksum=220734229818176377738523995150353688483 (lookup_accounts)
2025-12-12 19:32:55.203Z debug(replica): 2n: execute_op: commit_timestamp=1765567972427266629 prepare.header.timestamp=1765567972470227176
2025-12-12 19:32:55.203Z debug(replica): 2n: client_table_entry_update: client=298802811082733066315345031472557842243 session=2 request=68
2025-12-12 19:32:55.203Z debug(forest): entering forest.compact() op=70 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2025-12-12 19:32:55.203Z debug(vsr): 2: journal_repair_budget_timeout fired
2025-12-12 19:32:55.203Z debug(vsr): 2: journal_repair_budget_timeout reset
2025-12-12 19:32:55.203Z debug(client_replies): 2: write_reply: wrote (client=298802811082733066315345031472557842243 request=68)
2025-12-12 19:32:55.203Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 163012970321548452669911212396019818280, .checksum_padding = 0, .checksum_body = 310805550105796871911859957523491538008, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 111184, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 149014631894753246485525663021895623833, .parent_padding = 0, .client = 298802811082733066315345031472557842243, .session = 2, .timestamp = 0, .request = 69, .operation = vsr.Operation(141), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 43188566, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 19:32:55.203Z debug(replica): 1N: on_request: new request
2025-12-12 19:32:55.203Z debug(replica): 1N: on_request: ignoring (already preparing)
2025-12-12 19:32:55.203Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.PingClient{ .checksum = 243515121723767034546189595776801758411, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 0, .release = 0.0.1, .protocol = 0, .command = vsr.Command.ping_client, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .client = 298802811082733066315345031472557842243, .ping_timestamp_monotonic = 37683546508950871, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 19:32:55.203Z debug(replica): 1N: sending pong_client to client 298802811082733066315345031472557842243: vsr.message_header.Header.PongClient{ .checksum = 263394325428945562903854761866737980426, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.pong_client, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .ping_timestamp_monotonic = 37683546508950871, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 19:32:55.203Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.headers offset=16384 len=4096 unlocked
2025-12-12 19:32:55.204Z debug(journal): 1: write: view=1 slot=71 op=71 len=111184: 19453193703364400330890009371414682004 complete, marking clean
2025-12-12 19:32:55.204Z debug(replica): 1N: send_prepare_ok: op=71 checksum=19453193703364400330890009371414682004
2025-12-12 19:32:55.204Z debug(replica): 1N: sending prepare_ok to replica 1: vsr.message_header.Header.PrepareOk{ .checksum = 314785925074991411044690475196839521571, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 1, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 220734229818176377738523995150353688483, .parent_padding = 0, .prepare_checksum = 19453193703364400330890009371414682004, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 298802811082733066315345031472557842243, .op = 71, .commit_min = 70, .timestamp = 1765567972514904993, .request = 69, .operation = vsr.Operation(141), .reserved = { 0, 0, 0 } }
2025-12-12 19:32:55.204Z debug(replica): 2n: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 163012970321548452669911212396019818280, .checksum_padding = 0, .checksum_body = 310805550105796871911859957523491538008, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 111184, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 149014631894753246485525663021895623833, .parent_padding = 0, .client = 298802811082733066315345031472557842243, .session = 2, .timestamp = 0, .request = 69, .operation = vsr.Operation(141), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 43188566, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 19:32:55.204Z debug(replica): 2n: on_request: forwarding new request to primary (view=1)
2025-12-12 19:32:55.204Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.PrepareOk{ .checksum = 314785925074991411044690475196839521571, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 1, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 220734229818176377738523995150353688483, .parent_padding = 0, .prepare_checksum = 19453193703364400330890009371414682004, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 298802811082733066315345031472557842243, .op = 71, .commit_min = 70, .timestamp = 1765567972514904993, .request = 69, .operation = vsr.Operation(141), .reserved = { 0, 0, 0 } }
2025-12-12 19:32:55.204Z debug(vsr): 1: primary_abdicate_timeout reset
2025-12-12 19:32:55.204Z debug(replica): 1N: on_prepare_ok: 1 message(s)
2025-12-12 19:32:55.204Z debug(replica): 1N: on_prepare_ok: waiting for quorum
2025-12-12 19:32:55.204Z debug(replica): 2n: sending request to replica 1: vsr.message_header.Header.Request{ .checksum = 163012970321548452669911212396019818280, .checksum_padding = 0, .checksum_body = 310805550105796871911859957523491538008, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 111184, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 149014631894753246485525663021895623833, .parent_padding = 0, .client = 298802811082733066315345031472557842243, .session = 2, .timestamp = 0, .request = 69, .operation = vsr.Operation(141), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 43188566, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 19:32:55.204Z debug(vsr): 1: journal_repair_budget_timeout fired
2025-12-12 19:32:55.204Z debug(vsr): 1: journal_repair_budget_timeout reset
2025-12-12 19:32:55.204Z debug(vsr): 1: journal_repair_timeout fired
2025-12-12 19:32:55.204Z debug(vsr): 1: journal_repair_timeout reset
2025-12-12 19:32:55.204Z debug(replica): 2n: on_message: view=1 status=normal vsr.message_header.Header.PingClient{ .checksum = 243515121723767034546189595776801758411, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 0, .release = 0.0.1, .protocol = 0, .command = vsr.Command.ping_client, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .client = 298802811082733066315345031472557842243, .ping_timestamp_monotonic = 37683546508950871, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 19:32:55.204Z debug(replica): 2n: sending pong_client to client 298802811082733066315345031472557842243: vsr.message_header.Header.PongClient{ .checksum = 23415827500999010506570688613890700073, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.pong_client, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .ping_timestamp_monotonic = 37683546508950871, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 19:32:55.204Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.prepares offset=74448896 len=114688 unlocked
2025-12-12 19:32:55.204Z debug(journal): 2: write_header: op=71 sectors[16384..20480]
2025-12-12 19:32:55.204Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.headers offset=16384 len=4096 locked
2025-12-12 19:32:55.204Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.headers offset=16384 len=4096 unlocked
2025-12-12 19:32:55.204Z debug(journal): 2: write: view=1 slot=71 op=71 len=111184: 19453193703364400330890009371414682004 complete, marking clean
2025-12-12 19:32:55.204Z debug(replica): 2n: send_prepare_ok: op=71 checksum=19453193703364400330890009371414682004
2025-12-12 19:32:55.204Z debug(replica): 2n: sending prepare_ok to replica 1: vsr.message_header.Header.PrepareOk{ .checksum = 247488934777357744095331907969389254315, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 1, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 220734229818176377738523995150353688483, .parent_padding = 0, .prepare_checksum = 19453193703364400330890009371414682004, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 298802811082733066315345031472557842243, .op = 71, .commit_min = 70, .timestamp = 1765567972514904993, .request = 69, .operation = vsr.Operation(141), .reserved = { 0, 0, 0 } }
2025-12-12 19:32:55.204Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 163012970321548452669911212396019818280, .checksum_padding = 0, .checksum_body = 310805550105796871911859957523491538008, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 111184, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 149014631894753246485525663021895623833, .parent_padding = 0, .client = 298802811082733066315345031472557842243, .session = 2, .timestamp = 0, .request = 69, .operation = vsr.Operation(141), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 43188566, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 19:32:55.204Z debug(replica): 1N: on_request: new request
2025-12-12 19:32:55.204Z debug(replica): 1N: on_request: ignoring (already preparing)
2025-12-12 19:32:55.204Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.PrepareOk{ .checksum = 247488934777357744095331907969389254315, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 1, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 220734229818176377738523995150353688483, .parent_padding = 0, .prepare_checksum = 19453193703364400330890009371414682004, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 298802811082733066315345031472557842243, .op = 71, .commit_min = 70, .timestamp = 1765567972514904993, .request = 69, .operation = vsr.Operation(141), .reserved = { 0, 0, 0 } }
2025-12-12 19:32:55.204Z debug(vsr): 1: primary_abdicate_timeout reset
2025-12-12 19:32:55.204Z debug(replica): 1N: on_prepare_ok: 2 message(s)
2025-12-12 19:32:55.204Z debug(replica): 1N: on_prepare_ok: quorum received, context=19453193703364400330890009371414682004
2025-12-12 19:32:55.204Z debug(vsr): 1: prepare_timeout stopped
2025-12-12 19:32:55.204Z debug(vsr): 1: primary_abdicate_timeout stopped
2025-12-12 19:32:55.207Z debug(replica): 1N: execute_op: executing view=1 primary=true op=71 checksum=19453193703364400330890009371414682004 (lookup_transfers)
2025-12-12 19:32:55.207Z debug(replica): 1N: execute_op: commit_timestamp=1765567972470227176 prepare.header.timestamp=1765567972514904993
2025-12-12 19:32:55.208Z debug(replica): 1N: execute_op: advancing commit_max=70..71
2025-12-12 19:32:55.212Z debug(replica): 1N: client_table_entry_update: client=298802811082733066315345031472557842243 session=2 request=69
2025-12-12 19:32:55.212Z debug(replica): 1N: execute_op: replying to client: vsr.message_header.Header.Reply{ .checksum = 105808665973121506007853134581524147786, .checksum_padding = 0, .checksum_body = 58091871924114930895247063570994203325, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 887680, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 163012970321548452669911212396019818280, .request_checksum_padding = 0, .context = 2074998526063554631903105575065041376, .context_padding = 0, .client = 298802811082733066315345031472557842243, .op = 71, .commit = 71, .timestamp = 1765567972514904993, .request = 69, .operation = vsr.Operation(141), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 19:32:55.212Z debug(replica): 1N: sending reply to client 298802811082733066315345031472557842243: vsr.message_header.Header.Reply{ .checksum = 105808665973121506007853134581524147786, .checksum_padding = 0, .checksum_body = 58091871924114930895247063570994203325, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 887680, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 163012970321548452669911212396019818280, .request_checksum_padding = 0, .context = 2074998526063554631903105575065041376, .context_padding = 0, .client = 298802811082733066315345031472557842243, .op = 71, .commit = 71, .timestamp = 1765567972514904993, .request = 69, .operation = vsr.Operation(141), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 19:32:55.212Z debug(forest): entering forest.compact() op=71 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2025-12-12 19:32:55.213Z debug(client_replies): 1: write_reply: wrote (client=298802811082733066315345031472557842243 request=69)
warning(client): 298802811082733066315345031472557842243: on_reply: slow request, request=69 op=71 size=111184 lookup_transfers time=2707ms
2025-12-12 19:32:55.223Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 9616008126838753657814802678784126277, .checksum_padding = 0, .checksum_body = 335087834777102016521472518441542458906, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 1968, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 2074998526063554631903105575065041376, .parent_padding = 0, .client = 298802811082733066315345031472557842243, .session = 2, .timestamp = 0, .request = 70, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 2707938234, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 19:32:55.223Z debug(replica): 1N: on_request: new request
2025-12-12 19:32:55.223Z debug(replica): 1N: primary_pipeline_prepare: request checksum=9616008126838753657814802678784126277 client=298802811082733066315345031472557842243
2025-12-12 19:32:55.223Z debug(replica): 1N: primary_pipeline_prepare: prepare checksum=170196294727647713303824264919866539729 op=72
2025-12-12 19:32:55.223Z debug(vsr): 1: prepare_timeout started
2025-12-12 19:32:55.223Z debug(vsr): 1: primary_abdicate_timeout started
2025-12-12 19:32:55.223Z debug(vsr): 1: pulse_timeout reset
2025-12-12 19:32:55.223Z debug(replica): 1N: replicate: replicating op=72 to replica 0
2025-12-12 19:32:55.223Z debug(replica): 1N: sending prepare to replica 0: vsr.message_header.Header.Prepare{ .checksum = 170196294727647713303824264919866539729, .checksum_padding = 0, .checksum_body = 335087834777102016521472518441542458906, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 1968, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 19453193703364400330890009371414682004, .parent_padding = 0, .request_checksum = 9616008126838753657814802678784126277, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 298802811082733066315345031472557842243, .op = 72, .commit = 71, .timestamp = 1765567975223307295, .request = 70, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-12-12 19:32:55.223Z debug(message_bus): 1: send_message_to_replica: no connection to=0 header=vsr.message_header.Header.Prepare{ .checksum = 170196294727647713303824264919866539729, .checksum_padding = 0, .checksum_body = 335087834777102016521472518441542458906, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 1968, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 19453193703364400330890009371414682004, .parent_padding = 0, .request_checksum = 9616008126838753657814802678784126277, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 298802811082733066315345031472557842243, .op = 72, .commit = 71, .timestamp = 1765567975223307295, .request = 70, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-12-12 19:32:55.223Z debug(replica): 1N: replicate: replicating op=72 to replica 2
2025-12-12 19:32:55.223Z debug(replica): 1N: sending prepare to replica 2: vsr.message_header.Header.Prepare{ .checksum = 170196294727647713303824264919866539729, .checksum_padding = 0, .checksum_body = 335087834777102016521472518441542458906, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 1968, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 19453193703364400330890009371414682004, .parent_padding = 0, .request_checksum = 9616008126838753657814802678784126277, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 298802811082733066315345031472557842243, .op = 72, .commit = 71, .timestamp = 1765567975223307295, .request = 70, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-12-12 19:32:55.223Z debug(replica): 1N: on_prepare: advancing: op=71..72 checksum=19453193703364400330890009371414682004..170196294727647713303824264919866539729
2025-12-12 19:32:55.223Z debug(journal): 1: set_header_as_dirty: op=72 checksum=170196294727647713303824264919866539729
2025-12-12 19:32:55.223Z debug(replica): 1N: append: appending to journal op=72
2025-12-12 19:32:55.223Z debug(journal): 1: write: view=1 slot=72 op=72 len=1968: 170196294727647713303824264919866539729 starting
2025-12-12 19:32:55.223Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.prepares offset=75497472 len=4096 locked
2025-12-12 19:32:55.223Z debug(replica): 2n: on_message: view=1 status=normal vsr.message_header.Header.Prepare{ .checksum = 170196294727647713303824264919866539729, .checksum_padding = 0, .checksum_body = 335087834777102016521472518441542458906, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 1968, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 19453193703364400330890009371414682004, .parent_padding = 0, .request_checksum = 9616008126838753657814802678784126277, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 298802811082733066315345031472557842243, .op = 72, .commit = 71, .timestamp = 1765567975223307295, .request = 70, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-12-12 19:32:55.223Z debug(replica): 2n: on_prepare: advancing commit_max=70..71
2025-12-12 19:32:55.223Z debug(replica): 2n: on_prepare: caching prepare.op=72 (commit_min=70 op=71 commit_max=71 prepare_max=1007)
2025-12-12 19:32:55.223Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.prepares offset=75497472 len=4096 unlocked
2025-12-12 19:32:55.223Z debug(journal): 1: write_header: op=72 sectors[16384..20480]
2025-12-12 19:32:55.223Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.headers offset=16384 len=4096 locked
2025-12-12 19:32:55.223Z debug(replica): 2n: on_prepare: advancing: op=71..72 checksum=19453193703364400330890009371414682004..170196294727647713303824264919866539729
2025-12-12 19:32:55.223Z debug(journal): 2: set_header_as_dirty: op=72 checksum=170196294727647713303824264919866539729
2025-12-12 19:32:55.223Z debug(replica): 2n: append: appending to journal op=72
2025-12-12 19:32:55.223Z debug(journal): 2: write: view=1 slot=72 op=72 len=1968: 170196294727647713303824264919866539729 starting
2025-12-12 19:32:55.223Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.prepares offset=75497472 len=4096 locked
2025-12-12 19:32:55.223Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.headers offset=16384 len=4096 unlocked
2025-12-12 19:32:55.223Z debug(journal): 1: write: view=1 slot=72 op=72 len=1968: 170196294727647713303824264919866539729 complete, marking clean
2025-12-12 19:32:55.223Z debug(replica): 2n: commit_start_journal: cached prepare op=71 checksum=19453193703364400330890009371414682004
2025-12-12 19:32:55.223Z debug(replica): 1N: send_prepare_ok: op=72 checksum=170196294727647713303824264919866539729
2025-12-12 19:32:55.223Z debug(replica): 1N: sending prepare_ok to replica 1: vsr.message_header.Header.PrepareOk{ .checksum = 199023949128380178153777113121512726240, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 1, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 19453193703364400330890009371414682004, .parent_padding = 0, .prepare_checksum = 170196294727647713303824264919866539729, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 298802811082733066315345031472557842243, .op = 72, .commit_min = 71, .timestamp = 1765567975223307295, .request = 70, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-12-12 19:32:55.223Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.PrepareOk{ .checksum = 199023949128380178153777113121512726240, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 1, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 19453193703364400330890009371414682004, .parent_padding = 0, .prepare_checksum = 170196294727647713303824264919866539729, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 298802811082733066315345031472557842243, .op = 72, .commit_min = 71, .timestamp = 1765567975223307295, .request = 70, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-12-12 19:32:55.223Z debug(vsr): 1: primary_abdicate_timeout reset
2025-12-12 19:32:55.223Z debug(replica): 1N: on_prepare_ok: 1 message(s)
2025-12-12 19:32:55.223Z debug(replica): 1N: on_prepare_ok: waiting for quorum
2025-12-12 19:32:55.224Z debug(vsr): 1: journal_repair_budget_timeout fired
2025-12-12 19:32:55.224Z debug(vsr): 1: journal_repair_budget_timeout reset
2025-12-12 19:32:55.225Z debug(replica): 2n: repair_prepare: op=72 checksum=170196294727647713303824264919866539729 (already writing)
2025-12-12 19:32:55.225Z debug(replica): 2n: commit_journal: already committing (prefetch; commit_min=70)
2025-12-12 19:32:55.225Z debug(replica): 2n: execute_op: executing view=1 primary=false op=71 checksum=19453193703364400330890009371414682004 (lookup_transfers)
2025-12-12 19:32:55.225Z debug(replica): 2n: execute_op: commit_timestamp=1765567972470227176 prepare.header.timestamp=1765567972514904993
2025-12-12 19:32:55.230Z debug(replica): 2n: client_table_entry_update: client=298802811082733066315345031472557842243 session=2 request=69
2025-12-12 19:32:55.230Z debug(forest): entering forest.compact() op=71 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2025-12-12 19:32:55.231Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.prepares offset=75497472 len=4096 unlocked
2025-12-12 19:32:55.231Z debug(journal): 2: write_header: op=72 sectors[16384..20480]
2025-12-12 19:32:55.231Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.headers offset=16384 len=4096 locked
2025-12-12 19:32:55.231Z debug(vsr): 2: journal_repair_budget_timeout fired
2025-12-12 19:32:55.231Z debug(vsr): 2: journal_repair_budget_timeout reset
2025-12-12 19:32:55.231Z debug(client_replies): 2: write_reply: wrote (client=298802811082733066315345031472557842243 request=69)
2025-12-12 19:32:55.231Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.headers offset=16384 len=4096 unlocked
2025-12-12 19:32:55.231Z debug(journal): 2: write: view=1 slot=72 op=72 len=1968: 170196294727647713303824264919866539729 complete, marking clean
2025-12-12 19:32:55.231Z debug(replica): 2n: send_prepare_ok: op=72 checksum=170196294727647713303824264919866539729
2025-12-12 19:32:55.231Z debug(replica): 2n: sending prepare_ok to replica 1: vsr.message_header.Header.PrepareOk{ .checksum = 31137781974914786185690905445047502914, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 1, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 19453193703364400330890009371414682004, .parent_padding = 0, .prepare_checksum = 170196294727647713303824264919866539729, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 298802811082733066315345031472557842243, .op = 72, .commit_min = 71, .timestamp = 1765567975223307295, .request = 70, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-12-12 19:32:55.231Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.PrepareOk{ .checksum = 31137781974914786185690905445047502914, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 1, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 19453193703364400330890009371414682004, .parent_padding = 0, .prepare_checksum = 170196294727647713303824264919866539729, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 298802811082733066315345031472557842243, .op = 72, .commit_min = 71, .timestamp = 1765567975223307295, .request = 70, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-12-12 19:32:55.231Z debug(vsr): 1: primary_abdicate_timeout reset
2025-12-12 19:32:55.231Z debug(replica): 1N: on_prepare_ok: 2 message(s)
2025-12-12 19:32:55.231Z debug(replica): 1N: on_prepare_ok: quorum received, context=170196294727647713303824264919866539729
2025-12-12 19:32:55.231Z debug(vsr): 1: prepare_timeout stopped
2025-12-12 19:32:55.231Z debug(vsr): 1: primary_abdicate_timeout stopped
2025-12-12 19:32:55.231Z debug(replica): 1N: execute_op: executing view=1 primary=true op=72 checksum=170196294727647713303824264919866539729 (lookup_accounts)
2025-12-12 19:32:55.231Z debug(replica): 1N: execute_op: commit_timestamp=1765567972514904993 prepare.header.timestamp=1765567975223307295
2025-12-12 19:32:55.231Z debug(replica): 1N: execute_op: advancing commit_max=71..72
2025-12-12 19:32:55.231Z debug(replica): 1N: client_table_entry_update: client=298802811082733066315345031472557842243 session=2 request=70
2025-12-12 19:32:55.231Z debug(replica): 1N: execute_op: replying to client: vsr.message_header.Header.Reply{ .checksum = 291971749904446696090360180251998196356, .checksum_padding = 0, .checksum_body = 93161375402133554763691420682393406203, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 13952, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 9616008126838753657814802678784126277, .request_checksum_padding = 0, .context = 229536658124464336768204169954648478888, .context_padding = 0, .client = 298802811082733066315345031472557842243, .op = 72, .commit = 72, .timestamp = 1765567975223307295, .request = 70, .operation = vsr.Operation(140), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 19:32:55.231Z debug(replica): 1N: sending reply to client 298802811082733066315345031472557842243: vsr.message_header.Header.Reply{ .checksum = 291971749904446696090360180251998196356, .checksum_padding = 0, .checksum_body = 93161375402133554763691420682393406203, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 13952, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 9616008126838753657814802678784126277, .request_checksum_padding = 0, .context = 229536658124464336768204169954648478888, .context_padding = 0, .client = 298802811082733066315345031472557842243, .op = 72, .commit = 72, .timestamp = 1765567975223307295, .request = 70, .operation = vsr.Operation(140), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 19:32:55.231Z debug(forest): entering forest.compact() op=72 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2025-12-12 19:32:55.232Z debug(client_replies): 1: write_reply: wrote (client=298802811082733066315345031472557842243 request=70)
2025-12-12 19:32:55.232Z info(workload): accounts created = 106, transfers = 56418, pending transfers = 0, commands run = 35
2025-12-12 19:32:55.234Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 118792515570606957834534737278580879566, .checksum_padding = 0, .checksum_body = 253002634016144844156061361416318894167, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 132992, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 229536658124464336768204169954648478888, .parent_padding = 0, .client = 298802811082733066315345031472557842243, .session = 2, .timestamp = 0, .request = 71, .operation = vsr.Operation(139), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 9131356, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 19:32:55.234Z debug(replica): 1N: on_request: new request
2025-12-12 19:32:55.234Z debug(replica): 1N: primary_pipeline_prepare: request checksum=118792515570606957834534737278580879566 client=298802811082733066315345031472557842243
2025-12-12 19:32:55.235Z debug(replica): 2n: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 118792515570606957834534737278580879566, .checksum_padding = 0, .checksum_body = 253002634016144844156061361416318894167, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 132992, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 229536658124464336768204169954648478888, .parent_padding = 0, .client = 298802811082733066315345031472557842243, .session = 2, .timestamp = 0, .request = 71, .operation = vsr.Operation(139), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 9131356, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 19:32:55.235Z debug(replica): 2n: on_request: forwarding new request to primary (view=1)
2025-12-12 19:32:55.235Z debug(replica): 2n: sending request to replica 1: vsr.message_header.Header.Request{ .checksum = 118792515570606957834534737278580879566, .checksum_padding = 0, .checksum_body = 253002634016144844156061361416318894167, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 132992, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 229536658124464336768204169954648478888, .parent_padding = 0, .client = 298802811082733066315345031472557842243, .session = 2, .timestamp = 0, .request = 71, .operation = vsr.Operation(139), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 9131356, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 19:32:55.235Z debug(replica): 1N: primary_pipeline_prepare: prepare checksum=41521073241736067107091522209596288573 op=73
2025-12-12 19:32:55.235Z debug(vsr): 1: prepare_timeout started
2025-12-12 19:32:55.235Z debug(vsr): 1: primary_abdicate_timeout started
2025-12-12 19:32:55.235Z debug(vsr): 1: pulse_timeout reset
2025-12-12 19:32:55.235Z debug(replica): 1N: replicate: replicating op=73 to replica 0
2025-12-12 19:32:55.235Z debug(replica): 1N: sending prepare to replica 0: vsr.message_header.Header.Prepare{ .checksum = 41521073241736067107091522209596288573, .checksum_padding = 0, .checksum_body = 253002634016144844156061361416318894167, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 132992, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 170196294727647713303824264919866539729, .parent_padding = 0, .request_checksum = 118792515570606957834534737278580879566, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 298802811082733066315345031472557842243, .op = 73, .commit = 72, .timestamp = 1765567975234960302, .request = 71, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-12-12 19:32:55.235Z debug(message_bus): 1: send_message_to_replica: no connection to=0 header=vsr.message_header.Header.Prepare{ .checksum = 41521073241736067107091522209596288573, .checksum_padding = 0, .checksum_body = 253002634016144844156061361416318894167, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 132992, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 170196294727647713303824264919866539729, .parent_padding = 0, .request_checksum = 118792515570606957834534737278580879566, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 298802811082733066315345031472557842243, .op = 73, .commit = 72, .timestamp = 1765567975234960302, .request = 71, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-12-12 19:32:55.235Z debug(replica): 1N: replicate: replicating op=73 to replica 2
2025-12-12 19:32:55.235Z debug(replica): 1N: sending prepare to replica 2: vsr.message_header.Header.Prepare{ .checksum = 41521073241736067107091522209596288573, .checksum_padding = 0, .checksum_body = 253002634016144844156061361416318894167, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 132992, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 170196294727647713303824264919866539729, .parent_padding = 0, .request_checksum = 118792515570606957834534737278580879566, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 298802811082733066315345031472557842243, .op = 73, .commit = 72, .timestamp = 1765567975234960302, .request = 71, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-12-12 19:32:55.235Z debug(replica): 1N: on_prepare: advancing: op=72..73 checksum=170196294727647713303824264919866539729..41521073241736067107091522209596288573
2025-12-12 19:32:55.235Z debug(journal): 1: set_header_as_dirty: op=73 checksum=41521073241736067107091522209596288573
2025-12-12 19:32:55.235Z debug(replica): 1N: append: appending to journal op=73
2025-12-12 19:32:55.235Z debug(journal): 1: write: view=1 slot=73 op=73 len=132992: 41521073241736067107091522209596288573 starting
2025-12-12 19:32:55.235Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.prepares offset=76546048 len=135168 locked
2025-12-12 19:32:55.236Z debug(replica): 2n: on_message: view=1 status=normal vsr.message_header.Header.Prepare{ .checksum = 41521073241736067107091522209596288573, .checksum_padding = 0, .checksum_body = 253002634016144844156061361416318894167, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 132992, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 170196294727647713303824264919866539729, .parent_padding = 0, .request_checksum = 118792515570606957834534737278580879566, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 298802811082733066315345031472557842243, .op = 73, .commit = 72, .timestamp = 1765567975234960302, .request = 71, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-12-12 19:32:55.236Z debug(replica): 2n: on_prepare: advancing commit_max=71..72
2025-12-12 19:32:55.236Z debug(replica): 2n: on_prepare: caching prepare.op=73 (commit_min=71 op=72 commit_max=72 prepare_max=1007)
2025-12-12 19:32:55.236Z debug(replica): 2n: on_prepare: advancing: op=72..73 checksum=170196294727647713303824264919866539729..41521073241736067107091522209596288573
2025-12-12 19:32:55.236Z debug(journal): 2: set_header_as_dirty: op=73 checksum=41521073241736067107091522209596288573
2025-12-12 19:32:55.236Z debug(replica): 2n: append: appending to journal op=73
2025-12-12 19:32:55.236Z debug(journal): 2: write: view=1 slot=73 op=73 len=132992: 41521073241736067107091522209596288573 starting
2025-12-12 19:32:55.236Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.prepares offset=76546048 len=135168 locked
2025-12-12 19:32:55.236Z debug(replica): 2n: commit_start_journal: cached prepare op=72 checksum=170196294727647713303824264919866539729
2025-12-12 19:32:55.236Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 118792515570606957834534737278580879566, .checksum_padding = 0, .checksum_body = 253002634016144844156061361416318894167, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 132992, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 229536658124464336768204169954648478888, .parent_padding = 0, .client = 298802811082733066315345031472557842243, .session = 2, .timestamp = 0, .request = 71, .operation = vsr.Operation(139), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 9131356, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 19:32:55.236Z debug(replica): 1N: on_request: new request
2025-12-12 19:32:55.236Z debug(replica): 1N: on_request: ignoring (already preparing)
2025-12-12 19:32:55.236Z debug(replica): 2n: repair_prepare: op=73 checksum=41521073241736067107091522209596288573 (already writing)
2025-12-12 19:32:55.236Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.prepares offset=76546048 len=135168 unlocked
2025-12-12 19:32:55.236Z debug(replica): 2n: commit_journal: already committing (prefetch; commit_min=71)
2025-12-12 19:32:55.236Z debug(journal): 1: write_header: op=73 sectors[16384..20480]
2025-12-12 19:32:55.236Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.headers offset=16384 len=4096 locked
2025-12-12 19:32:55.236Z debug(replica): 2n: execute_op: executing view=1 primary=false op=72 checksum=170196294727647713303824264919866539729 (lookup_accounts)
2025-12-12 19:32:55.236Z debug(replica): 2n: execute_op: commit_timestamp=1765567972514904993 prepare.header.timestamp=1765567975223307295
2025-12-12 19:32:55.236Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.headers offset=16384 len=4096 unlocked
2025-12-12 19:32:55.236Z debug(journal): 1: write: view=1 slot=73 op=73 len=132992: 41521073241736067107091522209596288573 complete, marking clean
2025-12-12 19:32:55.236Z debug(replica): 1N: send_prepare_ok: op=73 checksum=41521073241736067107091522209596288573
2025-12-12 19:32:55.236Z debug(replica): 1N: sending prepare_ok to replica 1: vsr.message_header.Header.PrepareOk{ .checksum = 253505017699417065368417729648791529306, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 1, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 170196294727647713303824264919866539729, .parent_padding = 0, .prepare_checksum = 41521073241736067107091522209596288573, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 298802811082733066315345031472557842243, .op = 73, .commit_min = 72, .timestamp = 1765567975234960302, .request = 71, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-12-12 19:32:55.236Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.PrepareOk{ .checksum = 253505017699417065368417729648791529306, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 1, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 170196294727647713303824264919866539729, .parent_padding = 0, .prepare_checksum = 41521073241736067107091522209596288573, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 298802811082733066315345031472557842243, .op = 73, .commit_min = 72, .timestamp = 1765567975234960302, .request = 71, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-12-12 19:32:55.236Z debug(replica): 2n: client_table_entry_update: client=298802811082733066315345031472557842243 session=2 request=70
2025-12-12 19:32:55.236Z debug(vsr): 1: primary_abdicate_timeout reset
2025-12-12 19:32:55.236Z debug(replica): 1N: on_prepare_ok: 1 message(s)
2025-12-12 19:32:55.236Z debug(replica): 1N: on_prepare_ok: waiting for quorum
2025-12-12 19:32:55.236Z debug(replica): 2n: execute_op: replying to client: vsr.message_header.Header.Reply{ .checksum = 291971749904446696090360180251998196356, .checksum_padding = 0, .checksum_body = 93161375402133554763691420682393406203, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 13952, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 9616008126838753657814802678784126277, .request_checksum_padding = 0, .context = 229536658124464336768204169954648478888, .context_padding = 0, .client = 298802811082733066315345031472557842243, .op = 72, .commit = 72, .timestamp = 1765567975223307295, .request = 70, .operation = vsr.Operation(140), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 19:32:55.236Z debug(replica): 2n: sending reply to client 298802811082733066315345031472557842243: vsr.message_header.Header.Reply{ .checksum = 291971749904446696090360180251998196356, .checksum_padding = 0, .checksum_body = 93161375402133554763691420682393406203, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 13952, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 9616008126838753657814802678784126277, .request_checksum_padding = 0, .context = 229536658124464336768204169954648478888, .context_padding = 0, .client = 298802811082733066315345031472557842243, .op = 72, .commit = 72, .timestamp = 1765567975223307295, .request = 70, .operation = vsr.Operation(140), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 19:32:55.236Z debug(forest): entering forest.compact() op=72 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2025-12-12 19:32:55.237Z debug(client_replies): 2: write_reply: wrote (client=298802811082733066315345031472557842243 request=70)
2025-12-12 19:32:55.237Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.prepares offset=76546048 len=135168 unlocked
2025-12-12 19:32:55.237Z debug(journal): 2: write_header: op=73 sectors[16384..20480]
2025-12-12 19:32:55.237Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.headers offset=16384 len=4096 locked
2025-12-12 19:32:55.237Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.headers offset=16384 len=4096 unlocked
2025-12-12 19:32:55.237Z debug(journal): 2: write: view=1 slot=73 op=73 len=132992: 41521073241736067107091522209596288573 complete, marking clean
2025-12-12 19:32:55.237Z debug(replica): 2n: send_prepare_ok: op=73 checksum=41521073241736067107091522209596288573
2025-12-12 19:32:55.237Z debug(replica): 2n: sending prepare_ok to replica 1: vsr.message_header.Header.PrepareOk{ .checksum = 153074271564826544570503364501045602009, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 1, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 170196294727647713303824264919866539729, .parent_padding = 0, .prepare_checksum = 41521073241736067107091522209596288573, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 298802811082733066315345031472557842243, .op = 73, .commit_min = 72, .timestamp = 1765567975234960302, .request = 71, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-12-12 19:32:55.237Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.PrepareOk{ .checksum = 153074271564826544570503364501045602009, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 1, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 170196294727647713303824264919866539729, .parent_padding = 0, .prepare_checksum = 41521073241736067107091522209596288573, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 298802811082733066315345031472557842243, .op = 73, .commit_min = 72, .timestamp = 1765567975234960302, .request = 71, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-12-12 19:32:55.237Z debug(vsr): 1: primary_abdicate_timeout reset
2025-12-12 19:32:55.237Z debug(replica): 1N: on_prepare_ok: 2 message(s)
2025-12-12 19:32:55.237Z debug(replica): 1N: on_prepare_ok: quorum received, context=41521073241736067107091522209596288573
2025-12-12 19:32:55.237Z debug(vsr): 1: prepare_timeout stopped
2025-12-12 19:32:55.237Z debug(vsr): 1: primary_abdicate_timeout stopped
2025-12-12 19:32:55.238Z debug(replica): 1N: execute_op: executing view=1 primary=true op=73 checksum=41521073241736067107091522209596288573 (create_transfers)
2025-12-12 19:32:55.238Z debug(replica): 1N: execute_op: commit_timestamp=1765567975223307295 prepare.header.timestamp=1765567975234960302
2025-12-12 19:32:55.241Z debug(replica): 1N: execute_op: advancing commit_max=72..73
2025-12-12 19:32:55.241Z debug(replica): 1N: client_table_entry_update: client=298802811082733066315345031472557842243 session=2 request=71
2025-12-12 19:32:55.241Z debug(replica): 1N: execute_op: replying to client: vsr.message_header.Header.Reply{ .checksum = 262689735314998785234460294063227179877, .checksum_padding = 0, .checksum_body = 113459958520999273690212120980882356920, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 280, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 118792515570606957834534737278580879566, .request_checksum_padding = 0, .context = 27238481239491138118098985519206992678, .context_padding = 0, .client = 298802811082733066315345031472557842243, .op = 73, .commit = 73, .timestamp = 1765567975234960302, .request = 71, .operation = vsr.Operation(139), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 19:32:55.242Z debug(replica): 1N: sending reply to client 298802811082733066315345031472557842243: vsr.message_header.Header.Reply{ .checksum = 262689735314998785234460294063227179877, .checksum_padding = 0, .checksum_body = 113459958520999273690212120980882356920, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 280, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 118792515570606957834534737278580879566, .request_checksum_padding = 0, .context = 27238481239491138118098985519206992678, .context_padding = 0, .client = 298802811082733066315345031472557842243, .op = 73, .commit = 73, .timestamp = 1765567975234960302, .request = 71, .operation = vsr.Operation(139), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 19:32:55.242Z debug(forest): entering forest.compact() op=73 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2025-12-12 19:32:55.244Z debug(client_replies): 1: write_reply: wrote (client=298802811082733066315345031472557842243 request=71)
2025-12-12 19:32:55.246Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 107398349766854579756207944541071542942, .checksum_padding = 0, .checksum_body = 335087834777102016521472518441542458906, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 1968, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 27238481239491138118098985519206992678, .parent_padding = 0, .client = 298802811082733066315345031472557842243, .session = 2, .timestamp = 0, .request = 72, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 8889358, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 19:32:55.246Z debug(replica): 1N: on_request: new request
2025-12-12 19:32:55.246Z debug(replica): 1N: primary_pipeline_prepare: request checksum=107398349766854579756207944541071542942 client=298802811082733066315345031472557842243
2025-12-12 19:32:55.246Z debug(replica): 1N: primary_pipeline_prepare: prepare checksum=21627880707514499323886975476784525310 op=74
2025-12-12 19:32:55.246Z debug(vsr): 1: prepare_timeout started
2025-12-12 19:32:55.246Z debug(vsr): 1: primary_abdicate_timeout started
2025-12-12 19:32:55.246Z debug(vsr): 1: pulse_timeout reset
2025-12-12 19:32:55.251Z debug(vsr): 2: journal_repair_budget_timeout fired
2025-12-12 19:32:55.273Z warning(faulty_network): connect failed (0,1): error.ConnectionRefused
2025-12-12 19:32:57.735Z debug(vsr): 2: journal_repair_budget_timeout reset
2025-12-12 19:32:57.735Z debug(replica): 1N: replicate: replicating op=74 to replica 0
2025-12-12 19:32:57.735Z debug(vsr): 2: journal_repair_timeout fired
2025-12-12 19:32:57.735Z debug(vsr): 2: journal_repair_timeout reset
2025-12-12 19:32:57.735Z debug(replica): 1N: sending prepare to replica 0: vsr.message_header.Header.Prepare{ .checksum = 21627880707514499323886975476784525310, .checksum_padding = 0, .checksum_body = 335087834777102016521472518441542458906, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 1968, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 41521073241736067107091522209596288573, .parent_padding = 0, .request_checksum = 107398349766854579756207944541071542942, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 298802811082733066315345031472557842243, .op = 74, .commit = 73, .timestamp = 1765567975246588878, .request = 72, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-12-12 19:32:57.735Z debug(message_bus): 1: send_message_to_replica: no connection to=0 header=vsr.message_header.Header.Prepare{ .checksum = 21627880707514499323886975476784525310, .checksum_padding = 0, .checksum_body = 335087834777102016521472518441542458906, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 1968, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 41521073241736067107091522209596288573, .parent_padding = 0, .request_checksum = 107398349766854579756207944541071542942, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 298802811082733066315345031472557842243, .op = 74, .commit = 73, .timestamp = 1765567975246588878, .request = 72, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-12-12 19:32:57.735Z debug(replica): 1N: replicate: replicating op=74 to replica 2
2025-12-12 19:32:57.735Z debug(replica): 1N: sending prepare to replica 2: vsr.message_header.Header.Prepare{ .checksum = 21627880707514499323886975476784525310, .checksum_padding = 0, .checksum_body = 335087834777102016521472518441542458906, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 1968, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 41521073241736067107091522209596288573, .parent_padding = 0, .request_checksum = 107398349766854579756207944541071542942, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 298802811082733066315345031472557842243, .op = 74, .commit = 73, .timestamp = 1765567975246588878, .request = 72, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
warning(message_bus): 298802811082733066315345031472557842243: on_recv: from=vsr.Peer{ .replica = 0 } error.ConnectionResetByPeer
2025-12-12 19:32:57.735Z debug(replica): 1N: on_prepare: advancing: op=73..74 checksum=41521073241736067107091522209596288573..21627880707514499323886975476784525310
2025-12-12 19:32:57.735Z debug(journal): 1: set_header_as_dirty: op=74 checksum=21627880707514499323886975476784525310
2025-12-12 19:32:57.735Z debug(replica): 1N: append: appending to journal op=74
2025-12-12 19:32:57.735Z debug(journal): 1: write: view=1 slot=74 op=74 len=1968: 21627880707514499323886975476784525310 starting
2025-12-12 19:32:57.735Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.prepares offset=77594624 len=4096 locked
2025-12-12 19:32:57.735Z debug(replica): 2n: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 107398349766854579756207944541071542942, .checksum_padding = 0, .checksum_body = 335087834777102016521472518441542458906, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 1968, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 27238481239491138118098985519206992678, .parent_padding = 0, .client = 298802811082733066315345031472557842243, .session = 2, .timestamp = 0, .request = 72, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 8889358, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 19:32:57.735Z info(supervisor): sleeping for 4.455s
2025-12-12 19:32:57.735Z debug(replica): 2n: on_request: forwarding new request to primary (view=1)
2025-12-12 19:32:57.735Z debug(replica): 2n: sending request to replica 1: vsr.message_header.Header.Request{ .checksum = 107398349766854579756207944541071542942, .checksum_padding = 0, .checksum_body = 335087834777102016521472518441542458906, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 1968, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 27238481239491138118098985519206992678, .parent_padding = 0, .client = 298802811082733066315345031472557842243, .session = 2, .timestamp = 0, .request = 72, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 8889358, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 19:32:57.735Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 107398349766854579756207944541071542942, .checksum_padding = 0, .checksum_body = 335087834777102016521472518441542458906, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 1968, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 27238481239491138118098985519206992678, .parent_padding = 0, .client = 298802811082733066315345031472557842243, .session = 2, .timestamp = 0, .request = 72, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 8889358, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 19:32:57.735Z debug(replica): 1N: on_request: new request
2025-12-12 19:32:57.735Z debug(replica): 1N: on_request: ignoring (already preparing)
2025-12-12 19:32:57.735Z debug(replica): 2n: on_message: view=1 status=normal vsr.message_header.Header.Prepare{ .checksum = 21627880707514499323886975476784525310, .checksum_padding = 0, .checksum_body = 335087834777102016521472518441542458906, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 1968, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 41521073241736067107091522209596288573, .parent_padding = 0, .request_checksum = 107398349766854579756207944541071542942, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 298802811082733066315345031472557842243, .op = 74, .commit = 73, .timestamp = 1765567975246588878, .request = 72, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-12-12 19:32:57.735Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.prepares offset=77594624 len=4096 unlocked
2025-12-12 19:32:57.735Z debug(replica): 2n: on_prepare: advancing commit_max=72..73
2025-12-12 19:32:57.735Z debug(replica): 2n: on_prepare: caching prepare.op=74 (commit_min=72 op=73 commit_max=73 prepare_max=1007)
2025-12-12 19:32:57.735Z debug(journal): 1: write_header: op=74 sectors[16384..20480]
2025-12-12 19:32:57.735Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.headers offset=16384 len=4096 locked
2025-12-12 19:32:57.735Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 107398349766854579756207944541071542942, .checksum_padding = 0, .checksum_body = 335087834777102016521472518441542458906, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 1968, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 27238481239491138118098985519206992678, .parent_padding = 0, .client = 298802811082733066315345031472557842243, .session = 2, .timestamp = 0, .request = 72, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 8889358, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 19:32:57.735Z debug(replica): 1N: on_request: new request
2025-12-12 19:32:57.735Z debug(replica): 1N: on_request: ignoring (already preparing)
2025-12-12 19:32:57.735Z debug(replica): 2n: on_prepare: advancing: op=73..74 checksum=41521073241736067107091522209596288573..21627880707514499323886975476784525310
2025-12-12 19:32:57.735Z debug(journal): 2: set_header_as_dirty: op=74 checksum=21627880707514499323886975476784525310
2025-12-12 19:32:57.735Z debug(replica): 2n: append: appending to journal op=74
2025-12-12 19:32:57.735Z debug(journal): 2: write: view=1 slot=74 op=74 len=1968: 21627880707514499323886975476784525310 starting
2025-12-12 19:32:57.735Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.prepares offset=77594624 len=4096 locked
2025-12-12 19:32:57.735Z debug(replica): 2n: commit_start_journal: cached prepare op=73 checksum=41521073241736067107091522209596288573
2025-12-12 19:32:57.735Z debug(vsr): 1: journal_repair_budget_timeout fired
2025-12-12 19:32:57.735Z debug(vsr): 1: journal_repair_budget_timeout reset
2025-12-12 19:32:57.735Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.headers offset=16384 len=4096 unlocked
2025-12-12 19:32:57.735Z debug(journal): 1: write: view=1 slot=74 op=74 len=1968: 21627880707514499323886975476784525310 complete, marking clean
2025-12-12 19:32:57.735Z debug(replica): 1N: send_prepare_ok: op=74 checksum=21627880707514499323886975476784525310
2025-12-12 19:32:57.735Z debug(replica): 1N: sending prepare_ok to replica 1: vsr.message_header.Header.PrepareOk{ .checksum = 67553716431889921915919431204499787212, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 1, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 41521073241736067107091522209596288573, .parent_padding = 0, .prepare_checksum = 21627880707514499323886975476784525310, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 298802811082733066315345031472557842243, .op = 74, .commit_min = 73, .timestamp = 1765567975246588878, .request = 72, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-12-12 19:32:57.735Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.PrepareOk{ .checksum = 67553716431889921915919431204499787212, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 1, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 41521073241736067107091522209596288573, .parent_padding = 0, .prepare_checksum = 21627880707514499323886975476784525310, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 298802811082733066315345031472557842243, .op = 74, .commit_min = 73, .timestamp = 1765567975246588878, .request = 72, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-12-12 19:32:57.735Z debug(vsr): 1: primary_abdicate_timeout reset
2025-12-12 19:32:57.735Z debug(replica): 1N: on_prepare_ok: 1 message(s)
2025-12-12 19:32:57.735Z debug(replica): 1N: on_prepare_ok: waiting for quorum
2025-12-12 19:32:57.736Z debug(replica): 2n: repair_prepare: op=74 checksum=21627880707514499323886975476784525310 (already writing)
2025-12-12 19:32:57.736Z debug(replica): 2n: commit_journal: already committing (prefetch; commit_min=72)
2025-12-12 19:32:57.736Z debug(replica): 2n: execute_op: executing view=1 primary=false op=73 checksum=41521073241736067107091522209596288573 (create_transfers)
2025-12-12 19:32:57.736Z debug(replica): 2n: execute_op: commit_timestamp=1765567975223307295 prepare.header.timestamp=1765567975234960302
2025-12-12 19:32:57.740Z debug(replica): 2n: client_table_entry_update: client=298802811082733066315345031472557842243 session=2 request=71
2025-12-12 19:32:57.740Z debug(forest): entering forest.compact() op=73 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2025-12-12 19:32:57.743Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.prepares offset=77594624 len=4096 unlocked
2025-12-12 19:32:57.743Z debug(journal): 2: write_header: op=74 sectors[16384..20480]
2025-12-12 19:32:57.743Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.headers offset=16384 len=4096 locked
2025-12-12 19:32:57.743Z debug(client_replies): 2: write_reply: wrote (client=298802811082733066315345031472557842243 request=71)
2025-12-12 19:32:57.743Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.headers offset=16384 len=4096 unlocked
2025-12-12 19:32:57.743Z debug(journal): 2: write: view=1 slot=74 op=74 len=1968: 21627880707514499323886975476784525310 complete, marking clean
2025-12-12 19:32:57.743Z debug(replica): 2n: send_prepare_ok: op=74 checksum=21627880707514499323886975476784525310
2025-12-12 19:32:57.743Z debug(replica): 2n: sending prepare_ok to replica 1: vsr.message_header.Header.PrepareOk{ .checksum = 157386641099731289106043411531544952512, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 1, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 41521073241736067107091522209596288573, .parent_padding = 0, .prepare_checksum = 21627880707514499323886975476784525310, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 298802811082733066315345031472557842243, .op = 74, .commit_min = 73, .timestamp = 1765567975246588878, .request = 72, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-12-12 19:32:57.743Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.PrepareOk{ .checksum = 157386641099731289106043411531544952512, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 1, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 41521073241736067107091522209596288573, .parent_padding = 0, .prepare_checksum = 21627880707514499323886975476784525310, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 298802811082733066315345031472557842243, .op = 74, .commit_min = 73, .timestamp = 1765567975246588878, .request = 72, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-12-12 19:32:57.743Z debug(vsr): 1: primary_abdicate_timeout reset
2025-12-12 19:32:57.743Z debug(replica): 1N: on_prepare_ok: 2 message(s)
2025-12-12 19:32:57.743Z debug(replica): 1N: on_prepare_ok: quorum received, context=21627880707514499323886975476784525310
2025-12-12 19:32:57.743Z debug(vsr): 1: prepare_timeout stopped
2025-12-12 19:32:57.743Z debug(vsr): 1: primary_abdicate_timeout stopped
2025-12-12 19:32:57.743Z debug(replica): 1N: execute_op: executing view=1 primary=true op=74 checksum=21627880707514499323886975476784525310 (lookup_accounts)
2025-12-12 19:32:57.743Z debug(replica): 1N: execute_op: commit_timestamp=1765567975234960302 prepare.header.timestamp=1765567975246588878
2025-12-12 19:32:57.743Z debug(replica): 1N: execute_op: advancing commit_max=73..74
2025-12-12 19:32:57.743Z debug(replica): 1N: client_table_entry_update: client=298802811082733066315345031472557842243 session=2 request=72
2025-12-12 19:32:57.743Z debug(replica): 1N: execute_op: replying to client: vsr.message_header.Header.Reply{ .checksum = 16720434905771296807096561059681256293, .checksum_padding = 0, .checksum_body = 26452712830821830728989572728320080443, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 13952, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 107398349766854579756207944541071542942, .request_checksum_padding = 0, .context = 172933680987970862415041324501233496757, .context_padding = 0, .client = 298802811082733066315345031472557842243, .op = 74, .commit = 74, .timestamp = 1765567975246588878, .request = 72, .operation = vsr.Operation(140), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 19:32:57.743Z debug(replica): 1N: sending reply to client 298802811082733066315345031472557842243: vsr.message_header.Header.Reply{ .checksum = 16720434905771296807096561059681256293, .checksum_padding = 0, .checksum_body = 26452712830821830728989572728320080443, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 13952, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 107398349766854579756207944541071542942, .request_checksum_padding = 0, .context = 172933680987970862415041324501233496757, .context_padding = 0, .client = 298802811082733066315345031472557842243, .op = 74, .commit = 74, .timestamp = 1765567975246588878, .request = 72, .operation = vsr.Operation(140), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 19:32:57.744Z debug(forest): entering forest.compact() op=74 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
warning(client): 298802811082733066315345031472557842243: on_reply: slow request, request=72 op=74 size=1968 lookup_accounts time=2497ms
2025-12-12 19:32:57.744Z debug(client_replies): 1: write_reply: wrote (client=298802811082733066315345031472557842243 request=72)
2025-12-12 19:32:57.744Z info(workload): accounts created = 106, transfers = 57454, pending transfers = 0, commands run = 36
2025-12-12 19:32:57.755Z debug(vsr): 2: journal_repair_budget_timeout fired
2025-12-12 19:32:57.755Z debug(vsr): 2: journal_repair_budget_timeout reset
2025-12-12 19:32:57.759Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 198055145912486397690085632690373462909, .checksum_padding = 0, .checksum_body = 58486254979743657688735198079989346573, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 940032, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 172933680987970862415041324501233496757, .parent_padding = 0, .client = 298802811082733066315345031472557842243, .session = 2, .timestamp = 0, .request = 73, .operation = vsr.Operation(139), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 2497862672, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 19:32:57.759Z debug(replica): 1N: on_request: new request
2025-12-12 19:32:57.759Z debug(replica): 1N: primary_pipeline_prepare: request checksum=198055145912486397690085632690373462909 client=298802811082733066315345031472557842243
2025-12-12 19:32:57.763Z debug(replica): 1N: primary_pipeline_prepare: prepare checksum=166754955310077275321167839203233759374 op=75
2025-12-12 19:32:57.763Z debug(vsr): 1: prepare_timeout started
2025-12-12 19:32:57.763Z debug(vsr): 1: primary_abdicate_timeout started
2025-12-12 19:32:57.763Z debug(vsr): 1: pulse_timeout reset
2025-12-12 19:32:57.763Z debug(replica): 1N: replicate: replicating op=75 to replica 0
2025-12-12 19:32:57.763Z debug(replica): 1N: sending prepare to replica 0: vsr.message_header.Header.Prepare{ .checksum = 166754955310077275321167839203233759374, .checksum_padding = 0, .checksum_body = 58486254979743657688735198079989346573, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 940032, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 21627880707514499323886975476784525310, .parent_padding = 0, .request_checksum = 198055145912486397690085632690373462909, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 298802811082733066315345031472557842243, .op = 75, .commit = 74, .timestamp = 1765567977759265854, .request = 73, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-12-12 19:32:57.763Z debug(message_bus): 1: send_message_to_replica: no connection to=0 header=vsr.message_header.Header.Prepare{ .checksum = 166754955310077275321167839203233759374, .checksum_padding = 0, .checksum_body = 58486254979743657688735198079989346573, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 940032, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 21627880707514499323886975476784525310, .parent_padding = 0, .request_checksum = 198055145912486397690085632690373462909, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 298802811082733066315345031472557842243, .op = 75, .commit = 74, .timestamp = 1765567977759265854, .request = 73, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-12-12 19:32:57.763Z debug(replica): 1N: replicate: replicating op=75 to replica 2
2025-12-12 19:32:57.763Z debug(replica): 1N: sending prepare to replica 2: vsr.message_header.Header.Prepare{ .checksum = 166754955310077275321167839203233759374, .checksum_padding = 0, .checksum_body = 58486254979743657688735198079989346573, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 940032, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 21627880707514499323886975476784525310, .parent_padding = 0, .request_checksum = 198055145912486397690085632690373462909, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 298802811082733066315345031472557842243, .op = 75, .commit = 74, .timestamp = 1765567977759265854, .request = 73, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-12-12 19:32:57.763Z debug(replica): 1N: on_prepare: advancing: op=74..75 checksum=21627880707514499323886975476784525310..166754955310077275321167839203233759374
2025-12-12 19:32:57.763Z debug(journal): 1: set_header_as_dirty: op=75 checksum=166754955310077275321167839203233759374
2025-12-12 19:32:57.763Z debug(replica): 1N: append: appending to journal op=75
2025-12-12 19:32:57.763Z debug(journal): 1: write: view=1 slot=75 op=75 len=940032: 166754955310077275321167839203233759374 starting
2025-12-12 19:32:57.763Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.prepares offset=78643200 len=942080 locked
2025-12-12 19:32:57.764Z debug(vsr): 1: journal_repair_budget_timeout fired
2025-12-12 19:32:57.764Z debug(vsr): 1: journal_repair_budget_timeout reset
2025-12-12 19:32:57.764Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.prepares offset=78643200 len=942080 unlocked
2025-12-12 19:32:57.764Z debug(journal): 1: write_header: op=75 sectors[16384..20480]
2025-12-12 19:32:57.764Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.headers offset=16384 len=4096 locked
2025-12-12 19:32:57.764Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.headers offset=16384 len=4096 unlocked
2025-12-12 19:32:57.764Z debug(journal): 1: write: view=1 slot=75 op=75 len=940032: 166754955310077275321167839203233759374 complete, marking clean
2025-12-12 19:32:57.764Z debug(replica): 1N: send_prepare_ok: op=75 checksum=166754955310077275321167839203233759374
2025-12-12 19:32:57.764Z debug(replica): 1N: sending prepare_ok to replica 1: vsr.message_header.Header.PrepareOk{ .checksum = 81254015493845249841770711649454450410, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 1, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 21627880707514499323886975476784525310, .parent_padding = 0, .prepare_checksum = 166754955310077275321167839203233759374, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 298802811082733066315345031472557842243, .op = 75, .commit_min = 74, .timestamp = 1765567977759265854, .request = 73, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-12-12 19:32:57.764Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.PrepareOk{ .checksum = 81254015493845249841770711649454450410, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 1, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 21627880707514499323886975476784525310, .parent_padding = 0, .prepare_checksum = 166754955310077275321167839203233759374, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 298802811082733066315345031472557842243, .op = 75, .commit_min = 74, .timestamp = 1765567977759265854, .request = 73, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-12-12 19:32:57.764Z debug(vsr): 1: primary_abdicate_timeout reset
2025-12-12 19:32:57.764Z debug(replica): 1N: on_prepare_ok: 1 message(s)
2025-12-12 19:32:57.764Z debug(replica): 1N: on_prepare_ok: waiting for quorum
2025-12-12 19:32:57.768Z debug(replica): 2n: on_message: view=1 status=normal vsr.message_header.Header.Prepare{ .checksum = 166754955310077275321167839203233759374, .checksum_padding = 0, .checksum_body = 58486254979743657688735198079989346573, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 940032, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 21627880707514499323886975476784525310, .parent_padding = 0, .request_checksum = 198055145912486397690085632690373462909, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 298802811082733066315345031472557842243, .op = 75, .commit = 74, .timestamp = 1765567977759265854, .request = 73, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-12-12 19:32:57.768Z debug(replica): 2n: on_prepare: advancing commit_max=73..74
2025-12-12 19:32:57.768Z debug(replica): 2n: on_prepare: caching prepare.op=75 (commit_min=73 op=74 commit_max=74 prepare_max=1007)
2025-12-12 19:32:57.768Z debug(replica): 2n: on_prepare: advancing: op=74..75 checksum=21627880707514499323886975476784525310..166754955310077275321167839203233759374
2025-12-12 19:32:57.768Z debug(journal): 2: set_header_as_dirty: op=75 checksum=166754955310077275321167839203233759374
2025-12-12 19:32:57.768Z debug(replica): 2n: append: appending to journal op=75
2025-12-12 19:32:57.768Z debug(journal): 2: write: view=1 slot=75 op=75 len=940032: 166754955310077275321167839203233759374 starting
2025-12-12 19:32:57.768Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.prepares offset=78643200 len=942080 locked
2025-12-12 19:32:57.768Z debug(replica): 2n: commit_start_journal: cached prepare op=74 checksum=21627880707514499323886975476784525310
2025-12-12 19:32:57.768Z debug(replica): 2n: repair_prepare: op=75 checksum=166754955310077275321167839203233759374 (already writing)
2025-12-12 19:32:57.768Z debug(replica): 2n: commit_journal: already committing (prefetch; commit_min=73)
2025-12-12 19:32:57.768Z debug(replica): 2n: execute_op: executing view=1 primary=false op=74 checksum=21627880707514499323886975476784525310 (lookup_accounts)
2025-12-12 19:32:57.768Z debug(replica): 2n: execute_op: commit_timestamp=1765567975234960302 prepare.header.timestamp=1765567975246588878
2025-12-12 19:32:57.768Z debug(replica): 2n: client_table_entry_update: client=298802811082733066315345031472557842243 session=2 request=72
2025-12-12 19:32:57.768Z debug(forest): entering forest.compact() op=74 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2025-12-12 19:32:57.769Z debug(client_replies): 2: write_reply: wrote (client=298802811082733066315345031472557842243 request=72)
2025-12-12 19:32:57.769Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.prepares offset=78643200 len=942080 unlocked
2025-12-12 19:32:57.769Z debug(journal): 2: write_header: op=75 sectors[16384..20480]
2025-12-12 19:32:57.769Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.headers offset=16384 len=4096 locked
2025-12-12 19:32:57.769Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.headers offset=16384 len=4096 unlocked
2025-12-12 19:32:57.769Z debug(journal): 2: write: view=1 slot=75 op=75 len=940032: 166754955310077275321167839203233759374 complete, marking clean
2025-12-12 19:32:57.769Z debug(replica): 2n: send_prepare_ok: op=75 checksum=166754955310077275321167839203233759374
2025-12-12 19:32:57.769Z debug(replica): 2n: sending prepare_ok to replica 1: vsr.message_header.Header.PrepareOk{ .checksum = 300587522123080392829839010676141863284, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 1, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 21627880707514499323886975476784525310, .parent_padding = 0, .prepare_checksum = 166754955310077275321167839203233759374, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 298802811082733066315345031472557842243, .op = 75, .commit_min = 74, .timestamp = 1765567977759265854, .request = 73, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-12-12 19:32:57.769Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.PrepareOk{ .checksum = 300587522123080392829839010676141863284, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 1, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 21627880707514499323886975476784525310, .parent_padding = 0, .prepare_checksum = 166754955310077275321167839203233759374, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 298802811082733066315345031472557842243, .op = 75, .commit_min = 74, .timestamp = 1765567977759265854, .request = 73, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-12-12 19:32:57.769Z debug(vsr): 1: primary_abdicate_timeout reset
2025-12-12 19:32:57.769Z debug(replica): 1N: on_prepare_ok: 2 message(s)
2025-12-12 19:32:57.769Z debug(replica): 1N: on_prepare_ok: quorum received, context=166754955310077275321167839203233759374
2025-12-12 19:32:57.769Z debug(vsr): 1: prepare_timeout stopped
2025-12-12 19:32:57.769Z debug(vsr): 1: primary_abdicate_timeout stopped
2025-12-12 19:32:57.774Z debug(replica): 1N: execute_op: executing view=1 primary=true op=75 checksum=166754955310077275321167839203233759374 (create_transfers)
2025-12-12 19:32:57.774Z debug(replica): 1N: execute_op: commit_timestamp=1765567975246588878 prepare.header.timestamp=1765567977759265854
2025-12-12 19:32:57.779Z debug(vsr): 2: journal_repair_budget_timeout fired
2025-12-12 19:32:57.779Z debug(vsr): 2: journal_repair_budget_timeout reset
2025-12-12 19:32:57.799Z debug(vsr): 2: journal_repair_budget_timeout fired
2025-12-12 19:32:57.799Z debug(vsr): 2: journal_repair_budget_timeout reset
2025-12-12 19:32:57.802Z debug(replica): 1N: execute_op: advancing commit_max=74..75
2025-12-12 19:32:57.802Z debug(replica): 1N: client_table_entry_update: client=298802811082733066315345031472557842243 session=2 request=73
2025-12-12 19:32:57.802Z debug(replica): 1N: execute_op: replying to client: vsr.message_header.Header.Reply{ .checksum = 261620983172755341381200186536341242930, .checksum_padding = 0, .checksum_body = 240600056039427149320455259237371945566, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 376, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 198055145912486397690085632690373462909, .request_checksum_padding = 0, .context = 106577395012020414166669968530796511210, .context_padding = 0, .client = 298802811082733066315345031472557842243, .op = 75, .commit = 75, .timestamp = 1765567977759265854, .request = 73, .operation = vsr.Operation(139), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 19:32:57.802Z debug(replica): 1N: sending reply to client 298802811082733066315345031472557842243: vsr.message_header.Header.Reply{ .checksum = 261620983172755341381200186536341242930, .checksum_padding = 0, .checksum_body = 240600056039427149320455259237371945566, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 376, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 198055145912486397690085632690373462909, .request_checksum_padding = 0, .context = 106577395012020414166669968530796511210, .context_padding = 0, .client = 298802811082733066315345031472557842243, .op = 75, .commit = 75, .timestamp = 1765567977759265854, .request = 73, .operation = vsr.Operation(139), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 19:32:57.802Z debug(forest): entering forest.compact() op=75 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2025-12-12 19:32:57.817Z debug(client_replies): 1: write_reply: wrote (client=298802811082733066315345031472557842243 request=73)
2025-12-12 19:32:57.819Z debug(vsr): 2: journal_repair_budget_timeout fired
2025-12-12 19:32:57.819Z debug(vsr): 2: journal_repair_budget_timeout reset
2025-12-12 19:32:57.827Z debug(vsr): 1: journal_repair_budget_timeout fired
2025-12-12 19:32:57.827Z debug(vsr): 1: journal_repair_budget_timeout reset
2025-12-12 19:32:57.830Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 48554701213020936824831793686197591354, .checksum_padding = 0, .checksum_body = 335087834777102016521472518441542458906, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 1968, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 106577395012020414166669968530796511210, .parent_padding = 0, .client = 298802811082733066315345031472557842243, .session = 2, .timestamp = 0, .request = 74, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 52401471, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 19:32:57.830Z debug(replica): 2n: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 48554701213020936824831793686197591354, .checksum_padding = 0, .checksum_body = 335087834777102016521472518441542458906, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 1968, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 106577395012020414166669968530796511210, .parent_padding = 0, .client = 298802811082733066315345031472557842243, .session = 2, .timestamp = 0, .request = 74, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 52401471, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 19:32:57.830Z debug(replica): 2n: on_request: forwarding new request to primary (view=1)
2025-12-12 19:32:57.830Z debug(replica): 1N: on_request: new request
2025-12-12 19:32:57.830Z debug(replica): 1N: primary_pipeline_prepare: request checksum=48554701213020936824831793686197591354 client=298802811082733066315345031472557842243
2025-12-12 19:32:57.830Z debug(replica): 2n: sending request to replica 1: vsr.message_header.Header.Request{ .checksum = 48554701213020936824831793686197591354, .checksum_padding = 0, .checksum_body = 335087834777102016521472518441542458906, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 1968, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 106577395012020414166669968530796511210, .parent_padding = 0, .client = 298802811082733066315345031472557842243, .session = 2, .timestamp = 0, .request = 74, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 52401471, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 19:32:57.830Z debug(replica): 1N: primary_pipeline_prepare: prepare checksum=227017562941974017127234289375656335088 op=76
2025-12-12 19:32:57.830Z debug(vsr): 1: prepare_timeout started
2025-12-12 19:32:57.830Z debug(vsr): 1: primary_abdicate_timeout started
2025-12-12 19:32:57.830Z debug(vsr): 1: pulse_timeout reset
2025-12-12 19:32:57.830Z debug(replica): 1N: replicate: replicating op=76 to replica 0
2025-12-12 19:32:57.830Z debug(replica): 1N: sending prepare to replica 0: vsr.message_header.Header.Prepare{ .checksum = 227017562941974017127234289375656335088, .checksum_padding = 0, .checksum_body = 335087834777102016521472518441542458906, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 1968, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 166754955310077275321167839203233759374, .parent_padding = 0, .request_checksum = 48554701213020936824831793686197591354, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 298802811082733066315345031472557842243, .op = 76, .commit = 75, .timestamp = 1765567977830204445, .request = 74, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-12-12 19:32:57.830Z debug(message_bus): 1: send_message_to_replica: no connection to=0 header=vsr.message_header.Header.Prepare{ .checksum = 227017562941974017127234289375656335088, .checksum_padding = 0, .checksum_body = 335087834777102016521472518441542458906, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 1968, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 166754955310077275321167839203233759374, .parent_padding = 0, .request_checksum = 48554701213020936824831793686197591354, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 298802811082733066315345031472557842243, .op = 76, .commit = 75, .timestamp = 1765567977830204445, .request = 74, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-12-12 19:32:57.830Z debug(replica): 1N: replicate: replicating op=76 to replica 2
2025-12-12 19:32:57.830Z debug(replica): 1N: sending prepare to replica 2: vsr.message_header.Header.Prepare{ .checksum = 227017562941974017127234289375656335088, .checksum_padding = 0, .checksum_body = 335087834777102016521472518441542458906, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 1968, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 166754955310077275321167839203233759374, .parent_padding = 0, .request_checksum = 48554701213020936824831793686197591354, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 298802811082733066315345031472557842243, .op = 76, .commit = 75, .timestamp = 1765567977830204445, .request = 74, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-12-12 19:32:57.830Z debug(replica): 1N: on_prepare: advancing: op=75..76 checksum=166754955310077275321167839203233759374..227017562941974017127234289375656335088
2025-12-12 19:32:57.830Z debug(journal): 1: set_header_as_dirty: op=76 checksum=227017562941974017127234289375656335088
2025-12-12 19:32:57.830Z debug(replica): 1N: append: appending to journal op=76
2025-12-12 19:32:57.830Z debug(journal): 1: write: view=1 slot=76 op=76 len=1968: 227017562941974017127234289375656335088 starting
2025-12-12 19:32:57.830Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.prepares offset=79691776 len=4096 locked
2025-12-12 19:32:57.830Z debug(replica): 2n: on_message: view=1 status=normal vsr.message_header.Header.Prepare{ .checksum = 227017562941974017127234289375656335088, .checksum_padding = 0, .checksum_body = 335087834777102016521472518441542458906, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 1968, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 166754955310077275321167839203233759374, .parent_padding = 0, .request_checksum = 48554701213020936824831793686197591354, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 298802811082733066315345031472557842243, .op = 76, .commit = 75, .timestamp = 1765567977830204445, .request = 74, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-12-12 19:32:57.830Z debug(replica): 2n: on_prepare: advancing commit_max=74..75
2025-12-12 19:32:57.830Z debug(replica): 2n: on_prepare: caching prepare.op=76 (commit_min=74 op=75 commit_max=75 prepare_max=1007)
2025-12-12 19:32:57.830Z debug(replica): 2n: on_prepare: advancing: op=75..76 checksum=166754955310077275321167839203233759374..227017562941974017127234289375656335088
2025-12-12 19:32:57.830Z debug(journal): 2: set_header_as_dirty: op=76 checksum=227017562941974017127234289375656335088
2025-12-12 19:32:57.830Z debug(replica): 2n: append: appending to journal op=76
2025-12-12 19:32:57.830Z debug(journal): 2: write: view=1 slot=76 op=76 len=1968: 227017562941974017127234289375656335088 starting
2025-12-12 19:32:57.830Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.prepares offset=79691776 len=4096 locked
2025-12-12 19:32:57.830Z debug(replica): 2n: commit_start_journal: cached prepare op=75 checksum=166754955310077275321167839203233759374
2025-12-12 19:32:57.830Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 48554701213020936824831793686197591354, .checksum_padding = 0, .checksum_body = 335087834777102016521472518441542458906, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 1968, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 106577395012020414166669968530796511210, .parent_padding = 0, .client = 298802811082733066315345031472557842243, .session = 2, .timestamp = 0, .request = 74, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 52401471, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 19:32:57.830Z debug(replica): 1N: on_request: new request
2025-12-12 19:32:57.830Z debug(replica): 1N: on_request: ignoring (already preparing)
2025-12-12 19:32:57.830Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.prepares offset=79691776 len=4096 unlocked
2025-12-12 19:32:57.830Z debug(journal): 1: write_header: op=76 sectors[16384..20480]
2025-12-12 19:32:57.830Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.headers offset=16384 len=4096 locked
2025-12-12 19:32:57.830Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.headers offset=16384 len=4096 unlocked
2025-12-12 19:32:57.830Z debug(journal): 1: write: view=1 slot=76 op=76 len=1968: 227017562941974017127234289375656335088 complete, marking clean
2025-12-12 19:32:57.830Z debug(replica): 1N: send_prepare_ok: op=76 checksum=227017562941974017127234289375656335088
2025-12-12 19:32:57.830Z debug(replica): 1N: sending prepare_ok to replica 1: vsr.message_header.Header.PrepareOk{ .checksum = 112318454075674448363453141777422288201, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 1, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 166754955310077275321167839203233759374, .parent_padding = 0, .prepare_checksum = 227017562941974017127234289375656335088, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 298802811082733066315345031472557842243, .op = 76, .commit_min = 75, .timestamp = 1765567977830204445, .request = 74, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-12-12 19:32:57.830Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.PrepareOk{ .checksum = 112318454075674448363453141777422288201, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 1, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 166754955310077275321167839203233759374, .parent_padding = 0, .prepare_checksum = 227017562941974017127234289375656335088, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 298802811082733066315345031472557842243, .op = 76, .commit_min = 75, .timestamp = 1765567977830204445, .request = 74, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-12-12 19:32:57.830Z debug(vsr): 1: primary_abdicate_timeout reset
2025-12-12 19:32:57.830Z debug(replica): 1N: on_prepare_ok: 1 message(s)
2025-12-12 19:32:57.830Z debug(replica): 1N: on_prepare_ok: waiting for quorum
2025-12-12 19:32:57.832Z debug(replica): 2n: repair_prepare: op=76 checksum=227017562941974017127234289375656335088 (already writing)
2025-12-12 19:32:57.832Z debug(replica): 2n: commit_journal: already committing (prefetch; commit_min=74)
2025-12-12 19:32:57.834Z debug(replica): 2n: execute_op: executing view=1 primary=false op=75 checksum=166754955310077275321167839203233759374 (create_transfers)
2025-12-12 19:32:57.834Z debug(replica): 2n: execute_op: commit_timestamp=1765567975246588878 prepare.header.timestamp=1765567977759265854
2025-12-12 19:32:57.835Z warning(faulty_network): connect failed (0,2): error.ConnectionRefused
warning(message_bus): 298802811082733066315345031472557842243: on_recv: from=vsr.Peer{ .replica = 0 } error.ConnectionResetByPeer
2025-12-12 19:32:57.847Z debug(vsr): 1: journal_repair_budget_timeout fired
2025-12-12 19:32:57.847Z debug(vsr): 1: journal_repair_budget_timeout reset
2025-12-12 19:32:57.847Z debug(vsr): 1: journal_repair_timeout fired
2025-12-12 19:32:57.847Z debug(vsr): 1: journal_repair_timeout reset
2025-12-12 19:32:57.861Z debug(replica): 2n: client_table_entry_update: client=298802811082733066315345031472557842243 session=2 request=73
2025-12-12 19:32:57.861Z debug(forest): entering forest.compact() op=75 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2025-12-12 19:32:57.867Z debug(vsr): 1: journal_repair_budget_timeout fired
2025-12-12 19:32:57.867Z debug(vsr): 1: journal_repair_budget_timeout reset
2025-12-12 19:32:57.876Z debug(vsr): 2: journal_repair_budget_timeout fired
2025-12-12 19:32:57.876Z debug(vsr): 2: journal_repair_budget_timeout reset
2025-12-12 19:32:57.876Z debug(vsr): 2: journal_repair_timeout fired
2025-12-12 19:32:57.876Z debug(vsr): 2: journal_repair_timeout reset
2025-12-12 19:32:57.876Z debug(replica): 2n: repair_prepare: op=76 checksum=227017562941974017127234289375656335088 (already writing)
2025-12-12 19:32:57.876Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.prepares offset=79691776 len=4096 unlocked
2025-12-12 19:32:57.876Z debug(journal): 2: write_header: op=76 sectors[16384..20480]
2025-12-12 19:32:57.876Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.headers offset=16384 len=4096 locked
2025-12-12 19:32:57.876Z debug(client_replies): 2: write_reply: wrote (client=298802811082733066315345031472557842243 request=73)
2025-12-12 19:32:57.877Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.headers offset=16384 len=4096 unlocked
2025-12-12 19:32:57.877Z debug(journal): 2: write: view=1 slot=76 op=76 len=1968: 227017562941974017127234289375656335088 complete, marking clean
2025-12-12 19:32:57.877Z debug(replica): 2n: send_prepare_ok: op=76 checksum=227017562941974017127234289375656335088
2025-12-12 19:32:57.877Z debug(replica): 2n: sending prepare_ok to replica 1: vsr.message_header.Header.PrepareOk{ .checksum = 113174793119781940810884324305913914507, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 1, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 166754955310077275321167839203233759374, .parent_padding = 0, .prepare_checksum = 227017562941974017127234289375656335088, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 298802811082733066315345031472557842243, .op = 76, .commit_min = 75, .timestamp = 1765567977830204445, .request = 74, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-12-12 19:32:57.877Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.PrepareOk{ .checksum = 113174793119781940810884324305913914507, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 1, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 166754955310077275321167839203233759374, .parent_padding = 0, .prepare_checksum = 227017562941974017127234289375656335088, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 298802811082733066315345031472557842243, .op = 76, .commit_min = 75, .timestamp = 1765567977830204445, .request = 74, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-12-12 19:32:57.877Z debug(vsr): 1: primary_abdicate_timeout reset
2025-12-12 19:32:57.877Z debug(replica): 1N: on_prepare_ok: 2 message(s)
2025-12-12 19:32:57.877Z debug(replica): 1N: on_prepare_ok: quorum received, context=227017562941974017127234289375656335088
2025-12-12 19:32:57.877Z debug(vsr): 1: prepare_timeout stopped
2025-12-12 19:32:57.877Z debug(vsr): 1: primary_abdicate_timeout stopped
2025-12-12 19:32:57.877Z debug(replica): 1N: execute_op: executing view=1 primary=true op=76 checksum=227017562941974017127234289375656335088 (lookup_accounts)
2025-12-12 19:32:57.877Z debug(replica): 1N: execute_op: commit_timestamp=1765567977759265854 prepare.header.timestamp=1765567977830204445
2025-12-12 19:32:57.877Z debug(replica): 1N: execute_op: advancing commit_max=75..76
2025-12-12 19:32:57.877Z debug(replica): 1N: client_table_entry_update: client=298802811082733066315345031472557842243 session=2 request=74
2025-12-12 19:32:57.877Z debug(replica): 1N: execute_op: replying to client: vsr.message_header.Header.Reply{ .checksum = 194676854614920296324478611195080740139, .checksum_padding = 0, .checksum_body = 85553860524249846294771922562271274299, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 13952, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 48554701213020936824831793686197591354, .request_checksum_padding = 0, .context = 337109595689299129151409809149989579498, .context_padding = 0, .client = 298802811082733066315345031472557842243, .op = 76, .commit = 76, .timestamp = 1765567977830204445, .request = 74, .operation = vsr.Operation(140), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 19:32:57.877Z debug(replica): 1N: sending reply to client 298802811082733066315345031472557842243: vsr.message_header.Header.Reply{ .checksum = 194676854614920296324478611195080740139, .checksum_padding = 0, .checksum_body = 85553860524249846294771922562271274299, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 13952, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 48554701213020936824831793686197591354, .request_checksum_padding = 0, .context = 337109595689299129151409809149989579498, .context_padding = 0, .client = 298802811082733066315345031472557842243, .op = 76, .commit = 76, .timestamp = 1765567977830204445, .request = 74, .operation = vsr.Operation(140), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 19:32:57.877Z debug(forest): entering forest.compact() op=76 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2025-12-12 19:32:57.878Z debug(client_replies): 1: write_reply: wrote (client=298802811082733066315345031472557842243 request=74)
2025-12-12 19:32:57.878Z info(workload): accounts created = 106, transfers = 64795, pending transfers = 0, commands run = 37
2025-12-12 19:32:57.888Z debug(vsr): 1: journal_repair_budget_timeout fired
2025-12-12 19:32:57.888Z debug(vsr): 1: journal_repair_budget_timeout reset
2025-12-12 19:32:57.896Z debug(replica): 2n: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 16037302979060692649990508405715316506, .checksum_padding = 0, .checksum_body = 88187512808688459248792857380290978596, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 951296, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 337109595689299129151409809149989579498, .parent_padding = 0, .client = 298802811082733066315345031472557842243, .session = 2, .timestamp = 0, .request = 75, .operation = vsr.Operation(139), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 48008687, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 19:32:57.896Z debug(replica): 2n: on_request: forwarding new request to primary (view=1)
2025-12-12 19:32:57.941Z warning(faulty_network): connect failed (0,3): error.ConnectionRefused
2025-12-12 19:32:58.034Z warning(faulty_network): connect failed (0,4): error.ConnectionRefused
2025-12-12 19:32:58.135Z warning(faulty_network): connect failed (0,5): error.ConnectionRefused
2025-12-12 19:32:58.228Z warning(faulty_network): connect failed (0,6): error.ConnectionRefused
2025-12-12 19:32:58.299Z warning(faulty_network): connect failed (0,7): error.ConnectionRefused
2025-12-12 19:32:58.398Z warning(faulty_network): connect failed (0,8): error.ConnectionRefused
2025-12-12 19:32:58.502Z warning(faulty_network): connect failed (0,9): error.ConnectionRefused
2025-12-12 19:32:57.896Z debug(replica): 2n: sending request to replica 1: vsr.message_header.Header.Request{ .checksum = 16037302979060692649990508405715316506, .checksum_padding = 0, .checksum_body = 88187512808688459248792857380290978596, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 951296, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 337109595689299129151409809149989579498, .parent_padding = 0, .client = 298802811082733066315345031472557842243, .session = 2, .timestamp = 0, .request = 75, .operation = vsr.Operation(139), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 48008687, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 19:32:57.896Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 16037302979060692649990508405715316506, .checksum_padding = 0, .checksum_body = 88187512808688459248792857380290978596, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 951296, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 337109595689299129151409809149989579498, .parent_padding = 0, .client = 298802811082733066315345031472557842243, .session = 2, .timestamp = 0, .request = 75, .operation = vsr.Operation(139), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 48008687, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
warning(message_bus): 298802811082733066315345031472557842243: on_recv: from=vsr.Peer{ .replica = 0 } error.ConnectionResetByPeer
2025-12-12 19:32:59.922Z debug(replica): 1N: on_request: new request
2025-12-12 19:32:59.922Z debug(replica): 1N: primary_pipeline_prepare: request checksum=16037302979060692649990508405715316506 client=298802811082733066315345031472557842243
2025-12-12 19:32:59.923Z debug(vsr): 2: journal_repair_budget_timeout fired
2025-12-12 19:32:59.923Z debug(vsr): 2: journal_repair_budget_timeout reset
2025-12-12 19:32:59.926Z debug(replica): 1N: primary_pipeline_prepare: prepare checksum=50046125892507764113810559856184688619 op=77
2025-12-12 19:32:59.926Z debug(vsr): 1: prepare_timeout started
2025-12-12 19:32:59.926Z debug(vsr): 1: primary_abdicate_timeout started
2025-12-12 19:32:59.926Z debug(vsr): 1: pulse_timeout reset
2025-12-12 19:32:59.926Z debug(replica): 1N: replicate: replicating op=77 to replica 0
2025-12-12 19:32:59.926Z debug(replica): 1N: sending prepare to replica 0: vsr.message_header.Header.Prepare{ .checksum = 50046125892507764113810559856184688619, .checksum_padding = 0, .checksum_body = 88187512808688459248792857380290978596, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 951296, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 227017562941974017127234289375656335088, .parent_padding = 0, .request_checksum = 16037302979060692649990508405715316506, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 298802811082733066315345031472557842243, .op = 77, .commit = 76, .timestamp = 1765567979922565616, .request = 75, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-12-12 19:32:59.926Z debug(message_bus): 1: send_message_to_replica: no connection to=0 header=vsr.message_header.Header.Prepare{ .checksum = 50046125892507764113810559856184688619, .checksum_padding = 0, .checksum_body = 88187512808688459248792857380290978596, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 951296, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 227017562941974017127234289375656335088, .parent_padding = 0, .request_checksum = 16037302979060692649990508405715316506, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 298802811082733066315345031472557842243, .op = 77, .commit = 76, .timestamp = 1765567979922565616, .request = 75, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-12-12 19:32:59.926Z debug(replica): 1N: replicate: replicating op=77 to replica 2
2025-12-12 19:32:59.926Z debug(replica): 1N: sending prepare to replica 2: vsr.message_header.Header.Prepare{ .checksum = 50046125892507764113810559856184688619, .checksum_padding = 0, .checksum_body = 88187512808688459248792857380290978596, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 951296, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 227017562941974017127234289375656335088, .parent_padding = 0, .request_checksum = 16037302979060692649990508405715316506, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 298802811082733066315345031472557842243, .op = 77, .commit = 76, .timestamp = 1765567979922565616, .request = 75, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-12-12 19:32:59.926Z debug(replica): 1N: on_prepare: advancing: op=76..77 checksum=227017562941974017127234289375656335088..50046125892507764113810559856184688619
2025-12-12 19:32:59.927Z debug(journal): 1: set_header_as_dirty: op=77 checksum=50046125892507764113810559856184688619
2025-12-12 19:32:59.927Z debug(replica): 1N: append: appending to journal op=77
2025-12-12 19:32:59.927Z debug(journal): 1: write: view=1 slot=77 op=77 len=951296: 50046125892507764113810559856184688619 starting
2025-12-12 19:32:59.927Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.prepares offset=80740352 len=954368 locked
2025-12-12 19:32:59.931Z debug(replica): 2n: on_message: view=1 status=normal vsr.message_header.Header.Prepare{ .checksum = 50046125892507764113810559856184688619, .checksum_padding = 0, .checksum_body = 88187512808688459248792857380290978596, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 951296, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 227017562941974017127234289375656335088, .parent_padding = 0, .request_checksum = 16037302979060692649990508405715316506, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 298802811082733066315345031472557842243, .op = 77, .commit = 76, .timestamp = 1765567979922565616, .request = 75, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-12-12 19:32:59.931Z debug(replica): 2n: on_prepare: advancing commit_max=75..76
2025-12-12 19:32:59.931Z debug(replica): 2n: on_prepare: caching prepare.op=77 (commit_min=75 op=76 commit_max=76 prepare_max=1007)
2025-12-12 19:32:59.931Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 16037302979060692649990508405715316506, .checksum_padding = 0, .checksum_body = 88187512808688459248792857380290978596, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 951296, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 337109595689299129151409809149989579498, .parent_padding = 0, .client = 298802811082733066315345031472557842243, .session = 2, .timestamp = 0, .request = 75, .operation = vsr.Operation(139), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 48008687, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 19:32:59.931Z debug(replica): 1N: on_request: new request
2025-12-12 19:32:59.931Z debug(replica): 1N: on_request: ignoring (already preparing)
2025-12-12 19:32:59.932Z debug(replica): 2n: on_prepare: advancing: op=76..77 checksum=227017562941974017127234289375656335088..50046125892507764113810559856184688619
2025-12-12 19:32:59.932Z debug(journal): 2: set_header_as_dirty: op=77 checksum=50046125892507764113810559856184688619
2025-12-12 19:32:59.932Z debug(replica): 2n: append: appending to journal op=77
2025-12-12 19:32:59.932Z debug(journal): 2: write: view=1 slot=77 op=77 len=951296: 50046125892507764113810559856184688619 starting
2025-12-12 19:32:59.932Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.prepares offset=80740352 len=954368 unlocked
2025-12-12 19:32:59.932Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.prepares offset=80740352 len=954368 locked
2025-12-12 19:32:59.932Z debug(journal): 1: write_header: op=77 sectors[16384..20480]
2025-12-12 19:32:59.932Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.headers offset=16384 len=4096 locked
2025-12-12 19:32:59.932Z debug(replica): 2n: commit_start_journal: cached prepare op=76 checksum=227017562941974017127234289375656335088
2025-12-12 19:32:59.932Z debug(replica): 2n: repair_prepare: op=77 checksum=50046125892507764113810559856184688619 (already writing)
2025-12-12 19:32:59.932Z debug(replica): 2n: commit_journal: already committing (prefetch; commit_min=75)
2025-12-12 19:32:59.932Z debug(replica): 2n: execute_op: executing view=1 primary=false op=76 checksum=227017562941974017127234289375656335088 (lookup_accounts)
2025-12-12 19:32:59.932Z debug(replica): 2n: execute_op: commit_timestamp=1765567977759265854 prepare.header.timestamp=1765567977830204445
2025-12-12 19:32:59.932Z debug(replica): 2n: client_table_entry_update: client=298802811082733066315345031472557842243 session=2 request=74
2025-12-12 19:32:59.932Z debug(forest): entering forest.compact() op=76 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2025-12-12 19:32:59.933Z debug(client_replies): 2: write_reply: wrote (client=298802811082733066315345031472557842243 request=74)
2025-12-12 19:32:59.933Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.prepares offset=80740352 len=954368 unlocked
2025-12-12 19:32:59.933Z debug(journal): 2: write_header: op=77 sectors[16384..20480]
2025-12-12 19:32:59.933Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.headers offset=16384 len=4096 locked
2025-12-12 19:32:59.933Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.headers offset=16384 len=4096 unlocked
2025-12-12 19:32:59.933Z debug(journal): 2: write: view=1 slot=77 op=77 len=951296: 50046125892507764113810559856184688619 complete, marking clean
2025-12-12 19:32:59.933Z debug(replica): 2n: send_prepare_ok: op=77 checksum=50046125892507764113810559856184688619
2025-12-12 19:32:59.933Z debug(replica): 2n: sending prepare_ok to replica 1: vsr.message_header.Header.PrepareOk{ .checksum = 28345297875744660826718937621481429260, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 1, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 227017562941974017127234289375656335088, .parent_padding = 0, .prepare_checksum = 50046125892507764113810559856184688619, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 298802811082733066315345031472557842243, .op = 77, .commit_min = 76, .timestamp = 1765567979922565616, .request = 75, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-12-12 19:32:59.936Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 16037302979060692649990508405715316506, .checksum_padding = 0, .checksum_body = 88187512808688459248792857380290978596, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 951296, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 337109595689299129151409809149989579498, .parent_padding = 0, .client = 298802811082733066315345031472557842243, .session = 2, .timestamp = 0, .request = 75, .operation = vsr.Operation(139), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 48008687, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 19:32:59.936Z debug(replica): 1N: on_request: new request
2025-12-12 19:32:59.936Z debug(replica): 1N: on_request: ignoring (already preparing)
2025-12-12 19:32:59.936Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.headers offset=16384 len=4096 unlocked
2025-12-12 19:32:59.936Z debug(journal): 1: write: view=1 slot=77 op=77 len=951296: 50046125892507764113810559856184688619 complete, marking clean
2025-12-12 19:32:59.936Z debug(replica): 1N: send_prepare_ok: op=77 checksum=50046125892507764113810559856184688619
2025-12-12 19:32:59.936Z debug(replica): 1N: sending prepare_ok to replica 1: vsr.message_header.Header.PrepareOk{ .checksum = 85206791690634340352305787933499863270, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 1, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 227017562941974017127234289375656335088, .parent_padding = 0, .prepare_checksum = 50046125892507764113810559856184688619, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 298802811082733066315345031472557842243, .op = 77, .commit_min = 76, .timestamp = 1765567979922565616, .request = 75, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-12-12 19:32:59.936Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.PrepareOk{ .checksum = 85206791690634340352305787933499863270, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 1, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 227017562941974017127234289375656335088, .parent_padding = 0, .prepare_checksum = 50046125892507764113810559856184688619, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 298802811082733066315345031472557842243, .op = 77, .commit_min = 76, .timestamp = 1765567979922565616, .request = 75, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-12-12 19:32:59.936Z debug(vsr): 1: primary_abdicate_timeout reset
2025-12-12 19:32:59.936Z debug(replica): 1N: on_prepare_ok: 1 message(s)
2025-12-12 19:32:59.936Z debug(replica): 1N: on_prepare_ok: waiting for quorum
2025-12-12 19:32:59.943Z debug(vsr): 2: journal_repair_budget_timeout fired
2025-12-12 19:32:59.943Z debug(vsr): 2: journal_repair_budget_timeout reset
2025-12-12 19:32:59.946Z debug(vsr): 1: journal_repair_budget_timeout fired
2025-12-12 19:32:59.946Z debug(vsr): 1: journal_repair_budget_timeout reset
2025-12-12 19:32:59.963Z debug(vsr): 2: journal_repair_budget_timeout fired
2025-12-12 19:32:59.963Z debug(vsr): 2: journal_repair_budget_timeout reset
2025-12-12 19:32:59.966Z debug(vsr): 1: journal_repair_budget_timeout fired
2025-12-12 19:32:59.966Z debug(vsr): 1: journal_repair_budget_timeout reset
2025-12-12 19:32:59.972Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.PrepareOk{ .checksum = 28345297875744660826718937621481429260, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 1, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 227017562941974017127234289375656335088, .parent_padding = 0, .prepare_checksum = 50046125892507764113810559856184688619, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 298802811082733066315345031472557842243, .op = 77, .commit_min = 76, .timestamp = 1765567979922565616, .request = 75, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-12-12 19:32:59.972Z debug(vsr): 1: primary_abdicate_timeout reset
2025-12-12 19:32:59.972Z debug(replica): 1N: on_prepare_ok: 2 message(s)
2025-12-12 19:32:59.972Z debug(replica): 1N: on_prepare_ok: quorum received, context=50046125892507764113810559856184688619
2025-12-12 19:32:59.972Z debug(vsr): 1: prepare_timeout stopped
2025-12-12 19:32:59.972Z debug(vsr): 1: primary_abdicate_timeout stopped
2025-12-12 19:32:59.976Z debug(replica): 1N: execute_op: executing view=1 primary=true op=77 checksum=50046125892507764113810559856184688619 (create_transfers)
2025-12-12 19:32:59.976Z debug(replica): 1N: execute_op: commit_timestamp=1765567977830204445 prepare.header.timestamp=1765567979922565616
2025-12-12 19:32:59.983Z debug(vsr): 2: journal_repair_budget_timeout fired
2025-12-12 19:32:59.983Z debug(vsr): 2: journal_repair_budget_timeout reset
2025-12-12 19:33:00.003Z debug(vsr): 2: journal_repair_budget_timeout fired
2025-12-12 19:33:00.003Z debug(vsr): 2: journal_repair_budget_timeout reset
2025-12-12 19:33:00.003Z debug(vsr): 2: journal_repair_timeout fired
2025-12-12 19:33:00.003Z debug(vsr): 2: journal_repair_timeout reset
2025-12-12 19:33:00.004Z debug(replica): 1N: execute_op: advancing commit_max=76..77
2025-12-12 19:33:00.004Z debug(replica): 1N: client_table_entry_update: client=298802811082733066315345031472557842243 session=2 request=75
2025-12-12 19:33:00.004Z debug(replica): 1N: execute_op: replying to client: vsr.message_header.Header.Reply{ .checksum = 283601692497720617378655302827344485553, .checksum_padding = 0, .checksum_body = 318235044786297875279950245911222240311, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 320, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 16037302979060692649990508405715316506, .request_checksum_padding = 0, .context = 130693092147162158048836737178112347644, .context_padding = 0, .client = 298802811082733066315345031472557842243, .op = 77, .commit = 77, .timestamp = 1765567979922565616, .request = 75, .operation = vsr.Operation(139), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 19:33:00.004Z debug(replica): 1N: sending reply to client 298802811082733066315345031472557842243: vsr.message_header.Header.Reply{ .checksum = 283601692497720617378655302827344485553, .checksum_padding = 0, .checksum_body = 318235044786297875279950245911222240311, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 320, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 16037302979060692649990508405715316506, .request_checksum_padding = 0, .context = 130693092147162158048836737178112347644, .context_padding = 0, .client = 298802811082733066315345031472557842243, .op = 77, .commit = 77, .timestamp = 1765567979922565616, .request = 75, .operation = vsr.Operation(139), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 19:33:00.004Z debug(forest): entering forest.compact() op=77 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
warning(client): 298802811082733066315345031472557842243: on_reply: slow request, request=75 op=77 size=951296 create_transfers time=2118ms
2025-12-12 19:33:00.017Z warning(faulty_network): connect failed (0,0): error.ConnectionRefused
2025-12-12 19:33:00.018Z debug(client_replies): 1: write_reply: wrote (client=298802811082733066315345031472557842243 request=75)
2025-12-12 19:33:00.023Z debug(vsr): 2: journal_repair_budget_timeout fired
2025-12-12 19:33:00.023Z debug(vsr): 2: journal_repair_budget_timeout reset
2025-12-12 19:33:00.028Z debug(vsr): 1: journal_repair_budget_timeout fired
2025-12-12 19:33:00.028Z debug(vsr): 1: journal_repair_budget_timeout reset
2025-12-12 19:33:00.028Z debug(vsr): 1: journal_repair_timeout fired
2025-12-12 19:33:00.028Z debug(vsr): 1: journal_repair_timeout reset
2025-12-12 19:33:00.031Z debug(replica): 2n: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 121395962344306933791293852953846147119, .checksum_padding = 0, .checksum_body = 335087834777102016521472518441542458906, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 1968, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 130693092147162158048836737178112347644, .parent_padding = 0, .client = 298802811082733066315345031472557842243, .session = 2, .timestamp = 0, .request = 76, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 2119139754, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 19:33:00.031Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 121395962344306933791293852953846147119, .checksum_padding = 0, .checksum_body = 335087834777102016521472518441542458906, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 1968, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 130693092147162158048836737178112347644, .parent_padding = 0, .client = 298802811082733066315345031472557842243, .session = 2, .timestamp = 0, .request = 76, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 2119139754, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 19:33:00.031Z debug(replica): 2n: on_request: forwarding new request to primary (view=1)
2025-12-12 19:33:00.031Z debug(replica): 1N: on_request: new request
2025-12-12 19:33:00.031Z debug(replica): 1N: primary_pipeline_prepare: request checksum=121395962344306933791293852953846147119 client=298802811082733066315345031472557842243
2025-12-12 19:33:00.031Z debug(replica): 2n: sending request to replica 1: vsr.message_header.Header.Request{ .checksum = 121395962344306933791293852953846147119, .checksum_padding = 0, .checksum_body = 335087834777102016521472518441542458906, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 1968, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 130693092147162158048836737178112347644, .parent_padding = 0, .client = 298802811082733066315345031472557842243, .session = 2, .timestamp = 0, .request = 76, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 2119139754, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 19:33:00.031Z debug(replica): 1N: primary_pipeline_prepare: prepare checksum=240794380421414098388945324064346820912 op=78
2025-12-12 19:33:00.031Z debug(vsr): 1: prepare_timeout started
2025-12-12 19:33:00.031Z debug(vsr): 1: primary_abdicate_timeout started
2025-12-12 19:33:00.031Z debug(vsr): 1: pulse_timeout reset
2025-12-12 19:33:00.031Z debug(replica): 1N: replicate: replicating op=78 to replica 0
2025-12-12 19:33:00.031Z debug(replica): 1N: sending prepare to replica 0: vsr.message_header.Header.Prepare{ .checksum = 240794380421414098388945324064346820912, .checksum_padding = 0, .checksum_body = 335087834777102016521472518441542458906, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 1968, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 50046125892507764113810559856184688619, .parent_padding = 0, .request_checksum = 121395962344306933791293852953846147119, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 298802811082733066315345031472557842243, .op = 78, .commit = 77, .timestamp = 1765567980031825652, .request = 76, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-12-12 19:33:00.031Z debug(message_bus): 1: send_message_to_replica: no connection to=0 header=vsr.message_header.Header.Prepare{ .checksum = 240794380421414098388945324064346820912, .checksum_padding = 0, .checksum_body = 335087834777102016521472518441542458906, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 1968, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 50046125892507764113810559856184688619, .parent_padding = 0, .request_checksum = 121395962344306933791293852953846147119, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 298802811082733066315345031472557842243, .op = 78, .commit = 77, .timestamp = 1765567980031825652, .request = 76, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-12-12 19:33:00.031Z debug(replica): 1N: replicate: replicating op=78 to replica 2
2025-12-12 19:33:00.031Z debug(replica): 1N: sending prepare to replica 2: vsr.message_header.Header.Prepare{ .checksum = 240794380421414098388945324064346820912, .checksum_padding = 0, .checksum_body = 335087834777102016521472518441542458906, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 1968, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 50046125892507764113810559856184688619, .parent_padding = 0, .request_checksum = 121395962344306933791293852953846147119, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 298802811082733066315345031472557842243, .op = 78, .commit = 77, .timestamp = 1765567980031825652, .request = 76, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-12-12 19:33:00.031Z debug(replica): 1N: on_prepare: advancing: op=77..78 checksum=50046125892507764113810559856184688619..240794380421414098388945324064346820912
2025-12-12 19:33:00.032Z debug(journal): 1: set_header_as_dirty: op=78 checksum=240794380421414098388945324064346820912
2025-12-12 19:33:00.032Z debug(replica): 1N: append: appending to journal op=78
2025-12-12 19:33:00.032Z debug(journal): 1: write: view=1 slot=78 op=78 len=1968: 240794380421414098388945324064346820912 starting
2025-12-12 19:33:00.032Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.prepares offset=81788928 len=4096 locked
2025-12-12 19:33:00.032Z debug(replica): 2n: on_message: view=1 status=normal vsr.message_header.Header.Prepare{ .checksum = 240794380421414098388945324064346820912, .checksum_padding = 0, .checksum_body = 335087834777102016521472518441542458906, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 1968, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 50046125892507764113810559856184688619, .parent_padding = 0, .request_checksum = 121395962344306933791293852953846147119, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 298802811082733066315345031472557842243, .op = 78, .commit = 77, .timestamp = 1765567980031825652, .request = 76, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-12-12 19:33:00.032Z debug(replica): 2n: on_prepare: advancing commit_max=76..77
2025-12-12 19:33:00.032Z debug(replica): 2n: on_prepare: caching prepare.op=78 (commit_min=76 op=77 commit_max=77 prepare_max=1007)
2025-12-12 19:33:00.032Z debug(replica): 2n: on_prepare: advancing: op=77..78 checksum=50046125892507764113810559856184688619..240794380421414098388945324064346820912
2025-12-12 19:33:00.032Z debug(journal): 2: set_header_as_dirty: op=78 checksum=240794380421414098388945324064346820912
2025-12-12 19:33:00.032Z debug(replica): 2n: append: appending to journal op=78
2025-12-12 19:33:00.032Z debug(journal): 2: write: view=1 slot=78 op=78 len=1968: 240794380421414098388945324064346820912 starting
2025-12-12 19:33:00.032Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.prepares offset=81788928 len=4096 locked
2025-12-12 19:33:00.032Z debug(replica): 2n: commit_start_journal: cached prepare op=77 checksum=50046125892507764113810559856184688619
2025-12-12 19:33:00.032Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 121395962344306933791293852953846147119, .checksum_padding = 0, .checksum_body = 335087834777102016521472518441542458906, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 1968, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 130693092147162158048836737178112347644, .parent_padding = 0, .client = 298802811082733066315345031472557842243, .session = 2, .timestamp = 0, .request = 76, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 2119139754, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 19:33:00.032Z debug(replica): 1N: on_request: new request
2025-12-12 19:33:00.032Z debug(replica): 1N: on_request: ignoring (already preparing)
2025-12-12 19:33:00.032Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.prepares offset=81788928 len=4096 unlocked
2025-12-12 19:33:00.032Z debug(journal): 1: write_header: op=78 sectors[16384..20480]
2025-12-12 19:33:00.032Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.headers offset=16384 len=4096 locked
2025-12-12 19:33:00.032Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.headers offset=16384 len=4096 unlocked
2025-12-12 19:33:00.032Z debug(journal): 1: write: view=1 slot=78 op=78 len=1968: 240794380421414098388945324064346820912 complete, marking clean
2025-12-12 19:33:00.032Z debug(replica): 1N: send_prepare_ok: op=78 checksum=240794380421414098388945324064346820912
2025-12-12 19:33:00.032Z debug(replica): 1N: sending prepare_ok to replica 1: vsr.message_header.Header.PrepareOk{ .checksum = 317926070955433272438540975409924907802, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 1, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 50046125892507764113810559856184688619, .parent_padding = 0, .prepare_checksum = 240794380421414098388945324064346820912, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 298802811082733066315345031472557842243, .op = 78, .commit_min = 77, .timestamp = 1765567980031825652, .request = 76, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-12-12 19:33:00.032Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.PrepareOk{ .checksum = 317926070955433272438540975409924907802, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 1, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 50046125892507764113810559856184688619, .parent_padding = 0, .prepare_checksum = 240794380421414098388945324064346820912, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 298802811082733066315345031472557842243, .op = 78, .commit_min = 77, .timestamp = 1765567980031825652, .request = 76, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-12-12 19:33:00.032Z debug(vsr): 1: primary_abdicate_timeout reset
2025-12-12 19:33:00.032Z debug(replica): 1N: on_prepare_ok: 1 message(s)
2025-12-12 19:33:00.032Z debug(replica): 1N: on_prepare_ok: waiting for quorum
2025-12-12 19:33:00.033Z debug(replica): 2n: repair_prepare: op=78 checksum=240794380421414098388945324064346820912 (already writing)
2025-12-12 19:33:00.033Z debug(replica): 2n: commit_journal: already committing (prefetch; commit_min=76)
2025-12-12 19:33:00.035Z debug(replica): 2n: execute_op: executing view=1 primary=false op=77 checksum=50046125892507764113810559856184688619 (create_transfers)
2025-12-12 19:33:00.035Z debug(replica): 2n: execute_op: commit_timestamp=1765567977830204445 prepare.header.timestamp=1765567979922565616
2025-12-12 19:33:00.048Z debug(vsr): 1: journal_repair_budget_timeout fired
2025-12-12 19:33:00.048Z debug(vsr): 1: journal_repair_budget_timeout reset
2025-12-12 19:33:00.064Z debug(replica): 2n: client_table_entry_update: client=298802811082733066315345031472557842243 session=2 request=75
2025-12-12 19:33:00.064Z debug(forest): entering forest.compact() op=77 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2025-12-12 19:33:00.069Z debug(vsr): 1: journal_repair_budget_timeout fired
2025-12-12 19:33:00.069Z debug(vsr): 1: journal_repair_budget_timeout reset
2025-12-12 19:33:00.078Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.prepares offset=81788928 len=4096 unlocked
2025-12-12 19:33:00.078Z debug(journal): 2: write_header: op=78 sectors[16384..20480]
2025-12-12 19:33:00.078Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.headers offset=16384 len=4096 locked
2025-12-12 19:33:00.078Z debug(client_replies): 2: write_reply: wrote (client=298802811082733066315345031472557842243 request=75)
2025-12-12 19:33:00.078Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.headers offset=16384 len=4096 unlocked
2025-12-12 19:33:00.078Z debug(journal): 2: write: view=1 slot=78 op=78 len=1968: 240794380421414098388945324064346820912 complete, marking clean
2025-12-12 19:33:00.078Z debug(replica): 2n: send_prepare_ok: op=78 checksum=240794380421414098388945324064346820912
2025-12-12 19:33:00.078Z debug(replica): 2n: sending prepare_ok to replica 1: vsr.message_header.Header.PrepareOk{ .checksum = 9408635199046166367733849568929440881, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 1, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 50046125892507764113810559856184688619, .parent_padding = 0, .prepare_checksum = 240794380421414098388945324064346820912, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 298802811082733066315345031472557842243, .op = 78, .commit_min = 77, .timestamp = 1765567980031825652, .request = 76, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-12-12 19:33:00.079Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.PrepareOk{ .checksum = 9408635199046166367733849568929440881, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 1, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 50046125892507764113810559856184688619, .parent_padding = 0, .prepare_checksum = 240794380421414098388945324064346820912, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 298802811082733066315345031472557842243, .op = 78, .commit_min = 77, .timestamp = 1765567980031825652, .request = 76, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-12-12 19:33:00.079Z debug(vsr): 1: primary_abdicate_timeout reset
2025-12-12 19:33:00.079Z debug(replica): 1N: on_prepare_ok: 2 message(s)
2025-12-12 19:33:00.079Z debug(replica): 1N: on_prepare_ok: quorum received, context=240794380421414098388945324064346820912
2025-12-12 19:33:00.079Z debug(vsr): 1: prepare_timeout stopped
2025-12-12 19:33:00.079Z debug(vsr): 1: primary_abdicate_timeout stopped
2025-12-12 19:33:00.079Z debug(replica): 1N: execute_op: executing view=1 primary=true op=78 checksum=240794380421414098388945324064346820912 (lookup_accounts)
2025-12-12 19:33:00.079Z debug(replica): 1N: execute_op: commit_timestamp=1765567979922565616 prepare.header.timestamp=1765567980031825652
2025-12-12 19:33:00.079Z debug(replica): 1N: execute_op: advancing commit_max=77..78
2025-12-12 19:33:00.079Z debug(replica): 1N: client_table_entry_update: client=298802811082733066315345031472557842243 session=2 request=76
2025-12-12 19:33:00.079Z debug(replica): 1N: execute_op: replying to client: vsr.message_header.Header.Reply{ .checksum = 149207293765521930839498356483322557745, .checksum_padding = 0, .checksum_body = 23025828610556763205561369902170856607, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 13952, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 121395962344306933791293852953846147119, .request_checksum_padding = 0, .context = 130664118354361189701818416245013231515, .context_padding = 0, .client = 298802811082733066315345031472557842243, .op = 78, .commit = 78, .timestamp = 1765567980031825652, .request = 76, .operation = vsr.Operation(140), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 19:33:00.079Z debug(replica): 1N: sending reply to client 298802811082733066315345031472557842243: vsr.message_header.Header.Reply{ .checksum = 149207293765521930839498356483322557745, .checksum_padding = 0, .checksum_body = 23025828610556763205561369902170856607, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 13952, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 121395962344306933791293852953846147119, .request_checksum_padding = 0, .context = 130664118354361189701818416245013231515, .context_padding = 0, .client = 298802811082733066315345031472557842243, .op = 78, .commit = 78, .timestamp = 1765567980031825652, .request = 76, .operation = vsr.Operation(140), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 19:33:00.079Z debug(forest): entering forest.compact() op=78 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2025-12-12 19:33:00.079Z debug(client_replies): 1: write_reply: wrote (client=298802811082733066315345031472557842243 request=76)
2025-12-12 19:33:00.079Z info(workload): accounts created = 106, transfers = 72224, pending transfers = 0, commands run = 38
2025-12-12 19:33:00.083Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 115034186158730347307117257952508354410, .checksum_padding = 0, .checksum_body = 31887166394020559272421665616466282952, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 209024, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 130664118354361189701818416245013231515, .parent_padding = 0, .client = 298802811082733066315345031472557842243, .session = 2, .timestamp = 0, .request = 77, .operation = vsr.Operation(139), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 48081867, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 19:33:00.083Z debug(replica): 1N: on_request: new request
2025-12-12 19:33:00.083Z debug(replica): 1N: primary_pipeline_prepare: request checksum=115034186158730347307117257952508354410 client=298802811082733066315345031472557842243
2025-12-12 19:33:00.083Z debug(replica): 2n: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 115034186158730347307117257952508354410, .checksum_padding = 0, .checksum_body = 31887166394020559272421665616466282952, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 209024, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 130664118354361189701818416245013231515, .parent_padding = 0, .client = 298802811082733066315345031472557842243, .session = 2, .timestamp = 0, .request = 77, .operation = vsr.Operation(139), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 48081867, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 19:33:00.083Z debug(replica): 2n: on_request: forwarding new request to primary (view=1)
2025-12-12 19:33:00.083Z debug(replica): 2n: sending request to replica 1: vsr.message_header.Header.Request{ .checksum = 115034186158730347307117257952508354410, .checksum_padding = 0, .checksum_body = 31887166394020559272421665616466282952, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 209024, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 130664118354361189701818416245013231515, .parent_padding = 0, .client = 298802811082733066315345031472557842243, .session = 2, .timestamp = 0, .request = 77, .operation = vsr.Operation(139), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 48081867, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 19:33:00.084Z debug(replica): 1N: primary_pipeline_prepare: prepare checksum=68452566422114964625917319307032606675 op=79
2025-12-12 19:33:00.084Z debug(vsr): 1: prepare_timeout started
2025-12-12 19:33:00.084Z debug(vsr): 1: primary_abdicate_timeout started
2025-12-12 19:33:00.084Z debug(vsr): 1: pulse_timeout reset
2025-12-12 19:33:00.084Z debug(replica): 1N: replicate: replicating op=79 to replica 0
2025-12-12 19:33:00.084Z debug(replica): 1N: sending prepare to replica 0: vsr.message_header.Header.Prepare{ .checksum = 68452566422114964625917319307032606675, .checksum_padding = 0, .checksum_body = 31887166394020559272421665616466282952, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 209024, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 240794380421414098388945324064346820912, .parent_padding = 0, .request_checksum = 115034186158730347307117257952508354410, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 298802811082733066315345031472557842243, .op = 79, .commit = 78, .timestamp = 1765567980083194150, .request = 77, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-12-12 19:33:00.084Z debug(message_bus): 1: send_message_to_replica: no connection to=0 header=vsr.message_header.Header.Prepare{ .checksum = 68452566422114964625917319307032606675, .checksum_padding = 0, .checksum_body = 31887166394020559272421665616466282952, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 209024, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 240794380421414098388945324064346820912, .parent_padding = 0, .request_checksum = 115034186158730347307117257952508354410, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 298802811082733066315345031472557842243, .op = 79, .commit = 78, .timestamp = 1765567980083194150, .request = 77, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-12-12 19:33:00.084Z debug(replica): 1N: replicate: replicating op=79 to replica 2
2025-12-12 19:33:00.084Z debug(replica): 1N: sending prepare to replica 2: vsr.message_header.Header.Prepare{ .checksum = 68452566422114964625917319307032606675, .checksum_padding = 0, .checksum_body = 31887166394020559272421665616466282952, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 209024, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 240794380421414098388945324064346820912, .parent_padding = 0, .request_checksum = 115034186158730347307117257952508354410, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 298802811082733066315345031472557842243, .op = 79, .commit = 78, .timestamp = 1765567980083194150, .request = 77, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-12-12 19:33:00.084Z debug(replica): 1N: on_prepare: advancing: op=78..79 checksum=240794380421414098388945324064346820912..68452566422114964625917319307032606675
2025-12-12 19:33:00.084Z debug(journal): 1: set_header_as_dirty: op=79 checksum=68452566422114964625917319307032606675
2025-12-12 19:33:00.084Z debug(replica): 1N: append: appending to journal op=79
2025-12-12 19:33:00.084Z debug(journal): 1: write: view=1 slot=79 op=79 len=209024: 68452566422114964625917319307032606675 starting
2025-12-12 19:33:00.084Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.prepares offset=82837504 len=212992 locked
2025-12-12 19:33:00.085Z debug(replica): 2n: on_message: view=1 status=normal vsr.message_header.Header.Prepare{ .checksum = 68452566422114964625917319307032606675, .checksum_padding = 0, .checksum_body = 31887166394020559272421665616466282952, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 209024, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 240794380421414098388945324064346820912, .parent_padding = 0, .request_checksum = 115034186158730347307117257952508354410, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 298802811082733066315345031472557842243, .op = 79, .commit = 78, .timestamp = 1765567980083194150, .request = 77, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-12-12 19:33:00.085Z debug(replica): 2n: on_prepare: advancing commit_max=77..78
2025-12-12 19:33:00.085Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 115034186158730347307117257952508354410, .checksum_padding = 0, .checksum_body = 31887166394020559272421665616466282952, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 209024, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 130664118354361189701818416245013231515, .parent_padding = 0, .client = 298802811082733066315345031472557842243, .session = 2, .timestamp = 0, .request = 77, .operation = vsr.Operation(139), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 48081867, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 19:33:00.085Z debug(replica): 2n: on_prepare: caching prepare.op=79 (commit_min=77 op=78 commit_max=78 prepare_max=1007)
2025-12-12 19:33:00.085Z debug(replica): 1N: on_request: new request
2025-12-12 19:33:00.085Z debug(replica): 1N: on_request: ignoring (already preparing)
2025-12-12 19:33:00.085Z debug(replica): 2n: on_prepare: advancing: op=78..79 checksum=240794380421414098388945324064346820912..68452566422114964625917319307032606675
2025-12-12 19:33:00.085Z debug(journal): 2: set_header_as_dirty: op=79 checksum=68452566422114964625917319307032606675
2025-12-12 19:33:00.085Z debug(replica): 2n: append: appending to journal op=79
2025-12-12 19:33:00.085Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.prepares offset=82837504 len=212992 unlocked
2025-12-12 19:33:00.085Z debug(journal): 2: write: view=1 slot=79 op=79 len=209024: 68452566422114964625917319307032606675 starting
2025-12-12 19:33:00.085Z debug(journal): 1: write_header: op=79 sectors[16384..20480]
2025-12-12 19:33:00.085Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.headers offset=16384 len=4096 locked
2025-12-12 19:33:00.085Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.prepares offset=82837504 len=212992 locked
2025-12-12 19:33:00.085Z debug(replica): 2n: commit_start_journal: cached prepare op=78 checksum=240794380421414098388945324064346820912
2025-12-12 19:33:00.085Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.headers offset=16384 len=4096 unlocked
2025-12-12 19:33:00.085Z debug(journal): 1: write: view=1 slot=79 op=79 len=209024: 68452566422114964625917319307032606675 complete, marking clean
2025-12-12 19:33:00.085Z debug(replica): 1N: send_prepare_ok: op=79 checksum=68452566422114964625917319307032606675
2025-12-12 19:33:00.085Z debug(replica): 1N: sending prepare_ok to replica 1: vsr.message_header.Header.PrepareOk{ .checksum = 244436250514391560601342897706795172477, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 1, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 240794380421414098388945324064346820912, .parent_padding = 0, .prepare_checksum = 68452566422114964625917319307032606675, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 298802811082733066315345031472557842243, .op = 79, .commit_min = 78, .timestamp = 1765567980083194150, .request = 77, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-12-12 19:33:00.085Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.PrepareOk{ .checksum = 244436250514391560601342897706795172477, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 1, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 240794380421414098388945324064346820912, .parent_padding = 0, .prepare_checksum = 68452566422114964625917319307032606675, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 298802811082733066315345031472557842243, .op = 79, .commit_min = 78, .timestamp = 1765567980083194150, .request = 77, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-12-12 19:33:00.085Z debug(vsr): 1: primary_abdicate_timeout reset
2025-12-12 19:33:00.085Z debug(replica): 1N: on_prepare_ok: 1 message(s)
2025-12-12 19:33:00.085Z debug(replica): 2n: repair_prepare: op=79 checksum=68452566422114964625917319307032606675 (already writing)
2025-12-12 19:33:00.085Z debug(replica): 1N: on_prepare_ok: waiting for quorum
2025-12-12 19:33:00.085Z debug(replica): 2n: commit_journal: already committing (prefetch; commit_min=77)
2025-12-12 19:33:00.085Z debug(replica): 2n: execute_op: executing view=1 primary=false op=78 checksum=240794380421414098388945324064346820912 (lookup_accounts)
2025-12-12 19:33:00.085Z debug(replica): 2n: execute_op: commit_timestamp=1765567979922565616 prepare.header.timestamp=1765567980031825652
2025-12-12 19:33:00.085Z debug(replica): 2n: client_table_entry_update: client=298802811082733066315345031472557842243 session=2 request=76
2025-12-12 19:33:00.085Z debug(replica): 2n: execute_op: replying to client: vsr.message_header.Header.Reply{ .checksum = 149207293765521930839498356483322557745, .checksum_padding = 0, .checksum_body = 23025828610556763205561369902170856607, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 13952, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 121395962344306933791293852953846147119, .request_checksum_padding = 0, .context = 130664118354361189701818416245013231515, .context_padding = 0, .client = 298802811082733066315345031472557842243, .op = 78, .commit = 78, .timestamp = 1765567980031825652, .request = 76, .operation = vsr.Operation(140), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 19:33:00.085Z debug(replica): 2n: sending reply to client 298802811082733066315345031472557842243: vsr.message_header.Header.Reply{ .checksum = 149207293765521930839498356483322557745, .checksum_padding = 0, .checksum_body = 23025828610556763205561369902170856607, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 13952, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 121395962344306933791293852953846147119, .request_checksum_padding = 0, .context = 130664118354361189701818416245013231515, .context_padding = 0, .client = 298802811082733066315345031472557842243, .op = 78, .commit = 78, .timestamp = 1765567980031825652, .request = 76, .operation = vsr.Operation(140), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 19:33:00.085Z debug(forest): entering forest.compact() op=78 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2025-12-12 19:33:00.086Z debug(client_replies): 2: write_reply: wrote (client=298802811082733066315345031472557842243 request=76)
2025-12-12 19:33:00.086Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.prepares offset=82837504 len=212992 unlocked
2025-12-12 19:33:00.086Z debug(journal): 2: write_header: op=79 sectors[16384..20480]
2025-12-12 19:33:00.086Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.headers offset=16384 len=4096 locked
2025-12-12 19:33:00.086Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.headers offset=16384 len=4096 unlocked
2025-12-12 19:33:00.086Z debug(journal): 2: write: view=1 slot=79 op=79 len=209024: 68452566422114964625917319307032606675 complete, marking clean
2025-12-12 19:33:00.086Z debug(replica): 2n: send_prepare_ok: op=79 checksum=68452566422114964625917319307032606675
2025-12-12 19:33:00.086Z debug(replica): 2n: sending prepare_ok to replica 1: vsr.message_header.Header.PrepareOk{ .checksum = 155714127780771181964915827969340196824, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 1, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 240794380421414098388945324064346820912, .parent_padding = 0, .prepare_checksum = 68452566422114964625917319307032606675, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 298802811082733066315345031472557842243, .op = 79, .commit_min = 78, .timestamp = 1765567980083194150, .request = 77, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-12-12 19:33:00.086Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.PrepareOk{ .checksum = 155714127780771181964915827969340196824, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 1, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 240794380421414098388945324064346820912, .parent_padding = 0, .prepare_checksum = 68452566422114964625917319307032606675, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 298802811082733066315345031472557842243, .op = 79, .commit_min = 78, .timestamp = 1765567980083194150, .request = 77, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-12-12 19:33:00.086Z debug(vsr): 1: primary_abdicate_timeout reset
2025-12-12 19:33:00.086Z debug(replica): 1N: on_prepare_ok: 2 message(s)
2025-12-12 19:33:00.086Z debug(replica): 1N: on_prepare_ok: quorum received, context=68452566422114964625917319307032606675
2025-12-12 19:33:00.086Z debug(vsr): 1: prepare_timeout stopped
2025-12-12 19:33:00.086Z debug(vsr): 1: primary_abdicate_timeout stopped
2025-12-12 19:33:00.087Z debug(replica): 1N: execute_op: executing view=1 primary=true op=79 checksum=68452566422114964625917319307032606675 (create_transfers)
2025-12-12 19:33:00.088Z debug(vsr): 2: journal_repair_budget_timeout fired
2025-12-12 19:33:00.110Z warning(faulty_network): connect failed (0,1): error.ConnectionRefused
2025-12-12 19:36:56.232Z debug(replica): 1N: execute_op: commit_timestamp=1765567980031825652 prepare.header.timestamp=1765567980083194150
2025-12-12 19:36:56.232Z debug(vsr): 2: journal_repair_budget_timeout reset
warning(message_bus): 298802811082733066315345031472557842243: on_recv: from=vsr.Peer{ .replica = 0 } error.ConnectionTimedOut
2025-12-12 19:36:56.233Z info(supervisor): 0: starting replica
2025-12-12 19:36:56.233Z debug(replica): 2n: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 115034186158730347307117257952508354410, .checksum_padding = 0, .checksum_body = 31887166394020559272421665616466282952, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 209024, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 130664118354361189701818416245013231515, .parent_padding = 0, .client = 298802811082733066315345031472557842243, .session = 2, .timestamp = 0, .request = 77, .operation = vsr.Operation(139), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 48081867, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 19:36:56.233Z debug(replica): 2n: on_request: forwarding new request to primary (view=1)
2025-12-12 19:36:56.233Z debug(replica): 2n: sending request to replica 1: vsr.message_header.Header.Request{ .checksum = 115034186158730347307117257952508354410, .checksum_padding = 0, .checksum_body = 31887166394020559272421665616466282952, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 209024, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 130664118354361189701818416245013231515, .parent_padding = 0, .client = 298802811082733066315345031472557842243, .session = 2, .timestamp = 0, .request = 77, .operation = vsr.Operation(139), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 48081867, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 19:36:56.234Z info(io): opening "0_0.tigerbeetle"...
2025-12-12 19:36:56.238Z debug(replica): 1N: execute_op: advancing commit_max=78..79
2025-12-12 19:36:56.238Z debug(replica): 1N: client_table_entry_update: client=298802811082733066315345031472557842243 session=2 request=77
2025-12-12 19:36:56.238Z debug(replica): 1N: execute_op: replying to client: vsr.message_header.Header.Reply{ .checksum = 256784831566812540523678563333313226686, .checksum_padding = 0, .checksum_body = 212102088948749938456865492719814357451, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 320, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 115034186158730347307117257952508354410, .request_checksum_padding = 0, .context = 322782390311329851225019817310715273842, .context_padding = 0, .client = 298802811082733066315345031472557842243, .op = 79, .commit = 79, .timestamp = 1765567980083194150, .request = 77, .operation = vsr.Operation(139), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 19:36:56.238Z debug(replica): 1N: sending reply to client 298802811082733066315345031472557842243: vsr.message_header.Header.Reply{ .checksum = 256784831566812540523678563333313226686, .checksum_padding = 0, .checksum_body = 212102088948749938456865492719814357451, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 320, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 115034186158730347307117257952508354410, .request_checksum_padding = 0, .context = 322782390311329851225019817310715273842, .context_padding = 0, .client = 298802811082733066315345031472557842243, .op = 79, .commit = 79, .timestamp = 1765567980083194150, .request = 77, .operation = vsr.Operation(139), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 19:36:56.238Z debug(forest): entering forest.compact() op=79 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=true half_beat=false last_beat=false
2025-12-12 19:36:56.238Z debug(manifest_log): 1: flush: writing 0 block(s)
warning(client): 298802811082733066315345031472557842243: on_reply: slow request, request=77 op=79 size=209024 create_transfers time=236157ms
2025-12-12 19:36:56.240Z warning(replica): 1N: commit_dispatch: slow request, request=77 size=209024 create_transfers time=236154ms
2025-12-12 19:36:56.241Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 115034186158730347307117257952508354410, .checksum_padding = 0, .checksum_body = 31887166394020559272421665616466282952, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 209024, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 130664118354361189701818416245013231515, .parent_padding = 0, .client = 298802811082733066315345031472557842243, .session = 2, .timestamp = 0, .request = 77, .operation = vsr.Operation(139), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 48081867, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 19:36:56.241Z debug(replica): 1N: on_request: replying to duplicate request
2025-12-12 19:36:56.241Z debug(replica): 1N: on_request: repeat reply (client=298802811082733066315345031472557842243 request=77)
2025-12-12 19:36:56.241Z debug(replica): 1N: sending reply to client 298802811082733066315345031472557842243: vsr.message_header.Header.Reply{ .checksum = 256784831566812540523678563333313226686, .checksum_padding = 0, .checksum_body = 212102088948749938456865492719814357451, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 320, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 115034186158730347307117257952508354410, .request_checksum_padding = 0, .context = 322782390311329851225019817310715273842, .context_padding = 0, .client = 298802811082733066315345031472557842243, .op = 79, .commit = 79, .timestamp = 1765567980083194150, .request = 77, .operation = vsr.Operation(139), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 19:36:56.241Z debug(client_replies): 1: write_reply: wrote (client=298802811082733066315345031472557842243 request=77)
2025-12-12 19:36:56.242Z warning(clock): 2: synchronization failed, partitioned (sources=1 samples=1)
2025-12-12 19:36:56.242Z error(clock): 2: no agreement on cluster time (partitioned or too many clock faults)
2025-12-12 19:36:56.242Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 115034186158730347307117257952508354410, .checksum_padding = 0, .checksum_body = 31887166394020559272421665616466282952, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 209024, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 130664118354361189701818416245013231515, .parent_padding = 0, .client = 298802811082733066315345031472557842243, .session = 2, .timestamp = 0, .request = 77, .operation = vsr.Operation(139), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 48081867, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 19:36:56.242Z debug(replica): 1N: on_request: replying to duplicate request
2025-12-12 19:36:56.242Z debug(client_replies): 1: read_reply: start (client=298802811082733066315345031472557842243 reply=256784831566812540523678563333313226686)
2025-12-12 19:36:56.243Z info(supervisor): sleeping for 3.207s
2025-12-12 19:36:56.243Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 115034186158730347307117257952508354410, .checksum_padding = 0, .checksum_body = 31887166394020559272421665616466282952, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 209024, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 130664118354361189701818416245013231515, .parent_padding = 0, .client = 298802811082733066315345031472557842243, .session = 2, .timestamp = 0, .request = 77, .operation = vsr.Operation(139), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 48081867, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 19:36:56.243Z debug(replica): 1N: on_request: replying to duplicate request
2025-12-12 19:36:56.243Z debug(client_replies): 1: read_reply: busy (client=298802811082733066315345031472557842243 reply=256784831566812540523678563333313226686)
2025-12-12 19:36:56.243Z debug(replica): 1N: on_request: ignoring (client_replies busy)
2025-12-12 19:36:56.244Z debug(client_replies): 1: read_reply: done (client=298802811082733066315345031472557842243 reply=256784831566812540523678563333313226686)
2025-12-12 19:36:56.244Z debug(replica): 1N: on_request: repeat reply (client=298802811082733066315345031472557842243 request=77)
2025-12-12 19:36:56.244Z debug(replica): 1N: sending reply to client 298802811082733066315345031472557842243: vsr.message_header.Header.Reply{ .checksum = 256784831566812540523678563333313226686, .checksum_padding = 0, .checksum_body = 212102088948749938456865492719814357451, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 320, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 115034186158730347307117257952508354410, .request_checksum_padding = 0, .context = 322782390311329851225019817310715273842, .context_padding = 0, .client = 298802811082733066315345031472557842243, .op = 79, .commit = 79, .timestamp = 1765567980083194150, .request = 77, .operation = vsr.Operation(139), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 19:36:56.244Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 115034186158730347307117257952508354410, .checksum_padding = 0, .checksum_body = 31887166394020559272421665616466282952, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 209024, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 130664118354361189701818416245013231515, .parent_padding = 0, .client = 298802811082733066315345031472557842243, .session = 2, .timestamp = 0, .request = 77, .operation = vsr.Operation(139), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 48081867, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 19:36:56.244Z debug(replica): 1N: on_request: replying to duplicate request
2025-12-12 19:36:56.244Z debug(client_replies): 1: read_reply: start (client=298802811082733066315345031472557842243 reply=256784831566812540523678563333313226686)
2025-12-12 19:36:56.245Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 115034186158730347307117257952508354410, .checksum_padding = 0, .checksum_body = 31887166394020559272421665616466282952, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 209024, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 130664118354361189701818416245013231515, .parent_padding = 0, .client = 298802811082733066315345031472557842243, .session = 2, .timestamp = 0, .request = 77, .operation = vsr.Operation(139), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 48081867, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 19:36:56.245Z debug(replica): 1N: on_request: replying to duplicate request
2025-12-12 19:36:56.245Z debug(client_replies): 1: read_reply: busy (client=298802811082733066315345031472557842243 reply=256784831566812540523678563333313226686)
2025-12-12 19:36:56.245Z debug(replica): 1N: on_request: ignoring (client_replies busy)
2025-12-12 19:36:56.245Z debug(client_replies): 1: read_reply: done (client=298802811082733066315345031472557842243 reply=256784831566812540523678563333313226686)
2025-12-12 19:36:56.246Z debug(replica): 1N: on_request: repeat reply (client=298802811082733066315345031472557842243 request=77)
2025-12-12 19:36:56.246Z debug(replica): 1N: sending reply to client 298802811082733066315345031472557842243: vsr.message_header.Header.Reply{ .checksum = 256784831566812540523678563333313226686, .checksum_padding = 0, .checksum_body = 212102088948749938456865492719814357451, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 320, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 115034186158730347307117257952508354410, .request_checksum_padding = 0, .context = 322782390311329851225019817310715273842, .context_padding = 0, .client = 298802811082733066315345031472557842243, .op = 79, .commit = 79, .timestamp = 1765567980083194150, .request = 77, .operation = vsr.Operation(139), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 19:36:56.246Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 115034186158730347307117257952508354410, .checksum_padding = 0, .checksum_body = 31887166394020559272421665616466282952, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 209024, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 130664118354361189701818416245013231515, .parent_padding = 0, .client = 298802811082733066315345031472557842243, .session = 2, .timestamp = 0, .request = 77, .operation = vsr.Operation(139), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 48081867, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 19:36:56.246Z debug(replica): 1N: on_request: replying to duplicate request
2025-12-12 19:36:56.246Z debug(client_replies): 1: read_reply: start (client=298802811082733066315345031472557842243 reply=256784831566812540523678563333313226686)
2025-12-12 19:36:56.247Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 115034186158730347307117257952508354410, .checksum_padding = 0, .checksum_body = 31887166394020559272421665616466282952, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 209024, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 130664118354361189701818416245013231515, .parent_padding = 0, .client = 298802811082733066315345031472557842243, .session = 2, .timestamp = 0, .request = 77, .operation = vsr.Operation(139), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 48081867, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 19:36:56.247Z debug(replica): 1N: on_request: replying to duplicate request
2025-12-12 19:36:56.247Z debug(client_replies): 1: read_reply: busy (client=298802811082733066315345031472557842243 reply=256784831566812540523678563333313226686)
2025-12-12 19:36:56.247Z debug(replica): 1N: on_request: ignoring (client_replies busy)
2025-12-12 19:36:56.247Z debug(client_replies): 1: read_reply: done (client=298802811082733066315345031472557842243 reply=256784831566812540523678563333313226686)
2025-12-12 19:36:56.247Z debug(replica): 1N: on_request: repeat reply (client=298802811082733066315345031472557842243 request=77)
2025-12-12 19:36:56.247Z debug(replica): 1N: sending reply to client 298802811082733066315345031472557842243: vsr.message_header.Header.Reply{ .checksum = 256784831566812540523678563333313226686, .checksum_padding = 0, .checksum_body = 212102088948749938456865492719814357451, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 320, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 115034186158730347307117257952508354410, .request_checksum_padding = 0, .context = 322782390311329851225019817310715273842, .context_padding = 0, .client = 298802811082733066315345031472557842243, .op = 79, .commit = 79, .timestamp = 1765567980083194150, .request = 77, .operation = vsr.Operation(139), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 19:36:56.248Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 115034186158730347307117257952508354410, .checksum_padding = 0, .checksum_body = 31887166394020559272421665616466282952, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 209024, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 130664118354361189701818416245013231515, .parent_padding = 0, .client = 298802811082733066315345031472557842243, .session = 2, .timestamp = 0, .request = 77, .operation = vsr.Operation(139), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 48081867, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 19:36:56.248Z debug(replica): 1N: on_request: replying to duplicate request
2025-12-12 19:36:56.248Z debug(client_replies): 1: read_reply: start (client=298802811082733066315345031472557842243 reply=256784831566812540523678563333313226686)
2025-12-12 19:36:56.248Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 322982390719002015862251741112113089370, .checksum_padding = 0, .checksum_body = 335087834777102016521472518441542458906, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 1968, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 322782390311329851225019817310715273842, .parent_padding = 0, .client = 298802811082733066315345031472557842243, .session = 2, .timestamp = 0, .request = 78, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 4294967295, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 19:36:56.248Z debug(replica): 1N: on_request: new request
2025-12-12 19:36:56.248Z debug(replica): 1N: primary_pipeline_prepare: request checksum=322982390719002015862251741112113089370 client=298802811082733066315345031472557842243
2025-12-12 19:36:56.248Z debug(replica): 1N: primary_pipeline_prepare: prepare checksum=282960807081127385582626664792792058087 op=80
2025-12-12 19:36:56.248Z debug(vsr): 1: prepare_timeout started
2025-12-12 19:36:56.248Z debug(vsr): 1: primary_abdicate_timeout started
2025-12-12 19:36:56.248Z debug(vsr): 1: pulse_timeout reset
2025-12-12 19:36:56.248Z debug(replica): 1N: replicate: replicating op=80 to replica 0
2025-12-12 19:36:56.248Z debug(replica): 1N: sending prepare to replica 0: vsr.message_header.Header.Prepare{ .checksum = 282960807081127385582626664792792058087, .checksum_padding = 0, .checksum_body = 335087834777102016521472518441542458906, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 1968, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 68452566422114964625917319307032606675, .parent_padding = 0, .request_checksum = 322982390719002015862251741112113089370, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 298802811082733066315345031472557842243, .op = 80, .commit = 79, .timestamp = 1765568216248822207, .request = 78, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-12-12 19:36:56.248Z debug(message_bus): 1: send_message_to_replica: no connection to=0 header=vsr.message_header.Header.Prepare{ .checksum = 282960807081127385582626664792792058087, .checksum_padding = 0, .checksum_body = 335087834777102016521472518441542458906, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 1968, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 68452566422114964625917319307032606675, .parent_padding = 0, .request_checksum = 322982390719002015862251741112113089370, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 298802811082733066315345031472557842243, .op = 80, .commit = 79, .timestamp = 1765568216248822207, .request = 78, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-12-12 19:36:56.248Z debug(replica): 1N: replicate: replicating op=80 to replica 2
2025-12-12 19:36:56.248Z debug(replica): 1N: sending prepare to replica 2: vsr.message_header.Header.Prepare{ .checksum = 282960807081127385582626664792792058087, .checksum_padding = 0, .checksum_body = 335087834777102016521472518441542458906, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 1968, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 68452566422114964625917319307032606675, .parent_padding = 0, .request_checksum = 322982390719002015862251741112113089370, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 298802811082733066315345031472557842243, .op = 80, .commit = 79, .timestamp = 1765568216248822207, .request = 78, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-12-12 19:36:56.248Z debug(replica): 1N: on_prepare: advancing: op=79..80 checksum=68452566422114964625917319307032606675..282960807081127385582626664792792058087
2025-12-12 19:36:56.248Z debug(journal): 1: set_header_as_dirty: op=80 checksum=282960807081127385582626664792792058087
2025-12-12 19:36:56.248Z debug(replica): 1N: append: appending to journal op=80
2025-12-12 19:36:56.248Z debug(journal): 1: write: view=1 slot=80 op=80 len=1968: 282960807081127385582626664792792058087 starting
2025-12-12 19:36:56.248Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.prepares offset=83886080 len=4096 locked
2025-12-12 19:36:56.249Z debug(replica): 2n: on_message: view=1 status=normal vsr.message_header.Header.Prepare{ .checksum = 282960807081127385582626664792792058087, .checksum_padding = 0, .checksum_body = 335087834777102016521472518441542458906, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 1968, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 68452566422114964625917319307032606675, .parent_padding = 0, .request_checksum = 322982390719002015862251741112113089370, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 298802811082733066315345031472557842243, .op = 80, .commit = 79, .timestamp = 1765568216248822207, .request = 78, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-12-12 19:36:56.249Z debug(replica): 2n: on_prepare: advancing commit_max=78..79
2025-12-12 19:36:56.249Z debug(replica): 2n: on_prepare: caching prepare.op=80 (commit_min=78 op=79 commit_max=79 prepare_max=1007)
2025-12-12 19:36:56.249Z debug(client_replies): 1: read_reply: done (client=298802811082733066315345031472557842243 reply=256784831566812540523678563333313226686)
2025-12-12 19:36:56.249Z debug(replica): 1N: on_request: repeat reply (client=298802811082733066315345031472557842243 request=77)
2025-12-12 19:36:56.249Z debug(replica): 2n: on_prepare: advancing: op=79..80 checksum=68452566422114964625917319307032606675..282960807081127385582626664792792058087
2025-12-12 19:36:56.249Z debug(journal): 2: set_header_as_dirty: op=80 checksum=282960807081127385582626664792792058087
2025-12-12 19:36:56.249Z debug(replica): 1N: sending reply to client 298802811082733066315345031472557842243: vsr.message_header.Header.Reply{ .checksum = 256784831566812540523678563333313226686, .checksum_padding = 0, .checksum_body = 212102088948749938456865492719814357451, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 320, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 115034186158730347307117257952508354410, .request_checksum_padding = 0, .context = 322782390311329851225019817310715273842, .context_padding = 0, .client = 298802811082733066315345031472557842243, .op = 79, .commit = 79, .timestamp = 1765567980083194150, .request = 77, .operation = vsr.Operation(139), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-12-12 19:36:56.249Z debug(replica): 2n: append: appending to journal op=80
2025-12-12 19:36:56.249Z debug(journal): 2: write: view=1 slot=80 op=80 len=1968: 282960807081127385582626664792792058087 starting
2025-12-12 19:36:56.249Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.prepares offset=83886080 len=4096 locked
2025-12-12 19:36:56.249Z debug(replica): 2n: commit_start_journal: cached prepare op=79 checksum=68452566422114964625917319307032606675
2025-12-12 19:36:56.249Z warning(clock): 1: synchronization failed, partitioned (sources=1 samples=1)
2025-12-12 19:36:56.249Z error(clock): 1: no agreement on cluster time (partitioned or too many clock faults)
2025-12-12 19:36:56.249Z debug(vsr): 1: journal_repair_budget_timeout fired
2025-12-12 19:36:56.249Z debug(vsr): 1: journal_repair_budget_timeout reset
2025-12-12 19:36:56.249Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.prepares offset=83886080 len=4096 unlocked
2025-12-12 19:36:56.249Z debug(journal): 1: write_header: op=80 sectors[20480..24576]
2025-12-12 19:36:56.249Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.headers offset=20480 len=4096 locked
2025-12-12 19:36:56.249Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.headers offset=20480 len=4096 unlocked
2025-12-12 19:36:56.249Z debug(journal): 1: write: view=1 slot=80 op=80 len=1968: 282960807081127385582626664792792058087 complete, marking clean
2025-12-12 19:36:56.249Z debug(replica): 1N: send_prepare_ok: op=80 checksum=282960807081127385582626664792792058087
2025-12-12 19:36:56.249Z debug(replica): 1N: sending prepare_ok to replica 1: vsr.message_header.Header.PrepareOk{ .checksum = 235908673953652330532209569653311435077, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 1, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 68452566422114964625917319307032606675, .parent_padding = 0, .prepare_checksum = 282960807081127385582626664792792058087, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 298802811082733066315345031472557842243, .op = 80, .commit_min = 79, .timestamp = 1765568216248822207, .request = 78, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-12-12 19:36:56.249Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.PrepareOk{ .checksum = 235908673953652330532209569653311435077, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 1, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 68452566422114964625917319307032606675, .parent_padding = 0, .prepare_checksum = 282960807081127385582626664792792058087, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 298802811082733066315345031472557842243, .op = 80, .commit_min = 79, .timestamp = 1765568216248822207, .request = 78, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-12-12 19:36:56.249Z debug(vsr): 1: primary_abdicate_timeout reset
2025-12-12 19:36:56.249Z debug(replica): 1N: on_prepare_ok: 1 message(s)
2025-12-12 19:36:56.249Z debug(replica): 1N: on_prepare_ok: waiting for quorum
2025-12-12 19:36:56.249Z debug(replica): 2n: repair_prepare: op=80 checksum=282960807081127385582626664792792058087 (already writing)
2025-12-12 19:36:56.249Z debug(replica): 2n: commit_journal: already committing (prefetch; commit_min=78)
2025-12-12 19:36:56.250Z debug(replica): 2n: execute_op: executing view=1 primary=false op=79 checksum=68452566422114964625917319307032606675 (create_transfers)
2025-12-12 19:36:56.250Z debug(replica): 2n: execute_op: commit_timestamp=1765567980031825652 prepare.header.timestamp=1765567980083194150
2025-12-12 19:36:56.253Z error(supervisor): liveness check: too slow request
2025-12-12 19:36:56.254Z info(supervisor): 0: terminating replica
2025-12-12 19:36:56.255Z debug(replica): 2n: client_table_entry_update: client=298802811082733066315345031472557842243 session=2 request=77
2025-12-12 19:36:56.255Z info(supervisor): 1: terminating replica
2025-12-12 19:36:56.255Z debug(forest): entering forest.compact() op=79 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=true half_beat=false last_beat=false
2025-12-12 19:36:56.255Z debug(manifest_log): 2: flush: writing 0 block(s)
2025-12-12 19:36:56.259Z debug(vsr): 2: journal_repair_budget_timeout fired
2025-12-12 19:36:56.259Z debug(vsr): 2: journal_repair_budget_timeout reset
2025-12-12 19:36:56.259Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.prepares offset=83886080 len=4096 unlocked
2025-12-12 19:36:56.259Z debug(journal): 2: write_header: op=80 sectors[20480..24576]
2025-12-12 19:36:56.259Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.headers offset=20480 len=4096 locked
2025-12-12 19:36:56.259Z debug(client_replies): 2: write_reply: wrote (client=298802811082733066315345031472557842243 request=77)
2025-12-12 19:36:56.259Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.headers offset=20480 len=4096 unlocked
2025-12-12 19:36:56.259Z debug(journal): 2: write: view=1 slot=80 op=80 len=1968: 282960807081127385582626664792792058087 complete, marking clean
2025-12-12 19:36:56.259Z debug(replica): 2n: send_prepare_ok: op=80 checksum=282960807081127385582626664792792058087
2025-12-12 19:36:56.259Z debug(replica): 2n: sending prepare_ok to replica 1: vsr.message_header.Header.PrepareOk{ .checksum = 78315253814225078705935316154872560052, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 1, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 68452566422114964625917319307032606675, .parent_padding = 0, .prepare_checksum = 282960807081127385582626664792792058087, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 298802811082733066315345031472557842243, .op = 80, .commit_min = 79, .timestamp = 1765568216248822207, .request = 78, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-12-12 19:36:56.264Z info(supervisor): 2: terminating replica
warning(message_bus): 298802811082733066315345031472557842243: on_recv: from=vsr.Peer{ .replica = 0 } error.ConnectionResetByPeer
2025-12-12 19:36:56.301Z error: TestFailed
/root/tigerbeetle/working/main/src/testing/vortex/supervisor.zig:295:21: 0x1307eb0 in run (vortex)
                    return error.TestFailed;
                    ^
/root/tigerbeetle/working/main/src/testing/vortex/supervisor.zig:207:5: 0x130ca73 in main (vortex)
    try supervisor.run();
    ^
/root/tigerbeetle/working/main/src/vortex.zig:61:42: 0x13216d4 in main (vortex)
        .supervisor => |supervisor_args| try Supervisor.main(allocator, supervisor_args),
                                         ^
