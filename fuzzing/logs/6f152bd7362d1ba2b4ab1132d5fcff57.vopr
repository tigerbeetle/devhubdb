30 checksum=30370352403006904875143586656723095742..187478823532391127234834592963431897539
2025-11-24 15:04:16.219Z debug(journal): 1: set_header_as_dirty: op=130 checksum=187478823532391127234834592963431897539
2025-11-24 15:04:16.219Z debug(replica): 1n: append: appending to journal op=130
2025-11-24 15:04:16.219Z debug(journal): 1: write: view=3 slot=130 op=130 len=2240: 187478823532391127234834592963431897539 starting
2025-11-24 15:04:16.219Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.prepares offset=136314880 len=4096 locked
2025-11-24 15:04:16.219Z debug(replica): 1n: commit_journal: already committing (prefetch; commit_min=127)
2025-11-24 15:04:16.219Z debug(replica): 1n: repair_prepare: op=128 checksum=108899319724609156411158542483965582447 (already writing)
2025-11-24 15:04:16.219Z debug(replica): 1n: repair_prepare: op=129 checksum=30370352403006904875143586656723095742 (already writing)
2025-11-24 15:04:16.219Z debug(replica): 1n: repair_prepare: op=130 checksum=187478823532391127234834592963431897539 (already writing)
2025-11-24 15:04:16.219Z debug(replica): 1n: commit_journal: already committing (prefetch; commit_min=127)
2025-11-24 15:04:16.219Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.headers offset=32768 len=4096 unlocked
2025-11-24 15:04:16.219Z debug(journal): 1: write: view=3 slot=128 op=128 len=2240: 108899319724609156411158542483965582447 complete, marking clean
2025-11-24 15:04:16.219Z debug(replica): 1n: send_prepare_ok: op=128 checksum=108899319724609156411158542483965582447
2025-11-24 15:04:16.219Z debug(replica): 1n: sending prepare_ok to replica 0: vsr.message_header.Header.PrepareOk{ .checksum = 65759061733025748533228404245590527529, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 61409546665516173832840384617628896801, .parent_padding = 0, .prepare_checksum = 108899319724609156411158542483965582447, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 47899338719226163297711645970010401862, .op = 128, .commit_min = 127, .timestamp = 1763996651947154405, .request = 126, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-11-24 15:04:16.219Z debug(replica): 1n: execute_op: executing view=3 primary=false op=128 checksum=108899319724609156411158542483965582447 (lookup_accounts)
2025-11-24 15:04:16.219Z debug(replica): 1n: execute_op: commit_timestamp=1763996651706544007 prepare.header.timestamp=1763996651947154405
2025-11-24 15:04:16.219Z debug(replica): 1n: client_table_entry_update: client=47899338719226163297711645970010401862 session=2 request=126
2025-11-24 15:04:16.219Z debug(replica): 1n: execute_op: replying to client: vsr.message_header.Header.Reply{ .checksum = 295278054658370360789015086446709936460, .checksum_padding = 0, .checksum_body = 188467424296250908954677370394918651043, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 16128, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 324288851827761226209009497290306350355, .request_checksum_padding = 0, .context = 284322140373623728580408544636297003964, .context_padding = 0, .client = 47899338719226163297711645970010401862, .op = 128, .commit = 128, .timestamp = 1763996651947154405, .request = 126, .operation = vsr.Operation(140), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:04:16.219Z debug(replica): 1n: sending reply to client 47899338719226163297711645970010401862: vsr.message_header.Header.Reply{ .checksum = 295278054658370360789015086446709936460, .checksum_padding = 0, .checksum_body = 188467424296250908954677370394918651043, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 16128, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 324288851827761226209009497290306350355, .request_checksum_padding = 0, .context = 284322140373623728580408544636297003964, .context_padding = 0, .client = 47899338719226163297711645970010401862, .op = 128, .commit = 128, .timestamp = 1763996651947154405, .request = 126, .operation = vsr.Operation(140), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:04:16.219Z debug(forest): entering forest.compact() op=128 constants.lsm_compaction_ops=32 first_beat=true last_half_beat=false half_beat=false last_beat=false
2025-11-24 15:04:16.219Z debug(compaction): Account.id:1: bar_commence: nothing to compact
2025-11-24 15:04:16.219Z debug(compaction): Account.user_data_128:1: bar_commence: nothing to compact
2025-11-24 15:04:16.219Z debug(compaction): Account.user_data_64:1: bar_commence: nothing to compact
2025-11-24 15:04:16.219Z debug(compaction): Account.user_data_32:1: bar_commence: nothing to compact
2025-11-24 15:04:16.219Z debug(compaction): Account.ledger:1: bar_commence: nothing to compact
2025-11-24 15:04:16.219Z debug(compaction): Account.code:1: bar_commence: nothing to compact
2025-11-24 15:04:16.219Z debug(compaction): Account:1: bar_commence: nothing to compact
2025-11-24 15:04:16.219Z debug(compaction): Transfer.id:1: bar_commence: nothing to compact
2025-11-24 15:04:16.219Z debug(compaction): Transfer.debit_account_id:1: bar_commence: nothing to compact
2025-11-24 15:04:16.219Z debug(compaction): Transfer.credit_account_id:1: bar_commence: nothing to compact
2025-11-24 15:04:16.219Z debug(compaction): Transfer.amount:1: bar_commence: nothing to compact
2025-11-24 15:04:16.219Z debug(compaction): Transfer.pending_id:1: bar_commence: nothing to compact
2025-11-24 15:04:16.219Z debug(compaction): Transfer.user_data_128:1: bar_commence: nothing to compact
2025-11-24 15:04:16.219Z debug(compaction): Transfer.user_data_64:1: bar_commence: nothing to compact
2025-11-24 15:04:16.219Z debug(compaction): Transfer.user_data_32:1: bar_commence: nothing to compact
2025-11-24 15:04:16.219Z debug(compaction): Transfer.ledger:1: bar_commence: nothing to compact
2025-11-24 15:04:16.219Z debug(compaction): Transfer.code:1: bar_commence: nothing to compact
2025-11-24 15:04:16.219Z debug(compaction): Transfer:1: bar_commence: nothing to compact
2025-11-24 15:04:16.219Z debug(compaction): Transfer.expires_at:1: bar_commence: nothing to compact
2025-11-24 15:04:16.219Z debug(compaction): TransferPending:1: bar_commence: nothing to compact
2025-11-24 15:04:16.219Z debug(compaction): TransferPending.status:1: bar_commence: nothing to compact
2025-11-24 15:04:16.219Z debug(compaction): AccountEvent:1: bar_commence: nothing to compact
2025-11-24 15:04:16.219Z debug(compaction): Account.imported:1: bar_commence: nothing to compact
2025-11-24 15:04:16.220Z debug(compaction): Transfer.imported:1: bar_commence: nothing to compact
2025-11-24 15:04:16.220Z debug(compaction): Account.closed:1: bar_commence: nothing to compact
2025-11-24 15:04:16.220Z debug(compaction): Transfer.closing:1: bar_commence: nothing to compact
2025-11-24 15:04:16.220Z debug(compaction): AccountEvent.account_timestamp:1: bar_commence: nothing to compact
2025-11-24 15:04:16.220Z debug(compaction): AccountEvent.transfer_pending_status:1: bar_commence: nothing to compact
2025-11-24 15:04:16.220Z debug(compaction): AccountEvent.dr_account_id_expired:1: bar_commence: nothing to compact
2025-11-24 15:04:16.220Z debug(compaction): AccountEvent.cr_account_id_expired:1: bar_commence: nothing to compact
2025-11-24 15:04:16.220Z debug(compaction): AccountEvent.transfer_pending_id_expired:1: bar_commence: nothing to compact
2025-11-24 15:04:16.220Z debug(compaction): AccountEvent.ledger_expired:1: bar_commence: nothing to compact
2025-11-24 15:04:16.220Z debug(compaction): AccountEvent.prunable:1: bar_commence: nothing to compact
2025-11-24 15:04:16.220Z debug(compaction): Account.id:3: bar_commence: nothing to compact
2025-11-24 15:04:16.220Z debug(compaction): Account.user_data_128:3: bar_commence: nothing to compact
2025-11-24 15:04:16.220Z debug(compaction): Account.user_data_64:3: bar_commence: nothing to compact
2025-11-24 15:04:16.220Z debug(compaction): Account.user_data_32:3: bar_commence: nothing to compact
2025-11-24 15:04:16.220Z debug(compaction): Account.ledger:3: bar_commence: nothing to compact
2025-11-24 15:04:16.220Z debug(compaction): Account.code:3: bar_commence: nothing to compact
2025-11-24 15:04:16.220Z debug(compaction): Account:3: bar_commence: nothing to compact
2025-11-24 15:04:16.220Z debug(compaction): Transfer.id:3: bar_commence: nothing to compact
2025-11-24 15:04:16.220Z debug(compaction): Transfer.debit_account_id:3: bar_commence: nothing to compact
2025-11-24 15:04:16.220Z debug(compaction): Transfer.credit_account_id:3: bar_commence: nothing to compact
2025-11-24 15:04:16.220Z debug(compaction): Transfer.amount:3: bar_commence: nothing to compact
2025-11-24 15:04:16.220Z debug(compaction): Transfer.pending_id:3: bar_commence: nothing to compact
2025-11-24 15:04:16.220Z debug(compaction): Transfer.user_data_128:3: bar_commence: nothing to compact
2025-11-24 15:04:16.220Z debug(compaction): Transfer.user_data_64:3: bar_commence: nothing to compact
2025-11-24 15:04:16.220Z debug(compaction): Transfer.user_data_32:3: bar_commence: nothing to compact
2025-11-24 15:04:16.220Z debug(compaction): Transfer.ledger:3: bar_commence: nothing to compact
2025-11-24 15:04:16.220Z debug(compaction): Transfer.code:3: bar_commence: nothing to compact
2025-11-24 15:04:16.220Z debug(compaction): Transfer:3: bar_commence: nothing to compact
2025-11-24 15:04:16.220Z debug(compaction): Transfer.expires_at:3: bar_commence: nothing to compact
2025-11-24 15:04:16.220Z debug(compaction): TransferPending:3: bar_commence: nothing to compact
2025-11-24 15:04:16.220Z debug(compaction): TransferPending.status:3: bar_commence: nothing to compact
2025-11-24 15:04:16.220Z debug(compaction): AccountEvent:3: bar_commence: nothing to compact
2025-11-24 15:04:16.220Z debug(compaction): Account.imported:3: bar_commence: nothing to compact
2025-11-24 15:04:16.220Z debug(compaction): Transfer.imported:3: bar_commence: nothing to compact
2025-11-24 15:04:16.220Z debug(compaction): Account.closed:3: bar_commence: nothing to compact
2025-11-24 15:04:16.220Z debug(compaction): Transfer.closing:3: bar_commence: nothing to compact
2025-11-24 15:04:16.220Z debug(compaction): AccountEvent.account_timestamp:3: bar_commence: nothing to compact
2025-11-24 15:04:16.220Z debug(compaction): AccountEvent.transfer_pending_status:3: bar_commence: nothing to compact
2025-11-24 15:04:16.220Z debug(compaction): AccountEvent.dr_account_id_expired:3: bar_commence: nothing to compact
2025-11-24 15:04:16.220Z debug(compaction): AccountEvent.cr_account_id_expired:3: bar_commence: nothing to compact
2025-11-24 15:04:16.220Z debug(compaction): AccountEvent.transfer_pending_id_expired:3: bar_commence: nothing to compact
2025-11-24 15:04:16.220Z debug(compaction): AccountEvent.ledger_expired:3: bar_commence: nothing to compact
2025-11-24 15:04:16.220Z debug(compaction): AccountEvent.prunable:3: bar_commence: nothing to compact
2025-11-24 15:04:16.220Z debug(compaction): Account.id:5: bar_commence: nothing to compact
2025-11-24 15:04:16.220Z debug(compaction): Account.user_data_128:5: bar_commence: nothing to compact
2025-11-24 15:04:16.220Z debug(compaction): Account.user_data_64:5: bar_commence: nothing to compact
2025-11-24 15:04:16.220Z debug(compaction): Account.user_data_32:5: bar_commence: nothing to compact
2025-11-24 15:04:16.220Z debug(compaction): Account.ledger:5: bar_commence: nothing to compact
2025-11-24 15:04:16.220Z debug(compaction): Account.code:5: bar_commence: nothing to compact
2025-11-24 15:04:16.220Z debug(compaction): Account:5: bar_commence: nothing to compact
2025-11-24 15:04:16.220Z debug(compaction): Transfer.id:5: bar_commence: nothing to compact
2025-11-24 15:04:16.220Z debug(compaction): Transfer.debit_account_id:5: bar_commence: nothing to compact
2025-11-24 15:04:16.220Z debug(compaction): Transfer.credit_account_id:5: bar_commence: nothing to compact
2025-11-24 15:04:16.220Z debug(compaction): Transfer.amount:5: bar_commence: nothing to compact
2025-11-24 15:04:16.220Z debug(compaction): Transfer.pending_id:5: bar_commence: nothing to compact
2025-11-24 15:04:16.220Z debug(compaction): Transfer.user_data_128:5: bar_commence: nothing to compact
2025-11-24 15:04:16.220Z debug(compaction): Transfer.user_data_64:5: bar_commence: nothing to compact
2025-11-24 15:04:16.220Z debug(compaction): Transfer.user_data_32:5: bar_commence: nothing to compact
2025-11-24 15:04:16.220Z debug(compaction): Transfer.ledger:5: bar_commence: nothing to compact
2025-11-24 15:04:16.220Z debug(compaction): Transfer.code:5: bar_commence: nothing to compact
2025-11-24 15:04:16.220Z debug(compaction): Transfer:5: bar_commence: nothing to compact
2025-11-24 15:04:16.220Z debug(compaction): Transfer.expires_at:5: bar_commence: nothing to compact
2025-11-24 15:04:16.220Z debug(compaction): TransferPending:5: bar_commence: nothing to compact
2025-11-24 15:04:16.220Z debug(compaction): TransferPending.status:5: bar_commence: nothing to compact
2025-11-24 15:04:16.220Z debug(compaction): AccountEvent:5: bar_commence: nothing to compact
2025-11-24 15:04:16.220Z debug(compaction): Account.imported:5: bar_commence: nothing to compact
2025-11-24 15:04:16.220Z debug(compaction): Transfer.imported:5: bar_commence: nothing to compact
2025-11-24 15:04:16.220Z debug(compaction): Account.closed:5: bar_commence: nothing to compact
2025-11-24 15:04:16.220Z debug(compaction): Transfer.closing:5: bar_commence: nothing to compact
2025-11-24 15:04:16.220Z debug(compaction): AccountEvent.account_timestamp:5: bar_commence: nothing to compact
2025-11-24 15:04:16.220Z debug(compaction): AccountEvent.transfer_pending_status:5: bar_commence: nothing to compact
2025-11-24 15:04:16.220Z debug(compaction): AccountEvent.dr_account_id_expired:5: bar_commence: nothing to compact
2025-11-24 15:04:16.220Z debug(compaction): AccountEvent.cr_account_id_expired:5: bar_commence: nothing to compact
2025-11-24 15:04:16.220Z debug(compaction): AccountEvent.transfer_pending_id_expired:5: bar_commence: nothing to compact
2025-11-24 15:04:16.220Z debug(compaction): AccountEvent.ledger_expired:5: bar_commence: nothing to compact
2025-11-24 15:04:16.220Z debug(compaction): AccountEvent.prunable:5: bar_commence: nothing to compact
2025-11-24 15:04:16.220Z debug(replica): 1n: commit_start_journal: cached prepare op=129 checksum=30370352403006904875143586656723095742
2025-11-24 15:04:16.221Z debug(replica): 1n: execute_op: executing view=3 primary=false op=129 checksum=30370352403006904875143586656723095742 (create_transfers)
2025-11-24 15:04:16.221Z debug(replica): 1n: execute_op: commit_timestamp=1763996651947154405 prepare.header.timestamp=1763996653872660385
2025-11-24 15:04:16.221Z debug(replica): 0N: on_message: view=3 status=normal vsr.message_header.Header.Request{ .checksum = 145878784282764464388719038817018866562, .checksum_padding = 0, .checksum_body = 223534302417784426820269672909285101332, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 223616, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 284322140373623728580408544636297003964, .parent_padding = 0, .client = 47899338719226163297711645970010401862, .session = 2, .timestamp = 0, .request = 127, .operation = vsr.Operation(139), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 2114915545, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:04:16.221Z debug(replica): 0N: on_request: replying to duplicate request
2025-11-24 15:04:16.221Z debug(client_replies): 0: read_reply: start (client=47899338719226163297711645970010401862 reply=18244222555339071531525187129134853496)
2025-11-24 15:04:16.221Z debug(replica): 0N: on_message: view=3 status=normal vsr.message_header.Header.PrepareOk{ .checksum = 65759061733025748533228404245590527529, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 61409546665516173832840384617628896801, .parent_padding = 0, .prepare_checksum = 108899319724609156411158542483965582447, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 47899338719226163297711645970010401862, .op = 128, .commit_min = 127, .timestamp = 1763996651947154405, .request = 126, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-11-24 15:04:16.221Z debug(replica): 0N: on_prepare_ok: not preparing op=128 checksum=108899319724609156411158542483965582447
2025-11-24 15:04:16.222Z debug(client_replies): 0: read_reply: done (client=47899338719226163297711645970010401862 reply=18244222555339071531525187129134853496)
2025-11-24 15:04:16.222Z debug(replica): 0N: on_request: repeat reply (client=47899338719226163297711645970010401862 request=127)
2025-11-24 15:04:16.222Z debug(replica): 0N: sending reply to client 47899338719226163297711645970010401862: vsr.message_header.Header.Reply{ .checksum = 18244222555339071531525187129134853496, .checksum_padding = 0, .checksum_body = 311752944233308762869332694583075543730, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 264, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 145878784282764464388719038817018866562, .request_checksum_padding = 0, .context = 73877377662666956694541830594607326510, .context_padding = 0, .client = 47899338719226163297711645970010401862, .op = 129, .commit = 129, .timestamp = 1763996653872660385, .request = 127, .operation = vsr.Operation(139), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:04:16.223Z debug(replica): 2n: client_table_entry_update: client=47899338719226163297711645970010401862 session=2 request=127
2025-11-24 15:04:16.223Z debug(forest): entering forest.compact() op=129 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2025-11-24 15:04:16.226Z debug(vsr): 0: journal_repair_budget_timeout fired
2025-11-24 15:04:16.226Z debug(vsr): 0: journal_repair_budget_timeout reset
2025-11-24 15:04:16.228Z debug(replica): 1n: client_table_entry_update: client=47899338719226163297711645970010401862 session=2 request=127
2025-11-24 15:04:16.228Z debug(replica): 1n: execute_op: replying to client: vsr.message_header.Header.Reply{ .checksum = 18244222555339071531525187129134853496, .checksum_padding = 0, .checksum_body = 311752944233308762869332694583075543730, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 264, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 145878784282764464388719038817018866562, .request_checksum_padding = 0, .context = 73877377662666956694541830594607326510, .context_padding = 0, .client = 47899338719226163297711645970010401862, .op = 129, .commit = 129, .timestamp = 1763996653872660385, .request = 127, .operation = vsr.Operation(139), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:04:16.228Z debug(replica): 1n: sending reply to client 47899338719226163297711645970010401862: vsr.message_header.Header.Reply{ .checksum = 18244222555339071531525187129134853496, .checksum_padding = 0, .checksum_body = 311752944233308762869332694583075543730, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 264, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 145878784282764464388719038817018866562, .request_checksum_padding = 0, .context = 73877377662666956694541830594607326510, .context_padding = 0, .client = 47899338719226163297711645970010401862, .op = 129, .commit = 129, .timestamp = 1763996653872660385, .request = 127, .operation = vsr.Operation(139), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:04:16.228Z debug(forest): entering forest.compact() op=129 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2025-11-24 15:04:16.229Z debug(replica): 2n: on_message: view=3 status=normal vsr.message_header.Header.Request{ .checksum = 209445789965131376238533898150774579016, .checksum_padding = 0, .checksum_body = 326289093971322640297727606153193791024, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2240, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 73877377662666956694541830594607326510, .parent_padding = 0, .client = 47899338719226163297711645970010401862, .session = 2, .timestamp = 0, .request = 128, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 12970379, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:04:16.229Z debug(replica): 2n: on_request: forwarding new request to primary (view=3)
2025-11-24 15:04:16.229Z debug(replica): 2n: sending request to replica 0: vsr.message_header.Header.Request{ .checksum = 209445789965131376238533898150774579016, .checksum_padding = 0, .checksum_body = 326289093971322640297727606153193791024, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2240, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 73877377662666956694541830594607326510, .parent_padding = 0, .client = 47899338719226163297711645970010401862, .session = 2, .timestamp = 0, .request = 128, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 12970379, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:04:16.229Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.prepares offset=136314880 len=4096 unlocked
2025-11-24 15:04:16.229Z debug(journal): 2: write_header: op=130 sectors[32768..36864]
2025-11-24 15:04:16.229Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.headers offset=32768 len=4096 locked
2025-11-24 15:04:16.229Z debug(client_replies): 2: write_reply: wrote (client=47899338719226163297711645970010401862 request=127)
2025-11-24 15:04:16.229Z debug(replica): 0N: on_message: view=3 status=normal vsr.message_header.Header.Request{ .checksum = 209445789965131376238533898150774579016, .checksum_padding = 0, .checksum_body = 326289093971322640297727606153193791024, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2240, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 73877377662666956694541830594607326510, .parent_padding = 0, .client = 47899338719226163297711645970010401862, .session = 2, .timestamp = 0, .request = 128, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 12970379, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:04:16.229Z debug(vsr): 2: journal_repair_budget_timeout fired
2025-11-24 15:04:16.229Z debug(vsr): 2: journal_repair_budget_timeout reset
2025-11-24 15:04:16.229Z debug(replica): 0N: on_request: new request
2025-11-24 15:04:16.229Z debug(replica): 0N: on_request: ignoring (already preparing)
2025-11-24 15:04:16.229Z debug(replica): 2n: on_message: view=3 status=normal vsr.message_header.Header.PingClient{ .checksum = 155519281877223070960309837112622982089, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 0, .release = 0.0.1, .protocol = 0, .command = vsr.Command.ping_client, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .client = 47899338719226163297711645970010401862, .ping_timestamp_monotonic = 36214238481033308, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:04:16.229Z debug(replica): 2n: sending pong_client to client 47899338719226163297711645970010401862: vsr.message_header.Header.PongClient{ .checksum = 107339040698499865541610023640792461613, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.pong_client, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .ping_timestamp_monotonic = 36214238481033308, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:04:16.229Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.headers offset=32768 len=4096 unlocked
2025-11-24 15:04:16.229Z debug(journal): 2: write: view=3 slot=130 op=130 len=2240: 187478823532391127234834592963431897539 complete, marking clean
2025-11-24 15:04:16.229Z debug(replica): 2n: send_prepare_ok: op=130 checksum=187478823532391127234834592963431897539
2025-11-24 15:04:16.229Z debug(replica): 2n: sending prepare_ok to replica 0: vsr.message_header.Header.PrepareOk{ .checksum = 10416970330374719903338764819787761153, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 30370352403006904875143586656723095742, .parent_padding = 0, .prepare_checksum = 187478823532391127234834592963431897539, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 47899338719226163297711645970010401862, .op = 130, .commit_min = 129, .timestamp = 1763996653890065373, .request = 128, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-11-24 15:04:16.230Z debug(replica): 0N: on_message: view=3 status=normal vsr.message_header.Header.PrepareOk{ .checksum = 10416970330374719903338764819787761153, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 30370352403006904875143586656723095742, .parent_padding = 0, .prepare_checksum = 187478823532391127234834592963431897539, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 47899338719226163297711645970010401862, .op = 130, .commit_min = 129, .timestamp = 1763996653890065373, .request = 128, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-11-24 15:04:16.230Z debug(vsr): 0: primary_abdicate_timeout reset
2025-11-24 15:04:16.230Z debug(replica): 0N: on_prepare_ok: 2 message(s)
2025-11-24 15:04:16.230Z debug(replica): 0N: on_prepare_ok: quorum received, context=187478823532391127234834592963431897539
2025-11-24 15:04:16.230Z debug(vsr): 0: prepare_timeout stopped
2025-11-24 15:04:16.230Z debug(vsr): 0: primary_abdicate_timeout stopped
2025-11-24 15:04:16.230Z debug(replica): 0N: execute_op: executing view=3 primary=true op=130 checksum=187478823532391127234834592963431897539 (lookup_accounts)
2025-11-24 15:04:16.230Z debug(replica): 0N: execute_op: commit_timestamp=1763996653872660385 prepare.header.timestamp=1763996653890065373
2025-11-24 15:04:16.230Z debug(replica): 0N: execute_op: advancing commit_max=129..130
2025-11-24 15:04:16.230Z debug(replica): 0N: client_table_entry_update: client=47899338719226163297711645970010401862 session=2 request=128
2025-11-24 15:04:16.230Z debug(replica): 0N: execute_op: replying to client: vsr.message_header.Header.Reply{ .checksum = 277724582837712356938301052522302113318, .checksum_padding = 0, .checksum_body = 28660953513852756887522048579610843282, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 16128, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 209445789965131376238533898150774579016, .request_checksum_padding = 0, .context = 116763286385579920083328807655380641333, .context_padding = 0, .client = 47899338719226163297711645970010401862, .op = 130, .commit = 130, .timestamp = 1763996653890065373, .request = 128, .operation = vsr.Operation(140), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:04:16.231Z debug(replica): 0N: sending reply to client 47899338719226163297711645970010401862: vsr.message_header.Header.Reply{ .checksum = 277724582837712356938301052522302113318, .checksum_padding = 0, .checksum_body = 28660953513852756887522048579610843282, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 16128, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 209445789965131376238533898150774579016, .request_checksum_padding = 0, .context = 116763286385579920083328807655380641333, .context_padding = 0, .client = 47899338719226163297711645970010401862, .op = 130, .commit = 130, .timestamp = 1763996653890065373, .request = 128, .operation = vsr.Operation(140), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:04:16.231Z debug(forest): entering forest.compact() op=130 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2025-11-24 15:04:16.232Z debug(client_replies): 0: write_reply: wrote (client=47899338719226163297711645970010401862 request=128)
2025-11-24 15:04:16.234Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.prepares offset=136314880 len=4096 unlocked
2025-11-24 15:04:16.234Z debug(journal): 1: write_header: op=130 sectors[32768..36864]
2025-11-24 15:04:16.234Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.headers offset=32768 len=4096 locked
2025-11-24 15:04:16.234Z debug(client_replies): 1: write_reply: wrote (client=47899338719226163297711645970010401862 request=126)
2025-11-24 15:04:16.235Z debug(vsr): 1: journal_repair_budget_timeout fired
2025-11-24 15:04:16.235Z debug(vsr): 1: journal_repair_budget_timeout reset
2025-11-24 15:04:16.235Z debug(client_replies): 1: write_reply: wrote (client=47899338719226163297711645970010401862 request=127)
2025-11-24 15:04:16.235Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.prepares offset=135266304 len=225280 unlocked
2025-11-24 15:04:16.235Z debug(journal): 1: write_header: op=129 sectors[32768..36864]
2025-11-24 15:04:16.235Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.headers offset=32768 len=4096 unlocked
2025-11-24 15:04:16.235Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.headers offset=32768 len=4096 locked
2025-11-24 15:04:16.235Z debug(journal): 1: write: view=3 slot=130 op=130 len=2240: 187478823532391127234834592963431897539 complete, marking clean
2025-11-24 15:04:16.235Z debug(replica): 1n: send_prepare_ok: op=130 checksum=187478823532391127234834592963431897539
2025-11-24 15:04:16.235Z debug(replica): 1n: sending prepare_ok to replica 0: vsr.message_header.Header.PrepareOk{ .checksum = 227466414827287184414324067807506761522, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 30370352403006904875143586656723095742, .parent_padding = 0, .prepare_checksum = 187478823532391127234834592963431897539, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 47899338719226163297711645970010401862, .op = 130, .commit_min = 129, .timestamp = 1763996653890065373, .request = 128, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-11-24 15:04:16.235Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.headers offset=32768 len=4096 unlocked
2025-11-24 15:04:16.235Z debug(journal): 1: write: view=3 slot=129 op=129 len=223616: 30370352403006904875143586656723095742 complete, marking clean
2025-11-24 15:04:16.235Z debug(replica): 1n: send_prepare_ok: op=129 checksum=30370352403006904875143586656723095742
2025-11-24 15:04:16.235Z debug(replica): 1n: sending prepare_ok to replica 0: vsr.message_header.Header.PrepareOk{ .checksum = 214265633798858647053603272797796734302, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 108899319724609156411158542483965582447, .parent_padding = 0, .prepare_checksum = 30370352403006904875143586656723095742, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 47899338719226163297711645970010401862, .op = 129, .commit_min = 129, .timestamp = 1763996653872660385, .request = 127, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-11-24 15:04:16.235Z debug(replica): 0N: on_message: view=3 status=normal vsr.message_header.Header.PrepareOk{ .checksum = 227466414827287184414324067807506761522, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 30370352403006904875143586656723095742, .parent_padding = 0, .prepare_checksum = 187478823532391127234834592963431897539, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 47899338719226163297711645970010401862, .op = 130, .commit_min = 129, .timestamp = 1763996653890065373, .request = 128, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-11-24 15:04:16.235Z debug(replica): 0N: on_prepare_ok: not preparing op=130 checksum=187478823532391127234834592963431897539
2025-11-24 15:04:16.246Z debug(vsr): 0: journal_repair_budget_timeout fired
2025-11-24 15:04:16.246Z debug(vsr): 0: journal_repair_budget_timeout reset
2025-11-24 15:04:16.249Z debug(vsr): 2: journal_repair_budget_timeout fired
2025-11-24 15:04:16.249Z debug(vsr): 2: journal_repair_budget_timeout reset
2025-11-24 15:04:16.255Z debug(vsr): 1: journal_repair_budget_timeout fired
2025-11-24 15:04:16.255Z debug(vsr): 1: journal_repair_budget_timeout reset
warning(client): 47899338719226163297711645970010401862: on_reply: slow request, request=128 op=130 size=2240 lookup_accounts time=2366ms
2025-11-24 15:04:16.257Z info(workload): accounts created = 123, transfers = 141554, pending transfers = 0, commands run = 64
2025-11-24 15:04:16.265Z debug(vsr): 1: journal_repair_timeout fired
2025-11-24 15:04:16.265Z debug(vsr): 1: journal_repair_timeout reset
2025-11-24 15:04:16.266Z debug(vsr): 0: journal_repair_budget_timeout fired
2025-11-24 15:04:16.269Z debug(vsr): 2: journal_repair_budget_timeout fired
2025-11-24 15:04:16.275Z debug(replica): 1n: on_message: view=3 status=normal vsr.message_header.Header.Request{ .checksum = 205482676763264284441076365850162922661, .checksum_padding = 0, .checksum_body = 129182970691628556363288656237757415136, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 895616, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 116763286385579920083328807655380641333, .parent_padding = 0, .client = 47899338719226163297711645970010401862, .session = 2, .timestamp = 0, .request = 129, .operation = vsr.Operation(139), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 2367151764, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:04:17.971Z debug(vsr): 2: journal_repair_budget_timeout reset
2025-11-24 15:04:16.266Z debug(vsr): 0: journal_repair_budget_timeout reset
2025-11-24 15:04:17.971Z debug(replica): 1n: on_request: forwarding new request to primary (view=3)
2025-11-24 15:04:17.971Z debug(replica): 1n: sending request to replica 0: vsr.message_header.Header.Request{ .checksum = 205482676763264284441076365850162922661, .checksum_padding = 0, .checksum_body = 129182970691628556363288656237757415136, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 895616, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 116763286385579920083328807655380641333, .parent_padding = 0, .client = 47899338719226163297711645970010401862, .session = 2, .timestamp = 0, .request = 129, .operation = vsr.Operation(139), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 2367151764, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:04:17.971Z debug(replica): 0N: on_message: view=3 status=normal vsr.message_header.Header.PrepareOk{ .checksum = 214265633798858647053603272797796734302, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 108899319724609156411158542483965582447, .parent_padding = 0, .prepare_checksum = 30370352403006904875143586656723095742, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 47899338719226163297711645970010401862, .op = 129, .commit_min = 129, .timestamp = 1763996653872660385, .request = 127, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-11-24 15:04:17.971Z debug(replica): 0N: on_prepare_ok: not preparing op=129 checksum=30370352403006904875143586656723095742
2025-11-24 15:04:17.976Z debug(replica): 0N: on_message: view=3 status=normal vsr.message_header.Header.Request{ .checksum = 205482676763264284441076365850162922661, .checksum_padding = 0, .checksum_body = 129182970691628556363288656237757415136, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 895616, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 116763286385579920083328807655380641333, .parent_padding = 0, .client = 47899338719226163297711645970010401862, .session = 2, .timestamp = 0, .request = 129, .operation = vsr.Operation(139), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 2367151764, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:04:17.976Z debug(replica): 0N: on_request: new request
2025-11-24 15:04:17.976Z debug(replica): 0N: primary_pipeline_prepare: request checksum=205482676763264284441076365850162922661 client=47899338719226163297711645970010401862
2025-11-24 15:04:17.976Z debug(replica): 1n: on_message: view=3 status=normal vsr.message_header.Header.Request{ .checksum = 205482676763264284441076365850162922661, .checksum_padding = 0, .checksum_body = 129182970691628556363288656237757415136, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 895616, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 116763286385579920083328807655380641333, .parent_padding = 0, .client = 47899338719226163297711645970010401862, .session = 2, .timestamp = 0, .request = 129, .operation = vsr.Operation(139), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 2367151764, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:04:17.976Z debug(replica): 1n: on_request: forwarding new request to primary (view=3)
2025-11-24 15:04:17.976Z debug(replica): 1n: sending request to replica 0: vsr.message_header.Header.Request{ .checksum = 205482676763264284441076365850162922661, .checksum_padding = 0, .checksum_body = 129182970691628556363288656237757415136, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 895616, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 116763286385579920083328807655380641333, .parent_padding = 0, .client = 47899338719226163297711645970010401862, .session = 2, .timestamp = 0, .request = 129, .operation = vsr.Operation(139), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 2367151764, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:04:17.977Z debug(vsr): 1: journal_repair_budget_timeout fired
2025-11-24 15:04:17.977Z debug(vsr): 1: journal_repair_budget_timeout reset
2025-11-24 15:04:17.981Z debug(replica): 0N: primary_pipeline_prepare: prepare checksum=159279544561239178784939675080247518159 op=131
2025-11-24 15:04:17.981Z debug(vsr): 0: prepare_timeout started
2025-11-24 15:04:17.981Z debug(vsr): 0: primary_abdicate_timeout started
2025-11-24 15:04:17.981Z debug(vsr): 0: pulse_timeout reset
2025-11-24 15:04:17.981Z debug(replica): 0N: replicate: replicating op=131 to replica 2
2025-11-24 15:04:17.981Z debug(replica): 0N: sending prepare to replica 2: vsr.message_header.Header.Prepare{ .checksum = 159279544561239178784939675080247518159, .checksum_padding = 0, .checksum_body = 129182970691628556363288656237757415136, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 895616, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 187478823532391127234834592963431897539, .parent_padding = 0, .request_checksum = 205482676763264284441076365850162922661, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 47899338719226163297711645970010401862, .op = 131, .commit = 130, .timestamp = 1763996657976671190, .request = 129, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-11-24 15:04:17.981Z debug(replica): 0N: replicate: replicating op=131 to replica 1
2025-11-24 15:04:17.981Z debug(replica): 0N: sending prepare to replica 1: vsr.message_header.Header.Prepare{ .checksum = 159279544561239178784939675080247518159, .checksum_padding = 0, .checksum_body = 129182970691628556363288656237757415136, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 895616, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 187478823532391127234834592963431897539, .parent_padding = 0, .request_checksum = 205482676763264284441076365850162922661, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 47899338719226163297711645970010401862, .op = 131, .commit = 130, .timestamp = 1763996657976671190, .request = 129, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-11-24 15:04:17.981Z debug(replica): 0N: on_prepare: advancing: op=130..131 checksum=187478823532391127234834592963431897539..159279544561239178784939675080247518159
2025-11-24 15:04:17.981Z debug(journal): 0: set_header_as_dirty: op=131 checksum=159279544561239178784939675080247518159
2025-11-24 15:04:17.981Z debug(replica): 0N: append: appending to journal op=131
2025-11-24 15:04:17.981Z debug(journal): 0: write: view=3 slot=131 op=131 len=895616: 159279544561239178784939675080247518159 starting
2025-11-24 15:04:17.981Z debug(journal): 0: write_sectors: ring=vsr.journal.Ring.prepares offset=137363456 len=897024 locked
2025-11-24 15:04:17.985Z debug(replica): 2n: on_message: view=3 status=normal vsr.message_header.Header.Prepare{ .checksum = 159279544561239178784939675080247518159, .checksum_padding = 0, .checksum_body = 129182970691628556363288656237757415136, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 895616, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 187478823532391127234834592963431897539, .parent_padding = 0, .request_checksum = 205482676763264284441076365850162922661, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 47899338719226163297711645970010401862, .op = 131, .commit = 130, .timestamp = 1763996657976671190, .request = 129, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-11-24 15:04:17.985Z debug(replica): 2n: on_prepare: advancing commit_max=129..130
2025-11-24 15:04:17.985Z debug(replica): 2n: on_prepare: caching prepare.op=131 (commit_min=129 op=130 commit_max=130 prepare_max=1007)
2025-11-24 15:04:17.986Z debug(replica): 2n: on_prepare: advancing: op=130..131 checksum=187478823532391127234834592963431897539..159279544561239178784939675080247518159
2025-11-24 15:04:17.986Z debug(journal): 2: set_header_as_dirty: op=131 checksum=159279544561239178784939675080247518159
2025-11-24 15:04:17.986Z debug(replica): 2n: append: appending to journal op=131
2025-11-24 15:04:17.986Z debug(journal): 2: write: view=3 slot=131 op=131 len=895616: 159279544561239178784939675080247518159 starting
2025-11-24 15:04:17.986Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.prepares offset=137363456 len=897024 locked
2025-11-24 15:04:17.986Z debug(replica): 2n: commit_start_journal: cached prepare op=130 checksum=187478823532391127234834592963431897539
2025-11-24 15:04:17.986Z debug(replica): 2n: repair_prepare: op=131 checksum=159279544561239178784939675080247518159 (already writing)
2025-11-24 15:04:17.986Z debug(replica): 2n: commit_journal: already committing (prefetch; commit_min=129)
2025-11-24 15:04:17.986Z debug(replica): 2n: execute_op: executing view=3 primary=false op=130 checksum=187478823532391127234834592963431897539 (lookup_accounts)
2025-11-24 15:04:17.986Z debug(replica): 2n: execute_op: commit_timestamp=1763996653872660385 prepare.header.timestamp=1763996653890065373
2025-11-24 15:04:17.986Z debug(replica): 2n: client_table_entry_update: client=47899338719226163297711645970010401862 session=2 request=128
2025-11-24 15:04:17.986Z debug(forest): entering forest.compact() op=130 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2025-11-24 15:04:17.986Z debug(client_replies): 2: write_reply: wrote (client=47899338719226163297711645970010401862 request=128)
2025-11-24 15:04:17.986Z debug(replica): 0N: on_message: view=3 status=normal vsr.message_header.Header.Request{ .checksum = 205482676763264284441076365850162922661, .checksum_padding = 0, .checksum_body = 129182970691628556363288656237757415136, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 895616, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 116763286385579920083328807655380641333, .parent_padding = 0, .client = 47899338719226163297711645970010401862, .session = 2, .timestamp = 0, .request = 129, .operation = vsr.Operation(139), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 2367151764, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:04:17.987Z debug(replica): 0N: on_request: new request
2025-11-24 15:04:17.987Z debug(replica): 0N: on_request: ignoring (already preparing)
2025-11-24 15:04:17.987Z debug(replica): 1n: on_message: view=3 status=normal vsr.message_header.Header.Prepare{ .checksum = 159279544561239178784939675080247518159, .checksum_padding = 0, .checksum_body = 129182970691628556363288656237757415136, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 895616, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 187478823532391127234834592963431897539, .parent_padding = 0, .request_checksum = 205482676763264284441076365850162922661, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 47899338719226163297711645970010401862, .op = 131, .commit = 130, .timestamp = 1763996657976671190, .request = 129, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-11-24 15:04:17.987Z debug(replica): 1n: on_prepare: advancing commit_max=129..130
2025-11-24 15:04:17.987Z debug(replica): 1n: on_prepare: caching prepare.op=131 (commit_min=129 op=130 commit_max=130 prepare_max=1007)
2025-11-24 15:04:17.987Z debug(replica): 1n: on_prepare: advancing: op=130..131 checksum=187478823532391127234834592963431897539..159279544561239178784939675080247518159
2025-11-24 15:04:17.987Z debug(journal): 1: set_header_as_dirty: op=131 checksum=159279544561239178784939675080247518159
2025-11-24 15:04:17.987Z debug(replica): 1n: append: appending to journal op=131
2025-11-24 15:04:17.987Z debug(journal): 1: write: view=3 slot=131 op=131 len=895616: 159279544561239178784939675080247518159 starting
2025-11-24 15:04:17.987Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.prepares offset=137363456 len=897024 locked
2025-11-24 15:04:17.987Z debug(replica): 1n: commit_start_journal: cached prepare op=130 checksum=187478823532391127234834592963431897539
2025-11-24 15:04:17.987Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.prepares offset=137363456 len=897024 unlocked
2025-11-24 15:04:17.987Z debug(journal): 2: write_header: op=131 sectors[32768..36864]
2025-11-24 15:04:17.987Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.headers offset=32768 len=4096 locked
2025-11-24 15:04:17.987Z debug(journal): 0: write_sectors: ring=vsr.journal.Ring.prepares offset=137363456 len=897024 unlocked
2025-11-24 15:04:17.987Z debug(journal): 0: write_header: op=131 sectors[32768..36864]
2025-11-24 15:04:17.987Z debug(journal): 0: write_sectors: ring=vsr.journal.Ring.headers offset=32768 len=4096 locked
2025-11-24 15:04:17.987Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.headers offset=32768 len=4096 unlocked
2025-11-24 15:04:17.987Z debug(journal): 2: write: view=3 slot=131 op=131 len=895616: 159279544561239178784939675080247518159 complete, marking clean
2025-11-24 15:04:17.987Z debug(replica): 2n: send_prepare_ok: op=131 checksum=159279544561239178784939675080247518159
2025-11-24 15:04:17.987Z debug(replica): 2n: sending prepare_ok to replica 0: vsr.message_header.Header.PrepareOk{ .checksum = 23747328051198280095448645032231784707, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 187478823532391127234834592963431897539, .parent_padding = 0, .prepare_checksum = 159279544561239178784939675080247518159, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 47899338719226163297711645970010401862, .op = 131, .commit_min = 130, .timestamp = 1763996657976671190, .request = 129, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-11-24 15:04:17.987Z debug(replica): 1n: repair_prepare: op=131 checksum=159279544561239178784939675080247518159 (already writing)
2025-11-24 15:04:17.987Z debug(replica): 1n: commit_journal: already committing (prefetch; commit_min=129)
2025-11-24 15:04:17.987Z debug(replica): 1n: execute_op: executing view=3 primary=false op=130 checksum=187478823532391127234834592963431897539 (lookup_accounts)
2025-11-24 15:04:17.987Z debug(replica): 1n: execute_op: commit_timestamp=1763996653872660385 prepare.header.timestamp=1763996653890065373
2025-11-24 15:04:17.987Z debug(replica): 0N: on_message: view=3 status=normal vsr.message_header.Header.PrepareOk{ .checksum = 23747328051198280095448645032231784707, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 187478823532391127234834592963431897539, .parent_padding = 0, .prepare_checksum = 159279544561239178784939675080247518159, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 47899338719226163297711645970010401862, .op = 131, .commit_min = 130, .timestamp = 1763996657976671190, .request = 129, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-11-24 15:04:17.987Z debug(vsr): 0: primary_abdicate_timeout reset
2025-11-24 15:04:17.987Z debug(replica): 0N: on_prepare_ok: 1 message(s)
2025-11-24 15:04:17.987Z debug(replica): 0N: on_prepare_ok: waiting for quorum
2025-11-24 15:04:17.987Z debug(journal): 0: write_sectors: ring=vsr.journal.Ring.headers offset=32768 len=4096 unlocked
2025-11-24 15:04:17.987Z debug(journal): 0: write: view=3 slot=131 op=131 len=895616: 159279544561239178784939675080247518159 complete, marking clean
2025-11-24 15:04:17.987Z debug(replica): 0N: send_prepare_ok: op=131 checksum=159279544561239178784939675080247518159
2025-11-24 15:04:17.987Z debug(replica): 1n: client_table_entry_update: client=47899338719226163297711645970010401862 session=2 request=128
2025-11-24 15:04:17.987Z debug(replica): 0N: sending prepare_ok to replica 0: vsr.message_header.Header.PrepareOk{ .checksum = 129811552815901791301856075691610567271, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 187478823532391127234834592963431897539, .parent_padding = 0, .prepare_checksum = 159279544561239178784939675080247518159, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 47899338719226163297711645970010401862, .op = 131, .commit_min = 130, .timestamp = 1763996657976671190, .request = 129, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-11-24 15:04:17.987Z debug(replica): 1n: execute_op: replying to client: vsr.message_header.Header.Reply{ .checksum = 277724582837712356938301052522302113318, .checksum_padding = 0, .checksum_body = 28660953513852756887522048579610843282, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 16128, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 209445789965131376238533898150774579016, .request_checksum_padding = 0, .context = 116763286385579920083328807655380641333, .context_padding = 0, .client = 47899338719226163297711645970010401862, .op = 130, .commit = 130, .timestamp = 1763996653890065373, .request = 128, .operation = vsr.Operation(140), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:04:17.987Z debug(replica): 0N: on_message: view=3 status=normal vsr.message_header.Header.PrepareOk{ .checksum = 129811552815901791301856075691610567271, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 187478823532391127234834592963431897539, .parent_padding = 0, .prepare_checksum = 159279544561239178784939675080247518159, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 47899338719226163297711645970010401862, .op = 131, .commit_min = 130, .timestamp = 1763996657976671190, .request = 129, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-11-24 15:04:17.987Z debug(vsr): 0: primary_abdicate_timeout reset
2025-11-24 15:04:17.987Z debug(replica): 1n: sending reply to client 47899338719226163297711645970010401862: vsr.message_header.Header.Reply{ .checksum = 277724582837712356938301052522302113318, .checksum_padding = 0, .checksum_body = 28660953513852756887522048579610843282, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 16128, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 209445789965131376238533898150774579016, .request_checksum_padding = 0, .context = 116763286385579920083328807655380641333, .context_padding = 0, .client = 47899338719226163297711645970010401862, .op = 130, .commit = 130, .timestamp = 1763996653890065373, .request = 128, .operation = vsr.Operation(140), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:04:17.987Z debug(replica): 0N: on_prepare_ok: 2 message(s)
2025-11-24 15:04:17.987Z debug(replica): 0N: on_prepare_ok: quorum received, context=159279544561239178784939675080247518159
2025-11-24 15:04:17.987Z debug(vsr): 0: prepare_timeout stopped
2025-11-24 15:04:17.987Z debug(vsr): 0: primary_abdicate_timeout stopped
2025-11-24 15:04:17.987Z debug(forest): entering forest.compact() op=130 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2025-11-24 15:04:17.987Z debug(client_replies): 1: write_reply: wrote (client=47899338719226163297711645970010401862 request=128)
2025-11-24 15:04:17.988Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.prepares offset=137363456 len=897024 unlocked
2025-11-24 15:04:17.988Z debug(journal): 1: write_header: op=131 sectors[32768..36864]
2025-11-24 15:04:17.988Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.headers offset=32768 len=4096 locked
2025-11-24 15:04:17.988Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.headers offset=32768 len=4096 unlocked
2025-11-24 15:04:17.988Z debug(journal): 1: write: view=3 slot=131 op=131 len=895616: 159279544561239178784939675080247518159 complete, marking clean
2025-11-24 15:04:17.988Z debug(replica): 1n: send_prepare_ok: op=131 checksum=159279544561239178784939675080247518159
2025-11-24 15:04:17.988Z debug(replica): 1n: sending prepare_ok to replica 0: vsr.message_header.Header.PrepareOk{ .checksum = 149260360295804854358136457478062511291, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 187478823532391127234834592963431897539, .parent_padding = 0, .prepare_checksum = 159279544561239178784939675080247518159, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 47899338719226163297711645970010401862, .op = 131, .commit_min = 130, .timestamp = 1763996657976671190, .request = 129, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-11-24 15:04:17.991Z debug(replica): 0N: execute_op: executing view=3 primary=true op=131 checksum=159279544561239178784939675080247518159 (create_transfers)
2025-11-24 15:04:17.991Z debug(replica): 0N: execute_op: commit_timestamp=1763996653890065373 prepare.header.timestamp=1763996657976671190
2025-11-24 15:04:17.991Z debug(vsr): 2: journal_repair_budget_timeout fired
2025-11-24 15:04:17.991Z debug(vsr): 2: journal_repair_budget_timeout reset
2025-11-24 15:04:17.998Z debug(vsr): 1: journal_repair_budget_timeout fired
2025-11-24 15:04:17.998Z debug(vsr): 1: journal_repair_budget_timeout reset
2025-11-24 15:04:18.011Z debug(vsr): 2: journal_repair_budget_timeout fired
2025-11-24 15:04:18.011Z debug(vsr): 2: journal_repair_budget_timeout reset
2025-11-24 15:04:18.018Z debug(vsr): 1: journal_repair_budget_timeout fired
2025-11-24 15:04:18.018Z debug(vsr): 1: journal_repair_budget_timeout reset
2025-11-24 15:04:18.021Z debug(replica): 0N: execute_op: advancing commit_max=130..131
2025-11-24 15:04:18.021Z debug(replica): 0N: client_table_entry_update: client=47899338719226163297711645970010401862 session=2 request=129
2025-11-24 15:04:18.021Z debug(replica): 0N: execute_op: replying to client: vsr.message_header.Header.Reply{ .checksum = 263196637784657531143489452795006830212, .checksum_padding = 0, .checksum_body = 325783673900111050981678550500987780713, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 328, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 205482676763264284441076365850162922661, .request_checksum_padding = 0, .context = 316503818546185516714333301991110604703, .context_padding = 0, .client = 47899338719226163297711645970010401862, .op = 131, .commit = 131, .timestamp = 1763996657976671190, .request = 129, .operation = vsr.Operation(139), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:04:18.021Z debug(replica): 0N: sending reply to client 47899338719226163297711645970010401862: vsr.message_header.Header.Reply{ .checksum = 263196637784657531143489452795006830212, .checksum_padding = 0, .checksum_body = 325783673900111050981678550500987780713, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 328, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 205482676763264284441076365850162922661, .request_checksum_padding = 0, .context = 316503818546185516714333301991110604703, .context_padding = 0, .client = 47899338719226163297711645970010401862, .op = 131, .commit = 131, .timestamp = 1763996657976671190, .request = 129, .operation = vsr.Operation(139), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:04:18.021Z debug(vsr): 2: ping_timeout fired
2025-11-24 15:04:18.021Z debug(vsr): 2: ping_timeout reset
2025-11-24 15:04:18.021Z debug(replica): 2n: sending ping to replica 0: vsr.message_header.Header.Ping{ .checksum = 118359567628224697751344430036804024325, .checksum_padding = 0, .checksum_body = 154787626362930377789479683857780696253, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 512, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.ping, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .checkpoint_id = 321854455202207724029466302309042662424, .checkpoint_op = 0, .ping_timestamp_monotonic = 36214240973655344, .release_count = 1, .route_padding = { 0, 0, 0, 0, 0, 0 }, .route = 0, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:04:18.021Z debug(forest): entering forest.compact() op=131 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2025-11-24 15:04:18.021Z debug(replica): 2n: sending ping to replica 1: vsr.message_header.Header.Ping{ .checksum = 118359567628224697751344430036804024325, .checksum_padding = 0, .checksum_body = 154787626362930377789479683857780696253, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 512, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.ping, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .checkpoint_id = 321854455202207724029466302309042662424, .checkpoint_op = 0, .ping_timestamp_monotonic = 36214240973655344, .release_count = 1, .route_padding = { 0, 0, 0, 0, 0, 0 }, .route = 0, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
warning(client): 47899338719226163297711645970010401862: on_reply: slow request, request=129 op=131 size=895616 create_transfers time=1759ms
2025-11-24 15:04:18.022Z debug(vsr): 2: start_view_change_message_timeout fired
2025-11-24 15:04:18.022Z debug(vsr): 2: start_view_change_message_timeout reset
2025-11-24 15:04:18.022Z debug(vsr): 2: journal_repair_timeout fired
2025-11-24 15:04:18.022Z debug(vsr): 2: journal_repair_timeout reset
2025-11-24 15:04:18.022Z debug(replica): 1n: on_message: view=3 status=normal vsr.message_header.Header.Ping{ .checksum = 118359567628224697751344430036804024325, .checksum_padding = 0, .checksum_body = 154787626362930377789479683857780696253, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 512, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.ping, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .checkpoint_id = 321854455202207724029466302309042662424, .checkpoint_op = 0, .ping_timestamp_monotonic = 36214240973655344, .release_count = 1, .route_padding = { 0, 0, 0, 0, 0, 0 }, .route = 0, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:04:18.022Z debug(replica): 1n: sending pong to replica 2: vsr.message_header.Header.Pong{ .checksum = 218285262530651083664567457776622037712, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.pong, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .ping_timestamp_monotonic = 36214240973655344, .pong_timestamp_wall = 1763996658022106717, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:04:18.022Z debug(vsr): 2: grid_repair_budget_timeout fired
2025-11-24 15:04:18.022Z debug(vsr): 2: grid_repair_budget_timeout reset
2025-11-24 15:04:18.022Z debug(replica): 2n: on_message: view=3 status=normal vsr.message_header.Header.Pong{ .checksum = 218285262530651083664567457776622037712, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.pong, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .ping_timestamp_monotonic = 36214240973655344, .pong_timestamp_wall = 1763996658022106717, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:04:18.022Z debug(clock): 2: learn: replica=1 m0=36214240973655344 t1=1763996658022106717 m2=36214240974101315 t2=1763996658022328917 one_way_delay=222985 asymmetric_delay=0 clock_offset=785
2025-11-24 15:04:18.032Z debug(clock): 2: synchronized: truechimers=2/3 clock_offset=0ns..0ns accuracy=0ns
2025-11-24 15:04:18.032Z debug(clock): 2: system time is 60ns behind
2025-11-24 15:04:18.032Z debug(vsr): 2: journal_repair_budget_timeout fired
2025-11-24 15:04:18.032Z debug(vsr): 2: journal_repair_budget_timeout reset
2025-11-24 15:04:18.036Z debug(replica): 0N: on_message: view=3 status=normal vsr.message_header.Header.Ping{ .checksum = 118359567628224697751344430036804024325, .checksum_padding = 0, .checksum_body = 154787626362930377789479683857780696253, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 512, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.ping, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .checkpoint_id = 321854455202207724029466302309042662424, .checkpoint_op = 0, .ping_timestamp_monotonic = 36214240973655344, .release_count = 1, .route_padding = { 0, 0, 0, 0, 0, 0 }, .route = 0, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:04:18.036Z debug(replica): 0N: sending pong to replica 2: vsr.message_header.Header.Pong{ .checksum = 109099440640816744644982623756522112725, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.pong, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .ping_timestamp_monotonic = 36214240973655344, .pong_timestamp_wall = 1763996658036737537, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:04:18.036Z debug(replica): 2n: on_message: view=3 status=normal vsr.message_header.Header.Pong{ .checksum = 109099440640816744644982623756522112725, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.pong, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .ping_timestamp_monotonic = 36214240973655344, .pong_timestamp_wall = 1763996658036737537, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:04:18.036Z debug(clock): 2: learn: m0=36214240973655344 < window.monotonic=36214240984071902
2025-11-24 15:04:18.037Z debug(client_replies): 0: write_reply: wrote (client=47899338719226163297711645970010401862 request=129)
2025-11-24 15:04:18.038Z debug(vsr): 1: journal_repair_budget_timeout fired
2025-11-24 15:04:18.038Z debug(vsr): 1: journal_repair_budget_timeout reset
2025-11-24 15:04:18.042Z debug(replica): 0N: on_message: view=3 status=normal vsr.message_header.Header.Request{ .checksum = 205482676763264284441076365850162922661, .checksum_padding = 0, .checksum_body = 129182970691628556363288656237757415136, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 895616, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 116763286385579920083328807655380641333, .parent_padding = 0, .client = 47899338719226163297711645970010401862, .session = 2, .timestamp = 0, .request = 129, .operation = vsr.Operation(139), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 2367151764, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:04:18.042Z debug(replica): 0N: on_request: replying to duplicate request
2025-11-24 15:04:18.042Z debug(client_replies): 0: read_reply: start (client=47899338719226163297711645970010401862 reply=263196637784657531143489452795006830212)
2025-11-24 15:04:18.047Z debug(replica): 1n: on_message: view=3 status=normal vsr.message_header.Header.Request{ .checksum = 30633888162351370674734440574199062745, .checksum_padding = 0, .checksum_body = 326289093971322640297727606153193791024, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2240, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 316503818546185516714333301991110604703, .parent_padding = 0, .client = 47899338719226163297711645970010401862, .session = 2, .timestamp = 0, .request = 130, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 1759450096, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:04:18.047Z debug(replica): 1n: on_request: forwarding new request to primary (view=3)
2025-11-24 15:04:18.047Z debug(replica): 1n: sending request to replica 0: vsr.message_header.Header.Request{ .checksum = 30633888162351370674734440574199062745, .checksum_padding = 0, .checksum_body = 326289093971322640297727606153193791024, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2240, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 316503818546185516714333301991110604703, .parent_padding = 0, .client = 47899338719226163297711645970010401862, .session = 2, .timestamp = 0, .request = 130, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 1759450096, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:04:18.047Z debug(replica): 0N: on_message: view=3 status=normal vsr.message_header.Header.Request{ .checksum = 205482676763264284441076365850162922661, .checksum_padding = 0, .checksum_body = 129182970691628556363288656237757415136, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 895616, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 116763286385579920083328807655380641333, .parent_padding = 0, .client = 47899338719226163297711645970010401862, .session = 2, .timestamp = 0, .request = 129, .operation = vsr.Operation(139), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 2367151764, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:04:18.047Z debug(replica): 0N: on_request: replying to duplicate request
2025-11-24 15:04:18.047Z debug(client_replies): 0: read_reply: busy (client=47899338719226163297711645970010401862 reply=263196637784657531143489452795006830212)
2025-11-24 15:04:18.047Z debug(replica): 0N: on_request: ignoring (client_replies busy)
2025-11-24 15:04:18.047Z debug(replica): 0N: on_message: view=3 status=normal vsr.message_header.Header.PrepareOk{ .checksum = 149260360295804854358136457478062511291, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 187478823532391127234834592963431897539, .parent_padding = 0, .prepare_checksum = 159279544561239178784939675080247518159, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 47899338719226163297711645970010401862, .op = 131, .commit_min = 130, .timestamp = 1763996657976671190, .request = 129, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-11-24 15:04:18.047Z debug(replica): 0N: on_prepare_ok: not preparing op=131 checksum=159279544561239178784939675080247518159
2025-11-24 15:04:18.047Z debug(replica): 0N: on_message: view=3 status=normal vsr.message_header.Header.Request{ .checksum = 30633888162351370674734440574199062745, .checksum_padding = 0, .checksum_body = 326289093971322640297727606153193791024, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2240, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 316503818546185516714333301991110604703, .parent_padding = 0, .client = 47899338719226163297711645970010401862, .session = 2, .timestamp = 0, .request = 130, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 1759450096, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:04:18.048Z debug(replica): 0N: on_request: new request
2025-11-24 15:04:18.048Z debug(replica): 0N: primary_pipeline_prepare: request checksum=30633888162351370674734440574199062745 client=47899338719226163297711645970010401862
2025-11-24 15:04:18.048Z debug(replica): 0N: primary_pipeline_prepare: prepare checksum=307288560402019589988054472057743513540 op=132
2025-11-24 15:04:18.048Z debug(vsr): 0: prepare_timeout started
2025-11-24 15:04:18.048Z debug(vsr): 0: primary_abdicate_timeout started
2025-11-24 15:04:18.048Z debug(vsr): 0: pulse_timeout reset
2025-11-24 15:04:18.048Z debug(replica): 0N: replicate: replicating op=132 to replica 2
2025-11-24 15:04:18.048Z debug(replica): 0N: sending prepare to replica 2: vsr.message_header.Header.Prepare{ .checksum = 307288560402019589988054472057743513540, .checksum_padding = 0, .checksum_body = 326289093971322640297727606153193791024, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2240, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 159279544561239178784939675080247518159, .parent_padding = 0, .request_checksum = 30633888162351370674734440574199062745, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 47899338719226163297711645970010401862, .op = 132, .commit = 131, .timestamp = 1763996658048033204, .request = 130, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-11-24 15:04:18.048Z debug(replica): 0N: replicate: replicating op=132 to replica 1
2025-11-24 15:04:18.048Z debug(replica): 0N: sending prepare to replica 1: vsr.message_header.Header.Prepare{ .checksum = 307288560402019589988054472057743513540, .checksum_padding = 0, .checksum_body = 326289093971322640297727606153193791024, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2240, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 159279544561239178784939675080247518159, .parent_padding = 0, .request_checksum = 30633888162351370674734440574199062745, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 47899338719226163297711645970010401862, .op = 132, .commit = 131, .timestamp = 1763996658048033204, .request = 130, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-11-24 15:04:18.048Z debug(replica): 0N: on_prepare: advancing: op=131..132 checksum=159279544561239178784939675080247518159..307288560402019589988054472057743513540
2025-11-24 15:04:18.048Z debug(journal): 0: set_header_as_dirty: op=132 checksum=307288560402019589988054472057743513540
2025-11-24 15:04:18.048Z debug(replica): 0N: append: appending to journal op=132
2025-11-24 15:04:18.048Z debug(journal): 0: write: view=3 slot=132 op=132 len=2240: 307288560402019589988054472057743513540 starting
2025-11-24 15:04:18.048Z debug(journal): 0: write_sectors: ring=vsr.journal.Ring.prepares offset=138412032 len=4096 locked
2025-11-24 15:04:18.048Z debug(replica): 1n: on_message: view=3 status=normal vsr.message_header.Header.Prepare{ .checksum = 307288560402019589988054472057743513540, .checksum_padding = 0, .checksum_body = 326289093971322640297727606153193791024, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2240, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 159279544561239178784939675080247518159, .parent_padding = 0, .request_checksum = 30633888162351370674734440574199062745, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 47899338719226163297711645970010401862, .op = 132, .commit = 131, .timestamp = 1763996658048033204, .request = 130, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-11-24 15:04:18.048Z debug(replica): 1n: on_prepare: advancing commit_max=130..131
2025-11-24 15:04:18.048Z debug(replica): 1n: on_prepare: caching prepare.op=132 (commit_min=130 op=131 commit_max=131 prepare_max=1007)
2025-11-24 15:04:18.048Z debug(replica): 1n: on_prepare: advancing: op=131..132 checksum=159279544561239178784939675080247518159..307288560402019589988054472057743513540
2025-11-24 15:04:18.048Z debug(journal): 1: set_header_as_dirty: op=132 checksum=307288560402019589988054472057743513540
2025-11-24 15:04:18.048Z debug(client_replies): 0: read_reply: done (client=47899338719226163297711645970010401862 reply=263196637784657531143489452795006830212)
2025-11-24 15:04:18.048Z debug(replica): 1n: append: appending to journal op=132
2025-11-24 15:04:18.048Z debug(replica): 0N: on_request: repeat reply (client=47899338719226163297711645970010401862 request=129)
2025-11-24 15:04:18.048Z debug(journal): 1: write: view=3 slot=132 op=132 len=2240: 307288560402019589988054472057743513540 starting
2025-11-24 15:04:18.048Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.prepares offset=138412032 len=4096 locked
2025-11-24 15:04:18.048Z debug(replica): 0N: sending reply to client 47899338719226163297711645970010401862: vsr.message_header.Header.Reply{ .checksum = 263196637784657531143489452795006830212, .checksum_padding = 0, .checksum_body = 325783673900111050981678550500987780713, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 328, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 205482676763264284441076365850162922661, .request_checksum_padding = 0, .context = 316503818546185516714333301991110604703, .context_padding = 0, .client = 47899338719226163297711645970010401862, .op = 131, .commit = 131, .timestamp = 1763996657976671190, .request = 129, .operation = vsr.Operation(139), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:04:18.048Z debug(replica): 1n: commit_start_journal: cached prepare op=131 checksum=159279544561239178784939675080247518159
2025-11-24 15:04:18.048Z debug(journal): 0: write_sectors: ring=vsr.journal.Ring.prepares offset=138412032 len=4096 unlocked
2025-11-24 15:04:18.048Z debug(journal): 0: write_header: op=132 sectors[32768..36864]
2025-11-24 15:04:18.048Z debug(journal): 0: write_sectors: ring=vsr.journal.Ring.headers offset=32768 len=4096 locked
2025-11-24 15:04:18.048Z debug(replica): 0N: on_message: view=3 status=normal vsr.message_header.Header.Request{ .checksum = 30633888162351370674734440574199062745, .checksum_padding = 0, .checksum_body = 326289093971322640297727606153193791024, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2240, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 316503818546185516714333301991110604703, .parent_padding = 0, .client = 47899338719226163297711645970010401862, .session = 2, .timestamp = 0, .request = 130, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 1759450096, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:04:18.048Z debug(replica): 0N: on_request: new request
2025-11-24 15:04:18.048Z debug(replica): 0N: on_request: ignoring (already preparing)
2025-11-24 15:04:18.048Z debug(journal): 0: write_sectors: ring=vsr.journal.Ring.headers offset=32768 len=4096 unlocked
2025-11-24 15:04:18.048Z debug(journal): 0: write: view=3 slot=132 op=132 len=2240: 307288560402019589988054472057743513540 complete, marking clean
2025-11-24 15:04:18.048Z debug(replica): 0N: send_prepare_ok: op=132 checksum=307288560402019589988054472057743513540
2025-11-24 15:04:18.050Z debug(replica): 1n: repair_prepare: op=132 checksum=307288560402019589988054472057743513540 (already writing)
2025-11-24 15:04:18.050Z debug(replica): 1n: commit_journal: already committing (prefetch; commit_min=130)
2025-11-24 15:04:18.052Z debug(vsr): 2: journal_repair_budget_timeout fired
2025-11-24 15:04:18.052Z debug(vsr): 2: journal_repair_budget_timeout reset
2025-11-24 15:04:18.052Z debug(replica): 1n: execute_op: executing view=3 primary=false op=131 checksum=159279544561239178784939675080247518159 (create_transfers)
2025-11-24 15:04:18.052Z debug(replica): 1n: execute_op: commit_timestamp=1763996653890065373 prepare.header.timestamp=1763996657976671190
2025-11-24 15:04:18.072Z debug(vsr): 2: journal_repair_budget_timeout fired
2025-11-24 15:04:18.072Z debug(vsr): 2: journal_repair_budget_timeout reset
2025-11-24 15:04:18.048Z debug(replica): 0N: sending prepare_ok to replica 0: vsr.message_header.Header.PrepareOk{ .checksum = 71304018647750762913136141147584705607, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 159279544561239178784939675080247518159, .parent_padding = 0, .prepare_checksum = 307288560402019589988054472057743513540, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 47899338719226163297711645970010401862, .op = 132, .commit_min = 131, .timestamp = 1763996658048033204, .request = 130, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-11-24 15:04:18.081Z debug(replica): 1n: client_table_entry_update: client=47899338719226163297711645970010401862 session=2 request=129
2025-11-24 15:04:20.575Z debug(replica): 0N: on_message: view=3 status=normal vsr.message_header.Header.PrepareOk{ .checksum = 71304018647750762913136141147584705607, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 159279544561239178784939675080247518159, .parent_padding = 0, .prepare_checksum = 307288560402019589988054472057743513540, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 47899338719226163297711645970010401862, .op = 132, .commit_min = 131, .timestamp = 1763996658048033204, .request = 130, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-11-24 15:04:20.575Z debug(replica): 2n: on_message: view=3 status=normal vsr.message_header.Header.Prepare{ .checksum = 307288560402019589988054472057743513540, .checksum_padding = 0, .checksum_body = 326289093971322640297727606153193791024, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2240, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 159279544561239178784939675080247518159, .parent_padding = 0, .request_checksum = 30633888162351370674734440574199062745, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 47899338719226163297711645970010401862, .op = 132, .commit = 131, .timestamp = 1763996658048033204, .request = 130, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-11-24 15:04:20.575Z debug(forest): entering forest.compact() op=131 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2025-11-24 15:04:20.575Z debug(vsr): 0: primary_abdicate_timeout reset
2025-11-24 15:04:20.575Z debug(replica): 0N: on_prepare_ok: 1 message(s)
2025-11-24 15:04:20.575Z debug(replica): 0N: on_prepare_ok: waiting for quorum
2025-11-24 15:04:20.575Z debug(replica): 2n: on_prepare: advancing commit_max=130..131
2025-11-24 15:04:20.575Z debug(replica): 2n: on_prepare: caching prepare.op=132 (commit_min=130 op=131 commit_max=131 prepare_max=1007)
2025-11-24 15:04:20.575Z debug(replica): 2n: on_prepare: advancing: op=131..132 checksum=159279544561239178784939675080247518159..307288560402019589988054472057743513540
2025-11-24 15:04:20.575Z debug(journal): 2: set_header_as_dirty: op=132 checksum=307288560402019589988054472057743513540
2025-11-24 15:04:20.575Z debug(replica): 0N: on_message: view=3 status=normal vsr.message_header.Header.Request{ .checksum = 30633888162351370674734440574199062745, .checksum_padding = 0, .checksum_body = 326289093971322640297727606153193791024, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2240, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 316503818546185516714333301991110604703, .parent_padding = 0, .client = 47899338719226163297711645970010401862, .session = 2, .timestamp = 0, .request = 130, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 1759450096, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:04:20.575Z debug(replica): 2n: append: appending to journal op=132
2025-11-24 15:04:20.575Z debug(journal): 2: write: view=3 slot=132 op=132 len=2240: 307288560402019589988054472057743513540 starting
2025-11-24 15:04:20.575Z debug(replica): 0N: on_request: new request
2025-11-24 15:04:20.575Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.prepares offset=138412032 len=4096 locked
2025-11-24 15:04:20.575Z debug(replica): 0N: on_request: ignoring (already preparing)
2025-11-24 15:04:20.575Z debug(replica): 2n: commit_start_journal: cached prepare op=131 checksum=159279544561239178784939675080247518159
2025-11-24 15:04:20.575Z debug(replica): 0N: on_message: view=3 status=normal vsr.message_header.Header.Request{ .checksum = 30633888162351370674734440574199062745, .checksum_padding = 0, .checksum_body = 326289093971322640297727606153193791024, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2240, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 316503818546185516714333301991110604703, .parent_padding = 0, .client = 47899338719226163297711645970010401862, .session = 2, .timestamp = 0, .request = 130, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 1759450096, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:04:20.575Z debug(replica): 0N: on_request: new request
2025-11-24 15:04:20.575Z debug(replica): 0N: on_request: ignoring (already preparing)
2025-11-24 15:04:20.575Z debug(vsr): 0: journal_repair_budget_timeout fired
2025-11-24 15:04:20.575Z debug(vsr): 0: journal_repair_budget_timeout reset
2025-11-24 15:04:20.577Z debug(replica): 2n: repair_prepare: op=132 checksum=307288560402019589988054472057743513540 (already writing)
2025-11-24 15:04:20.577Z debug(replica): 2n: commit_journal: already committing (prefetch; commit_min=130)
2025-11-24 15:04:20.577Z debug(replica): 2n: on_message: view=3 status=normal vsr.message_header.Header.Request{ .checksum = 30633888162351370674734440574199062745, .checksum_padding = 0, .checksum_body = 326289093971322640297727606153193791024, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2240, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 316503818546185516714333301991110604703, .parent_padding = 0, .client = 47899338719226163297711645970010401862, .session = 2, .timestamp = 0, .request = 130, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 1759450096, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:04:20.577Z debug(replica): 2n: on_request: forwarding new request to primary (view=3)
2025-11-24 15:04:20.577Z debug(replica): 2n: sending request to replica 0: vsr.message_header.Header.Request{ .checksum = 30633888162351370674734440574199062745, .checksum_padding = 0, .checksum_body = 326289093971322640297727606153193791024, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2240, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 316503818546185516714333301991110604703, .parent_padding = 0, .client = 47899338719226163297711645970010401862, .session = 2, .timestamp = 0, .request = 130, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 1759450096, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:04:20.578Z debug(replica): 0N: on_message: view=3 status=normal vsr.message_header.Header.Request{ .checksum = 30633888162351370674734440574199062745, .checksum_padding = 0, .checksum_body = 326289093971322640297727606153193791024, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2240, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 316503818546185516714333301991110604703, .parent_padding = 0, .client = 47899338719226163297711645970010401862, .session = 2, .timestamp = 0, .request = 130, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 1759450096, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:04:20.578Z debug(replica): 0N: on_request: new request
2025-11-24 15:04:20.578Z debug(replica): 0N: on_request: ignoring (already preparing)
2025-11-24 15:04:20.580Z debug(replica): 2n: execute_op: executing view=3 primary=false op=131 checksum=159279544561239178784939675080247518159 (create_transfers)
2025-11-24 15:04:20.580Z debug(replica): 2n: execute_op: commit_timestamp=1763996653890065373 prepare.header.timestamp=1763996657976671190
2025-11-24 15:04:20.585Z debug(vsr): 0: journal_repair_timeout fired
2025-11-24 15:04:20.586Z debug(vsr): 0: journal_repair_timeout reset
2025-11-24 15:04:20.589Z warning(replica): 1n: commit_dispatch: slow request, request=129 size=895616 create_transfers time=2541ms
2025-11-24 15:04:20.590Z debug(replica): 1n: on_message: view=3 status=normal vsr.message_header.Header.Request{ .checksum = 30633888162351370674734440574199062745, .checksum_padding = 0, .checksum_body = 326289093971322640297727606153193791024, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2240, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 316503818546185516714333301991110604703, .parent_padding = 0, .client = 47899338719226163297711645970010401862, .session = 2, .timestamp = 0, .request = 130, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 1759450096, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:04:20.590Z debug(replica): 1n: on_request: forwarding new request to primary (view=3)
2025-11-24 15:04:20.590Z debug(replica): 1n: sending request to replica 0: vsr.message_header.Header.Request{ .checksum = 30633888162351370674734440574199062745, .checksum_padding = 0, .checksum_body = 326289093971322640297727606153193791024, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2240, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 316503818546185516714333301991110604703, .parent_padding = 0, .client = 47899338719226163297711645970010401862, .session = 2, .timestamp = 0, .request = 130, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 1759450096, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:04:20.590Z debug(replica): 0N: on_message: view=3 status=normal vsr.message_header.Header.Request{ .checksum = 30633888162351370674734440574199062745, .checksum_padding = 0, .checksum_body = 326289093971322640297727606153193791024, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2240, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 316503818546185516714333301991110604703, .parent_padding = 0, .client = 47899338719226163297711645970010401862, .session = 2, .timestamp = 0, .request = 130, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 1759450096, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:04:20.590Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.prepares offset=138412032 len=4096 unlocked
2025-11-24 15:04:20.590Z debug(journal): 1: write_header: op=132 sectors[32768..36864]
2025-11-24 15:04:20.590Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.headers offset=32768 len=4096 locked
2025-11-24 15:04:20.590Z debug(replica): 0N: on_request: new request
2025-11-24 15:04:20.590Z debug(replica): 0N: on_request: ignoring (already preparing)
2025-11-24 15:04:20.590Z debug(client_replies): 1: write_reply: wrote (client=47899338719226163297711645970010401862 request=129)
2025-11-24 15:04:20.590Z debug(vsr): 1: journal_repair_budget_timeout fired
2025-11-24 15:04:20.590Z debug(vsr): 1: journal_repair_budget_timeout reset
2025-11-24 15:04:20.590Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.headers offset=32768 len=4096 unlocked
2025-11-24 15:04:20.590Z debug(journal): 1: write: view=3 slot=132 op=132 len=2240: 307288560402019589988054472057743513540 complete, marking clean
2025-11-24 15:04:20.590Z debug(replica): 1n: send_prepare_ok: op=132 checksum=307288560402019589988054472057743513540
2025-11-24 15:04:20.590Z debug(replica): 1n: sending prepare_ok to replica 0: vsr.message_header.Header.PrepareOk{ .checksum = 112303908605910446941041095266148462156, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 159279544561239178784939675080247518159, .parent_padding = 0, .prepare_checksum = 307288560402019589988054472057743513540, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 47899338719226163297711645970010401862, .op = 132, .commit_min = 131, .timestamp = 1763996658048033204, .request = 130, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-11-24 15:04:20.596Z debug(vsr): 0: journal_repair_budget_timeout fired
2025-11-24 15:04:20.596Z debug(vsr): 0: journal_repair_budget_timeout reset
2025-11-24 15:04:20.600Z debug(vsr): 1: journal_repair_timeout fired
2025-11-24 15:04:20.600Z debug(vsr): 1: journal_repair_timeout reset
2025-11-24 15:04:20.611Z debug(vsr): 1: journal_repair_budget_timeout fired
2025-11-24 15:04:20.611Z debug(vsr): 1: journal_repair_budget_timeout reset
2025-11-24 15:04:20.616Z debug(vsr): 0: journal_repair_budget_timeout fired
2025-11-24 15:04:20.616Z debug(vsr): 0: journal_repair_budget_timeout reset
2025-11-24 15:04:20.620Z debug(replica): 2n: client_table_entry_update: client=47899338719226163297711645970010401862 session=2 request=129
2025-11-24 15:04:20.620Z debug(replica): 2n: execute_op: replying to client: vsr.message_header.Header.Reply{ .checksum = 263196637784657531143489452795006830212, .checksum_padding = 0, .checksum_body = 325783673900111050981678550500987780713, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 328, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 205482676763264284441076365850162922661, .request_checksum_padding = 0, .context = 316503818546185516714333301991110604703, .context_padding = 0, .client = 47899338719226163297711645970010401862, .op = 131, .commit = 131, .timestamp = 1763996657976671190, .request = 129, .operation = vsr.Operation(139), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:04:20.620Z debug(replica): 2n: sending reply to client 47899338719226163297711645970010401862: vsr.message_header.Header.Reply{ .checksum = 263196637784657531143489452795006830212, .checksum_padding = 0, .checksum_body = 325783673900111050981678550500987780713, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 328, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 205482676763264284441076365850162922661, .request_checksum_padding = 0, .context = 316503818546185516714333301991110604703, .context_padding = 0, .client = 47899338719226163297711645970010401862, .op = 131, .commit = 131, .timestamp = 1763996657976671190, .request = 129, .operation = vsr.Operation(139), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:04:20.620Z debug(forest): entering forest.compact() op=131 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2025-11-24 15:04:20.629Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.prepares offset=138412032 len=4096 unlocked
2025-11-24 15:04:20.629Z debug(journal): 2: write_header: op=132 sectors[32768..36864]
2025-11-24 15:04:20.629Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.headers offset=32768 len=4096 locked
2025-11-24 15:04:20.629Z debug(client_replies): 2: write_reply: wrote (client=47899338719226163297711645970010401862 request=129)
2025-11-24 15:04:20.629Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.headers offset=32768 len=4096 unlocked
2025-11-24 15:04:20.629Z debug(journal): 2: write: view=3 slot=132 op=132 len=2240: 307288560402019589988054472057743513540 complete, marking clean
2025-11-24 15:04:20.629Z debug(replica): 2n: send_prepare_ok: op=132 checksum=307288560402019589988054472057743513540
2025-11-24 15:04:20.629Z debug(replica): 2n: sending prepare_ok to replica 0: vsr.message_header.Header.PrepareOk{ .checksum = 177866660826906749211518075787269270122, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 159279544561239178784939675080247518159, .parent_padding = 0, .prepare_checksum = 307288560402019589988054472057743513540, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 47899338719226163297711645970010401862, .op = 132, .commit_min = 131, .timestamp = 1763996658048033204, .request = 130, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-11-24 15:04:20.629Z debug(replica): 0N: on_message: view=3 status=normal vsr.message_header.Header.PrepareOk{ .checksum = 177866660826906749211518075787269270122, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 159279544561239178784939675080247518159, .parent_padding = 0, .prepare_checksum = 307288560402019589988054472057743513540, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 47899338719226163297711645970010401862, .op = 132, .commit_min = 131, .timestamp = 1763996658048033204, .request = 130, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-11-24 15:04:20.629Z debug(vsr): 0: primary_abdicate_timeout reset
2025-11-24 15:04:20.629Z debug(replica): 0N: on_prepare_ok: 2 message(s)
2025-11-24 15:04:20.629Z debug(replica): 0N: on_prepare_ok: quorum received, context=307288560402019589988054472057743513540
2025-11-24 15:04:20.629Z debug(vsr): 0: prepare_timeout stopped
2025-11-24 15:04:20.629Z debug(vsr): 0: primary_abdicate_timeout stopped
2025-11-24 15:04:20.629Z debug(replica): 0N: execute_op: executing view=3 primary=true op=132 checksum=307288560402019589988054472057743513540 (lookup_accounts)
2025-11-24 15:04:20.629Z debug(replica): 0N: execute_op: commit_timestamp=1763996657976671190 prepare.header.timestamp=1763996658048033204
2025-11-24 15:04:20.629Z debug(replica): 0N: execute_op: advancing commit_max=131..132
2025-11-24 15:04:20.629Z debug(replica): 0N: client_table_entry_update: client=47899338719226163297711645970010401862 session=2 request=130
2025-11-24 15:04:20.629Z debug(replica): 0N: execute_op: replying to client: vsr.message_header.Header.Reply{ .checksum = 134806148739455008285651090978248289448, .checksum_padding = 0, .checksum_body = 32222288799182611566902284274619174430, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 16128, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 30633888162351370674734440574199062745, .request_checksum_padding = 0, .context = 65755497154990361850656627475480702482, .context_padding = 0, .client = 47899338719226163297711645970010401862, .op = 132, .commit = 132, .timestamp = 1763996658048033204, .request = 130, .operation = vsr.Operation(140), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:04:20.629Z debug(replica): 0N: sending reply to client 47899338719226163297711645970010401862: vsr.message_header.Header.Reply{ .checksum = 134806148739455008285651090978248289448, .checksum_padding = 0, .checksum_body = 32222288799182611566902284274619174430, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 16128, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 30633888162351370674734440574199062745, .request_checksum_padding = 0, .context = 65755497154990361850656627475480702482, .context_padding = 0, .client = 47899338719226163297711645970010401862, .op = 132, .commit = 132, .timestamp = 1763996658048033204, .request = 130, .operation = vsr.Operation(140), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:04:20.630Z debug(forest): entering forest.compact() op=132 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
warning(client): 47899338719226163297711645970010401862: on_reply: slow request, request=130 op=132 size=2240 lookup_accounts time=2583ms
2025-11-24 15:04:20.630Z debug(client_replies): 0: write_reply: wrote (client=47899338719226163297711645970010401862 request=130)
2025-11-24 15:04:20.630Z info(workload): accounts created = 123, transfers = 148548, pending transfers = 0, commands run = 65
2025-11-24 15:04:20.631Z debug(vsr): 1: journal_repair_budget_timeout fired
2025-11-24 15:04:20.631Z debug(vsr): 1: journal_repair_budget_timeout reset
2025-11-24 15:04:20.632Z debug(replica): 0N: on_message: view=3 status=normal vsr.message_header.Header.Request{ .checksum = 244042845466204053672150878127194591882, .checksum_padding = 0, .checksum_body = 20703937596433664616046125862836029005, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 129184, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 65755497154990361850656627475480702482, .parent_padding = 0, .client = 47899338719226163297711645970010401862, .session = 2, .timestamp = 0, .request = 131, .operation = vsr.Operation(141), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 2583238072, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:04:20.632Z debug(replica): 0N: on_request: new request
2025-11-24 15:04:20.632Z debug(replica): 0N: primary_pipeline_prepare: request checksum=244042845466204053672150878127194591882 client=47899338719226163297711645970010401862
2025-11-24 15:04:20.632Z debug(replica): 1n: on_message: view=3 status=normal vsr.message_header.Header.Request{ .checksum = 244042845466204053672150878127194591882, .checksum_padding = 0, .checksum_body = 20703937596433664616046125862836029005, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 129184, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 65755497154990361850656627475480702482, .parent_padding = 0, .client = 47899338719226163297711645970010401862, .session = 2, .timestamp = 0, .request = 131, .operation = vsr.Operation(141), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 2583238072, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:04:20.632Z debug(replica): 1n: on_request: forwarding new request to primary (view=3)
2025-11-24 15:04:20.632Z debug(replica): 1n: sending request to replica 0: vsr.message_header.Header.Request{ .checksum = 244042845466204053672150878127194591882, .checksum_padding = 0, .checksum_body = 20703937596433664616046125862836029005, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 129184, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 65755497154990361850656627475480702482, .parent_padding = 0, .client = 47899338719226163297711645970010401862, .session = 2, .timestamp = 0, .request = 131, .operation = vsr.Operation(141), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 2583238072, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:04:20.632Z debug(replica): 0N: primary_pipeline_prepare: prepare checksum=32022280389824693374785059271038071692 op=133
2025-11-24 15:04:20.632Z debug(vsr): 0: prepare_timeout started
2025-11-24 15:04:20.632Z debug(vsr): 0: primary_abdicate_timeout started
2025-11-24 15:04:20.632Z debug(vsr): 0: pulse_timeout reset
2025-11-24 15:04:20.632Z debug(replica): 0N: replicate: replicating op=133 to replica 2
2025-11-24 15:04:20.632Z debug(replica): 0N: sending prepare to replica 2: vsr.message_header.Header.Prepare{ .checksum = 32022280389824693374785059271038071692, .checksum_padding = 0, .checksum_body = 20703937596433664616046125862836029005, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 129184, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 307288560402019589988054472057743513540, .parent_padding = 0, .request_checksum = 244042845466204053672150878127194591882, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 47899338719226163297711645970010401862, .op = 133, .commit = 132, .timestamp = 1763996660632307578, .request = 131, .operation = vsr.Operation(141), .reserved = { 0, 0, 0 } }
2025-11-24 15:04:20.632Z debug(replica): 0N: replicate: replicating op=133 to replica 1
2025-11-24 15:04:20.632Z debug(replica): 0N: sending prepare to replica 1: vsr.message_header.Header.Prepare{ .checksum = 32022280389824693374785059271038071692, .checksum_padding = 0, .checksum_body = 20703937596433664616046125862836029005, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 129184, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 307288560402019589988054472057743513540, .parent_padding = 0, .request_checksum = 244042845466204053672150878127194591882, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 47899338719226163297711645970010401862, .op = 133, .commit = 132, .timestamp = 1763996660632307578, .request = 131, .operation = vsr.Operation(141), .reserved = { 0, 0, 0 } }
2025-11-24 15:04:20.633Z debug(replica): 0N: on_prepare: advancing: op=132..133 checksum=307288560402019589988054472057743513540..32022280389824693374785059271038071692
2025-11-24 15:04:20.633Z debug(journal): 0: set_header_as_dirty: op=133 checksum=32022280389824693374785059271038071692
2025-11-24 15:04:20.633Z debug(replica): 0N: append: appending to journal op=133
2025-11-24 15:04:20.633Z debug(journal): 0: write: view=3 slot=133 op=133 len=129184: 32022280389824693374785059271038071692 starting
2025-11-24 15:04:20.633Z debug(journal): 0: write_sectors: ring=vsr.journal.Ring.prepares offset=139460608 len=131072 locked
2025-11-24 15:04:20.633Z debug(replica): 0N: on_message: view=3 status=normal vsr.message_header.Header.PrepareOk{ .checksum = 112303908605910446941041095266148462156, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 159279544561239178784939675080247518159, .parent_padding = 0, .prepare_checksum = 307288560402019589988054472057743513540, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 47899338719226163297711645970010401862, .op = 132, .commit_min = 131, .timestamp = 1763996658048033204, .request = 130, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-11-24 15:04:20.633Z debug(replica): 0N: on_prepare_ok: not preparing op=132 checksum=307288560402019589988054472057743513540
2025-11-24 15:04:20.633Z debug(replica): 2n: on_message: view=3 status=normal vsr.message_header.Header.Prepare{ .checksum = 32022280389824693374785059271038071692, .checksum_padding = 0, .checksum_body = 20703937596433664616046125862836029005, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 129184, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 307288560402019589988054472057743513540, .parent_padding = 0, .request_checksum = 244042845466204053672150878127194591882, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 47899338719226163297711645970010401862, .op = 133, .commit = 132, .timestamp = 1763996660632307578, .request = 131, .operation = vsr.Operation(141), .reserved = { 0, 0, 0 } }
2025-11-24 15:04:20.633Z debug(replica): 2n: on_prepare: advancing commit_max=131..132
2025-11-24 15:04:20.633Z debug(replica): 2n: on_prepare: caching prepare.op=133 (commit_min=131 op=132 commit_max=132 prepare_max=1007)
2025-11-24 15:04:20.633Z debug(replica): 2n: on_prepare: advancing: op=132..133 checksum=307288560402019589988054472057743513540..32022280389824693374785059271038071692
2025-11-24 15:04:20.633Z debug(journal): 2: set_header_as_dirty: op=133 checksum=32022280389824693374785059271038071692
2025-11-24 15:04:20.633Z debug(replica): 2n: append: appending to journal op=133
2025-11-24 15:04:20.633Z debug(journal): 2: write: view=3 slot=133 op=133 len=129184: 32022280389824693374785059271038071692 starting
2025-11-24 15:04:20.633Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.prepares offset=139460608 len=131072 locked
2025-11-24 15:04:20.633Z debug(replica): 0N: on_message: view=3 status=normal vsr.message_header.Header.Request{ .checksum = 244042845466204053672150878127194591882, .checksum_padding = 0, .checksum_body = 20703937596433664616046125862836029005, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 129184, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 65755497154990361850656627475480702482, .parent_padding = 0, .client = 47899338719226163297711645970010401862, .session = 2, .timestamp = 0, .request = 131, .operation = vsr.Operation(141), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 2583238072, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:04:20.633Z debug(replica): 2n: commit_start_journal: cached prepare op=132 checksum=307288560402019589988054472057743513540
2025-11-24 15:04:20.633Z debug(replica): 0N: on_request: new request
2025-11-24 15:04:20.633Z debug(replica): 0N: on_request: ignoring (already preparing)
2025-11-24 15:04:20.633Z debug(replica): 1n: on_message: view=3 status=normal vsr.message_header.Header.Prepare{ .checksum = 32022280389824693374785059271038071692, .checksum_padding = 0, .checksum_body = 20703937596433664616046125862836029005, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 129184, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 307288560402019589988054472057743513540, .parent_padding = 0, .request_checksum = 244042845466204053672150878127194591882, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 47899338719226163297711645970010401862, .op = 133, .commit = 132, .timestamp = 1763996660632307578, .request = 131, .operation = vsr.Operation(141), .reserved = { 0, 0, 0 } }
2025-11-24 15:04:20.633Z debug(journal): 0: write_sectors: ring=vsr.journal.Ring.prepares offset=139460608 len=131072 unlocked
2025-11-24 15:04:20.633Z debug(replica): 1n: on_prepare: advancing commit_max=131..132
2025-11-24 15:04:20.633Z debug(journal): 0: write_header: op=133 sectors[32768..36864]
2025-11-24 15:04:20.633Z debug(replica): 1n: on_prepare: caching prepare.op=133 (commit_min=131 op=132 commit_max=132 prepare_max=1007)
2025-11-24 15:04:20.633Z debug(replica): 2n: repair_prepare: op=133 checksum=32022280389824693374785059271038071692 (already writing)
2025-11-24 15:04:20.633Z debug(journal): 0: write_sectors: ring=vsr.journal.Ring.headers offset=32768 len=4096 locked
2025-11-24 15:04:20.633Z debug(replica): 2n: commit_journal: already committing (prefetch; commit_min=131)
2025-11-24 15:04:20.633Z debug(replica): 2n: execute_op: executing view=3 primary=false op=132 checksum=307288560402019589988054472057743513540 (lookup_accounts)
2025-11-24 15:04:20.633Z debug(replica): 2n: execute_op: commit_timestamp=1763996657976671190 prepare.header.timestamp=1763996658048033204
2025-11-24 15:04:20.633Z debug(replica): 1n: on_prepare: advancing: op=132..133 checksum=307288560402019589988054472057743513540..32022280389824693374785059271038071692
2025-11-24 15:04:20.633Z debug(journal): 0: write_sectors: ring=vsr.journal.Ring.headers offset=32768 len=4096 unlocked
2025-11-24 15:04:20.633Z debug(journal): 1: set_header_as_dirty: op=133 checksum=32022280389824693374785059271038071692
2025-11-24 15:04:20.633Z debug(journal): 0: write: view=3 slot=133 op=133 len=129184: 32022280389824693374785059271038071692 complete, marking clean
2025-11-24 15:04:20.633Z debug(replica): 1n: append: appending to journal op=133
2025-11-24 15:04:20.633Z debug(replica): 0N: send_prepare_ok: op=133 checksum=32022280389824693374785059271038071692
2025-11-24 15:04:20.633Z debug(journal): 1: write: view=3 slot=133 op=133 len=129184: 32022280389824693374785059271038071692 starting
2025-11-24 15:04:20.633Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.prepares offset=139460608 len=131072 locked
2025-11-24 15:04:20.633Z debug(replica): 0N: sending prepare_ok to replica 0: vsr.message_header.Header.PrepareOk{ .checksum = 52631661949674858495174228010958458470, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 307288560402019589988054472057743513540, .parent_padding = 0, .prepare_checksum = 32022280389824693374785059271038071692, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 47899338719226163297711645970010401862, .op = 133, .commit_min = 132, .timestamp = 1763996660632307578, .request = 131, .operation = vsr.Operation(141), .reserved = { 0, 0, 0 } }
2025-11-24 15:04:20.633Z debug(replica): 1n: commit_start_journal: cached prepare op=132 checksum=307288560402019589988054472057743513540
2025-11-24 15:04:20.633Z debug(replica): 0N: on_message: view=3 status=normal vsr.message_header.Header.PrepareOk{ .checksum = 52631661949674858495174228010958458470, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 307288560402019589988054472057743513540, .parent_padding = 0, .prepare_checksum = 32022280389824693374785059271038071692, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 47899338719226163297711645970010401862, .op = 133, .commit_min = 132, .timestamp = 1763996660632307578, .request = 131, .operation = vsr.Operation(141), .reserved = { 0, 0, 0 } }
2025-11-24 15:04:20.633Z debug(vsr): 0: primary_abdicate_timeout reset
2025-11-24 15:04:20.634Z debug(replica): 0N: on_prepare_ok: 1 message(s)
2025-11-24 15:04:20.634Z debug(replica): 0N: on_prepare_ok: waiting for quorum
2025-11-24 15:04:20.634Z debug(replica): 2n: client_table_entry_update: client=47899338719226163297711645970010401862 session=2 request=130
2025-11-24 15:04:20.634Z debug(replica): 2n: execute_op: replying to client: vsr.message_header.Header.Reply{ .checksum = 134806148739455008285651090978248289448, .checksum_padding = 0, .checksum_body = 32222288799182611566902284274619174430, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 16128, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 30633888162351370674734440574199062745, .request_checksum_padding = 0, .context = 65755497154990361850656627475480702482, .context_padding = 0, .client = 47899338719226163297711645970010401862, .op = 132, .commit = 132, .timestamp = 1763996658048033204, .request = 130, .operation = vsr.Operation(140), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:04:20.634Z debug(replica): 2n: sending reply to client 47899338719226163297711645970010401862: vsr.message_header.Header.Reply{ .checksum = 134806148739455008285651090978248289448, .checksum_padding = 0, .checksum_body = 32222288799182611566902284274619174430, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 16128, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 30633888162351370674734440574199062745, .request_checksum_padding = 0, .context = 65755497154990361850656627475480702482, .context_padding = 0, .client = 47899338719226163297711645970010401862, .op = 132, .commit = 132, .timestamp = 1763996658048033204, .request = 130, .operation = vsr.Operation(140), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:04:20.634Z debug(forest): entering forest.compact() op=132 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2025-11-24 15:04:20.634Z debug(replica): 1n: repair_prepare: op=133 checksum=32022280389824693374785059271038071692 (already writing)
2025-11-24 15:04:20.634Z debug(replica): 1n: commit_journal: already committing (prefetch; commit_min=131)
2025-11-24 15:04:20.634Z debug(replica): 1n: execute_op: executing view=3 primary=false op=132 checksum=307288560402019589988054472057743513540 (lookup_accounts)
2025-11-24 15:04:20.634Z debug(replica): 1n: execute_op: commit_timestamp=1763996657976671190 prepare.header.timestamp=1763996658048033204
2025-11-24 15:04:20.634Z debug(client_replies): 2: write_reply: wrote (client=47899338719226163297711645970010401862 request=130)
2025-11-24 15:04:20.634Z debug(replica): 1n: client_table_entry_update: client=47899338719226163297711645970010401862 session=2 request=130
2025-11-24 15:04:20.634Z debug(forest): entering forest.compact() op=132 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2025-11-24 15:04:20.634Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.prepares offset=139460608 len=131072 unlocked
2025-11-24 15:04:20.634Z debug(journal): 2: write_header: op=133 sectors[32768..36864]
2025-11-24 15:04:20.634Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.headers offset=32768 len=4096 locked
2025-11-24 15:04:20.634Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.headers offset=32768 len=4096 unlocked
2025-11-24 15:04:20.634Z debug(journal): 2: write: view=3 slot=133 op=133 len=129184: 32022280389824693374785059271038071692 complete, marking clean
2025-11-24 15:04:20.634Z debug(replica): 2n: send_prepare_ok: op=133 checksum=32022280389824693374785059271038071692
2025-11-24 15:04:20.634Z debug(replica): 2n: sending prepare_ok to replica 0: vsr.message_header.Header.PrepareOk{ .checksum = 145300723583502135970551818586882701273, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 307288560402019589988054472057743513540, .parent_padding = 0, .prepare_checksum = 32022280389824693374785059271038071692, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 47899338719226163297711645970010401862, .op = 133, .commit_min = 132, .timestamp = 1763996660632307578, .request = 131, .operation = vsr.Operation(141), .reserved = { 0, 0, 0 } }
2025-11-24 15:04:20.634Z debug(replica): 0N: on_message: view=3 status=normal vsr.message_header.Header.PrepareOk{ .checksum = 145300723583502135970551818586882701273, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 307288560402019589988054472057743513540, .parent_padding = 0, .prepare_checksum = 32022280389824693374785059271038071692, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 47899338719226163297711645970010401862, .op = 133, .commit_min = 132, .timestamp = 1763996660632307578, .request = 131, .operation = vsr.Operation(141), .reserved = { 0, 0, 0 } }
2025-11-24 15:04:20.634Z debug(vsr): 0: primary_abdicate_timeout reset
2025-11-24 15:04:20.634Z debug(client_replies): 1: write_reply: wrote (client=47899338719226163297711645970010401862 request=130)
2025-11-24 15:04:20.634Z debug(replica): 0N: on_prepare_ok: 2 message(s)
2025-11-24 15:04:20.634Z debug(replica): 0N: on_prepare_ok: quorum received, context=32022280389824693374785059271038071692
2025-11-24 15:04:20.634Z debug(vsr): 0: prepare_timeout stopped
2025-11-24 15:04:20.634Z debug(vsr): 0: primary_abdicate_timeout stopped
2025-11-24 15:04:20.634Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.prepares offset=139460608 len=131072 unlocked
2025-11-24 15:04:20.634Z debug(journal): 1: write_header: op=133 sectors[32768..36864]
2025-11-24 15:04:20.634Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.headers offset=32768 len=4096 locked
2025-11-24 15:04:20.634Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.headers offset=32768 len=4096 unlocked
2025-11-24 15:04:20.634Z debug(journal): 1: write: view=3 slot=133 op=133 len=129184: 32022280389824693374785059271038071692 complete, marking clean
2025-11-24 15:04:20.634Z debug(replica): 1n: send_prepare_ok: op=133 checksum=32022280389824693374785059271038071692
2025-11-24 15:04:20.634Z debug(replica): 1n: sending prepare_ok to replica 0: vsr.message_header.Header.PrepareOk{ .checksum = 109920504978575438195863685867770493474, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 307288560402019589988054472057743513540, .parent_padding = 0, .prepare_checksum = 32022280389824693374785059271038071692, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 47899338719226163297711645970010401862, .op = 133, .commit_min = 132, .timestamp = 1763996660632307578, .request = 131, .operation = vsr.Operation(141), .reserved = { 0, 0, 0 } }
2025-11-24 15:04:20.639Z debug(replica): 0N: execute_op: executing view=3 primary=true op=133 checksum=32022280389824693374785059271038071692 (lookup_transfers)
2025-11-24 15:04:20.639Z debug(replica): 0N: execute_op: commit_timestamp=1763996658048033204 prepare.header.timestamp=1763996660632307578
2025-11-24 15:04:20.639Z debug(vsr): 2: journal_repair_budget_timeout fired
2025-11-24 15:04:20.639Z debug(vsr): 2: journal_repair_budget_timeout reset
2025-11-24 15:04:20.641Z debug(replica): 0N: execute_op: advancing commit_max=132..133
2025-11-24 15:04:20.646Z debug(replica): 0N: client_table_entry_update: client=47899338719226163297711645970010401862 session=2 request=131
2025-11-24 15:04:20.646Z debug(replica): 0N: execute_op: replying to client: vsr.message_header.Header.Reply{ .checksum = 171822703833997194214594192852549845234, .checksum_padding = 0, .checksum_body = 241048930132707616446879240313637650104, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 1031680, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 244042845466204053672150878127194591882, .request_checksum_padding = 0, .context = 324032326419089524664645871664683721802, .context_padding = 0, .client = 47899338719226163297711645970010401862, .op = 133, .commit = 133, .timestamp = 1763996660632307578, .request = 131, .operation = vsr.Operation(141), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:04:20.646Z debug(replica): 0N: sending reply to client 47899338719226163297711645970010401862: vsr.message_header.Header.Reply{ .checksum = 171822703833997194214594192852549845234, .checksum_padding = 0, .checksum_body = 241048930132707616446879240313637650104, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 1031680, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 244042845466204053672150878127194591882, .request_checksum_padding = 0, .context = 324032326419089524664645871664683721802, .context_padding = 0, .client = 47899338719226163297711645970010401862, .op = 133, .commit = 133, .timestamp = 1763996660632307578, .request = 131, .operation = vsr.Operation(141), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:04:20.646Z debug(forest): entering forest.compact() op=133 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2025-11-24 15:04:20.647Z debug(replica): 0N: on_message: view=3 status=normal vsr.message_header.Header.PrepareOk{ .checksum = 109920504978575438195863685867770493474, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 307288560402019589988054472057743513540, .parent_padding = 0, .prepare_checksum = 32022280389824693374785059271038071692, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 47899338719226163297711645970010401862, .op = 133, .commit_min = 132, .timestamp = 1763996660632307578, .request = 131, .operation = vsr.Operation(141), .reserved = { 0, 0, 0 } }
2025-11-24 15:04:20.647Z debug(replica): 0N: on_prepare_ok: not preparing op=133 checksum=32022280389824693374785059271038071692
2025-11-24 15:04:20.648Z debug(client_replies): 0: write_reply: wrote (client=47899338719226163297711645970010401862 request=131)
2025-11-24 15:04:20.648Z debug(vsr): 0: journal_repair_budget_timeout fired
2025-11-24 15:04:20.648Z debug(vsr): 0: journal_repair_budget_timeout reset
2025-11-24 15:04:20.651Z debug(vsr): 1: journal_repair_budget_timeout fired
2025-11-24 15:04:20.651Z debug(vsr): 1: journal_repair_budget_timeout reset
2025-11-24 15:04:20.658Z debug(replica): 0N: on_message: view=3 status=normal vsr.message_header.Header.Request{ .checksum = 96289780212968966528001553264574252255, .checksum_padding = 0, .checksum_body = 326289093971322640297727606153193791024, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2240, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 324032326419089524664645871664683721802, .parent_padding = 0, .client = 47899338719226163297711645970010401862, .session = 2, .timestamp = 0, .request = 132, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 26564258, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:04:20.658Z debug(replica): 1n: on_message: view=3 status=normal vsr.message_header.Header.Request{ .checksum = 96289780212968966528001553264574252255, .checksum_padding = 0, .checksum_body = 326289093971322640297727606153193791024, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2240, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 324032326419089524664645871664683721802, .parent_padding = 0, .client = 47899338719226163297711645970010401862, .session = 2, .timestamp = 0, .request = 132, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 26564258, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:04:20.658Z debug(replica): 0N: on_request: new request
2025-11-24 15:04:20.658Z debug(replica): 1n: on_request: forwarding new request to primary (view=3)
2025-11-24 15:04:20.658Z debug(replica): 0N: primary_pipeline_prepare: request checksum=96289780212968966528001553264574252255 client=47899338719226163297711645970010401862
2025-11-24 15:04:20.658Z debug(replica): 1n: sending request to replica 0: vsr.message_header.Header.Request{ .checksum = 96289780212968966528001553264574252255, .checksum_padding = 0, .checksum_body = 326289093971322640297727606153193791024, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2240, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 324032326419089524664645871664683721802, .parent_padding = 0, .client = 47899338719226163297711645970010401862, .session = 2, .timestamp = 0, .request = 132, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 26564258, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:04:20.658Z debug(replica): 0N: primary_pipeline_prepare: prepare checksum=232042921376966079360087090401252901567 op=134
2025-11-24 15:04:20.658Z debug(vsr): 0: prepare_timeout started
2025-11-24 15:04:20.658Z debug(vsr): 0: primary_abdicate_timeout started
2025-11-24 15:04:20.658Z debug(vsr): 0: pulse_timeout reset
2025-11-24 15:04:20.658Z debug(replica): 0N: replicate: replicating op=134 to replica 2
2025-11-24 15:04:20.658Z debug(replica): 0N: sending prepare to replica 2: vsr.message_header.Header.Prepare{ .checksum = 232042921376966079360087090401252901567, .checksum_padding = 0, .checksum_body = 326289093971322640297727606153193791024, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2240, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 32022280389824693374785059271038071692, .parent_padding = 0, .request_checksum = 96289780212968966528001553264574252255, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 47899338719226163297711645970010401862, .op = 134, .commit = 133, .timestamp = 1763996660658700576, .request = 132, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-11-24 15:04:20.658Z debug(replica): 0N: replicate: replicating op=134 to replica 1
2025-11-24 15:04:20.658Z debug(replica): 0N: sending prepare to replica 1: vsr.message_header.Header.Prepare{ .checksum = 232042921376966079360087090401252901567, .checksum_padding = 0, .checksum_body = 326289093971322640297727606153193791024, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2240, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 32022280389824693374785059271038071692, .parent_padding = 0, .request_checksum = 96289780212968966528001553264574252255, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 47899338719226163297711645970010401862, .op = 134, .commit = 133, .timestamp = 1763996660658700576, .request = 132, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-11-24 15:04:20.658Z debug(replica): 0N: on_prepare: advancing: op=133..134 checksum=32022280389824693374785059271038071692..232042921376966079360087090401252901567
2025-11-24 15:04:20.658Z debug(journal): 0: set_header_as_dirty: op=134 checksum=232042921376966079360087090401252901567
2025-11-24 15:04:20.658Z debug(replica): 0N: append: appending to journal op=134
2025-11-24 15:04:20.658Z debug(journal): 0: write: view=3 slot=134 op=134 len=2240: 232042921376966079360087090401252901567 starting
2025-11-24 15:04:20.658Z debug(journal): 0: write_sectors: ring=vsr.journal.Ring.prepares offset=140509184 len=4096 locked
2025-11-24 15:04:20.658Z debug(replica): 2n: on_message: view=3 status=normal vsr.message_header.Header.Prepare{ .checksum = 232042921376966079360087090401252901567, .checksum_padding = 0, .checksum_body = 326289093971322640297727606153193791024, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2240, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 32022280389824693374785059271038071692, .parent_padding = 0, .request_checksum = 96289780212968966528001553264574252255, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 47899338719226163297711645970010401862, .op = 134, .commit = 133, .timestamp = 1763996660658700576, .request = 132, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-11-24 15:04:20.658Z debug(replica): 2n: on_prepare: advancing commit_max=132..133
2025-11-24 15:04:20.658Z debug(replica): 2n: on_prepare: caching prepare.op=134 (commit_min=132 op=133 commit_max=133 prepare_max=1007)
2025-11-24 15:04:20.659Z debug(replica): 2n: on_prepare: advancing: op=133..134 checksum=32022280389824693374785059271038071692..232042921376966079360087090401252901567
2025-11-24 15:04:20.659Z debug(journal): 2: set_header_as_dirty: op=134 checksum=232042921376966079360087090401252901567
2025-11-24 15:04:20.659Z debug(replica): 2n: append: appending to journal op=134
2025-11-24 15:04:20.659Z debug(journal): 2: write: view=3 slot=134 op=134 len=2240: 232042921376966079360087090401252901567 starting
2025-11-24 15:04:20.658Z debug(replica): 0N: on_message: view=3 status=normal vsr.message_header.Header.Request{ .checksum = 96289780212968966528001553264574252255, .checksum_padding = 0, .checksum_body = 326289093971322640297727606153193791024, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2240, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 324032326419089524664645871664683721802, .parent_padding = 0, .client = 47899338719226163297711645970010401862, .session = 2, .timestamp = 0, .request = 132, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 26564258, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:04:20.659Z debug(replica): 1n: on_message: view=3 status=normal vsr.message_header.Header.Prepare{ .checksum = 232042921376966079360087090401252901567, .checksum_padding = 0, .checksum_body = 326289093971322640297727606153193791024, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2240, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 32022280389824693374785059271038071692, .parent_padding = 0, .request_checksum = 96289780212968966528001553264574252255, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 47899338719226163297711645970010401862, .op = 134, .commit = 133, .timestamp = 1763996660658700576, .request = 132, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-11-24 15:04:20.659Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.prepares offset=140509184 len=4096 locked
2025-11-24 15:04:22.833Z debug(replica): 0N: on_request: new request
2025-11-24 15:04:22.833Z debug(replica): 1n: on_prepare: advancing commit_max=132..133
2025-11-24 15:04:22.833Z debug(replica): 0N: on_request: ignoring (already preparing)
2025-11-24 15:04:22.833Z debug(replica): 1n: on_prepare: caching prepare.op=134 (commit_min=132 op=133 commit_max=133 prepare_max=1007)
2025-11-24 15:04:22.833Z debug(replica): 2n: commit_start_journal: cached prepare op=133 checksum=32022280389824693374785059271038071692
2025-11-24 15:04:22.833Z debug(replica): 1n: on_prepare: advancing: op=133..134 checksum=32022280389824693374785059271038071692..232042921376966079360087090401252901567
2025-11-24 15:04:22.833Z debug(journal): 0: write_sectors: ring=vsr.journal.Ring.prepares offset=140509184 len=4096 unlocked
2025-11-24 15:04:22.833Z debug(journal): 1: set_header_as_dirty: op=134 checksum=232042921376966079360087090401252901567
2025-11-24 15:04:22.833Z debug(journal): 0: write_header: op=134 sectors[32768..36864]
2025-11-24 15:04:22.833Z debug(replica): 1n: append: appending to journal op=134
2025-11-24 15:04:22.833Z debug(journal): 0: write_sectors: ring=vsr.journal.Ring.headers offset=32768 len=4096 locked
2025-11-24 15:04:22.833Z debug(journal): 1: write: view=3 slot=134 op=134 len=2240: 232042921376966079360087090401252901567 starting
2025-11-24 15:04:22.834Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.prepares offset=140509184 len=4096 locked
2025-11-24 15:04:22.834Z debug(replica): 1n: commit_start_journal: cached prepare op=133 checksum=32022280389824693374785059271038071692
2025-11-24 15:04:22.834Z debug(replica): 0N: on_message: view=3 status=normal vsr.message_header.Header.Request{ .checksum = 96289780212968966528001553264574252255, .checksum_padding = 0, .checksum_body = 326289093971322640297727606153193791024, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2240, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 324032326419089524664645871664683721802, .parent_padding = 0, .client = 47899338719226163297711645970010401862, .session = 2, .timestamp = 0, .request = 132, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 26564258, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:04:22.834Z debug(replica): 0N: on_request: new request
2025-11-24 15:04:22.834Z debug(replica): 0N: on_request: ignoring (already preparing)
2025-11-24 15:04:22.834Z debug(replica): 0N: on_message: view=3 status=normal vsr.message_header.Header.Request{ .checksum = 96289780212968966528001553264574252255, .checksum_padding = 0, .checksum_body = 326289093971322640297727606153193791024, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2240, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 324032326419089524664645871664683721802, .parent_padding = 0, .client = 47899338719226163297711645970010401862, .session = 2, .timestamp = 0, .request = 132, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 26564258, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:04:22.834Z debug(replica): 0N: on_request: new request
2025-11-24 15:04:22.834Z debug(replica): 0N: on_request: ignoring (already preparing)
2025-11-24 15:04:22.834Z debug(vsr): 0: journal_repair_budget_timeout fired
2025-11-24 15:04:22.834Z debug(vsr): 0: journal_repair_budget_timeout reset
2025-11-24 15:04:22.834Z debug(journal): 0: write_sectors: ring=vsr.journal.Ring.headers offset=32768 len=4096 unlocked
2025-11-24 15:04:22.834Z debug(journal): 0: write: view=3 slot=134 op=134 len=2240: 232042921376966079360087090401252901567 complete, marking clean
2025-11-24 15:04:22.834Z debug(replica): 0N: send_prepare_ok: op=134 checksum=232042921376966079360087090401252901567
2025-11-24 15:04:22.834Z debug(replica): 0N: sending prepare_ok to replica 0: vsr.message_header.Header.PrepareOk{ .checksum = 53030390409419243698031986399944960705, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 32022280389824693374785059271038071692, .parent_padding = 0, .prepare_checksum = 232042921376966079360087090401252901567, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 47899338719226163297711645970010401862, .op = 134, .commit_min = 133, .timestamp = 1763996660658700576, .request = 132, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-11-24 15:04:22.834Z debug(replica): 0N: on_message: view=3 status=normal vsr.message_header.Header.PrepareOk{ .checksum = 53030390409419243698031986399944960705, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 32022280389824693374785059271038071692, .parent_padding = 0, .prepare_checksum = 232042921376966079360087090401252901567, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 47899338719226163297711645970010401862, .op = 134, .commit_min = 133, .timestamp = 1763996660658700576, .request = 132, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-11-24 15:04:22.834Z debug(vsr): 0: primary_abdicate_timeout reset
2025-11-24 15:04:22.834Z debug(replica): 0N: on_prepare_ok: 1 message(s)
2025-11-24 15:04:22.834Z debug(replica): 0N: on_prepare_ok: waiting for quorum
2025-11-24 15:04:22.838Z debug(replica): 2n: repair_prepare: op=134 checksum=232042921376966079360087090401252901567 (already writing)
2025-11-24 15:04:22.838Z debug(replica): 2n: commit_journal: already committing (prefetch; commit_min=132)
2025-11-24 15:04:22.838Z debug(replica): 2n: execute_op: executing view=3 primary=false op=133 checksum=32022280389824693374785059271038071692 (lookup_transfers)
2025-11-24 15:04:22.838Z debug(replica): 2n: execute_op: commit_timestamp=1763996658048033204 prepare.header.timestamp=1763996660632307578
2025-11-24 15:04:22.838Z debug(replica): 1n: repair_prepare: op=134 checksum=232042921376966079360087090401252901567 (already writing)
2025-11-24 15:04:22.838Z debug(replica): 1n: commit_journal: already committing (prefetch; commit_min=132)
2025-11-24 15:04:22.838Z debug(replica): 1n: execute_op: executing view=3 primary=false op=133 checksum=32022280389824693374785059271038071692 (lookup_transfers)
2025-11-24 15:04:22.838Z debug(replica): 1n: execute_op: commit_timestamp=1763996658048033204 prepare.header.timestamp=1763996660632307578
2025-11-24 15:04:22.844Z debug(replica): 1n: client_table_entry_update: client=47899338719226163297711645970010401862 session=2 request=131
2025-11-24 15:04:22.844Z debug(replica): 1n: execute_op: replying to client: vsr.message_header.Header.Reply{ .checksum = 171822703833997194214594192852549845234, .checksum_padding = 0, .checksum_body = 241048930132707616446879240313637650104, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 1031680, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 244042845466204053672150878127194591882, .request_checksum_padding = 0, .context = 324032326419089524664645871664683721802, .context_padding = 0, .client = 47899338719226163297711645970010401862, .op = 133, .commit = 133, .timestamp = 1763996660632307578, .request = 131, .operation = vsr.Operation(141), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:04:22.844Z debug(replica): 1n: sending reply to client 47899338719226163297711645970010401862: vsr.message_header.Header.Reply{ .checksum = 171822703833997194214594192852549845234, .checksum_padding = 0, .checksum_body = 241048930132707616446879240313637650104, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 1031680, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 244042845466204053672150878127194591882, .request_checksum_padding = 0, .context = 324032326419089524664645871664683721802, .context_padding = 0, .client = 47899338719226163297711645970010401862, .op = 133, .commit = 133, .timestamp = 1763996660632307578, .request = 131, .operation = vsr.Operation(141), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:04:22.844Z debug(forest): entering forest.compact() op=133 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2025-11-24 15:04:22.844Z debug(replica): 2n: client_table_entry_update: client=47899338719226163297711645970010401862 session=2 request=131
2025-11-24 15:04:22.844Z debug(forest): entering forest.compact() op=133 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2025-11-24 15:04:22.845Z debug(replica): 2n: on_message: view=3 status=normal vsr.message_header.Header.Request{ .checksum = 96289780212968966528001553264574252255, .checksum_padding = 0, .checksum_body = 326289093971322640297727606153193791024, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2240, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 324032326419089524664645871664683721802, .parent_padding = 0, .client = 47899338719226163297711645970010401862, .session = 2, .timestamp = 0, .request = 132, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 26564258, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:04:22.845Z debug(replica): 2n: on_request: forwarding new request to primary (view=3)
2025-11-24 15:04:22.845Z debug(replica): 2n: sending request to replica 0: vsr.message_header.Header.Request{ .checksum = 96289780212968966528001553264574252255, .checksum_padding = 0, .checksum_body = 326289093971322640297727606153193791024, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2240, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 324032326419089524664645871664683721802, .parent_padding = 0, .client = 47899338719226163297711645970010401862, .session = 2, .timestamp = 0, .request = 132, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 26564258, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:04:22.845Z debug(replica): 1n: on_message: view=3 status=normal vsr.message_header.Header.Request{ .checksum = 96289780212968966528001553264574252255, .checksum_padding = 0, .checksum_body = 326289093971322640297727606153193791024, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2240, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 324032326419089524664645871664683721802, .parent_padding = 0, .client = 47899338719226163297711645970010401862, .session = 2, .timestamp = 0, .request = 132, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 26564258, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:04:22.845Z debug(replica): 1n: on_request: forwarding new request to primary (view=3)
2025-11-24 15:04:22.845Z debug(replica): 1n: sending request to replica 0: vsr.message_header.Header.Request{ .checksum = 96289780212968966528001553264574252255, .checksum_padding = 0, .checksum_body = 326289093971322640297727606153193791024, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2240, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 324032326419089524664645871664683721802, .parent_padding = 0, .client = 47899338719226163297711645970010401862, .session = 2, .timestamp = 0, .request = 132, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 26564258, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:04:22.845Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.prepares offset=140509184 len=4096 unlocked
2025-11-24 15:04:22.845Z debug(journal): 2: write_header: op=134 sectors[32768..36864]
2025-11-24 15:04:22.845Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.headers offset=32768 len=4096 locked
2025-11-24 15:04:22.845Z debug(vsr): 2: journal_repair_budget_timeout fired
2025-11-24 15:04:22.845Z debug(vsr): 2: journal_repair_budget_timeout reset
2025-11-24 15:04:22.845Z debug(replica): 0N: on_message: view=3 status=normal vsr.message_header.Header.Request{ .checksum = 96289780212968966528001553264574252255, .checksum_padding = 0, .checksum_body = 326289093971322640297727606153193791024, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2240, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 324032326419089524664645871664683721802, .parent_padding = 0, .client = 47899338719226163297711645970010401862, .session = 2, .timestamp = 0, .request = 132, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 26564258, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:04:22.845Z debug(replica): 0N: on_request: new request
2025-11-24 15:04:22.845Z debug(replica): 0N: on_request: ignoring (already preparing)
2025-11-24 15:04:22.845Z debug(client_replies): 2: write_reply: wrote (client=47899338719226163297711645970010401862 request=131)
2025-11-24 15:04:22.845Z debug(replica): 0N: on_message: view=3 status=normal vsr.message_header.Header.Request{ .checksum = 96289780212968966528001553264574252255, .checksum_padding = 0, .checksum_body = 326289093971322640297727606153193791024, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2240, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 324032326419089524664645871664683721802, .parent_padding = 0, .client = 47899338719226163297711645970010401862, .session = 2, .timestamp = 0, .request = 132, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 26564258, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:04:22.845Z debug(replica): 0N: on_request: new request
2025-11-24 15:04:22.845Z debug(replica): 0N: on_request: ignoring (already preparing)
2025-11-24 15:04:22.845Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.prepares offset=140509184 len=4096 unlocked
2025-11-24 15:04:22.845Z debug(journal): 1: write_header: op=134 sectors[32768..36864]
2025-11-24 15:04:22.845Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.headers offset=32768 len=4096 locked
2025-11-24 15:04:22.845Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.headers offset=32768 len=4096 unlocked
2025-11-24 15:04:22.845Z debug(journal): 2: write: view=3 slot=134 op=134 len=2240: 232042921376966079360087090401252901567 complete, marking clean
2025-11-24 15:04:22.845Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.headers offset=32768 len=4096 unlocked
2025-11-24 15:04:22.845Z debug(replica): 2n: send_prepare_ok: op=134 checksum=232042921376966079360087090401252901567
2025-11-24 15:04:22.845Z debug(journal): 1: write: view=3 slot=134 op=134 len=2240: 232042921376966079360087090401252901567 complete, marking clean
2025-11-24 15:04:22.845Z debug(replica): 1n: send_prepare_ok: op=134 checksum=232042921376966079360087090401252901567
2025-11-24 15:04:22.845Z debug(replica): 2n: sending prepare_ok to replica 0: vsr.message_header.Header.PrepareOk{ .checksum = 313290877265343933811833076155026426659, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 32022280389824693374785059271038071692, .parent_padding = 0, .prepare_checksum = 232042921376966079360087090401252901567, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 47899338719226163297711645970010401862, .op = 134, .commit_min = 133, .timestamp = 1763996660658700576, .request = 132, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-11-24 15:04:22.845Z debug(replica): 1n: sending prepare_ok to replica 0: vsr.message_header.Header.PrepareOk{ .checksum = 330531380316961429441572683220541005261, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 32022280389824693374785059271038071692, .parent_padding = 0, .prepare_checksum = 232042921376966079360087090401252901567, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 47899338719226163297711645970010401862, .op = 134, .commit_min = 133, .timestamp = 1763996660658700576, .request = 132, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-11-24 15:04:22.845Z debug(replica): 0N: on_message: view=3 status=normal vsr.message_header.Header.PrepareOk{ .checksum = 330531380316961429441572683220541005261, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 32022280389824693374785059271038071692, .parent_padding = 0, .prepare_checksum = 232042921376966079360087090401252901567, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 47899338719226163297711645970010401862, .op = 134, .commit_min = 133, .timestamp = 1763996660658700576, .request = 132, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-11-24 15:04:22.845Z debug(client_replies): 1: write_reply: wrote (client=47899338719226163297711645970010401862 request=131)
2025-11-24 15:04:22.845Z debug(vsr): 0: primary_abdicate_timeout reset
2025-11-24 15:04:22.845Z debug(replica): 0N: on_prepare_ok: 2 message(s)
2025-11-24 15:04:22.845Z debug(replica): 0N: on_prepare_ok: quorum received, context=232042921376966079360087090401252901567
2025-11-24 15:04:22.845Z debug(vsr): 0: prepare_timeout stopped
2025-11-24 15:04:22.845Z debug(vsr): 0: primary_abdicate_timeout stopped
2025-11-24 15:04:22.846Z debug(replica): 0N: execute_op: executing view=3 primary=true op=134 checksum=232042921376966079360087090401252901567 (lookup_accounts)
2025-11-24 15:04:22.846Z debug(replica): 0N: execute_op: commit_timestamp=1763996660632307578 prepare.header.timestamp=1763996660658700576
2025-11-24 15:04:22.846Z debug(replica): 0N: execute_op: advancing commit_max=133..134
2025-11-24 15:04:22.846Z debug(replica): 0N: client_table_entry_update: client=47899338719226163297711645970010401862 session=2 request=132
2025-11-24 15:04:22.846Z debug(replica): 0N: execute_op: replying to client: vsr.message_header.Header.Reply{ .checksum = 186303368534218621249199075748179993482, .checksum_padding = 0, .checksum_body = 32222288799182611566902284274619174430, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 16128, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 96289780212968966528001553264574252255, .request_checksum_padding = 0, .context = 136023495080697200491152873417338192286, .context_padding = 0, .client = 47899338719226163297711645970010401862, .op = 134, .commit = 134, .timestamp = 1763996660658700576, .request = 132, .operation = vsr.Operation(140), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:04:22.846Z debug(replica): 0N: sending reply to client 47899338719226163297711645970010401862: vsr.message_header.Header.Reply{ .checksum = 186303368534218621249199075748179993482, .checksum_padding = 0, .checksum_body = 32222288799182611566902284274619174430, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 16128, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 96289780212968966528001553264574252255, .request_checksum_padding = 0, .context = 136023495080697200491152873417338192286, .context_padding = 0, .client = 47899338719226163297711645970010401862, .op = 134, .commit = 134, .timestamp = 1763996660658700576, .request = 132, .operation = vsr.Operation(140), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:04:22.846Z debug(forest): entering forest.compact() op=134 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2025-11-24 15:04:22.846Z debug(client_replies): 0: write_reply: wrote (client=47899338719226163297711645970010401862 request=132)
2025-11-24 15:04:22.854Z debug(vsr): 0: journal_repair_budget_timeout fired
2025-11-24 15:04:22.854Z debug(vsr): 0: journal_repair_budget_timeout reset
warning(client): 47899338719226163297711645970010401862: on_reply: slow request, request=132 op=134 size=2240 lookup_accounts time=2196ms
2025-11-24 15:04:22.854Z info(workload): accounts created = 123, transfers = 148548, pending transfers = 0, commands run = 66
2025-11-24 15:04:22.855Z debug(vsr): 2: journal_repair_timeout fired
2025-11-24 15:04:22.855Z debug(vsr): 2: journal_repair_timeout reset
2025-11-24 15:04:22.855Z debug(vsr): 1: journal_repair_budget_timeout fired
2025-11-24 15:04:22.855Z debug(vsr): 1: journal_repair_budget_timeout reset
2025-11-24 15:04:22.856Z debug(replica): 0N: on_message: view=3 status=normal vsr.message_header.Header.Request{ .checksum = 277867663734364631672568522860204162140, .checksum_padding = 0, .checksum_body = 242894706565499686312880999159249718121, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 140032, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 136023495080697200491152873417338192286, .parent_padding = 0, .client = 47899338719226163297711645970010401862, .session = 2, .timestamp = 0, .request = 133, .operation = vsr.Operation(139), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 2196072217, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:04:22.856Z debug(replica): 0N: on_request: new request
2025-11-24 15:04:22.856Z debug(replica): 0N: primary_pipeline_prepare: request checksum=277867663734364631672568522860204162140 client=47899338719226163297711645970010401862
2025-11-24 15:04:22.857Z debug(replica): 2n: on_message: view=3 status=normal vsr.message_header.Header.Request{ .checksum = 277867663734364631672568522860204162140, .checksum_padding = 0, .checksum_body = 242894706565499686312880999159249718121, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 140032, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 136023495080697200491152873417338192286, .parent_padding = 0, .client = 47899338719226163297711645970010401862, .session = 2, .timestamp = 0, .request = 133, .operation = vsr.Operation(139), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 2196072217, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:04:22.857Z debug(replica): 2n: on_request: forwarding new request to primary (view=3)
2025-11-24 15:04:22.857Z debug(replica): 2n: sending request to replica 0: vsr.message_header.Header.Request{ .checksum = 277867663734364631672568522860204162140, .checksum_padding = 0, .checksum_body = 242894706565499686312880999159249718121, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 140032, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 136023495080697200491152873417338192286, .parent_padding = 0, .client = 47899338719226163297711645970010401862, .session = 2, .timestamp = 0, .request = 133, .operation = vsr.Operation(139), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 2196072217, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:04:22.857Z debug(replica): 0N: primary_pipeline_prepare: prepare checksum=238447080257963584688034703090984724737 op=135
2025-11-24 15:04:22.857Z debug(vsr): 0: prepare_timeout started
2025-11-24 15:04:22.857Z debug(vsr): 0: primary_abdicate_timeout started
2025-11-24 15:04:22.857Z debug(vsr): 0: pulse_timeout reset
2025-11-24 15:04:22.857Z debug(replica): 0N: replicate: replicating op=135 to replica 2
2025-11-24 15:04:22.857Z debug(replica): 0N: sending prepare to replica 2: vsr.message_header.Header.Prepare{ .checksum = 238447080257963584688034703090984724737, .checksum_padding = 0, .checksum_body = 242894706565499686312880999159249718121, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 140032, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 232042921376966079360087090401252901567, .parent_padding = 0, .request_checksum = 277867663734364631672568522860204162140, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 47899338719226163297711645970010401862, .op = 135, .commit = 134, .timestamp = 1763996662856898414, .request = 133, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-11-24 15:04:22.857Z debug(replica): 0N: replicate: replicating op=135 to replica 1
2025-11-24 15:04:22.857Z debug(replica): 0N: sending prepare to replica 1: vsr.message_header.Header.Prepare{ .checksum = 238447080257963584688034703090984724737, .checksum_padding = 0, .checksum_body = 242894706565499686312880999159249718121, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 140032, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 232042921376966079360087090401252901567, .parent_padding = 0, .request_checksum = 277867663734364631672568522860204162140, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 47899338719226163297711645970010401862, .op = 135, .commit = 134, .timestamp = 1763996662856898414, .request = 133, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-11-24 15:04:22.857Z debug(replica): 0N: on_prepare: advancing: op=134..135 checksum=232042921376966079360087090401252901567..238447080257963584688034703090984724737
2025-11-24 15:04:22.857Z debug(journal): 0: set_header_as_dirty: op=135 checksum=238447080257963584688034703090984724737
2025-11-24 15:04:22.857Z debug(replica): 0N: append: appending to journal op=135
2025-11-24 15:04:22.857Z debug(journal): 0: write: view=3 slot=135 op=135 len=140032: 238447080257963584688034703090984724737 starting
2025-11-24 15:04:22.857Z debug(journal): 0: write_sectors: ring=vsr.journal.Ring.prepares offset=141557760 len=143360 locked
2025-11-24 15:04:22.857Z debug(replica): 0N: on_message: view=3 status=normal vsr.message_header.Header.PrepareOk{ .checksum = 313290877265343933811833076155026426659, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 32022280389824693374785059271038071692, .parent_padding = 0, .prepare_checksum = 232042921376966079360087090401252901567, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 47899338719226163297711645970010401862, .op = 134, .commit_min = 133, .timestamp = 1763996660658700576, .request = 132, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-11-24 15:04:22.857Z debug(replica): 0N: on_prepare_ok: not preparing op=134 checksum=232042921376966079360087090401252901567
2025-11-24 15:04:22.858Z debug(replica): 0N: on_message: view=3 status=normal vsr.message_header.Header.Request{ .checksum = 277867663734364631672568522860204162140, .checksum_padding = 0, .checksum_body = 242894706565499686312880999159249718121, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 140032, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 136023495080697200491152873417338192286, .parent_padding = 0, .client = 47899338719226163297711645970010401862, .session = 2, .timestamp = 0, .request = 133, .operation = vsr.Operation(139), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 2196072217, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:04:22.858Z debug(replica): 0N: on_request: new request
2025-11-24 15:04:22.858Z debug(replica): 0N: on_request: ignoring (already preparing)
2025-11-24 15:04:22.858Z debug(replica): 1n: on_message: view=3 status=normal vsr.message_header.Header.Prepare{ .checksum = 238447080257963584688034703090984724737, .checksum_padding = 0, .checksum_body = 242894706565499686312880999159249718121, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 140032, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 232042921376966079360087090401252901567, .parent_padding = 0, .request_checksum = 277867663734364631672568522860204162140, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 47899338719226163297711645970010401862, .op = 135, .commit = 134, .timestamp = 1763996662856898414, .request = 133, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-11-24 15:04:22.858Z debug(journal): 0: write_sectors: ring=vsr.journal.Ring.prepares offset=141557760 len=143360 unlocked
2025-11-24 15:04:22.858Z debug(journal): 0: write_header: op=135 sectors[32768..36864]
2025-11-24 15:04:22.858Z debug(replica): 1n: on_prepare: advancing commit_max=133..134
2025-11-24 15:04:22.858Z debug(journal): 0: write_sectors: ring=vsr.journal.Ring.headers offset=32768 len=4096 locked
2025-11-24 15:04:22.858Z debug(replica): 1n: on_prepare: caching prepare.op=135 (commit_min=133 op=134 commit_max=134 prepare_max=1007)
2025-11-24 15:04:22.858Z debug(journal): 0: write_sectors: ring=vsr.journal.Ring.headers offset=32768 len=4096 unlocked
2025-11-24 15:04:22.858Z debug(replica): 1n: on_prepare: advancing: op=134..135 checksum=232042921376966079360087090401252901567..238447080257963584688034703090984724737
2025-11-24 15:04:22.858Z debug(journal): 0: write: view=3 slot=135 op=135 len=140032: 238447080257963584688034703090984724737 complete, marking clean
2025-11-24 15:04:22.858Z debug(journal): 1: set_header_as_dirty: op=135 checksum=238447080257963584688034703090984724737
2025-11-24 15:04:22.858Z debug(replica): 0N: send_prepare_ok: op=135 checksum=238447080257963584688034703090984724737
2025-11-24 15:04:22.858Z debug(replica): 2n: on_message: view=3 status=normal vsr.message_header.Header.Prepare{ .checksum = 238447080257963584688034703090984724737, .checksum_padding = 0, .checksum_body = 242894706565499686312880999159249718121, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 140032, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 232042921376966079360087090401252901567, .parent_padding = 0, .request_checksum = 277867663734364631672568522860204162140, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 47899338719226163297711645970010401862, .op = 135, .commit = 134, .timestamp = 1763996662856898414, .request = 133, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-11-24 15:04:22.858Z debug(replica): 1n: append: appending to journal op=135
2025-11-24 15:04:22.858Z debug(journal): 1: write: view=3 slot=135 op=135 len=140032: 238447080257963584688034703090984724737 starting
2025-11-24 15:04:22.858Z debug(replica): 2n: on_prepare: advancing commit_max=133..134
2025-11-24 15:04:22.858Z debug(replica): 0N: sending prepare_ok to replica 0: vsr.message_header.Header.PrepareOk{ .checksum = 330416979520180080546807679700061516846, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 232042921376966079360087090401252901567, .parent_padding = 0, .prepare_checksum = 238447080257963584688034703090984724737, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 47899338719226163297711645970010401862, .op = 135, .commit_min = 134, .timestamp = 1763996662856898414, .request = 133, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-11-24 15:04:22.858Z debug(replica): 2n: on_prepare: caching prepare.op=135 (commit_min=133 op=134 commit_max=134 prepare_max=1007)
2025-11-24 15:04:22.858Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.prepares offset=141557760 len=143360 locked
2025-11-24 15:04:22.858Z debug(replica): 0N: on_message: view=3 status=normal vsr.message_header.Header.PrepareOk{ .checksum = 330416979520180080546807679700061516846, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 232042921376966079360087090401252901567, .parent_padding = 0, .prepare_checksum = 238447080257963584688034703090984724737, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 47899338719226163297711645970010401862, .op = 135, .commit_min = 134, .timestamp = 1763996662856898414, .request = 133, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-11-24 15:04:22.858Z debug(vsr): 0: primary_abdicate_timeout reset
2025-11-24 15:04:22.858Z debug(replica): 0N: on_prepare_ok: 1 message(s)
2025-11-24 15:04:22.858Z debug(replica): 1n: commit_start_journal: cached prepare op=134 checksum=232042921376966079360087090401252901567
2025-11-24 15:04:22.858Z debug(replica): 0N: on_prepare_ok: waiting for quorum
2025-11-24 15:04:22.858Z debug(replica): 2n: on_prepare: advancing: op=134..135 checksum=232042921376966079360087090401252901567..238447080257963584688034703090984724737
2025-11-24 15:04:22.858Z debug(journal): 2: set_header_as_dirty: op=135 checksum=238447080257963584688034703090984724737
2025-11-24 15:04:22.858Z debug(replica): 2n: append: appending to journal op=135
2025-11-24 15:04:22.858Z debug(journal): 2: write: view=3 slot=135 op=135 len=140032: 238447080257963584688034703090984724737 starting
2025-11-24 15:04:22.858Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.prepares offset=141557760 len=143360 locked
2025-11-24 15:04:22.858Z debug(replica): 2n: commit_start_journal: cached prepare op=134 checksum=232042921376966079360087090401252901567
2025-11-24 15:04:22.858Z debug(replica): 1n: repair_prepare: op=135 checksum=238447080257963584688034703090984724737 (already writing)
2025-11-24 15:04:22.858Z debug(replica): 1n: commit_journal: already committing (prefetch; commit_min=133)
2025-11-24 15:04:22.858Z debug(replica): 1n: execute_op: executing view=3 primary=false op=134 checksum=232042921376966079360087090401252901567 (lookup_accounts)
2025-11-24 15:04:22.858Z debug(replica): 1n: execute_op: commit_timestamp=1763996660632307578 prepare.header.timestamp=1763996660658700576
2025-11-24 15:04:22.858Z debug(replica): 2n: repair_prepare: op=135 checksum=238447080257963584688034703090984724737 (already writing)
2025-11-24 15:04:22.858Z debug(replica): 2n: commit_journal: already committing (prefetch; commit_min=133)
2025-11-24 15:04:22.858Z debug(replica): 2n: execute_op: executing view=3 primary=false op=134 checksum=232042921376966079360087090401252901567 (lookup_accounts)
2025-11-24 15:04:22.858Z debug(replica): 2n: execute_op: commit_timestamp=1763996660632307578 prepare.header.timestamp=1763996660658700576
2025-11-24 15:04:22.858Z debug(replica): 1n: client_table_entry_update: client=47899338719226163297711645970010401862 session=2 request=132
2025-11-24 15:04:22.858Z debug(replica): 1n: execute_op: replying to client: vsr.message_header.Header.Reply{ .checksum = 186303368534218621249199075748179993482, .checksum_padding = 0, .checksum_body = 32222288799182611566902284274619174430, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 16128, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 96289780212968966528001553264574252255, .request_checksum_padding = 0, .context = 136023495080697200491152873417338192286, .context_padding = 0, .client = 47899338719226163297711645970010401862, .op = 134, .commit = 134, .timestamp = 1763996660658700576, .request = 132, .operation = vsr.Operation(140), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:04:22.858Z debug(replica): 1n: sending reply to client 47899338719226163297711645970010401862: vsr.message_header.Header.Reply{ .checksum = 186303368534218621249199075748179993482, .checksum_padding = 0, .checksum_body = 32222288799182611566902284274619174430, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 16128, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 96289780212968966528001553264574252255, .request_checksum_padding = 0, .context = 136023495080697200491152873417338192286, .context_padding = 0, .client = 47899338719226163297711645970010401862, .op = 134, .commit = 134, .timestamp = 1763996660658700576, .request = 132, .operation = vsr.Operation(140), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:04:22.858Z debug(forest): entering forest.compact() op=134 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2025-11-24 15:04:22.858Z debug(replica): 2n: client_table_entry_update: client=47899338719226163297711645970010401862 session=2 request=132
2025-11-24 15:04:22.858Z debug(forest): entering forest.compact() op=134 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2025-11-24 15:04:22.859Z debug(client_replies): 1: write_reply: wrote (client=47899338719226163297711645970010401862 request=132)
2025-11-24 15:04:22.859Z debug(client_replies): 2: write_reply: wrote (client=47899338719226163297711645970010401862 request=132)
2025-11-24 15:04:22.859Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.prepares offset=141557760 len=143360 unlocked
2025-11-24 15:04:22.859Z debug(journal): 2: write_header: op=135 sectors[32768..36864]
2025-11-24 15:04:22.859Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.headers offset=32768 len=4096 locked
2025-11-24 15:04:22.859Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.headers offset=32768 len=4096 unlocked
2025-11-24 15:04:22.859Z debug(journal): 2: write: view=3 slot=135 op=135 len=140032: 238447080257963584688034703090984724737 complete, marking clean
2025-11-24 15:04:22.859Z debug(replica): 2n: send_prepare_ok: op=135 checksum=238447080257963584688034703090984724737
2025-11-24 15:04:22.859Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.prepares offset=141557760 len=143360 unlocked
2025-11-24 15:04:22.859Z debug(journal): 1: write_header: op=135 sectors[32768..36864]
2025-11-24 15:04:22.859Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.headers offset=32768 len=4096 locked
2025-11-24 15:04:22.859Z debug(replica): 2n: sending prepare_ok to replica 0: vsr.message_header.Header.PrepareOk{ .checksum = 273257949287700793479271728007307656659, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 232042921376966079360087090401252901567, .parent_padding = 0, .prepare_checksum = 238447080257963584688034703090984724737, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 47899338719226163297711645970010401862, .op = 135, .commit_min = 134, .timestamp = 1763996662856898414, .request = 133, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-11-24 15:04:22.859Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.headers offset=32768 len=4096 unlocked
2025-11-24 15:04:22.859Z debug(journal): 1: write: view=3 slot=135 op=135 len=140032: 238447080257963584688034703090984724737 complete, marking clean
2025-11-24 15:04:22.859Z debug(replica): 1n: send_prepare_ok: op=135 checksum=238447080257963584688034703090984724737
2025-11-24 15:04:22.859Z debug(replica): 0N: on_message: view=3 status=normal vsr.message_header.Header.PrepareOk{ .checksum = 273257949287700793479271728007307656659, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 232042921376966079360087090401252901567, .parent_padding = 0, .prepare_checksum = 238447080257963584688034703090984724737, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 47899338719226163297711645970010401862, .op = 135, .commit_min = 134, .timestamp = 1763996662856898414, .request = 133, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-11-24 15:04:22.859Z debug(vsr): 0: primary_abdicate_timeout reset
2025-11-24 15:04:22.859Z debug(replica): 0N: on_prepare_ok: 2 message(s)
2025-11-24 15:04:22.859Z debug(replica): 1n: sending prepare_ok to replica 0: vsr.message_header.Header.PrepareOk{ .checksum = 315902939963692722053823599104658990769, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 232042921376966079360087090401252901567, .parent_padding = 0, .prepare_checksum = 238447080257963584688034703090984724737, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 47899338719226163297711645970010401862, .op = 135, .commit_min = 134, .timestamp = 1763996662856898414, .request = 133, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-11-24 15:04:22.859Z debug(replica): 0N: on_prepare_ok: quorum received, context=238447080257963584688034703090984724737
2025-11-24 15:04:22.859Z debug(vsr): 0: prepare_timeout stopped
2025-11-24 15:04:22.859Z debug(vsr): 0: primary_abdicate_timeout stopped
2025-11-24 15:04:22.860Z debug(replica): 0N: execute_op: executing view=3 primary=true op=135 checksum=238447080257963584688034703090984724737 (create_transfers)
2025-11-24 15:04:22.860Z debug(replica): 0N: execute_op: commit_timestamp=1763996660658700576 prepare.header.timestamp=1763996662856898414
2025-11-24 15:04:22.862Z debug(replica): 0N: execute_op: advancing commit_max=134..135
2025-11-24 15:04:22.862Z debug(replica): 0N: client_table_entry_update: client=47899338719226163297711645970010401862 session=2 request=133
2025-11-24 15:04:22.862Z debug(replica): 0N: execute_op: replying to client: vsr.message_header.Header.Reply{ .checksum = 82463302535738240527575781208925510211, .checksum_padding = 0, .checksum_body = 280888397998551554775133939907273910887, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 272, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 277867663734364631672568522860204162140, .request_checksum_padding = 0, .context = 167011173865265016650135292372277511698, .context_padding = 0, .client = 47899338719226163297711645970010401862, .op = 135, .commit = 135, .timestamp = 1763996662856898414, .request = 133, .operation = vsr.Operation(139), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:04:22.862Z debug(replica): 0N: sending reply to client 47899338719226163297711645970010401862: vsr.message_header.Header.Reply{ .checksum = 82463302535738240527575781208925510211, .checksum_padding = 0, .checksum_body = 280888397998551554775133939907273910887, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 272, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 277867663734364631672568522860204162140, .request_checksum_padding = 0, .context = 167011173865265016650135292372277511698, .context_padding = 0, .client = 47899338719226163297711645970010401862, .op = 135, .commit = 135, .timestamp = 1763996662856898414, .request = 133, .operation = vsr.Operation(139), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:04:22.862Z debug(forest): entering forest.compact() op=135 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2025-11-24 15:04:22.864Z debug(replica): 0N: on_message: view=3 status=normal vsr.message_header.Header.PrepareOk{ .checksum = 315902939963692722053823599104658990769, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 232042921376966079360087090401252901567, .parent_padding = 0, .prepare_checksum = 238447080257963584688034703090984724737, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 47899338719226163297711645970010401862, .op = 135, .commit_min = 134, .timestamp = 1763996662856898414, .request = 133, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-11-24 15:04:22.864Z debug(replica): 0N: on_prepare_ok: not preparing op=135 checksum=238447080257963584688034703090984724737
2025-11-24 15:04:22.864Z debug(vsr): 0: journal_repair_timeout fired
2025-11-24 15:04:22.864Z debug(vsr): 0: journal_repair_timeout reset
2025-11-24 15:04:22.864Z debug(client_replies): 0: write_reply: wrote (client=47899338719226163297711645970010401862 request=133)
2025-11-24 15:04:22.865Z debug(vsr): 2: journal_repair_budget_timeout fired
2025-11-24 15:04:22.865Z debug(vsr): 2: journal_repair_budget_timeout reset
2025-11-24 15:04:22.866Z debug(replica): 0N: on_message: view=3 status=normal vsr.message_header.Header.Request{ .checksum = 269920912450624060375079935141954184145, .checksum_padding = 0, .checksum_body = 326289093971322640297727606153193791024, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2240, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 167011173865265016650135292372277511698, .parent_padding = 0, .client = 47899338719226163297711645970010401862, .session = 2, .timestamp = 0, .request = 134, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 7318105, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:04:22.866Z debug(replica): 1n: on_message: view=3 status=normal vsr.message_header.Header.Request{ .checksum = 269920912450624060375079935141954184145, .checksum_padding = 0, .checksum_body = 326289093971322640297727606153193791024, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2240, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 167011173865265016650135292372277511698, .parent_padding = 0, .client = 47899338719226163297711645970010401862, .session = 2, .timestamp = 0, .request = 134, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 7318105, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:04:22.866Z debug(replica): 0N: on_request: new request
2025-11-24 15:04:22.866Z debug(replica): 1n: on_request: forwarding new request to primary (view=3)
2025-11-24 15:04:22.866Z debug(replica): 0N: primary_pipeline_prepare: request checksum=269920912450624060375079935141954184145 client=47899338719226163297711645970010401862
2025-11-24 15:04:22.866Z debug(replica): 1n: sending request to replica 0: vsr.message_header.Header.Request{ .checksum = 269920912450624060375079935141954184145, .checksum_padding = 0, .checksum_body = 326289093971322640297727606153193791024, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2240, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 167011173865265016650135292372277511698, .parent_padding = 0, .client = 47899338719226163297711645970010401862, .session = 2, .timestamp = 0, .request = 134, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 7318105, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:04:22.866Z debug(replica): 0N: primary_pipeline_prepare: prepare checksum=217007747168728139790049223929420409766 op=136
2025-11-24 15:04:22.866Z debug(vsr): 0: prepare_timeout started
2025-11-24 15:04:22.866Z debug(vsr): 0: primary_abdicate_timeout started
2025-11-24 15:04:22.866Z debug(vsr): 0: pulse_timeout reset
2025-11-24 15:04:22.866Z debug(replica): 0N: replicate: replicating op=136 to replica 2
2025-11-24 15:04:22.875Z debug(vsr): 1: journal_repair_budget_timeout fired
2025-11-24 15:04:22.875Z debug(vsr): 1: journal_repair_budget_timeout reset
2025-11-24 15:04:22.885Z debug(vsr): 2: journal_repair_budget_timeout fired
2025-11-24 15:04:22.885Z debug(vsr): 2: journal_repair_budget_timeout reset
2025-11-24 15:04:22.885Z debug(vsr): 1: journal_repair_timeout fired
2025-11-24 15:04:22.885Z debug(vsr): 1: journal_repair_timeout reset
2025-11-24 15:04:22.866Z debug(replica): 0N: sending prepare to replica 2: vsr.message_header.Header.Prepare{ .checksum = 217007747168728139790049223929420409766, .checksum_padding = 0, .checksum_body = 326289093971322640297727606153193791024, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2240, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 238447080257963584688034703090984724737, .parent_padding = 0, .request_checksum = 269920912450624060375079935141954184145, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 47899338719226163297711645970010401862, .op = 136, .commit = 135, .timestamp = 1763996662866912860, .request = 134, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-11-24 15:04:26.025Z debug(replica): 0N: replicate: replicating op=136 to replica 1
2025-11-24 15:04:26.025Z debug(replica): 0N: sending prepare to replica 1: vsr.message_header.Header.Prepare{ .checksum = 217007747168728139790049223929420409766, .checksum_padding = 0, .checksum_body = 326289093971322640297727606153193791024, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2240, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 238447080257963584688034703090984724737, .parent_padding = 0, .request_checksum = 269920912450624060375079935141954184145, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 47899338719226163297711645970010401862, .op = 136, .commit = 135, .timestamp = 1763996662866912860, .request = 134, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-11-24 15:04:26.025Z debug(replica): 0N: on_prepare: advancing: op=135..136 checksum=238447080257963584688034703090984724737..217007747168728139790049223929420409766
2025-11-24 15:04:26.025Z debug(journal): 0: set_header_as_dirty: op=136 checksum=217007747168728139790049223929420409766
2025-11-24 15:04:22.895Z debug(vsr): 1: journal_repair_budget_timeout fired
2025-11-24 15:04:26.025Z debug(replica): 0N: append: appending to journal op=136
2025-11-24 15:04:26.025Z debug(journal): 0: write: view=3 slot=136 op=136 len=2240: 217007747168728139790049223929420409766 starting
2025-11-24 15:04:26.025Z debug(journal): 0: write_sectors: ring=vsr.journal.Ring.prepares offset=142606336 len=4096 locked
2025-11-24 15:04:26.025Z debug(vsr): 1: journal_repair_budget_timeout reset
2025-11-24 15:04:26.025Z debug(replica): 1n: on_message: view=3 status=normal vsr.message_header.Header.Request{ .checksum = 269920912450624060375079935141954184145, .checksum_padding = 0, .checksum_body = 326289093971322640297727606153193791024, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2240, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 167011173865265016650135292372277511698, .parent_padding = 0, .client = 47899338719226163297711645970010401862, .session = 2, .timestamp = 0, .request = 134, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 7318105, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:04:26.025Z debug(replica): 1n: on_request: forwarding new request to primary (view=3)
2025-11-24 15:04:22.905Z debug(vsr): 2: journal_repair_budget_timeout fired
2025-11-24 15:04:26.025Z debug(replica): 1n: sending request to replica 0: vsr.message_header.Header.Request{ .checksum = 269920912450624060375079935141954184145, .checksum_padding = 0, .checksum_body = 326289093971322640297727606153193791024, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2240, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 167011173865265016650135292372277511698, .parent_padding = 0, .client = 47899338719226163297711645970010401862, .session = 2, .timestamp = 0, .request = 134, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 7318105, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:04:26.025Z debug(vsr): 2: journal_repair_budget_timeout reset
2025-11-24 15:04:26.025Z debug(replica): 2n: on_message: view=3 status=normal vsr.message_header.Header.Prepare{ .checksum = 217007747168728139790049223929420409766, .checksum_padding = 0, .checksum_body = 326289093971322640297727606153193791024, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2240, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 238447080257963584688034703090984724737, .parent_padding = 0, .request_checksum = 269920912450624060375079935141954184145, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 47899338719226163297711645970010401862, .op = 136, .commit = 135, .timestamp = 1763996662866912860, .request = 134, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-11-24 15:04:26.025Z debug(replica): 1n: on_message: view=3 status=normal vsr.message_header.Header.Prepare{ .checksum = 217007747168728139790049223929420409766, .checksum_padding = 0, .checksum_body = 326289093971322640297727606153193791024, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2240, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 238447080257963584688034703090984724737, .parent_padding = 0, .request_checksum = 269920912450624060375079935141954184145, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 47899338719226163297711645970010401862, .op = 136, .commit = 135, .timestamp = 1763996662866912860, .request = 134, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-11-24 15:04:26.025Z debug(replica): 1n: on_prepare: advancing commit_max=134..135
2025-11-24 15:04:26.025Z debug(replica): 2n: on_prepare: advancing commit_max=134..135
2025-11-24 15:04:26.025Z debug(replica): 1n: on_prepare: caching prepare.op=136 (commit_min=134 op=135 commit_max=135 prepare_max=1007)
2025-11-24 15:04:26.025Z debug(replica): 2n: on_prepare: caching prepare.op=136 (commit_min=134 op=135 commit_max=135 prepare_max=1007)
2025-11-24 15:04:26.025Z debug(replica): 1n: on_prepare: advancing: op=135..136 checksum=238447080257963584688034703090984724737..217007747168728139790049223929420409766
2025-11-24 15:04:26.025Z debug(journal): 1: set_header_as_dirty: op=136 checksum=217007747168728139790049223929420409766
2025-11-24 15:04:26.025Z debug(replica): 1n: append: appending to journal op=136
2025-11-24 15:04:26.025Z debug(journal): 1: write: view=3 slot=136 op=136 len=2240: 217007747168728139790049223929420409766 starting
2025-11-24 15:04:26.025Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.prepares offset=142606336 len=4096 locked
2025-11-24 15:04:26.025Z debug(replica): 1n: commit_start_journal: cached prepare op=135 checksum=238447080257963584688034703090984724737
2025-11-24 15:04:26.025Z debug(replica): 2n: on_prepare: advancing: op=135..136 checksum=238447080257963584688034703090984724737..217007747168728139790049223929420409766
2025-11-24 15:04:26.026Z debug(journal): 2: set_header_as_dirty: op=136 checksum=217007747168728139790049223929420409766
2025-11-24 15:04:26.026Z debug(replica): 2n: append: appending to journal op=136
2025-11-24 15:04:26.026Z debug(journal): 2: write: view=3 slot=136 op=136 len=2240: 217007747168728139790049223929420409766 starting
2025-11-24 15:04:26.026Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.prepares offset=142606336 len=4096 locked
2025-11-24 15:04:26.026Z debug(replica): 2n: commit_start_journal: cached prepare op=135 checksum=238447080257963584688034703090984724737
2025-11-24 15:04:26.026Z debug(replica): 1n: repair_prepare: op=136 checksum=217007747168728139790049223929420409766 (already writing)
2025-11-24 15:04:26.026Z debug(replica): 1n: commit_journal: already committing (prefetch; commit_min=134)
2025-11-24 15:04:26.026Z debug(replica): 2n: repair_prepare: op=136 checksum=217007747168728139790049223929420409766 (already writing)
2025-11-24 15:04:26.026Z debug(replica): 2n: commit_journal: already committing (prefetch; commit_min=134)
2025-11-24 15:04:26.026Z debug(replica): 1n: execute_op: executing view=3 primary=false op=135 checksum=238447080257963584688034703090984724737 (create_transfers)
2025-11-24 15:04:26.026Z debug(replica): 1n: execute_op: commit_timestamp=1763996660658700576 prepare.header.timestamp=1763996662856898414
2025-11-24 15:04:26.027Z debug(replica): 2n: execute_op: executing view=3 primary=false op=135 checksum=238447080257963584688034703090984724737 (create_transfers)
2025-11-24 15:04:26.027Z debug(replica): 2n: execute_op: commit_timestamp=1763996660658700576 prepare.header.timestamp=1763996662856898414
2025-11-24 15:04:26.031Z debug(replica): 1n: client_table_entry_update: client=47899338719226163297711645970010401862 session=2 request=133
2025-11-24 15:04:26.031Z debug(forest): entering forest.compact() op=135 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2025-11-24 15:04:26.031Z debug(replica): 2n: client_table_entry_update: client=47899338719226163297711645970010401862 session=2 request=133
2025-11-24 15:04:26.032Z debug(replica): 2n: execute_op: replying to client: vsr.message_header.Header.Reply{ .checksum = 82463302535738240527575781208925510211, .checksum_padding = 0, .checksum_body = 280888397998551554775133939907273910887, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 272, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 277867663734364631672568522860204162140, .request_checksum_padding = 0, .context = 167011173865265016650135292372277511698, .context_padding = 0, .client = 47899338719226163297711645970010401862, .op = 135, .commit = 135, .timestamp = 1763996662856898414, .request = 133, .operation = vsr.Operation(139), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:04:26.032Z debug(replica): 2n: sending reply to client 47899338719226163297711645970010401862: vsr.message_header.Header.Reply{ .checksum = 82463302535738240527575781208925510211, .checksum_padding = 0, .checksum_body = 280888397998551554775133939907273910887, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 272, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 277867663734364631672568522860204162140, .request_checksum_padding = 0, .context = 167011173865265016650135292372277511698, .context_padding = 0, .client = 47899338719226163297711645970010401862, .op = 135, .commit = 135, .timestamp = 1763996662856898414, .request = 133, .operation = vsr.Operation(139), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:04:26.032Z debug(forest): entering forest.compact() op=135 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2025-11-24 15:04:26.033Z debug(replica): 0N: on_message: view=3 status=normal vsr.message_header.Header.Request{ .checksum = 269920912450624060375079935141954184145, .checksum_padding = 0, .checksum_body = 326289093971322640297727606153193791024, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2240, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 167011173865265016650135292372277511698, .parent_padding = 0, .client = 47899338719226163297711645970010401862, .session = 2, .timestamp = 0, .request = 134, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 7318105, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:04:26.033Z debug(replica): 0N: on_request: new request
2025-11-24 15:04:26.033Z debug(replica): 0N: on_request: ignoring (already preparing)
2025-11-24 15:04:26.033Z debug(replica): 0N: on_message: view=3 status=normal vsr.message_header.Header.Request{ .checksum = 269920912450624060375079935141954184145, .checksum_padding = 0, .checksum_body = 326289093971322640297727606153193791024, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2240, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 167011173865265016650135292372277511698, .parent_padding = 0, .client = 47899338719226163297711645970010401862, .session = 2, .timestamp = 0, .request = 134, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 7318105, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:04:26.033Z debug(replica): 0N: on_request: new request
2025-11-24 15:04:26.033Z debug(replica): 0N: on_request: ignoring (already preparing)
2025-11-24 15:04:26.033Z debug(replica): 0N: on_message: view=3 status=normal vsr.message_header.Header.Request{ .checksum = 269920912450624060375079935141954184145, .checksum_padding = 0, .checksum_body = 326289093971322640297727606153193791024, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2240, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 167011173865265016650135292372277511698, .parent_padding = 0, .client = 47899338719226163297711645970010401862, .session = 2, .timestamp = 0, .request = 134, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 7318105, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:04:26.033Z debug(replica): 0N: on_request: new request
2025-11-24 15:04:26.033Z debug(replica): 0N: on_request: ignoring (already preparing)
2025-11-24 15:04:26.033Z debug(journal): 0: write_sectors: ring=vsr.journal.Ring.prepares offset=142606336 len=4096 unlocked
2025-11-24 15:04:26.033Z debug(journal): 0: write_header: op=136 sectors[32768..36864]
2025-11-24 15:04:26.033Z debug(journal): 0: write_sectors: ring=vsr.journal.Ring.headers offset=32768 len=4096 locked
2025-11-24 15:04:26.034Z debug(replica): 0N: on_message: view=3 status=normal vsr.message_header.Header.Request{ .checksum = 269920912450624060375079935141954184145, .checksum_padding = 0, .checksum_body = 326289093971322640297727606153193791024, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2240, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 167011173865265016650135292372277511698, .parent_padding = 0, .client = 47899338719226163297711645970010401862, .session = 2, .timestamp = 0, .request = 134, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 7318105, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:04:26.034Z debug(replica): 0N: on_request: new request
2025-11-24 15:04:26.034Z debug(replica): 0N: on_request: ignoring (already preparing)
2025-11-24 15:04:26.034Z debug(journal): 0: write_sectors: ring=vsr.journal.Ring.headers offset=32768 len=4096 unlocked
2025-11-24 15:04:26.034Z debug(journal): 0: write: view=3 slot=136 op=136 len=2240: 217007747168728139790049223929420409766 complete, marking clean
2025-11-24 15:04:26.034Z debug(replica): 0N: send_prepare_ok: op=136 checksum=217007747168728139790049223929420409766
2025-11-24 15:04:26.034Z debug(replica): 1n: on_message: view=3 status=normal vsr.message_header.Header.Request{ .checksum = 269920912450624060375079935141954184145, .checksum_padding = 0, .checksum_body = 326289093971322640297727606153193791024, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2240, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 167011173865265016650135292372277511698, .parent_padding = 0, .client = 47899338719226163297711645970010401862, .session = 2, .timestamp = 0, .request = 134, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 7318105, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:04:26.034Z debug(replica): 0N: sending prepare_ok to replica 0: vsr.message_header.Header.PrepareOk{ .checksum = 327402301972193871733702683324798446356, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 238447080257963584688034703090984724737, .parent_padding = 0, .prepare_checksum = 217007747168728139790049223929420409766, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 47899338719226163297711645970010401862, .op = 136, .commit_min = 135, .timestamp = 1763996662866912860, .request = 134, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-11-24 15:04:26.034Z debug(replica): 1n: on_request: forwarding new request to primary (view=3)
2025-11-24 15:04:26.034Z debug(replica): 0N: on_message: view=3 status=normal vsr.message_header.Header.PrepareOk{ .checksum = 327402301972193871733702683324798446356, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 238447080257963584688034703090984724737, .parent_padding = 0, .prepare_checksum = 217007747168728139790049223929420409766, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 47899338719226163297711645970010401862, .op = 136, .commit_min = 135, .timestamp = 1763996662866912860, .request = 134, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-11-24 15:04:26.034Z debug(vsr): 0: primary_abdicate_timeout reset
2025-11-24 15:04:26.034Z debug(replica): 0N: on_prepare_ok: 1 message(s)
2025-11-24 15:04:26.034Z debug(replica): 1n: sending request to replica 0: vsr.message_header.Header.Request{ .checksum = 269920912450624060375079935141954184145, .checksum_padding = 0, .checksum_body = 326289093971322640297727606153193791024, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2240, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 167011173865265016650135292372277511698, .parent_padding = 0, .client = 47899338719226163297711645970010401862, .session = 2, .timestamp = 0, .request = 134, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 7318105, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:04:26.034Z debug(replica): 0N: on_prepare_ok: waiting for quorum
2025-11-24 15:04:26.034Z debug(vsr): 0: journal_repair_budget_timeout fired
2025-11-24 15:04:26.034Z debug(vsr): 0: journal_repair_budget_timeout reset
2025-11-24 15:04:26.034Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.prepares offset=142606336 len=4096 unlocked
2025-11-24 15:04:26.034Z debug(journal): 1: write_header: op=136 sectors[32768..36864]
2025-11-24 15:04:26.034Z debug(replica): 0N: on_message: view=3 status=normal vsr.message_header.Header.Request{ .checksum = 269920912450624060375079935141954184145, .checksum_padding = 0, .checksum_body = 326289093971322640297727606153193791024, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2240, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 167011173865265016650135292372277511698, .parent_padding = 0, .client = 47899338719226163297711645970010401862, .session = 2, .timestamp = 0, .request = 134, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 7318105, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:04:26.034Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.headers offset=32768 len=4096 locked
2025-11-24 15:04:26.034Z debug(replica): 0N: on_request: new request
2025-11-24 15:04:26.034Z debug(client_replies): 1: write_reply: wrote (client=47899338719226163297711645970010401862 request=133)
2025-11-24 15:04:26.034Z debug(replica): 0N: on_request: ignoring (already preparing)
2025-11-24 15:04:26.034Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.headers offset=32768 len=4096 unlocked
2025-11-24 15:04:26.034Z debug(journal): 1: write: view=3 slot=136 op=136 len=2240: 217007747168728139790049223929420409766 complete, marking clean
2025-11-24 15:04:26.034Z debug(replica): 1n: send_prepare_ok: op=136 checksum=217007747168728139790049223929420409766
2025-11-24 15:04:26.034Z debug(replica): 1n: sending prepare_ok to replica 0: vsr.message_header.Header.PrepareOk{ .checksum = 291803518110945324546745513846156421847, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 238447080257963584688034703090984724737, .parent_padding = 0, .prepare_checksum = 217007747168728139790049223929420409766, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 47899338719226163297711645970010401862, .op = 136, .commit_min = 135, .timestamp = 1763996662866912860, .request = 134, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-11-24 15:04:26.034Z debug(replica): 0N: on_message: view=3 status=normal vsr.message_header.Header.PrepareOk{ .checksum = 291803518110945324546745513846156421847, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 238447080257963584688034703090984724737, .parent_padding = 0, .prepare_checksum = 217007747168728139790049223929420409766, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 47899338719226163297711645970010401862, .op = 136, .commit_min = 135, .timestamp = 1763996662866912860, .request = 134, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-11-24 15:04:26.034Z debug(vsr): 0: primary_abdicate_timeout reset
2025-11-24 15:04:26.034Z debug(replica): 0N: on_prepare_ok: 2 message(s)
2025-11-24 15:04:26.034Z debug(replica): 0N: on_prepare_ok: quorum received, context=217007747168728139790049223929420409766
2025-11-24 15:04:26.034Z debug(vsr): 0: prepare_timeout stopped
2025-11-24 15:04:26.034Z debug(vsr): 0: primary_abdicate_timeout stopped
2025-11-24 15:04:26.035Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.prepares offset=142606336 len=4096 unlocked
2025-11-24 15:04:26.035Z debug(journal): 2: write_header: op=136 sectors[32768..36864]
2025-11-24 15:04:26.035Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.headers offset=32768 len=4096 locked
2025-11-24 15:04:26.035Z debug(client_replies): 2: write_reply: wrote (client=47899338719226163297711645970010401862 request=133)
2025-11-24 15:04:26.035Z debug(replica): 0N: execute_op: executing view=3 primary=true op=136 checksum=217007747168728139790049223929420409766 (lookup_accounts)
2025-11-24 15:04:26.035Z debug(replica): 0N: execute_op: commit_timestamp=1763996662856898414 prepare.header.timestamp=1763996662866912860
2025-11-24 15:04:26.035Z debug(replica): 0N: execute_op: advancing commit_max=135..136
2025-11-24 15:04:26.035Z debug(replica): 0N: client_table_entry_update: client=47899338719226163297711645970010401862 session=2 request=134
2025-11-24 15:04:26.035Z debug(replica): 0N: execute_op: replying to client: vsr.message_header.Header.Reply{ .checksum = 98206438905762972913806947968348119535, .checksum_padding = 0, .checksum_body = 47593893661410242558481480173055552124, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 16128, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 269920912450624060375079935141954184145, .request_checksum_padding = 0, .context = 14330724469910135810312754645440234171, .context_padding = 0, .client = 47899338719226163297711645970010401862, .op = 136, .commit = 136, .timestamp = 1763996662866912860, .request = 134, .operation = vsr.Operation(140), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:04:26.035Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.headers offset=32768 len=4096 unlocked
2025-11-24 15:04:26.035Z debug(replica): 0N: sending reply to client 47899338719226163297711645970010401862: vsr.message_header.Header.Reply{ .checksum = 98206438905762972913806947968348119535, .checksum_padding = 0, .checksum_body = 47593893661410242558481480173055552124, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 16128, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 269920912450624060375079935141954184145, .request_checksum_padding = 0, .context = 14330724469910135810312754645440234171, .context_padding = 0, .client = 47899338719226163297711645970010401862, .op = 136, .commit = 136, .timestamp = 1763996662866912860, .request = 134, .operation = vsr.Operation(140), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:04:26.035Z debug(journal): 2: write: view=3 slot=136 op=136 len=2240: 217007747168728139790049223929420409766 complete, marking clean
2025-11-24 15:04:26.035Z debug(replica): 2n: send_prepare_ok: op=136 checksum=217007747168728139790049223929420409766
2025-11-24 15:04:26.035Z debug(forest): entering forest.compact() op=136 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2025-11-24 15:04:26.035Z debug(replica): 2n: sending prepare_ok to replica 0: vsr.message_header.Header.PrepareOk{ .checksum = 75904003503323443472328342967340007621, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 238447080257963584688034703090984724737, .parent_padding = 0, .prepare_checksum = 217007747168728139790049223929420409766, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 47899338719226163297711645970010401862, .op = 136, .commit_min = 135, .timestamp = 1763996662866912860, .request = 134, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
warning(client): 47899338719226163297711645970010401862: on_reply: slow request, request=134 op=136 size=2240 lookup_accounts time=3169ms
2025-11-24 15:04:26.036Z debug(replica): 0N: on_message: view=3 status=normal vsr.message_header.Header.PrepareOk{ .checksum = 75904003503323443472328342967340007621, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 238447080257963584688034703090984724737, .parent_padding = 0, .prepare_checksum = 217007747168728139790049223929420409766, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 47899338719226163297711645970010401862, .op = 136, .commit_min = 135, .timestamp = 1763996662866912860, .request = 134, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-11-24 15:04:26.036Z debug(replica): 0N: on_prepare_ok: not preparing op=136 checksum=217007747168728139790049223929420409766
2025-11-24 15:04:26.036Z debug(client_replies): 0: write_reply: wrote (client=47899338719226163297711645970010401862 request=134)
2025-11-24 15:04:26.036Z info(workload): accounts created = 123, transfers = 149639, pending transfers = 0, commands run = 67
2025-11-24 15:04:26.039Z debug(replica): 0N: on_message: view=3 status=normal vsr.message_header.Header.Request{ .checksum = 230610731585297784448338444199878822078, .checksum_padding = 0, .checksum_body = 73422816465872014824228908356899921776, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 169216, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 14330724469910135810312754645440234171, .parent_padding = 0, .client = 47899338719226163297711645970010401862, .session = 2, .timestamp = 0, .request = 135, .operation = vsr.Operation(139), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 3169494419, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:04:26.039Z debug(replica): 0N: on_request: new request
2025-11-24 15:04:26.039Z debug(replica): 0N: primary_pipeline_prepare: request checksum=230610731585297784448338444199878822078 client=47899338719226163297711645970010401862
2025-11-24 15:04:26.040Z debug(replica): 2n: on_message: view=3 status=normal vsr.message_header.Header.Request{ .checksum = 230610731585297784448338444199878822078, .checksum_padding = 0, .checksum_body = 73422816465872014824228908356899921776, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 169216, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 14330724469910135810312754645440234171, .parent_padding = 0, .client = 47899338719226163297711645970010401862, .session = 2, .timestamp = 0, .request = 135, .operation = vsr.Operation(139), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 3169494419, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:04:26.040Z debug(replica): 2n: on_request: forwarding new request to primary (view=3)
2025-11-24 15:04:26.040Z debug(replica): 2n: sending request to replica 0: vsr.message_header.Header.Request{ .checksum = 230610731585297784448338444199878822078, .checksum_padding = 0, .checksum_body = 73422816465872014824228908356899921776, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 169216, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 14330724469910135810312754645440234171, .parent_padding = 0, .client = 47899338719226163297711645970010401862, .session = 2, .timestamp = 0, .request = 135, .operation = vsr.Operation(139), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 3169494419, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:04:26.040Z debug(replica): 0N: primary_pipeline_prepare: prepare checksum=294801872995564543169944161164793483888 op=137
2025-11-24 15:04:26.040Z debug(vsr): 0: prepare_timeout started
2025-11-24 15:04:26.040Z debug(vsr): 0: primary_abdicate_timeout started
2025-11-24 15:04:26.040Z debug(vsr): 0: pulse_timeout reset
2025-11-24 15:04:26.040Z debug(replica): 0N: replicate: replicating op=137 to replica 2
2025-11-24 15:04:26.040Z debug(replica): 0N: sending prepare to replica 2: vsr.message_header.Header.Prepare{ .checksum = 294801872995564543169944161164793483888, .checksum_padding = 0, .checksum_body = 73422816465872014824228908356899921776, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 169216, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 217007747168728139790049223929420409766, .parent_padding = 0, .request_checksum = 230610731585297784448338444199878822078, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 47899338719226163297711645970010401862, .op = 137, .commit = 136, .timestamp = 1763996666039908400, .request = 135, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-11-24 15:04:26.040Z debug(replica): 0N: replicate: replicating op=137 to replica 1
2025-11-24 15:04:26.040Z debug(replica): 0N: sending prepare to replica 1: vsr.message_header.Header.Prepare{ .checksum = 294801872995564543169944161164793483888, .checksum_padding = 0, .checksum_body = 73422816465872014824228908356899921776, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 169216, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 217007747168728139790049223929420409766, .parent_padding = 0, .request_checksum = 230610731585297784448338444199878822078, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 47899338719226163297711645970010401862, .op = 137, .commit = 136, .timestamp = 1763996666039908400, .request = 135, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-11-24 15:04:26.040Z debug(replica): 0N: on_prepare: advancing: op=136..137 checksum=217007747168728139790049223929420409766..294801872995564543169944161164793483888
2025-11-24 15:04:26.040Z debug(journal): 0: set_header_as_dirty: op=137 checksum=294801872995564543169944161164793483888
2025-11-24 15:04:26.040Z debug(replica): 0N: append: appending to journal op=137
2025-11-24 15:04:26.040Z debug(journal): 0: write: view=3 slot=137 op=137 len=169216: 294801872995564543169944161164793483888 starting
2025-11-24 15:04:26.040Z debug(journal): 0: write_sectors: ring=vsr.journal.Ring.prepares offset=143654912 len=172032 locked
2025-11-24 15:04:26.041Z debug(replica): 0N: on_message: view=3 status=normal vsr.message_header.Header.Request{ .checksum = 230610731585297784448338444199878822078, .checksum_padding = 0, .checksum_body = 73422816465872014824228908356899921776, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 169216, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 14330724469910135810312754645440234171, .parent_padding = 0, .client = 47899338719226163297711645970010401862, .session = 2, .timestamp = 0, .request = 135, .operation = vsr.Operation(139), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 3169494419, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:04:26.041Z debug(replica): 0N: on_request: new request
2025-11-24 15:04:26.041Z debug(replica): 0N: on_request: ignoring (already preparing)
2025-11-24 15:04:26.041Z debug(replica): 2n: on_message: view=3 status=normal vsr.message_header.Header.Prepare{ .checksum = 294801872995564543169944161164793483888, .checksum_padding = 0, .checksum_body = 73422816465872014824228908356899921776, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 169216, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 217007747168728139790049223929420409766, .parent_padding = 0, .request_checksum = 230610731585297784448338444199878822078, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 47899338719226163297711645970010401862, .op = 137, .commit = 136, .timestamp = 1763996666039908400, .request = 135, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-11-24 15:04:26.041Z debug(journal): 0: write_sectors: ring=vsr.journal.Ring.prepares offset=143654912 len=172032 unlocked
2025-11-24 15:04:26.041Z debug(replica): 2n: on_prepare: advancing commit_max=135..136
2025-11-24 15:04:26.041Z debug(journal): 0: write_header: op=137 sectors[32768..36864]
2025-11-24 15:04:26.041Z debug(journal): 0: write_sectors: ring=vsr.journal.Ring.headers offset=32768 len=4096 locked
2025-11-24 15:04:26.041Z debug(replica): 2n: on_prepare: caching prepare.op=137 (commit_min=135 op=136 commit_max=136 prepare_max=1007)
2025-11-24 15:04:26.041Z debug(journal): 0: write_sectors: ring=vsr.journal.Ring.headers offset=32768 len=4096 unlocked
2025-11-24 15:04:26.041Z debug(journal): 0: write: view=3 slot=137 op=137 len=169216: 294801872995564543169944161164793483888 complete, marking clean
2025-11-24 15:04:26.041Z debug(replica): 0N: send_prepare_ok: op=137 checksum=294801872995564543169944161164793483888
2025-11-24 15:04:26.041Z debug(replica): 0N: sending prepare_ok to replica 0: vsr.message_header.Header.PrepareOk{ .checksum = 260743093520151565382607213426558213966, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 217007747168728139790049223929420409766, .parent_padding = 0, .prepare_checksum = 294801872995564543169944161164793483888, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 47899338719226163297711645970010401862, .op = 137, .commit_min = 136, .timestamp = 1763996666039908400, .request = 135, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-11-24 15:04:26.041Z debug(replica): 0N: on_message: view=3 status=normal vsr.message_header.Header.PrepareOk{ .checksum = 260743093520151565382607213426558213966, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 217007747168728139790049223929420409766, .parent_padding = 0, .prepare_checksum = 294801872995564543169944161164793483888, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 47899338719226163297711645970010401862, .op = 137, .commit_min = 136, .timestamp = 1763996666039908400, .request = 135, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-11-24 15:04:26.041Z debug(replica): 1n: on_message: view=3 status=normal vsr.message_header.Header.Prepare{ .checksum = 294801872995564543169944161164793483888, .checksum_padding = 0, .checksum_body = 73422816465872014824228908356899921776, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 169216, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 217007747168728139790049223929420409766, .parent_padding = 0, .request_checksum = 230610731585297784448338444199878822078, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 47899338719226163297711645970010401862, .op = 137, .commit = 136, .timestamp = 1763996666039908400, .request = 135, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-11-24 15:04:26.041Z debug(vsr): 0: primary_abdicate_timeout reset
2025-11-24 15:04:26.041Z debug(replica): 2n: on_prepare: advancing: op=136..137 checksum=217007747168728139790049223929420409766..294801872995564543169944161164793483888
2025-11-24 15:04:26.041Z debug(replica): 0N: on_prepare_ok: 1 message(s)
2025-11-24 15:04:26.041Z debug(replica): 0N: on_prepare_ok: waiting for quorum
2025-11-24 15:04:26.041Z debug(journal): 2: set_header_as_dirty: op=137 checksum=294801872995564543169944161164793483888
2025-11-24 15:04:26.041Z debug(replica): 1n: on_prepare: advancing commit_max=135..136
2025-11-24 15:04:26.041Z debug(replica): 2n: append: appending to journal op=137
2025-11-24 15:04:26.041Z debug(replica): 1n: on_prepare: caching prepare.op=137 (commit_min=135 op=136 commit_max=136 prepare_max=1007)
2025-11-24 15:04:26.042Z debug(journal): 2: write: view=3 slot=137 op=137 len=169216: 294801872995564543169944161164793483888 starting
2025-11-24 15:04:26.042Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.prepares offset=143654912 len=172032 locked
2025-11-24 15:04:26.042Z debug(replica): 2n: commit_start_journal: cached prepare op=136 checksum=217007747168728139790049223929420409766
2025-11-24 15:04:26.042Z debug(replica): 1n: on_prepare: advancing: op=136..137 checksum=217007747168728139790049223929420409766..294801872995564543169944161164793483888
2025-11-24 15:04:26.042Z debug(journal): 1: set_header_as_dirty: op=137 checksum=294801872995564543169944161164793483888
2025-11-24 15:04:26.042Z debug(replica): 1n: append: appending to journal op=137
2025-11-24 15:04:26.042Z debug(journal): 1: write: view=3 slot=137 op=137 len=169216: 294801872995564543169944161164793483888 starting
2025-11-24 15:04:26.042Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.prepares offset=143654912 len=172032 locked
2025-11-24 15:04:26.042Z debug(replica): 1n: commit_start_journal: cached prepare op=136 checksum=217007747168728139790049223929420409766
2025-11-24 15:04:26.042Z debug(replica): 2n: repair_prepare: op=137 checksum=294801872995564543169944161164793483888 (already writing)
2025-11-24 15:04:26.042Z debug(replica): 1n: repair_prepare: op=137 checksum=294801872995564543169944161164793483888 (already writing)
2025-11-24 15:04:26.042Z debug(replica): 2n: commit_journal: already committing (prefetch; commit_min=135)
2025-11-24 15:04:26.042Z debug(replica): 1n: commit_journal: already committing (prefetch; commit_min=135)
2025-11-24 15:04:26.042Z debug(replica): 2n: execute_op: executing view=3 primary=false op=136 checksum=217007747168728139790049223929420409766 (lookup_accounts)
2025-11-24 15:04:26.042Z debug(replica): 2n: execute_op: commit_timestamp=1763996662856898414 prepare.header.timestamp=1763996662866912860
2025-11-24 15:04:26.042Z debug(replica): 1n: execute_op: executing view=3 primary=false op=136 checksum=217007747168728139790049223929420409766 (lookup_accounts)
2025-11-24 15:04:26.042Z debug(replica): 1n: execute_op: commit_timestamp=1763996662856898414 prepare.header.timestamp=1763996662866912860
2025-11-24 15:04:26.042Z debug(replica): 2n: client_table_entry_update: client=47899338719226163297711645970010401862 session=2 request=134
2025-11-24 15:04:26.042Z debug(replica): 1n: client_table_entry_update: client=47899338719226163297711645970010401862 session=2 request=134
2025-11-24 15:04:26.042Z debug(forest): entering forest.compact() op=136 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2025-11-24 15:04:26.042Z debug(replica): 2n: execute_op: replying to client: vsr.message_header.Header.Reply{ .checksum = 98206438905762972913806947968348119535, .checksum_padding = 0, .checksum_body = 47593893661410242558481480173055552124, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 16128, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 269920912450624060375079935141954184145, .request_checksum_padding = 0, .context = 14330724469910135810312754645440234171, .context_padding = 0, .client = 47899338719226163297711645970010401862, .op = 136, .commit = 136, .timestamp = 1763996662866912860, .request = 134, .operation = vsr.Operation(140), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:04:26.042Z debug(replica): 2n: sending reply to client 47899338719226163297711645970010401862: vsr.message_header.Header.Reply{ .checksum = 98206438905762972913806947968348119535, .checksum_padding = 0, .checksum_body = 47593893661410242558481480173055552124, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 16128, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 269920912450624060375079935141954184145, .request_checksum_padding = 0, .context = 14330724469910135810312754645440234171, .context_padding = 0, .client = 47899338719226163297711645970010401862, .op = 136, .commit = 136, .timestamp = 1763996662866912860, .request = 134, .operation = vsr.Operation(140), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:04:26.042Z debug(forest): entering forest.compact() op=136 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2025-11-24 15:04:26.042Z debug(client_replies): 1: write_reply: wrote (client=47899338719226163297711645970010401862 request=134)
2025-11-24 15:04:26.042Z debug(client_replies): 2: write_reply: wrote (client=47899338719226163297711645970010401862 request=134)
2025-11-24 15:04:26.043Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.prepares offset=143654912 len=172032 unlocked
2025-11-24 15:04:26.043Z debug(journal): 1: write_header: op=137 sectors[32768..36864]
2025-11-24 15:04:26.043Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.headers offset=32768 len=4096 locked
2025-11-24 15:04:26.043Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.headers offset=32768 len=4096 unlocked
2025-11-24 15:04:26.043Z debug(journal): 1: write: view=3 slot=137 op=137 len=169216: 294801872995564543169944161164793483888 complete, marking clean
2025-11-24 15:04:26.043Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.prepares offset=143654912 len=172032 unlocked
2025-11-24 15:04:26.043Z debug(replica): 1n: send_prepare_ok: op=137 checksum=294801872995564543169944161164793483888
2025-11-24 15:04:26.043Z debug(journal): 2: write_header: op=137 sectors[32768..36864]
2025-11-24 15:04:26.043Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.headers offset=32768 len=4096 locked
2025-11-24 15:04:26.043Z debug(replica): 1n: sending prepare_ok to replica 0: vsr.message_header.Header.PrepareOk{ .checksum = 32300057897639427476288628324467730327, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 217007747168728139790049223929420409766, .parent_padding = 0, .prepare_checksum = 294801872995564543169944161164793483888, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 47899338719226163297711645970010401862, .op = 137, .commit_min = 136, .timestamp = 1763996666039908400, .request = 135, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-11-24 15:04:26.043Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.headers offset=32768 len=4096 unlocked
2025-11-24 15:04:26.043Z debug(journal): 2: write: view=3 slot=137 op=137 len=169216: 294801872995564543169944161164793483888 complete, marking clean
2025-11-24 15:04:26.043Z debug(replica): 2n: send_prepare_ok: op=137 checksum=294801872995564543169944161164793483888
2025-11-24 15:04:26.043Z debug(replica): 2n: sending prepare_ok to replica 0: vsr.message_header.Header.PrepareOk{ .checksum = 256662065229944656214206226087915462187, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 217007747168728139790049223929420409766, .parent_padding = 0, .prepare_checksum = 294801872995564543169944161164793483888, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 47899338719226163297711645970010401862, .op = 137, .commit_min = 136, .timestamp = 1763996666039908400, .request = 135, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-11-24 15:04:26.043Z debug(replica): 0N: on_message: view=3 status=normal vsr.message_header.Header.PrepareOk{ .checksum = 32300057897639427476288628324467730327, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 217007747168728139790049223929420409766, .parent_padding = 0, .prepare_checksum = 294801872995564543169944161164793483888, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 47899338719226163297711645970010401862, .op = 137, .commit_min = 136, .timestamp = 1763996666039908400, .request = 135, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-11-24 15:04:26.043Z debug(vsr): 0: primary_abdicate_timeout reset
2025-11-24 15:04:26.043Z debug(replica): 0N: on_prepare_ok: 2 message(s)
2025-11-24 15:04:26.043Z debug(replica): 0N: on_prepare_ok: quorum received, context=294801872995564543169944161164793483888
2025-11-24 15:04:26.043Z debug(vsr): 0: prepare_timeout stopped
2025-11-24 15:04:26.043Z debug(vsr): 0: primary_abdicate_timeout stopped
2025-11-24 15:04:26.044Z debug(replica): 0N: execute_op: executing view=3 primary=true op=137 checksum=294801872995564543169944161164793483888 (create_transfers)
2025-11-24 15:04:26.044Z debug(replica): 0N: execute_op: commit_timestamp=1763996662866912860 prepare.header.timestamp=1763996666039908400
2025-11-24 15:04:26.045Z debug(vsr): 1: journal_repair_budget_timeout fired
2025-11-24 15:04:26.045Z debug(vsr): 1: journal_repair_budget_timeout reset
2025-11-24 15:04:26.045Z debug(vsr): 2: journal_repair_budget_timeout fired
2025-11-24 15:04:26.045Z debug(vsr): 2: journal_repair_budget_timeout reset
2025-11-24 15:04:26.049Z debug(replica): 0N: execute_op: advancing commit_max=136..137
2025-11-24 15:04:26.049Z debug(replica): 0N: client_table_entry_update: client=47899338719226163297711645970010401862 session=2 request=135
2025-11-24 15:04:26.049Z debug(replica): 0N: execute_op: replying to client: vsr.message_header.Header.Reply{ .checksum = 99341825952368218246126542755088244418, .checksum_padding = 0, .checksum_body = 311752944233308762869332694583075543730, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 264, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 230610731585297784448338444199878822078, .request_checksum_padding = 0, .context = 102587662247583573936060453063581059322, .context_padding = 0, .client = 47899338719226163297711645970010401862, .op = 137, .commit = 137, .timestamp = 1763996666039908400, .request = 135, .operation = vsr.Operation(139), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:04:26.049Z debug(replica): 0N: sending reply to client 47899338719226163297711645970010401862: vsr.message_header.Header.Reply{ .checksum = 99341825952368218246126542755088244418, .checksum_padding = 0, .checksum_body = 311752944233308762869332694583075543730, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 264, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 230610731585297784448338444199878822078, .request_checksum_padding = 0, .context = 102587662247583573936060453063581059322, .context_padding = 0, .client = 47899338719226163297711645970010401862, .op = 137, .commit = 137, .timestamp = 1763996666039908400, .request = 135, .operation = vsr.Operation(139), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:04:26.049Z debug(forest): entering forest.compact() op=137 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2025-11-24 15:04:26.052Z debug(replica): 0N: on_message: view=3 status=normal vsr.message_header.Header.PrepareOk{ .checksum = 256662065229944656214206226087915462187, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 217007747168728139790049223929420409766, .parent_padding = 0, .prepare_checksum = 294801872995564543169944161164793483888, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 47899338719226163297711645970010401862, .op = 137, .commit_min = 136, .timestamp = 1763996666039908400, .request = 135, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-11-24 15:04:26.052Z debug(replica): 0N: on_prepare_ok: not preparing op=137 checksum=294801872995564543169944161164793483888
2025-11-24 15:04:26.053Z debug(client_replies): 0: write_reply: wrote (client=47899338719226163297711645970010401862 request=135)
2025-11-24 15:04:26.066Z debug(vsr): 2: journal_repair_budget_timeout fired
2025-11-24 15:04:26.066Z debug(vsr): 2: journal_repair_budget_timeout reset
2025-11-24 15:04:26.076Z debug(vsr): 2: journal_repair_timeout fired
2025-11-24 15:04:26.076Z debug(vsr): 2: journal_repair_timeout reset
2025-11-24 15:04:26.055Z debug(replica): 0N: on_message: view=3 status=normal vsr.message_header.Header.Request{ .checksum = 148703547347258000848344500813009311411, .checksum_padding = 0, .checksum_body = 326289093971322640297727606153193791024, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2240, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 102587662247583573936060453063581059322, .parent_padding = 0, .client = 47899338719226163297711645970010401862, .session = 2, .timestamp = 0, .request = 136, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 12326948, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
