ccounts
tb.client_request_round_trip_us.max:3336158|g|#cluster:00000000000000000000000000000000,replica:1,operation:lookup_accounts
tb.client_request_round_trip_us.avg:1276237|g|#cluster:00000000000000000000000000000000,replica:1,operation:lookup_accounts
tb.client_request_round_trip_us.sum:103375229|c|#cluster:00000000000000000000000000000000,replica:1,operation:lookup_accounts
tb.client_request_round_trip_us.count:81|c|#cluster:00000000000000000000000000000000,replica:1,operation:lookup_accounts
tb.client_request_round_trip_us.min:1505|g|#cluster:00000000000000000000000000000000,replica:1,operation:lookup_transfers
tb.client_request_round_trip_us.max:4294967|g|#cluster:00000000000000000000000000000000,replica:1,operation:lookup_transfers
tb.client_request_round_trip_us.avg:876942|g|#cluster:00000000000000000000000000000000,replica:1,operation:lookup_transfers
tb.client_request_round_trip_us.sum:27185212|c|#cluster:00000000000000000000000000000000,replica:1,operation:lookup_transfers
tb.client_request_round_trip_us.count:31|c|#cluster:00000000000000000000000000000000,replica:1,operation:lookup_transfers

2026-01-23 19:44:31.644Z debug(replica): 2n: on_message: view=1 status=normal Request{ .checksum=bee073db25771d963c86f120d80140db, .checksum_body=9c4e7938e45ae090fd61797e144d0f08, .cluster=0, .size=124928, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.request, .replica=0, .parent=4741b60f9621c6553022b04a33ba1b48, .client=60324011015611665437153036865704073740, .session=2, .timestamp=0, .request=163, .operation=vsr.Operation(141), .previous_request_latency=4294967295 }
2026-01-23 19:44:31.644Z debug(replica): 2n: on_request: forwarding new request to primary (view=1)
2026-01-23 19:44:31.644Z debug(replica): 2n: sending request to replica 1: Request{ .checksum=bee073db25771d963c86f120d80140db, .checksum_body=9c4e7938e45ae090fd61797e144d0f08, .cluster=0, .size=124928, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.request, .replica=0, .parent=4741b60f9621c6553022b04a33ba1b48, .client=60324011015611665437153036865704073740, .session=2, .timestamp=0, .request=163, .operation=vsr.Operation(141), .previous_request_latency=4294967295 }
2026-01-23 19:44:31.644Z info(message_bus): 0: on_recv: from=vsr.Peer{ .client = 60324011015611665437153036865704073740 } orderly shutdown
2026-01-23 19:44:31.644Z info(message_bus): 1: set_and_verify_peer connection from client_likely=60324011015611665437153036865704073740
2026-01-23 19:44:31.644Z info(message_bus): 1: set_and_verify_peer connection from client=60324011015611665437153036865704073740
2026-01-23 19:44:31.645Z debug(replica): 1N: on_message: view=1 status=normal Request{ .checksum=bee073db25771d963c86f120d80140db, .checksum_body=9c4e7938e45ae090fd61797e144d0f08, .cluster=0, .size=124928, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.request, .replica=0, .parent=4741b60f9621c6553022b04a33ba1b48, .client=60324011015611665437153036865704073740, .session=2, .timestamp=0, .request=163, .operation=vsr.Operation(141), .previous_request_latency=4294967295 }
2026-01-23 19:44:31.645Z debug(replica): 1N: on_request: replying to duplicate request
2026-01-23 19:44:31.645Z debug(client_replies): 1: read_reply: start (client=60324011015611665437153036865704073740 reply=4289ad358a342cba408feb2d3317de40)
2026-01-23 19:44:31.645Z debug(replica): 1N: on_message: view=1 status=normal PingClient{ .checksum=d62246e445a1a1e766ea37926de35a85, .checksum_body=49f174618255402de6e7e3c40d60cc83, .cluster=0, .size=256, .epoch=0, .view=0, .release=0.0.1, .protocol=0, .command=vsr.Command.ping_client, .replica=0, .client=60324011015611665437153036865704073740, .ping_timestamp_monotonic=41313036919442740 }
2026-01-23 19:44:31.645Z debug(replica): 1N: sending pong_client to client 60324011015611665437153036865704073740: PongClient{ .checksum=2252676a12c6b94b527911973d1eb873, .checksum_body=49f174618255402de6e7e3c40d60cc83, .cluster=0, .size=256, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.pong_client, .replica=1, .ping_timestamp_monotonic=41313036919442740 }
2026-01-23 19:44:31.645Z debug(replica): 1N: on_message: view=1 status=normal Request{ .checksum=bee073db25771d963c86f120d80140db, .checksum_body=9c4e7938e45ae090fd61797e144d0f08, .cluster=0, .size=124928, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.request, .replica=0, .parent=4741b60f9621c6553022b04a33ba1b48, .client=60324011015611665437153036865704073740, .session=2, .timestamp=0, .request=163, .operation=vsr.Operation(141), .previous_request_latency=4294967295 }
2026-01-23 19:44:31.645Z debug(replica): 1N: on_request: replying to duplicate request
2026-01-23 19:44:31.645Z debug(client_replies): 1: read_reply: busy (client=60324011015611665437153036865704073740 reply=4289ad358a342cba408feb2d3317de40)
2026-01-23 19:44:31.645Z debug(replica): 1N: on_request: ignoring (client_replies busy)
2026-01-23 19:44:31.646Z debug(replica): 1N: on_message: view=1 status=normal Request{ .checksum=bee073db25771d963c86f120d80140db, .checksum_body=9c4e7938e45ae090fd61797e144d0f08, .cluster=0, .size=124928, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.request, .replica=0, .parent=4741b60f9621c6553022b04a33ba1b48, .client=60324011015611665437153036865704073740, .session=2, .timestamp=0, .request=163, .operation=vsr.Operation(141), .previous_request_latency=4294967295 }
2026-01-23 19:44:31.646Z debug(replica): 1N: on_request: replying to duplicate request
2026-01-23 19:44:31.646Z debug(client_replies): 1: read_reply: busy (client=60324011015611665437153036865704073740 reply=4289ad358a342cba408feb2d3317de40)
2026-01-23 19:44:31.646Z debug(replica): 1N: on_request: ignoring (client_replies busy)
2026-01-23 19:44:31.647Z debug(replica): 1N: on_message: view=1 status=normal Request{ .checksum=bee073db25771d963c86f120d80140db, .checksum_body=9c4e7938e45ae090fd61797e144d0f08, .cluster=0, .size=124928, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.request, .replica=0, .parent=4741b60f9621c6553022b04a33ba1b48, .client=60324011015611665437153036865704073740, .session=2, .timestamp=0, .request=163, .operation=vsr.Operation(141), .previous_request_latency=4294967295 }
2026-01-23 19:44:31.647Z debug(replica): 1N: on_request: replying to duplicate request
2026-01-23 19:44:31.647Z debug(client_replies): 1: read_reply: busy (client=60324011015611665437153036865704073740 reply=4289ad358a342cba408feb2d3317de40)
2026-01-23 19:44:31.647Z debug(replica): 1N: on_request: ignoring (client_replies busy)
2026-01-23 19:44:31.651Z debug(client_replies): 1: read_reply: done (client=60324011015611665437153036865704073740 reply=4289ad358a342cba408feb2d3317de40)
2026-01-23 19:44:31.651Z debug(replica): 1N: on_request: repeat reply (client=60324011015611665437153036865704073740 request=163)
2026-01-23 19:44:31.651Z debug(replica): 1N: sending reply to client 60324011015611665437153036865704073740: Reply{ .checksum=4289ad358a342cba408feb2d3317de40, .checksum_body=9b7b40f33265a82ef9311d8934c2e291, .cluster=0, .size=997632, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.reply, .replica=1, .request_checksum=bee073db25771d963c86f120d80140db, .context=b5e204dffc7da73d3731d47b0b03ede8, .client=60324011015611665437153036865704073740, .op=165, .commit=165, .timestamp=1769197462802130111, .request=163, .operation=vsr.Operation(141) }
2026-01-23 19:44:31.654Z warning(clock): 1: synchronization failed, partitioned (sources=1 samples=1)
2026-01-23 19:44:31.654Z debug(vsr): 1: journal_repair_budget_timeout fired
2026-01-23 19:44:31.654Z debug(vsr): 1: journal_repair_budget_timeout reset
2026-01-23 19:44:31.654Z debug(vsr): 1: pulse_timeout fired
2026-01-23 19:44:31.654Z debug(vsr): 1: pulse_timeout reset
2026-01-23 19:44:31.654Z debug(vsr): 2: journal_repair_budget_timeout fired
2026-01-23 19:44:31.654Z debug(vsr): 2: journal_repair_budget_timeout reset
2026-01-23 19:44:31.663Z debug(replica): 1N: on_message: view=1 status=normal Request{ .checksum=1588bb205a7acb07732cddc23c457ac3, .checksum_body=05818375add20fa5892afe2394de4b74, .cluster=0, .size=2320, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.request, .replica=0, .parent=b5e204dffc7da73d3731d47b0b03ede8, .client=60324011015611665437153036865704073740, .session=2, .timestamp=0, .request=164, .operation=vsr.Operation(140), .previous_request_latency=4294967295 }
2026-01-23 19:44:31.663Z debug(replica): 1N: on_request: new request
2026-01-23 19:44:31.663Z debug(replica): 1N: primary_pipeline_prepare: request checksum=1588bb205a7acb07732cddc23c457ac3 client=60324011015611665437153036865704073740
2026-01-23 19:44:31.663Z debug(replica): 1N: primary_pipeline_prepare: prepare checksum=48e4a96dd27c813d3c97f54a0b69beab op=166
2026-01-23 19:44:31.663Z debug(vsr): 1: prepare_timeout started
2026-01-23 19:44:31.663Z debug(vsr): 1: primary_abdicate_timeout started
2026-01-23 19:44:31.663Z debug(vsr): 1: pulse_timeout reset
2026-01-23 19:44:31.663Z debug(replica): 1N: replicate: replicating op=166 to replica 0
2026-01-23 19:44:31.663Z debug(replica): 1N: sending prepare to replica 0: Prepare{ .checksum=48e4a96dd27c813d3c97f54a0b69beab, .checksum_body=05818375add20fa5892afe2394de4b74, .cluster=0, .size=2320, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.prepare, .replica=1, .parent=af985051dabcca4098805bf4227a3379, .request_checksum=1588bb205a7acb07732cddc23c457ac3, .checkpoint_id=00000000000000000000000000000000, .client=60324011015611665437153036865704073740, .op=166, .commit=165, .timestamp=1769197471663495683, .request=164, .operation=vsr.Operation(140) }
2026-01-23 19:44:31.663Z debug(replica): 1N: replicate: replicating op=166 to replica 2
2026-01-23 19:44:31.663Z debug(replica): 1N: sending prepare to replica 2: Prepare{ .checksum=48e4a96dd27c813d3c97f54a0b69beab, .checksum_body=05818375add20fa5892afe2394de4b74, .cluster=0, .size=2320, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.prepare, .replica=1, .parent=af985051dabcca4098805bf4227a3379, .request_checksum=1588bb205a7acb07732cddc23c457ac3, .checkpoint_id=00000000000000000000000000000000, .client=60324011015611665437153036865704073740, .op=166, .commit=165, .timestamp=1769197471663495683, .request=164, .operation=vsr.Operation(140) }
2026-01-23 19:44:31.663Z debug(replica): 1N: on_prepare: advancing: op=165..166 checksum=af985051dabcca4098805bf4227a3379..48e4a96dd27c813d3c97f54a0b69beab
2026-01-23 19:44:31.663Z debug(journal): 1: set_header_as_dirty: op=166 checksum=48e4a96dd27c813d3c97f54a0b69beab
2026-01-23 19:44:31.663Z debug(replica): 1N: append: appending to journal op=166
2026-01-23 19:44:31.663Z debug(journal): 1: write: view=1 slot=166 op=166 len=2320: 48e4a96dd27c813d3c97f54a0b69beab starting
2026-01-23 19:44:31.663Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.prepares offset=174063616 len=4096 locked
2026-01-23 19:44:31.663Z debug(replica): 0n: on_message: view=1 status=normal Prepare{ .checksum=48e4a96dd27c813d3c97f54a0b69beab, .checksum_body=05818375add20fa5892afe2394de4b74, .cluster=0, .size=2320, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.prepare, .replica=1, .parent=af985051dabcca4098805bf4227a3379, .request_checksum=1588bb205a7acb07732cddc23c457ac3, .checkpoint_id=00000000000000000000000000000000, .client=60324011015611665437153036865704073740, .op=166, .commit=165, .timestamp=1769197471663495683, .request=164, .operation=vsr.Operation(140) }
2026-01-23 19:44:31.663Z debug(replica): 0n: on_prepare: advancing commit_max=164..165
2026-01-23 19:44:31.663Z debug(replica): 0n: on_prepare: caching prepare.op=166 (commit_min=164 op=165 commit_max=165 prepare_max=1007)
2026-01-23 19:44:31.663Z debug(replica): 2n: on_message: view=1 status=normal Prepare{ .checksum=48e4a96dd27c813d3c97f54a0b69beab, .checksum_body=05818375add20fa5892afe2394de4b74, .cluster=0, .size=2320, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.prepare, .replica=1, .parent=af985051dabcca4098805bf4227a3379, .request_checksum=1588bb205a7acb07732cddc23c457ac3, .checkpoint_id=00000000000000000000000000000000, .client=60324011015611665437153036865704073740, .op=166, .commit=165, .timestamp=1769197471663495683, .request=164, .operation=vsr.Operation(140) }
2026-01-23 19:44:31.663Z debug(replica): 2n: on_prepare: advancing commit_max=164..165
2026-01-23 19:44:31.663Z debug(replica): 2n: on_prepare: caching prepare.op=166 (commit_min=164 op=165 commit_max=165 prepare_max=1007)
2026-01-23 19:44:31.663Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.prepares offset=174063616 len=4096 unlocked
2026-01-23 19:44:31.663Z debug(replica): 0n: on_prepare: advancing: op=165..166 checksum=af985051dabcca4098805bf4227a3379..48e4a96dd27c813d3c97f54a0b69beab
2026-01-23 19:44:31.663Z debug(journal): 1: write_header: op=166 sectors[40960..45056]
2026-01-23 19:44:31.663Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.headers offset=40960 len=4096 locked
2026-01-23 19:44:31.663Z debug(journal): 0: set_header_as_dirty: op=166 checksum=48e4a96dd27c813d3c97f54a0b69beab
2026-01-23 19:44:31.663Z debug(replica): 0n: append: appending to journal op=166
2026-01-23 19:44:31.663Z debug(replica): 2n: on_prepare: advancing: op=165..166 checksum=af985051dabcca4098805bf4227a3379..48e4a96dd27c813d3c97f54a0b69beab
2026-01-23 19:44:31.663Z debug(journal): 0: write: view=1 slot=166 op=166 len=2320: 48e4a96dd27c813d3c97f54a0b69beab starting
2026-01-23 19:44:31.663Z debug(journal): 2: set_header_as_dirty: op=166 checksum=48e4a96dd27c813d3c97f54a0b69beab
2026-01-23 19:44:31.663Z debug(journal): 0: write_sectors: ring=vsr.journal.Ring.prepares offset=174063616 len=4096 locked
2026-01-23 19:44:31.663Z debug(replica): 2n: append: appending to journal op=166
2026-01-23 19:44:31.663Z debug(journal): 2: write: view=1 slot=166 op=166 len=2320: 48e4a96dd27c813d3c97f54a0b69beab starting
2026-01-23 19:44:31.663Z debug(replica): 0n: commit_start_journal: cached prepare op=165 checksum=af985051dabcca4098805bf4227a3379
2026-01-23 19:44:31.663Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.prepares offset=174063616 len=4096 locked
2026-01-23 19:44:31.663Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.headers offset=40960 len=4096 unlocked
2026-01-23 19:44:31.663Z debug(journal): 1: write: view=1 slot=166 op=166 len=2320: 48e4a96dd27c813d3c97f54a0b69beab complete, marking clean
2026-01-23 19:44:31.663Z debug(replica): 2n: commit_start_journal: cached prepare op=165 checksum=af985051dabcca4098805bf4227a3379
2026-01-23 19:44:31.663Z debug(replica): 1N: send_prepare_ok: op=166 checksum=48e4a96dd27c813d3c97f54a0b69beab
2026-01-23 19:44:31.663Z debug(replica): 1N: sending prepare_ok to replica 1: PrepareOk{ .checksum=ca68e0247813933939eeb90a9ffca1ec, .checksum_body=49f174618255402de6e7e3c40d60cc83, .cluster=0, .size=256, .epoch=0, .view=1, .release=0.0.0, .protocol=0, .command=vsr.Command.prepare_ok, .replica=1, .parent=af985051dabcca4098805bf4227a3379, .prepare_checksum=48e4a96dd27c813d3c97f54a0b69beab, .checkpoint_id=00000000000000000000000000000000, .client=60324011015611665437153036865704073740, .op=166, .commit_min=165, .timestamp=1769197471663495683, .request=164, .operation=vsr.Operation(140) }
2026-01-23 19:44:31.663Z debug(replica): 1N: on_message: view=1 status=normal PrepareOk{ .checksum=ca68e0247813933939eeb90a9ffca1ec, .checksum_body=49f174618255402de6e7e3c40d60cc83, .cluster=0, .size=256, .epoch=0, .view=1, .release=0.0.0, .protocol=0, .command=vsr.Command.prepare_ok, .replica=1, .parent=af985051dabcca4098805bf4227a3379, .prepare_checksum=48e4a96dd27c813d3c97f54a0b69beab, .checkpoint_id=00000000000000000000000000000000, .client=60324011015611665437153036865704073740, .op=166, .commit_min=165, .timestamp=1769197471663495683, .request=164, .operation=vsr.Operation(140) }
2026-01-23 19:44:31.663Z debug(vsr): 1: primary_abdicate_timeout reset
2026-01-23 19:44:31.663Z debug(replica): 1N: on_prepare_ok: 1 message(s)
2026-01-23 19:44:31.663Z debug(replica): 1N: on_prepare_ok: waiting for quorum
2026-01-23 19:44:31.666Z debug(replica): 0n: repair_prepare: op=166 checksum=48e4a96dd27c813d3c97f54a0b69beab (already writing)
2026-01-23 19:44:31.666Z debug(replica): 0n: commit_journal: already committing (prefetch; commit_min=164)
2026-01-23 19:44:31.666Z debug(replica): 2n: repair_prepare: op=166 checksum=48e4a96dd27c813d3c97f54a0b69beab (already writing)
2026-01-23 19:44:31.666Z debug(replica): 0n: execute_op: executing view=1 primary=false op=165 checksum=af985051dabcca4098805bf4227a3379 (lookup_transfers)
2026-01-23 19:44:31.666Z debug(replica): 0n: execute_op: commit_timestamp=1769197462588147297 prepare.header.timestamp=1769197462802130111
2026-01-23 19:44:31.666Z debug(replica): 2n: commit_journal: already committing (prefetch; commit_min=164)
2026-01-23 19:44:31.666Z debug(replica): 2n: execute_op: executing view=1 primary=false op=165 checksum=af985051dabcca4098805bf4227a3379 (lookup_transfers)
2026-01-23 19:44:31.666Z debug(replica): 2n: execute_op: commit_timestamp=1769197462588147297 prepare.header.timestamp=1769197462802130111
2026-01-23 19:44:31.673Z debug(replica): 0n: client_table_entry_update: client=60324011015611665437153036865704073740 session=2 request=163
2026-01-23 19:44:31.673Z debug(replica): 2n: client_table_entry_update: client=60324011015611665437153036865704073740 session=2 request=163
2026-01-23 19:44:31.673Z debug(forest): entering forest.compact() op=165 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2026-01-23 19:44:31.673Z debug(replica): 2n: execute_op: replying to client: Reply{ .checksum=4289ad358a342cba408feb2d3317de40, .checksum_body=9b7b40f33265a82ef9311d8934c2e291, .cluster=0, .size=997632, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.reply, .replica=1, .request_checksum=bee073db25771d963c86f120d80140db, .context=b5e204dffc7da73d3731d47b0b03ede8, .client=60324011015611665437153036865704073740, .op=165, .commit=165, .timestamp=1769197462802130111, .request=163, .operation=vsr.Operation(141) }
2026-01-23 19:44:31.673Z debug(replica): 2n: sending reply to client 60324011015611665437153036865704073740: Reply{ .checksum=4289ad358a342cba408feb2d3317de40, .checksum_body=9b7b40f33265a82ef9311d8934c2e291, .cluster=0, .size=997632, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.reply, .replica=1, .request_checksum=bee073db25771d963c86f120d80140db, .context=b5e204dffc7da73d3731d47b0b03ede8, .client=60324011015611665437153036865704073740, .op=165, .commit=165, .timestamp=1769197462802130111, .request=163, .operation=vsr.Operation(141) }
2026-01-23 19:44:31.673Z debug(forest): entering forest.compact() op=165 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2026-01-23 19:44:31.673Z debug(journal): 0: write_sectors: ring=vsr.journal.Ring.prepares offset=174063616 len=4096 unlocked
2026-01-23 19:44:31.673Z debug(journal): 0: write_header: op=166 sectors[40960..45056]
2026-01-23 19:44:31.673Z debug(journal): 0: write_sectors: ring=vsr.journal.Ring.headers offset=40960 len=4096 locked
2026-01-23 19:44:31.673Z debug(vsr): 0: journal_repair_budget_timeout fired
2026-01-23 19:44:31.673Z debug(vsr): 0: journal_repair_budget_timeout reset
2026-01-23 19:44:31.673Z debug(client_replies): 0: write_reply: wrote (client=60324011015611665437153036865704073740 request=163)
2026-01-23 19:44:31.673Z debug(journal): 0: write_sectors: ring=vsr.journal.Ring.headers offset=40960 len=4096 unlocked
2026-01-23 19:44:31.673Z debug(journal): 0: write: view=1 slot=166 op=166 len=2320: 48e4a96dd27c813d3c97f54a0b69beab complete, marking clean
2026-01-23 19:44:31.673Z debug(replica): 0n: send_prepare_ok: op=166 checksum=48e4a96dd27c813d3c97f54a0b69beab
2026-01-23 19:44:31.673Z debug(replica): 0n: sending prepare_ok to replica 1: PrepareOk{ .checksum=df33c0f9def8136c3b7ed094854c0581, .checksum_body=49f174618255402de6e7e3c40d60cc83, .cluster=0, .size=256, .epoch=0, .view=1, .release=0.0.0, .protocol=0, .command=vsr.Command.prepare_ok, .replica=0, .parent=af985051dabcca4098805bf4227a3379, .prepare_checksum=48e4a96dd27c813d3c97f54a0b69beab, .checkpoint_id=00000000000000000000000000000000, .client=60324011015611665437153036865704073740, .op=166, .commit_min=165, .timestamp=1769197471663495683, .request=164, .operation=vsr.Operation(140) }
2026-01-23 19:44:31.674Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.prepares offset=174063616 len=4096 unlocked
2026-01-23 19:44:31.674Z debug(journal): 2: write_header: op=166 sectors[40960..45056]
2026-01-23 19:44:31.674Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.headers offset=40960 len=4096 locked
2026-01-23 19:44:31.674Z debug(vsr): 1: journal_repair_budget_timeout fired
2026-01-23 19:44:31.674Z debug(vsr): 1: journal_repair_budget_timeout reset
2026-01-23 19:44:31.674Z debug(replica): 1N: on_message: view=1 status=normal PrepareOk{ .checksum=df33c0f9def8136c3b7ed094854c0581, .checksum_body=49f174618255402de6e7e3c40d60cc83, .cluster=0, .size=256, .epoch=0, .view=1, .release=0.0.0, .protocol=0, .command=vsr.Command.prepare_ok, .replica=0, .parent=af985051dabcca4098805bf4227a3379, .prepare_checksum=48e4a96dd27c813d3c97f54a0b69beab, .checkpoint_id=00000000000000000000000000000000, .client=60324011015611665437153036865704073740, .op=166, .commit_min=165, .timestamp=1769197471663495683, .request=164, .operation=vsr.Operation(140) }
2026-01-23 19:44:31.674Z debug(vsr): 1: primary_abdicate_timeout reset
2026-01-23 19:44:31.674Z debug(replica): 1N: on_prepare_ok: 2 message(s)
2026-01-23 19:44:31.674Z debug(replica): 1N: on_prepare_ok: quorum received, prepare_checksum=48e4a96dd27c813d3c97f54a0b69beab
2026-01-23 19:44:31.674Z debug(vsr): 1: prepare_timeout stopped
2026-01-23 19:44:31.674Z debug(vsr): 1: primary_abdicate_timeout stopped
2026-01-23 19:44:31.674Z debug(replica): 1N: execute_op: executing view=1 primary=true op=166 checksum=48e4a96dd27c813d3c97f54a0b69beab (lookup_accounts)
2026-01-23 19:44:31.674Z debug(replica): 1N: execute_op: commit_timestamp=1769197462802130111 prepare.header.timestamp=1769197471663495683
2026-01-23 19:44:31.674Z debug(replica): 1N: execute_op: advancing commit_max=165..166
2026-01-23 19:44:31.674Z debug(replica): 1N: client_table_entry_update: client=60324011015611665437153036865704073740 session=2 request=164
2026-01-23 19:44:31.674Z debug(replica): 1N: execute_op: replying to client: Reply{ .checksum=0f8047a8a1fd96fde1fcd917315e0f41, .checksum_body=47bd3eb550008c851a6fcb8d46c5fd51, .cluster=0, .size=16768, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.reply, .replica=1, .request_checksum=1588bb205a7acb07732cddc23c457ac3, .context=2ae414bb7be21eb50c4b25d6128a6986, .client=60324011015611665437153036865704073740, .op=166, .commit=166, .timestamp=1769197471663495683, .request=164, .operation=vsr.Operation(140) }
2026-01-23 19:44:31.674Z debug(replica): 1N: sending reply to client 60324011015611665437153036865704073740: Reply{ .checksum=0f8047a8a1fd96fde1fcd917315e0f41, .checksum_body=47bd3eb550008c851a6fcb8d46c5fd51, .cluster=0, .size=16768, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.reply, .replica=1, .request_checksum=1588bb205a7acb07732cddc23c457ac3, .context=2ae414bb7be21eb50c4b25d6128a6986, .client=60324011015611665437153036865704073740, .op=166, .commit=166, .timestamp=1769197471663495683, .request=164, .operation=vsr.Operation(140) }
2026-01-23 19:44:31.674Z debug(client_replies): 2: write_reply: wrote (client=60324011015611665437153036865704073740 request=163)
2026-01-23 19:44:31.674Z debug(forest): entering forest.compact() op=166 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2026-01-23 19:44:31.674Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.headers offset=40960 len=4096 unlocked
2026-01-23 19:44:31.674Z debug(journal): 2: write: view=1 slot=166 op=166 len=2320: 48e4a96dd27c813d3c97f54a0b69beab complete, marking clean
2026-01-23 19:44:31.674Z debug(replica): 2n: send_prepare_ok: op=166 checksum=48e4a96dd27c813d3c97f54a0b69beab
2026-01-23 19:44:31.674Z debug(replica): 2n: sending prepare_ok to replica 1: PrepareOk{ .checksum=53d504e1b23d6eb07133a672e115ced0, .checksum_body=49f174618255402de6e7e3c40d60cc83, .cluster=0, .size=256, .epoch=0, .view=1, .release=0.0.0, .protocol=0, .command=vsr.Command.prepare_ok, .replica=2, .parent=af985051dabcca4098805bf4227a3379, .prepare_checksum=48e4a96dd27c813d3c97f54a0b69beab, .checkpoint_id=00000000000000000000000000000000, .client=60324011015611665437153036865704073740, .op=166, .commit_min=165, .timestamp=1769197471663495683, .request=164, .operation=vsr.Operation(140) }
2026-01-23 19:44:31.674Z debug(replica): 1N: on_message: view=1 status=normal PrepareOk{ .checksum=53d504e1b23d6eb07133a672e115ced0, .checksum_body=49f174618255402de6e7e3c40d60cc83, .cluster=0, .size=256, .epoch=0, .view=1, .release=0.0.0, .protocol=0, .command=vsr.Command.prepare_ok, .replica=2, .parent=af985051dabcca4098805bf4227a3379, .prepare_checksum=48e4a96dd27c813d3c97f54a0b69beab, .checkpoint_id=00000000000000000000000000000000, .client=60324011015611665437153036865704073740, .op=166, .commit_min=165, .timestamp=1769197471663495683, .request=164, .operation=vsr.Operation(140) }
2026-01-23 19:44:31.674Z debug(replica): 1N: on_prepare_ok: not preparing op=166 checksum=48e4a96dd27c813d3c97f54a0b69beab
2026-01-23 19:44:31.675Z debug(client_replies): 1: write_reply: wrote (client=60324011015611665437153036865704073740 request=164)
2026-01-23 19:44:31.683Z info(workload): accounts created = 128, transfers = 190141, pending transfers = 0, commands run = 82
2026-01-23 19:44:31.684Z debug(vsr): 2: journal_repair_budget_timeout fired
2026-01-23 19:44:31.684Z debug(vsr): 2: journal_repair_budget_timeout reset
2026-01-23 19:44:31.685Z debug(replica): 1N: on_message: view=1 status=normal Request{ .checksum=37200c479b09c2abd4675ccc359a3c7b, .checksum_body=9c4e7938e45ae090fd61797e144d0f08, .cluster=0, .size=124928, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.request, .replica=0, .parent=2ae414bb7be21eb50c4b25d6128a6986, .client=60324011015611665437153036865704073740, .session=2, .timestamp=0, .request=165, .operation=vsr.Operation(141), .previous_request_latency=20329262 }
2026-01-23 19:44:31.685Z debug(replica): 1N: on_request: new request
2026-01-23 19:44:31.685Z debug(replica): 1N: primary_pipeline_prepare: request checksum=37200c479b09c2abd4675ccc359a3c7b client=60324011015611665437153036865704073740
2026-01-23 19:44:31.686Z debug(replica): 1N: primary_pipeline_prepare: prepare checksum=44d3ac3ee5339774a8ffabe2ef93a635 op=167
2026-01-23 19:44:31.686Z debug(vsr): 1: prepare_timeout started
2026-01-23 19:44:31.686Z debug(vsr): 1: primary_abdicate_timeout started
2026-01-23 19:44:31.686Z debug(vsr): 1: pulse_timeout reset
2026-01-23 19:44:31.686Z debug(replica): 1N: replicate: replicating op=167 to replica 0
2026-01-23 19:44:31.686Z debug(replica): 1N: sending prepare to replica 0: Prepare{ .checksum=44d3ac3ee5339774a8ffabe2ef93a635, .checksum_body=9c4e7938e45ae090fd61797e144d0f08, .cluster=0, .size=124928, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.prepare, .replica=1, .parent=48e4a96dd27c813d3c97f54a0b69beab, .request_checksum=37200c479b09c2abd4675ccc359a3c7b, .checkpoint_id=00000000000000000000000000000000, .client=60324011015611665437153036865704073740, .op=167, .commit=166, .timestamp=1769197471685577697, .request=165, .operation=vsr.Operation(141) }
2026-01-23 19:44:31.686Z debug(replica): 1N: replicate: replicating op=167 to replica 2
2026-01-23 19:44:31.686Z debug(replica): 1N: sending prepare to replica 2: Prepare{ .checksum=44d3ac3ee5339774a8ffabe2ef93a635, .checksum_body=9c4e7938e45ae090fd61797e144d0f08, .cluster=0, .size=124928, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.prepare, .replica=1, .parent=48e4a96dd27c813d3c97f54a0b69beab, .request_checksum=37200c479b09c2abd4675ccc359a3c7b, .checkpoint_id=00000000000000000000000000000000, .client=60324011015611665437153036865704073740, .op=167, .commit=166, .timestamp=1769197471685577697, .request=165, .operation=vsr.Operation(141) }
2026-01-23 19:44:31.686Z debug(replica): 1N: on_prepare: advancing: op=166..167 checksum=48e4a96dd27c813d3c97f54a0b69beab..44d3ac3ee5339774a8ffabe2ef93a635
2026-01-23 19:44:31.686Z debug(journal): 1: set_header_as_dirty: op=167 checksum=44d3ac3ee5339774a8ffabe2ef93a635
2026-01-23 19:44:31.686Z debug(replica): 1N: append: appending to journal op=167
2026-01-23 19:44:31.686Z debug(journal): 1: write: view=1 slot=167 op=167 len=124928: 44d3ac3ee5339774a8ffabe2ef93a635 starting
2026-01-23 19:44:31.686Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.prepares offset=175112192 len=126976 locked
2026-01-23 19:44:31.686Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.prepares offset=175112192 len=126976 unlocked
2026-01-23 19:44:31.686Z debug(journal): 1: write_header: op=167 sectors[40960..45056]
2026-01-23 19:44:31.686Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.headers offset=40960 len=4096 locked
2026-01-23 19:44:31.687Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.headers offset=40960 len=4096 unlocked
2026-01-23 19:44:31.687Z debug(journal): 1: write: view=1 slot=167 op=167 len=124928: 44d3ac3ee5339774a8ffabe2ef93a635 complete, marking clean
2026-01-23 19:44:31.687Z debug(replica): 1N: send_prepare_ok: op=167 checksum=44d3ac3ee5339774a8ffabe2ef93a635
2026-01-23 19:44:31.687Z debug(replica): 0n: on_message: view=1 status=normal Prepare{ .checksum=44d3ac3ee5339774a8ffabe2ef93a635, .checksum_body=9c4e7938e45ae090fd61797e144d0f08, .cluster=0, .size=124928, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.prepare, .replica=1, .parent=48e4a96dd27c813d3c97f54a0b69beab, .request_checksum=37200c479b09c2abd4675ccc359a3c7b, .checkpoint_id=00000000000000000000000000000000, .client=60324011015611665437153036865704073740, .op=167, .commit=166, .timestamp=1769197471685577697, .request=165, .operation=vsr.Operation(141) }
2026-01-23 19:44:31.687Z debug(replica): 1N: sending prepare_ok to replica 1: PrepareOk{ .checksum=6d1dba35792213c4faa0bdced9dc6b64, .checksum_body=49f174618255402de6e7e3c40d60cc83, .cluster=0, .size=256, .epoch=0, .view=1, .release=0.0.0, .protocol=0, .command=vsr.Command.prepare_ok, .replica=1, .parent=48e4a96dd27c813d3c97f54a0b69beab, .prepare_checksum=44d3ac3ee5339774a8ffabe2ef93a635, .checkpoint_id=00000000000000000000000000000000, .client=60324011015611665437153036865704073740, .op=167, .commit_min=166, .timestamp=1769197471685577697, .request=165, .operation=vsr.Operation(141) }
2026-01-23 19:44:31.687Z debug(replica): 2n: on_message: view=1 status=normal Prepare{ .checksum=44d3ac3ee5339774a8ffabe2ef93a635, .checksum_body=9c4e7938e45ae090fd61797e144d0f08, .cluster=0, .size=124928, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.prepare, .replica=1, .parent=48e4a96dd27c813d3c97f54a0b69beab, .request_checksum=37200c479b09c2abd4675ccc359a3c7b, .checkpoint_id=00000000000000000000000000000000, .client=60324011015611665437153036865704073740, .op=167, .commit=166, .timestamp=1769197471685577697, .request=165, .operation=vsr.Operation(141) }
2026-01-23 19:44:34.107Z debug(replica): 0n: on_prepare: advancing commit_max=165..166
2026-01-23 19:44:34.107Z debug(replica): 0n: on_prepare: caching prepare.op=167 (commit_min=165 op=166 commit_max=166 prepare_max=1007)
2026-01-23 19:44:34.107Z debug(replica): 2n: on_prepare: advancing commit_max=165..166
2026-01-23 19:44:34.107Z debug(replica): 2n: on_prepare: caching prepare.op=167 (commit_min=165 op=166 commit_max=166 prepare_max=1007)
2026-01-23 19:44:34.107Z debug(replica): 1N: on_message: view=1 status=normal PrepareOk{ .checksum=6d1dba35792213c4faa0bdced9dc6b64, .checksum_body=49f174618255402de6e7e3c40d60cc83, .cluster=0, .size=256, .epoch=0, .view=1, .release=0.0.0, .protocol=0, .command=vsr.Command.prepare_ok, .replica=1, .parent=48e4a96dd27c813d3c97f54a0b69beab, .prepare_checksum=44d3ac3ee5339774a8ffabe2ef93a635, .checkpoint_id=00000000000000000000000000000000, .client=60324011015611665437153036865704073740, .op=167, .commit_min=166, .timestamp=1769197471685577697, .request=165, .operation=vsr.Operation(141) }
2026-01-23 19:44:34.108Z debug(vsr): 1: primary_abdicate_timeout reset
2026-01-23 19:44:34.108Z debug(replica): 1N: on_prepare_ok: 1 message(s)
2026-01-23 19:44:34.108Z debug(replica): 1N: on_prepare_ok: waiting for quorum
2026-01-23 19:44:34.108Z debug(replica): 0n: on_prepare: advancing: op=166..167 checksum=48e4a96dd27c813d3c97f54a0b69beab..44d3ac3ee5339774a8ffabe2ef93a635
2026-01-23 19:44:34.108Z debug(replica): 2n: on_prepare: advancing: op=166..167 checksum=48e4a96dd27c813d3c97f54a0b69beab..44d3ac3ee5339774a8ffabe2ef93a635
2026-01-23 19:44:34.108Z debug(journal): 0: set_header_as_dirty: op=167 checksum=44d3ac3ee5339774a8ffabe2ef93a635
2026-01-23 19:44:34.108Z debug(journal): 2: set_header_as_dirty: op=167 checksum=44d3ac3ee5339774a8ffabe2ef93a635
2026-01-23 19:44:34.108Z debug(replica): 0n: append: appending to journal op=167
2026-01-23 19:44:34.108Z debug(replica): 2n: append: appending to journal op=167
2026-01-23 19:44:34.108Z debug(journal): 0: write: view=1 slot=167 op=167 len=124928: 44d3ac3ee5339774a8ffabe2ef93a635 starting
2026-01-23 19:44:34.108Z debug(journal): 2: write: view=1 slot=167 op=167 len=124928: 44d3ac3ee5339774a8ffabe2ef93a635 starting
2026-01-23 19:44:34.108Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.prepares offset=175112192 len=126976 locked
2026-01-23 19:44:34.108Z debug(journal): 0: write_sectors: ring=vsr.journal.Ring.prepares offset=175112192 len=126976 locked
2026-01-23 19:44:34.108Z debug(replica): 0n: commit_start_journal: cached prepare op=166 checksum=48e4a96dd27c813d3c97f54a0b69beab
2026-01-23 19:44:34.108Z debug(replica): 2n: commit_start_journal: cached prepare op=166 checksum=48e4a96dd27c813d3c97f54a0b69beab
2026-01-23 19:44:34.108Z debug(replica): 2n: repair_prepare: op=167 checksum=44d3ac3ee5339774a8ffabe2ef93a635 (already writing)
2026-01-23 19:44:34.108Z debug(replica): 0n: repair_prepare: op=167 checksum=44d3ac3ee5339774a8ffabe2ef93a635 (already writing)
2026-01-23 19:44:34.108Z debug(replica): 2n: commit_journal: already committing (prefetch; commit_min=165)
2026-01-23 19:44:34.108Z debug(replica): 0n: commit_journal: already committing (prefetch; commit_min=165)
2026-01-23 19:44:34.108Z debug(replica): 2n: execute_op: executing view=1 primary=false op=166 checksum=48e4a96dd27c813d3c97f54a0b69beab (lookup_accounts)
2026-01-23 19:44:34.108Z debug(replica): 0n: execute_op: executing view=1 primary=false op=166 checksum=48e4a96dd27c813d3c97f54a0b69beab (lookup_accounts)
2026-01-23 19:44:34.108Z debug(replica): 2n: execute_op: commit_timestamp=1769197462802130111 prepare.header.timestamp=1769197471663495683
2026-01-23 19:44:34.108Z debug(replica): 0n: execute_op: commit_timestamp=1769197462802130111 prepare.header.timestamp=1769197471663495683
2026-01-23 19:44:34.108Z debug(replica): 2n: client_table_entry_update: client=60324011015611665437153036865704073740 session=2 request=164
2026-01-23 19:44:34.108Z debug(replica): 0n: client_table_entry_update: client=60324011015611665437153036865704073740 session=2 request=164
2026-01-23 19:44:34.108Z debug(forest): entering forest.compact() op=166 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2026-01-23 19:44:34.108Z debug(replica): 2n: execute_op: replying to client: Reply{ .checksum=0f8047a8a1fd96fde1fcd917315e0f41, .checksum_body=47bd3eb550008c851a6fcb8d46c5fd51, .cluster=0, .size=16768, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.reply, .replica=1, .request_checksum=1588bb205a7acb07732cddc23c457ac3, .context=2ae414bb7be21eb50c4b25d6128a6986, .client=60324011015611665437153036865704073740, .op=166, .commit=166, .timestamp=1769197471663495683, .request=164, .operation=vsr.Operation(140) }
2026-01-23 19:44:34.108Z debug(replica): 2n: sending reply to client 60324011015611665437153036865704073740: Reply{ .checksum=0f8047a8a1fd96fde1fcd917315e0f41, .checksum_body=47bd3eb550008c851a6fcb8d46c5fd51, .cluster=0, .size=16768, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.reply, .replica=1, .request_checksum=1588bb205a7acb07732cddc23c457ac3, .context=2ae414bb7be21eb50c4b25d6128a6986, .client=60324011015611665437153036865704073740, .op=166, .commit=166, .timestamp=1769197471663495683, .request=164, .operation=vsr.Operation(140) }
2026-01-23 19:44:34.108Z debug(replica): 1N: on_message: view=1 status=normal Request{ .checksum=37200c479b09c2abd4675ccc359a3c7b, .checksum_body=9c4e7938e45ae090fd61797e144d0f08, .cluster=0, .size=124928, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.request, .replica=0, .parent=2ae414bb7be21eb50c4b25d6128a6986, .client=60324011015611665437153036865704073740, .session=2, .timestamp=0, .request=165, .operation=vsr.Operation(141), .previous_request_latency=20329262 }
2026-01-23 19:44:34.108Z debug(replica): 1N: on_request: new request
2026-01-23 19:44:34.108Z debug(replica): 1N: on_request: ignoring (already preparing)
2026-01-23 19:44:34.108Z debug(forest): entering forest.compact() op=166 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2026-01-23 19:44:34.108Z debug(vsr): 1: journal_repair_budget_timeout fired
2026-01-23 19:44:34.108Z debug(vsr): 1: journal_repair_budget_timeout reset
2026-01-23 19:44:34.108Z debug(vsr): 0: journal_repair_budget_timeout fired
2026-01-23 19:44:34.108Z debug(vsr): 0: journal_repair_budget_timeout reset
2026-01-23 19:44:34.108Z debug(client_replies): 0: write_reply: wrote (client=60324011015611665437153036865704073740 request=164)
2026-01-23 19:44:34.108Z info(message_bus): 0: set_and_verify_peer connection from client_likely=60324011015611665437153036865704073740
2026-01-23 19:44:34.109Z debug(replica): 0n: on_message: view=1 status=normal Request{ .checksum=1588bb205a7acb07732cddc23c457ac3, .checksum_body=05818375add20fa5892afe2394de4b74, .cluster=0, .size=2320, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.request, .replica=0, .parent=b5e204dffc7da73d3731d47b0b03ede8, .client=60324011015611665437153036865704073740, .session=2, .timestamp=0, .request=164, .operation=vsr.Operation(140), .previous_request_latency=4294967295 }
2026-01-23 19:44:34.109Z debug(replica): 0n: on_request: replying to duplicate request
2026-01-23 19:44:34.109Z debug(client_replies): 0: read_reply: start (client=60324011015611665437153036865704073740 reply=0f8047a8a1fd96fde1fcd917315e0f41)
2026-01-23 19:44:34.109Z debug(replica): 0n: on_message: view=1 status=normal Request{ .checksum=37200c479b09c2abd4675ccc359a3c7b, .checksum_body=9c4e7938e45ae090fd61797e144d0f08, .cluster=0, .size=124928, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.request, .replica=0, .parent=2ae414bb7be21eb50c4b25d6128a6986, .client=60324011015611665437153036865704073740, .session=2, .timestamp=0, .request=165, .operation=vsr.Operation(141), .previous_request_latency=20329262 }
2026-01-23 19:44:34.109Z debug(replica): 0n: on_request: forwarding new request to primary (view=1)
2026-01-23 19:44:34.109Z debug(replica): 0n: sending request to replica 1: Request{ .checksum=37200c479b09c2abd4675ccc359a3c7b, .checksum_body=9c4e7938e45ae090fd61797e144d0f08, .cluster=0, .size=124928, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.request, .replica=0, .parent=2ae414bb7be21eb50c4b25d6128a6986, .client=60324011015611665437153036865704073740, .session=2, .timestamp=0, .request=165, .operation=vsr.Operation(141), .previous_request_latency=20329262 }
2026-01-23 19:44:34.109Z debug(replica): 2n: on_message: view=1 status=normal Request{ .checksum=37200c479b09c2abd4675ccc359a3c7b, .checksum_body=9c4e7938e45ae090fd61797e144d0f08, .cluster=0, .size=124928, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.request, .replica=0, .parent=2ae414bb7be21eb50c4b25d6128a6986, .client=60324011015611665437153036865704073740, .session=2, .timestamp=0, .request=165, .operation=vsr.Operation(141), .previous_request_latency=20329262 }
2026-01-23 19:44:34.109Z debug(replica): 2n: on_request: forwarding new request to primary (view=1)
2026-01-23 19:44:34.109Z debug(replica): 2n: sending request to replica 1: Request{ .checksum=37200c479b09c2abd4675ccc359a3c7b, .checksum_body=9c4e7938e45ae090fd61797e144d0f08, .cluster=0, .size=124928, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.request, .replica=0, .parent=2ae414bb7be21eb50c4b25d6128a6986, .client=60324011015611665437153036865704073740, .session=2, .timestamp=0, .request=165, .operation=vsr.Operation(141), .previous_request_latency=20329262 }
2026-01-23 19:44:34.109Z debug(journal): 0: write_sectors: ring=vsr.journal.Ring.prepares offset=175112192 len=126976 unlocked
2026-01-23 19:44:34.109Z debug(journal): 0: write_header: op=167 sectors[40960..45056]
2026-01-23 19:44:34.109Z debug(journal): 0: write_sectors: ring=vsr.journal.Ring.headers offset=40960 len=4096 locked
2026-01-23 19:44:34.109Z debug(client_replies): 2: write_reply: wrote (client=60324011015611665437153036865704073740 request=164)
2026-01-23 19:44:34.109Z debug(journal): 0: write_sectors: ring=vsr.journal.Ring.headers offset=40960 len=4096 unlocked
2026-01-23 19:44:34.109Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.prepares offset=175112192 len=126976 unlocked
2026-01-23 19:44:34.109Z debug(journal): 0: write: view=1 slot=167 op=167 len=124928: 44d3ac3ee5339774a8ffabe2ef93a635 complete, marking clean
2026-01-23 19:44:34.109Z debug(journal): 2: write_header: op=167 sectors[40960..45056]
2026-01-23 19:44:34.109Z debug(replica): 0n: send_prepare_ok: op=167 checksum=44d3ac3ee5339774a8ffabe2ef93a635
2026-01-23 19:44:34.109Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.headers offset=40960 len=4096 locked
2026-01-23 19:44:34.109Z debug(replica): 0n: sending prepare_ok to replica 1: PrepareOk{ .checksum=5763262feee1ea6abf9a7d0723075cd6, .checksum_body=49f174618255402de6e7e3c40d60cc83, .cluster=0, .size=256, .epoch=0, .view=1, .release=0.0.0, .protocol=0, .command=vsr.Command.prepare_ok, .replica=0, .parent=48e4a96dd27c813d3c97f54a0b69beab, .prepare_checksum=44d3ac3ee5339774a8ffabe2ef93a635, .checkpoint_id=00000000000000000000000000000000, .client=60324011015611665437153036865704073740, .op=167, .commit_min=166, .timestamp=1769197471685577697, .request=165, .operation=vsr.Operation(141) }
2026-01-23 19:44:34.109Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.headers offset=40960 len=4096 unlocked
2026-01-23 19:44:34.109Z debug(journal): 2: write: view=1 slot=167 op=167 len=124928: 44d3ac3ee5339774a8ffabe2ef93a635 complete, marking clean
2026-01-23 19:44:34.109Z debug(replica): 2n: send_prepare_ok: op=167 checksum=44d3ac3ee5339774a8ffabe2ef93a635
2026-01-23 19:44:34.109Z debug(replica): 2n: sending prepare_ok to replica 1: PrepareOk{ .checksum=852733431625637e0f96e2b6dae8e92a, .checksum_body=49f174618255402de6e7e3c40d60cc83, .cluster=0, .size=256, .epoch=0, .view=1, .release=0.0.0, .protocol=0, .command=vsr.Command.prepare_ok, .replica=2, .parent=48e4a96dd27c813d3c97f54a0b69beab, .prepare_checksum=44d3ac3ee5339774a8ffabe2ef93a635, .checkpoint_id=00000000000000000000000000000000, .client=60324011015611665437153036865704073740, .op=167, .commit_min=166, .timestamp=1769197471685577697, .request=165, .operation=vsr.Operation(141) }
2026-01-23 19:44:34.110Z debug(client_replies): 0: read_reply: done (client=60324011015611665437153036865704073740 reply=0f8047a8a1fd96fde1fcd917315e0f41)
2026-01-23 19:44:34.110Z debug(replica): 0n: on_request: repeat reply (client=60324011015611665437153036865704073740 request=164)
2026-01-23 19:44:34.110Z debug(replica): 0n: sending reply to client 60324011015611665437153036865704073740: Reply{ .checksum=0f8047a8a1fd96fde1fcd917315e0f41, .checksum_body=47bd3eb550008c851a6fcb8d46c5fd51, .cluster=0, .size=16768, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.reply, .replica=1, .request_checksum=1588bb205a7acb07732cddc23c457ac3, .context=2ae414bb7be21eb50c4b25d6128a6986, .client=60324011015611665437153036865704073740, .op=166, .commit=166, .timestamp=1769197471663495683, .request=164, .operation=vsr.Operation(140) }
2026-01-23 19:44:34.110Z debug(replica): 1N: on_message: view=1 status=normal Request{ .checksum=37200c479b09c2abd4675ccc359a3c7b, .checksum_body=9c4e7938e45ae090fd61797e144d0f08, .cluster=0, .size=124928, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.request, .replica=0, .parent=2ae414bb7be21eb50c4b25d6128a6986, .client=60324011015611665437153036865704073740, .session=2, .timestamp=0, .request=165, .operation=vsr.Operation(141), .previous_request_latency=20329262 }
2026-01-23 19:44:34.110Z debug(replica): 1N: on_request: new request
2026-01-23 19:44:34.110Z debug(replica): 1N: on_request: ignoring (already preparing)
2026-01-23 19:44:34.111Z debug(replica): 1N: on_message: view=1 status=normal Request{ .checksum=37200c479b09c2abd4675ccc359a3c7b, .checksum_body=9c4e7938e45ae090fd61797e144d0f08, .cluster=0, .size=124928, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.request, .replica=0, .parent=2ae414bb7be21eb50c4b25d6128a6986, .client=60324011015611665437153036865704073740, .session=2, .timestamp=0, .request=165, .operation=vsr.Operation(141), .previous_request_latency=20329262 }
2026-01-23 19:44:34.111Z debug(replica): 1N: on_request: new request
2026-01-23 19:44:34.111Z debug(replica): 1N: on_request: ignoring (already preparing)
2026-01-23 19:44:34.111Z debug(replica): 1N: on_message: view=1 status=normal PrepareOk{ .checksum=5763262feee1ea6abf9a7d0723075cd6, .checksum_body=49f174618255402de6e7e3c40d60cc83, .cluster=0, .size=256, .epoch=0, .view=1, .release=0.0.0, .protocol=0, .command=vsr.Command.prepare_ok, .replica=0, .parent=48e4a96dd27c813d3c97f54a0b69beab, .prepare_checksum=44d3ac3ee5339774a8ffabe2ef93a635, .checkpoint_id=00000000000000000000000000000000, .client=60324011015611665437153036865704073740, .op=167, .commit_min=166, .timestamp=1769197471685577697, .request=165, .operation=vsr.Operation(141) }
2026-01-23 19:44:34.111Z debug(vsr): 1: primary_abdicate_timeout reset
2026-01-23 19:44:34.111Z debug(replica): 1N: on_prepare_ok: 2 message(s)
2026-01-23 19:44:34.111Z debug(replica): 1N: on_prepare_ok: quorum received, prepare_checksum=44d3ac3ee5339774a8ffabe2ef93a635
2026-01-23 19:44:34.111Z debug(vsr): 1: prepare_timeout stopped
2026-01-23 19:44:34.111Z debug(vsr): 1: primary_abdicate_timeout stopped
2026-01-23 19:44:34.113Z debug(replica): 1N: on_message: view=1 status=normal PrepareOk{ .checksum=852733431625637e0f96e2b6dae8e92a, .checksum_body=49f174618255402de6e7e3c40d60cc83, .cluster=0, .size=256, .epoch=0, .view=1, .release=0.0.0, .protocol=0, .command=vsr.Command.prepare_ok, .replica=2, .parent=48e4a96dd27c813d3c97f54a0b69beab, .prepare_checksum=44d3ac3ee5339774a8ffabe2ef93a635, .checkpoint_id=00000000000000000000000000000000, .client=60324011015611665437153036865704073740, .op=167, .commit_min=166, .timestamp=1769197471685577697, .request=165, .operation=vsr.Operation(141) }
2026-01-23 19:44:34.113Z debug(replica): 1N: on_prepare_ok: 3 message(s)
2026-01-23 19:44:34.113Z debug(replica): 1N: on_prepare_ok: ignoring (quorum received already)
2026-01-23 19:44:34.113Z debug(replica): 1N: execute_op: executing view=1 primary=true op=167 checksum=44d3ac3ee5339774a8ffabe2ef93a635 (lookup_transfers)
2026-01-23 19:44:34.113Z debug(replica): 1N: execute_op: commit_timestamp=1769197471663495683 prepare.header.timestamp=1769197471685577697
2026-01-23 19:44:34.115Z debug(replica): 1N: execute_op: advancing commit_max=166..167
2026-01-23 19:44:34.119Z debug(vsr): 2: journal_repair_budget_timeout fired
2026-01-23 19:44:34.119Z debug(vsr): 2: journal_repair_budget_timeout reset
2026-01-23 19:44:34.119Z debug(replica): 1N: client_table_entry_update: client=60324011015611665437153036865704073740 session=2 request=165
2026-01-23 19:44:34.119Z debug(replica): 1N: execute_op: replying to client: Reply{ .checksum=8625271a1105b7d462562109e40b2c0a, .checksum_body=9b7b40f33265a82ef9311d8934c2e291, .cluster=0, .size=997632, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.reply, .replica=1, .request_checksum=37200c479b09c2abd4675ccc359a3c7b, .context=ec6518ce726ff48fcb358f12c9b87e99, .client=60324011015611665437153036865704073740, .op=167, .commit=167, .timestamp=1769197471685577697, .request=165, .operation=vsr.Operation(141) }
2026-01-23 19:44:34.119Z debug(replica): 1N: sending reply to client 60324011015611665437153036865704073740: Reply{ .checksum=8625271a1105b7d462562109e40b2c0a, .checksum_body=9b7b40f33265a82ef9311d8934c2e291, .cluster=0, .size=997632, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.reply, .replica=1, .request_checksum=37200c479b09c2abd4675ccc359a3c7b, .context=ec6518ce726ff48fcb358f12c9b87e99, .client=60324011015611665437153036865704073740, .op=167, .commit=167, .timestamp=1769197471685577697, .request=165, .operation=vsr.Operation(141) }
2026-01-23 19:44:34.119Z debug(forest): entering forest.compact() op=167 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2026-01-23 19:44:34.121Z debug(client_replies): 1: write_reply: wrote (client=60324011015611665437153036865704073740 request=165)
2026-01-23 19:44:34.128Z debug(vsr): 0: journal_repair_budget_timeout fired
2026-01-23 19:44:34.128Z debug(vsr): 0: journal_repair_budget_timeout reset
2026-01-23 19:44:34.130Z debug(vsr): 1: journal_repair_budget_timeout fired
2026-01-23 19:44:34.130Z debug(vsr): 1: journal_repair_budget_timeout reset
2026-01-23 19:44:34.130Z debug(replica): 1N: on_message: view=1 status=normal Request{ .checksum=c9cb24c6fce0051c8a86058f7d942814, .checksum_body=05818375add20fa5892afe2394de4b74, .cluster=0, .size=2320, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.request, .replica=0, .parent=ec6518ce726ff48fcb358f12c9b87e99, .client=60324011015611665437153036865704073740, .session=2, .timestamp=0, .request=166, .operation=vsr.Operation(140), .previous_request_latency=2445312748 }
2026-01-23 19:44:34.131Z debug(replica): 1N: on_request: new request
2026-01-23 19:44:34.131Z debug(replica): 1N: primary_pipeline_prepare: request checksum=c9cb24c6fce0051c8a86058f7d942814 client=60324011015611665437153036865704073740
2026-01-23 19:44:34.131Z debug(replica): 0n: on_message: view=1 status=normal Request{ .checksum=c9cb24c6fce0051c8a86058f7d942814, .checksum_body=05818375add20fa5892afe2394de4b74, .cluster=0, .size=2320, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.request, .replica=0, .parent=ec6518ce726ff48fcb358f12c9b87e99, .client=60324011015611665437153036865704073740, .session=2, .timestamp=0, .request=166, .operation=vsr.Operation(140), .previous_request_latency=2445312748 }
2026-01-23 19:44:34.131Z debug(replica): 0n: on_request: forwarding new request to primary (view=1)
2026-01-23 19:44:34.131Z debug(replica): 1N: primary_pipeline_prepare: prepare checksum=40da3fa1320312aee202b927adb46b22 op=168
2026-01-23 19:44:34.131Z debug(replica): 0n: sending request to replica 1: Request{ .checksum=c9cb24c6fce0051c8a86058f7d942814, .checksum_body=05818375add20fa5892afe2394de4b74, .cluster=0, .size=2320, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.request, .replica=0, .parent=ec6518ce726ff48fcb358f12c9b87e99, .client=60324011015611665437153036865704073740, .session=2, .timestamp=0, .request=166, .operation=vsr.Operation(140), .previous_request_latency=2445312748 }
2026-01-23 19:44:34.131Z debug(vsr): 1: prepare_timeout started
2026-01-23 19:44:34.131Z debug(vsr): 1: primary_abdicate_timeout started
2026-01-23 19:44:34.131Z debug(vsr): 1: pulse_timeout reset
2026-01-23 19:44:34.131Z debug(replica): 1N: replicate: replicating op=168 to replica 0
2026-01-23 19:44:34.131Z debug(replica): 1N: sending prepare to replica 0: Prepare{ .checksum=40da3fa1320312aee202b927adb46b22, .checksum_body=05818375add20fa5892afe2394de4b74, .cluster=0, .size=2320, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.prepare, .replica=1, .parent=44d3ac3ee5339774a8ffabe2ef93a635, .request_checksum=c9cb24c6fce0051c8a86058f7d942814, .checkpoint_id=00000000000000000000000000000000, .client=60324011015611665437153036865704073740, .op=168, .commit=167, .timestamp=1769197474131015563, .request=166, .operation=vsr.Operation(140) }
2026-01-23 19:44:34.131Z debug(replica): 1N: replicate: replicating op=168 to replica 2
2026-01-23 19:44:34.131Z debug(replica): 1N: sending prepare to replica 2: Prepare{ .checksum=40da3fa1320312aee202b927adb46b22, .checksum_body=05818375add20fa5892afe2394de4b74, .cluster=0, .size=2320, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.prepare, .replica=1, .parent=44d3ac3ee5339774a8ffabe2ef93a635, .request_checksum=c9cb24c6fce0051c8a86058f7d942814, .checkpoint_id=00000000000000000000000000000000, .client=60324011015611665437153036865704073740, .op=168, .commit=167, .timestamp=1769197474131015563, .request=166, .operation=vsr.Operation(140) }
2026-01-23 19:44:34.131Z debug(replica): 1N: on_prepare: advancing: op=167..168 checksum=44d3ac3ee5339774a8ffabe2ef93a635..40da3fa1320312aee202b927adb46b22
2026-01-23 19:44:34.131Z debug(journal): 1: set_header_as_dirty: op=168 checksum=40da3fa1320312aee202b927adb46b22
2026-01-23 19:44:34.131Z debug(replica): 0n: on_message: view=1 status=normal Prepare{ .checksum=40da3fa1320312aee202b927adb46b22, .checksum_body=05818375add20fa5892afe2394de4b74, .cluster=0, .size=2320, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.prepare, .replica=1, .parent=44d3ac3ee5339774a8ffabe2ef93a635, .request_checksum=c9cb24c6fce0051c8a86058f7d942814, .checkpoint_id=00000000000000000000000000000000, .client=60324011015611665437153036865704073740, .op=168, .commit=167, .timestamp=1769197474131015563, .request=166, .operation=vsr.Operation(140) }
2026-01-23 19:44:34.131Z debug(replica): 1N: append: appending to journal op=168
2026-01-23 19:44:34.131Z debug(replica): 0n: on_prepare: advancing commit_max=166..167
2026-01-23 19:44:34.131Z debug(journal): 1: write: view=1 slot=168 op=168 len=2320: 40da3fa1320312aee202b927adb46b22 starting
2026-01-23 19:44:34.131Z debug(replica): 0n: on_prepare: caching prepare.op=168 (commit_min=166 op=167 commit_max=167 prepare_max=1007)
2026-01-23 19:44:34.131Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.prepares offset=176160768 len=4096 locked
2026-01-23 19:44:34.131Z debug(replica): 2n: on_message: view=1 status=normal Prepare{ .checksum=40da3fa1320312aee202b927adb46b22, .checksum_body=05818375add20fa5892afe2394de4b74, .cluster=0, .size=2320, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.prepare, .replica=1, .parent=44d3ac3ee5339774a8ffabe2ef93a635, .request_checksum=c9cb24c6fce0051c8a86058f7d942814, .checkpoint_id=00000000000000000000000000000000, .client=60324011015611665437153036865704073740, .op=168, .commit=167, .timestamp=1769197474131015563, .request=166, .operation=vsr.Operation(140) }
2026-01-23 19:44:34.131Z debug(replica): 2n: on_prepare: advancing commit_max=166..167
2026-01-23 19:44:34.131Z debug(replica): 2n: on_prepare: caching prepare.op=168 (commit_min=166 op=167 commit_max=167 prepare_max=1007)
2026-01-23 19:44:34.131Z debug(replica): 0n: on_prepare: advancing: op=167..168 checksum=44d3ac3ee5339774a8ffabe2ef93a635..40da3fa1320312aee202b927adb46b22
2026-01-23 19:44:34.131Z debug(journal): 0: set_header_as_dirty: op=168 checksum=40da3fa1320312aee202b927adb46b22
2026-01-23 19:44:34.131Z debug(replica): 0n: append: appending to journal op=168
2026-01-23 19:44:34.131Z debug(journal): 0: write: view=1 slot=168 op=168 len=2320: 40da3fa1320312aee202b927adb46b22 starting
2026-01-23 19:44:34.131Z debug(replica): 1N: on_message: view=1 status=normal Request{ .checksum=c9cb24c6fce0051c8a86058f7d942814, .checksum_body=05818375add20fa5892afe2394de4b74, .cluster=0, .size=2320, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.request, .replica=0, .parent=ec6518ce726ff48fcb358f12c9b87e99, .client=60324011015611665437153036865704073740, .session=2, .timestamp=0, .request=166, .operation=vsr.Operation(140), .previous_request_latency=2445312748 }
2026-01-23 19:44:34.131Z debug(journal): 0: write_sectors: ring=vsr.journal.Ring.prepares offset=176160768 len=4096 locked
2026-01-23 19:44:34.131Z debug(replica): 1N: on_request: new request
2026-01-23 19:44:34.131Z debug(replica): 0n: commit_start_journal: cached prepare op=167 checksum=44d3ac3ee5339774a8ffabe2ef93a635
2026-01-23 19:44:34.131Z debug(replica): 2n: on_prepare: advancing: op=167..168 checksum=44d3ac3ee5339774a8ffabe2ef93a635..40da3fa1320312aee202b927adb46b22
2026-01-23 19:44:34.131Z debug(replica): 1N: on_request: ignoring (already preparing)
2026-01-23 19:44:34.131Z debug(journal): 2: set_header_as_dirty: op=168 checksum=40da3fa1320312aee202b927adb46b22
2026-01-23 19:44:34.131Z debug(replica): 2n: append: appending to journal op=168
2026-01-23 19:44:34.131Z debug(journal): 2: write: view=1 slot=168 op=168 len=2320: 40da3fa1320312aee202b927adb46b22 starting
2026-01-23 19:44:34.131Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.prepares offset=176160768 len=4096 locked
2026-01-23 19:44:34.131Z debug(replica): 2n: commit_start_journal: cached prepare op=167 checksum=44d3ac3ee5339774a8ffabe2ef93a635
2026-01-23 19:44:34.131Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.prepares offset=176160768 len=4096 unlocked
2026-01-23 19:44:34.131Z debug(journal): 1: write_header: op=168 sectors[40960..45056]
2026-01-23 19:44:34.131Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.headers offset=40960 len=4096 locked
2026-01-23 19:44:34.131Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.headers offset=40960 len=4096 unlocked
2026-01-23 19:44:34.131Z debug(journal): 1: write: view=1 slot=168 op=168 len=2320: 40da3fa1320312aee202b927adb46b22 complete, marking clean
2026-01-23 19:44:34.131Z debug(replica): 1N: send_prepare_ok: op=168 checksum=40da3fa1320312aee202b927adb46b22
2026-01-23 19:44:34.131Z debug(replica): 1N: sending prepare_ok to replica 1: PrepareOk{ .checksum=5b392bc40ba11ec4035ecbde31ca7926, .checksum_body=49f174618255402de6e7e3c40d60cc83, .cluster=0, .size=256, .epoch=0, .view=1, .release=0.0.0, .protocol=0, .command=vsr.Command.prepare_ok, .replica=1, .parent=44d3ac3ee5339774a8ffabe2ef93a635, .prepare_checksum=40da3fa1320312aee202b927adb46b22, .checkpoint_id=00000000000000000000000000000000, .client=60324011015611665437153036865704073740, .op=168, .commit_min=167, .timestamp=1769197474131015563, .request=166, .operation=vsr.Operation(140) }
2026-01-23 19:44:34.131Z debug(replica): 1N: on_message: view=1 status=normal PrepareOk{ .checksum=5b392bc40ba11ec4035ecbde31ca7926, .checksum_body=49f174618255402de6e7e3c40d60cc83, .cluster=0, .size=256, .epoch=0, .view=1, .release=0.0.0, .protocol=0, .command=vsr.Command.prepare_ok, .replica=1, .parent=44d3ac3ee5339774a8ffabe2ef93a635, .prepare_checksum=40da3fa1320312aee202b927adb46b22, .checkpoint_id=00000000000000000000000000000000, .client=60324011015611665437153036865704073740, .op=168, .commit_min=167, .timestamp=1769197474131015563, .request=166, .operation=vsr.Operation(140) }
2026-01-23 19:44:34.131Z debug(vsr): 1: primary_abdicate_timeout reset
2026-01-23 19:44:34.131Z debug(replica): 1N: on_prepare_ok: 1 message(s)
2026-01-23 19:44:34.131Z debug(replica): 1N: on_prepare_ok: waiting for quorum
2026-01-23 19:44:34.133Z debug(replica): 0n: repair_prepare: op=168 checksum=40da3fa1320312aee202b927adb46b22 (already writing)
2026-01-23 19:44:34.133Z debug(replica): 0n: commit_journal: already committing (prefetch; commit_min=166)
2026-01-23 19:44:34.133Z debug(replica): 0n: execute_op: executing view=1 primary=false op=167 checksum=44d3ac3ee5339774a8ffabe2ef93a635 (lookup_transfers)
2026-01-23 19:44:34.133Z debug(replica): 0n: execute_op: commit_timestamp=1769197471663495683 prepare.header.timestamp=1769197471685577697
2026-01-23 19:44:34.133Z debug(replica): 2n: repair_prepare: op=168 checksum=40da3fa1320312aee202b927adb46b22 (already writing)
2026-01-23 19:44:34.133Z debug(replica): 2n: commit_journal: already committing (prefetch; commit_min=166)
2026-01-23 19:44:34.133Z debug(replica): 2n: execute_op: executing view=1 primary=false op=167 checksum=44d3ac3ee5339774a8ffabe2ef93a635 (lookup_transfers)
2026-01-23 19:44:34.133Z debug(replica): 2n: execute_op: commit_timestamp=1769197471663495683 prepare.header.timestamp=1769197471685577697
2026-01-23 19:44:34.140Z debug(replica): 0n: client_table_entry_update: client=60324011015611665437153036865704073740 session=2 request=165
2026-01-23 19:44:34.140Z debug(forest): entering forest.compact() op=167 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2026-01-23 19:44:34.140Z debug(replica): 2n: client_table_entry_update: client=60324011015611665437153036865704073740 session=2 request=165
2026-01-23 19:44:34.140Z debug(replica): 2n: execute_op: replying to client: Reply{ .checksum=8625271a1105b7d462562109e40b2c0a, .checksum_body=9b7b40f33265a82ef9311d8934c2e291, .cluster=0, .size=997632, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.reply, .replica=1, .request_checksum=37200c479b09c2abd4675ccc359a3c7b, .context=ec6518ce726ff48fcb358f12c9b87e99, .client=60324011015611665437153036865704073740, .op=167, .commit=167, .timestamp=1769197471685577697, .request=165, .operation=vsr.Operation(141) }
2026-01-23 19:44:34.140Z debug(replica): 2n: sending reply to client 60324011015611665437153036865704073740: Reply{ .checksum=8625271a1105b7d462562109e40b2c0a, .checksum_body=9b7b40f33265a82ef9311d8934c2e291, .cluster=0, .size=997632, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.reply, .replica=1, .request_checksum=37200c479b09c2abd4675ccc359a3c7b, .context=ec6518ce726ff48fcb358f12c9b87e99, .client=60324011015611665437153036865704073740, .op=167, .commit=167, .timestamp=1769197471685577697, .request=165, .operation=vsr.Operation(141) }
2026-01-23 19:44:34.140Z debug(forest): entering forest.compact() op=167 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2026-01-23 19:44:34.140Z debug(journal): 0: write_sectors: ring=vsr.journal.Ring.prepares offset=176160768 len=4096 unlocked
2026-01-23 19:44:34.140Z debug(journal): 0: write_header: op=168 sectors[40960..45056]
2026-01-23 19:44:34.140Z debug(journal): 0: write_sectors: ring=vsr.journal.Ring.headers offset=40960 len=4096 locked
2026-01-23 19:44:34.141Z debug(client_replies): 0: write_reply: wrote (client=60324011015611665437153036865704073740 request=165)
2026-01-23 19:44:34.141Z debug(journal): 0: write_sectors: ring=vsr.journal.Ring.headers offset=40960 len=4096 unlocked
2026-01-23 19:44:34.141Z debug(journal): 0: write: view=1 slot=168 op=168 len=2320: 40da3fa1320312aee202b927adb46b22 complete, marking clean
2026-01-23 19:44:34.141Z debug(replica): 0n: send_prepare_ok: op=168 checksum=40da3fa1320312aee202b927adb46b22
2026-01-23 19:44:34.141Z debug(replica): 0n: sending prepare_ok to replica 1: PrepareOk{ .checksum=a5a6b5311f1105419588344b5286f9a8, .checksum_body=49f174618255402de6e7e3c40d60cc83, .cluster=0, .size=256, .epoch=0, .view=1, .release=0.0.0, .protocol=0, .command=vsr.Command.prepare_ok, .replica=0, .parent=44d3ac3ee5339774a8ffabe2ef93a635, .prepare_checksum=40da3fa1320312aee202b927adb46b22, .checkpoint_id=00000000000000000000000000000000, .client=60324011015611665437153036865704073740, .op=168, .commit_min=167, .timestamp=1769197474131015563, .request=166, .operation=vsr.Operation(140) }
2026-01-23 19:44:34.141Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.prepares offset=176160768 len=4096 unlocked
2026-01-23 19:44:34.141Z debug(journal): 2: write_header: op=168 sectors[40960..45056]
2026-01-23 19:44:34.141Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.headers offset=40960 len=4096 locked
2026-01-23 19:44:34.141Z debug(vsr): 2: journal_repair_budget_timeout fired
2026-01-23 19:44:34.141Z debug(vsr): 2: journal_repair_budget_timeout reset
2026-01-23 19:44:34.141Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.headers offset=40960 len=4096 unlocked
2026-01-23 19:44:34.141Z debug(journal): 2: write: view=1 slot=168 op=168 len=2320: 40da3fa1320312aee202b927adb46b22 complete, marking clean
2026-01-23 19:44:34.141Z debug(replica): 2n: send_prepare_ok: op=168 checksum=40da3fa1320312aee202b927adb46b22
2026-01-23 19:44:34.142Z debug(replica): 2n: sending prepare_ok to replica 1: PrepareOk{ .checksum=d67d121530c6298950885cf59d93017c, .checksum_body=49f174618255402de6e7e3c40d60cc83, .cluster=0, .size=256, .epoch=0, .view=1, .release=0.0.0, .protocol=0, .command=vsr.Command.prepare_ok, .replica=2, .parent=44d3ac3ee5339774a8ffabe2ef93a635, .prepare_checksum=40da3fa1320312aee202b927adb46b22, .checkpoint_id=00000000000000000000000000000000, .client=60324011015611665437153036865704073740, .op=168, .commit_min=167, .timestamp=1769197474131015563, .request=166, .operation=vsr.Operation(140) }
2026-01-23 19:44:34.142Z debug(client_replies): 2: write_reply: wrote (client=60324011015611665437153036865704073740 request=165)
2026-01-23 19:44:34.142Z debug(replica): 1N: on_message: view=1 status=normal PrepareOk{ .checksum=d67d121530c6298950885cf59d93017c, .checksum_body=49f174618255402de6e7e3c40d60cc83, .cluster=0, .size=256, .epoch=0, .view=1, .release=0.0.0, .protocol=0, .command=vsr.Command.prepare_ok, .replica=2, .parent=44d3ac3ee5339774a8ffabe2ef93a635, .prepare_checksum=40da3fa1320312aee202b927adb46b22, .checkpoint_id=00000000000000000000000000000000, .client=60324011015611665437153036865704073740, .op=168, .commit_min=167, .timestamp=1769197474131015563, .request=166, .operation=vsr.Operation(140) }
2026-01-23 19:44:34.142Z debug(vsr): 1: primary_abdicate_timeout reset
2026-01-23 19:44:34.142Z debug(replica): 1N: on_prepare_ok: 2 message(s)
2026-01-23 19:44:34.142Z debug(replica): 1N: on_prepare_ok: quorum received, prepare_checksum=40da3fa1320312aee202b927adb46b22
2026-01-23 19:44:34.142Z debug(vsr): 1: prepare_timeout stopped
2026-01-23 19:44:34.142Z debug(vsr): 1: primary_abdicate_timeout stopped
2026-01-23 19:44:34.142Z debug(replica): 1N: execute_op: executing view=1 primary=true op=168 checksum=40da3fa1320312aee202b927adb46b22 (lookup_accounts)
2026-01-23 19:44:34.142Z debug(replica): 1N: execute_op: commit_timestamp=1769197471685577697 prepare.header.timestamp=1769197474131015563
2026-01-23 19:44:34.142Z debug(replica): 1N: execute_op: advancing commit_max=167..168
2026-01-23 19:44:34.142Z debug(replica): 1N: client_table_entry_update: client=60324011015611665437153036865704073740 session=2 request=166
2026-01-23 19:44:34.142Z debug(replica): 1N: execute_op: replying to client: Reply{ .checksum=3450106eab10a67c0fece38679549202, .checksum_body=47bd3eb550008c851a6fcb8d46c5fd51, .cluster=0, .size=16768, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.reply, .replica=1, .request_checksum=c9cb24c6fce0051c8a86058f7d942814, .context=dec11d0bfe3978da12dfc07bf978bb9b, .client=60324011015611665437153036865704073740, .op=168, .commit=168, .timestamp=1769197474131015563, .request=166, .operation=vsr.Operation(140) }
2026-01-23 19:44:34.142Z debug(replica): 1N: sending reply to client 60324011015611665437153036865704073740: Reply{ .checksum=3450106eab10a67c0fece38679549202, .checksum_body=47bd3eb550008c851a6fcb8d46c5fd51, .cluster=0, .size=16768, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.reply, .replica=1, .request_checksum=c9cb24c6fce0051c8a86058f7d942814, .context=dec11d0bfe3978da12dfc07bf978bb9b, .client=60324011015611665437153036865704073740, .op=168, .commit=168, .timestamp=1769197474131015563, .request=166, .operation=vsr.Operation(140) }
2026-01-23 19:44:34.142Z debug(forest): entering forest.compact() op=168 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2026-01-23 19:44:34.142Z debug(client_replies): 1: write_reply: wrote (client=60324011015611665437153036865704073740 request=166)
2026-01-23 19:44:34.150Z info(workload): accounts created = 128, transfers = 190141, pending transfers = 0, commands run = 83
2026-01-23 19:44:34.150Z debug(vsr): 1: journal_repair_budget_timeout fired
2026-01-23 19:44:34.150Z debug(vsr): 1: journal_repair_budget_timeout reset
2026-01-23 19:44:34.150Z debug(vsr): 1: journal_repair_timeout fired
2026-01-23 19:44:34.150Z debug(vsr): 1: journal_repair_timeout reset
2026-01-23 19:44:34.150Z debug(vsr): 0: journal_repair_budget_timeout fired
2026-01-23 19:44:34.150Z debug(vsr): 0: journal_repair_budget_timeout reset
2026-01-23 19:44:34.160Z debug(vsr): 0: start_view_change_message_timeout fired
2026-01-23 19:44:34.160Z debug(vsr): 0: start_view_change_message_timeout reset
2026-01-23 19:44:34.160Z debug(vsr): 0: journal_repair_timeout fired
2026-01-23 19:44:34.160Z debug(vsr): 0: journal_repair_timeout reset
2026-01-23 19:44:34.160Z debug(vsr): 0: grid_repair_budget_timeout fired
2026-01-23 19:44:34.160Z debug(vsr): 0: grid_repair_budget_timeout reset
2026-01-23 19:44:34.164Z debug(replica): 1N: on_message: view=1 status=normal Request{ .checksum=cce5eca12e7f8ec22de200730483e7be, .checksum_body=20d74cc1501619335b56668e6eb5382b, .cluster=0, .size=874880, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.request, .replica=0, .parent=dec11d0bfe3978da12dfc07bf978bb9b, .client=60324011015611665437153036865704073740, .session=2, .timestamp=0, .request=167, .operation=vsr.Operation(139), .previous_request_latency=19349758 }
2026-01-23 19:44:34.164Z debug(replica): 1N: on_request: new request
2026-01-23 19:44:34.164Z debug(replica): 1N: primary_pipeline_prepare: request checksum=cce5eca12e7f8ec22de200730483e7be client=60324011015611665437153036865704073740
2026-01-23 19:44:34.164Z debug(replica): 2n: on_message: view=1 status=normal Request{ .checksum=cce5eca12e7f8ec22de200730483e7be, .checksum_body=20d74cc1501619335b56668e6eb5382b, .cluster=0, .size=874880, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.request, .replica=0, .parent=dec11d0bfe3978da12dfc07bf978bb9b, .client=60324011015611665437153036865704073740, .session=2, .timestamp=0, .request=167, .operation=vsr.Operation(139), .previous_request_latency=19349758 }
2026-01-23 19:44:34.164Z debug(replica): 2n: on_request: forwarding new request to primary (view=1)
2026-01-23 19:44:34.164Z debug(replica): 2n: sending request to replica 1: Request{ .checksum=cce5eca12e7f8ec22de200730483e7be, .checksum_body=20d74cc1501619335b56668e6eb5382b, .cluster=0, .size=874880, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.request, .replica=0, .parent=dec11d0bfe3978da12dfc07bf978bb9b, .client=60324011015611665437153036865704073740, .session=2, .timestamp=0, .request=167, .operation=vsr.Operation(139), .previous_request_latency=19349758 }
2026-01-23 19:44:34.164Z debug(vsr): 2: journal_repair_budget_timeout fired
2026-01-23 19:44:34.164Z debug(vsr): 2: journal_repair_budget_timeout reset
2026-01-23 19:44:34.164Z debug(vsr): 2: journal_repair_timeout fired
2026-01-23 19:44:34.164Z debug(vsr): 2: journal_repair_timeout reset
2026-01-23 19:44:34.168Z debug(replica): 1N: primary_pipeline_prepare: prepare checksum=ede03ad241a74ffbd5111869f7746158 op=169
2026-01-23 19:44:34.168Z debug(vsr): 1: prepare_timeout started
2026-01-23 19:44:34.168Z debug(vsr): 1: primary_abdicate_timeout started
2026-01-23 19:44:34.168Z debug(vsr): 1: pulse_timeout reset
2026-01-23 19:44:34.168Z debug(replica): 1N: replicate: replicating op=169 to replica 0
2026-01-23 19:44:34.168Z debug(replica): 1N: sending prepare to replica 0: Prepare{ .checksum=ede03ad241a74ffbd5111869f7746158, .checksum_body=20d74cc1501619335b56668e6eb5382b, .cluster=0, .size=874880, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.prepare, .replica=1, .parent=40da3fa1320312aee202b927adb46b22, .request_checksum=cce5eca12e7f8ec22de200730483e7be, .checkpoint_id=00000000000000000000000000000000, .client=60324011015611665437153036865704073740, .op=169, .commit=168, .timestamp=1769197474164316910, .request=167, .operation=vsr.Operation(139) }
2026-01-23 19:44:34.168Z debug(replica): 1N: replicate: replicating op=169 to replica 2
2026-01-23 19:44:34.168Z debug(replica): 1N: sending prepare to replica 2: Prepare{ .checksum=ede03ad241a74ffbd5111869f7746158, .checksum_body=20d74cc1501619335b56668e6eb5382b, .cluster=0, .size=874880, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.prepare, .replica=1, .parent=40da3fa1320312aee202b927adb46b22, .request_checksum=cce5eca12e7f8ec22de200730483e7be, .checkpoint_id=00000000000000000000000000000000, .client=60324011015611665437153036865704073740, .op=169, .commit=168, .timestamp=1769197474164316910, .request=167, .operation=vsr.Operation(139) }
2026-01-23 19:44:34.168Z debug(replica): 1N: on_prepare: advancing: op=168..169 checksum=40da3fa1320312aee202b927adb46b22..ede03ad241a74ffbd5111869f7746158
2026-01-23 19:44:34.168Z debug(journal): 1: set_header_as_dirty: op=169 checksum=ede03ad241a74ffbd5111869f7746158
2026-01-23 19:44:34.168Z debug(replica): 1N: append: appending to journal op=169
2026-01-23 19:44:34.168Z debug(journal): 1: write: view=1 slot=169 op=169 len=874880: ede03ad241a74ffbd5111869f7746158 starting
2026-01-23 19:44:34.168Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.prepares offset=177209344 len=876544 locked
2026-01-23 19:44:34.169Z debug(replica): 1N: on_message: view=1 status=normal PrepareOk{ .checksum=a5a6b5311f1105419588344b5286f9a8, .checksum_body=49f174618255402de6e7e3c40d60cc83, .cluster=0, .size=256, .epoch=0, .view=1, .release=0.0.0, .protocol=0, .command=vsr.Command.prepare_ok, .replica=0, .parent=44d3ac3ee5339774a8ffabe2ef93a635, .prepare_checksum=40da3fa1320312aee202b927adb46b22, .checkpoint_id=00000000000000000000000000000000, .client=60324011015611665437153036865704073740, .op=168, .commit_min=167, .timestamp=1769197474131015563, .request=166, .operation=vsr.Operation(140) }
2026-01-23 19:44:34.169Z debug(replica): 1N: on_prepare_ok: not preparing op=168 checksum=40da3fa1320312aee202b927adb46b22
2026-01-23 19:44:34.173Z debug(replica): 2n: on_message: view=1 status=normal Prepare{ .checksum=ede03ad241a74ffbd5111869f7746158, .checksum_body=20d74cc1501619335b56668e6eb5382b, .cluster=0, .size=874880, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.prepare, .replica=1, .parent=40da3fa1320312aee202b927adb46b22, .request_checksum=cce5eca12e7f8ec22de200730483e7be, .checkpoint_id=00000000000000000000000000000000, .client=60324011015611665437153036865704073740, .op=169, .commit=168, .timestamp=1769197474164316910, .request=167, .operation=vsr.Operation(139) }
2026-01-23 19:44:34.173Z debug(replica): 2n: on_prepare: advancing commit_max=167..168
2026-01-23 19:44:34.173Z debug(replica): 2n: on_prepare: caching prepare.op=169 (commit_min=167 op=168 commit_max=168 prepare_max=1007)
2026-01-23 19:44:34.173Z debug(replica): 2n: on_prepare: advancing: op=168..169 checksum=40da3fa1320312aee202b927adb46b22..ede03ad241a74ffbd5111869f7746158
2026-01-23 19:44:34.173Z debug(journal): 2: set_header_as_dirty: op=169 checksum=ede03ad241a74ffbd5111869f7746158
2026-01-23 19:44:34.173Z debug(replica): 2n: append: appending to journal op=169
2026-01-23 19:44:34.173Z debug(journal): 2: write: view=1 slot=169 op=169 len=874880: ede03ad241a74ffbd5111869f7746158 starting
2026-01-23 19:44:34.173Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.prepares offset=177209344 len=876544 locked
2026-01-23 19:44:34.173Z debug(replica): 2n: commit_start_journal: cached prepare op=168 checksum=40da3fa1320312aee202b927adb46b22
2026-01-23 19:44:34.173Z debug(replica): 0n: on_message: view=1 status=normal Prepare{ .checksum=ede03ad241a74ffbd5111869f7746158, .checksum_body=20d74cc1501619335b56668e6eb5382b, .cluster=0, .size=874880, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.prepare, .replica=1, .parent=40da3fa1320312aee202b927adb46b22, .request_checksum=cce5eca12e7f8ec22de200730483e7be, .checkpoint_id=00000000000000000000000000000000, .client=60324011015611665437153036865704073740, .op=169, .commit=168, .timestamp=1769197474164316910, .request=167, .operation=vsr.Operation(139) }
2026-01-23 19:44:34.173Z debug(replica): 0n: on_prepare: advancing commit_max=167..168
2026-01-23 19:44:34.173Z debug(replica): 0n: on_prepare: caching prepare.op=169 (commit_min=167 op=168 commit_max=168 prepare_max=1007)
2026-01-23 19:44:34.173Z debug(replica): 2n: repair_prepare: op=169 checksum=ede03ad241a74ffbd5111869f7746158 (already writing)
2026-01-23 19:44:34.173Z debug(replica): 2n: commit_journal: already committing (prefetch; commit_min=167)
2026-01-23 19:44:34.173Z debug(replica): 0n: on_prepare: advancing: op=168..169 checksum=40da3fa1320312aee202b927adb46b22..ede03ad241a74ffbd5111869f7746158
2026-01-23 19:44:34.173Z debug(journal): 0: set_header_as_dirty: op=169 checksum=ede03ad241a74ffbd5111869f7746158
2026-01-23 19:44:34.173Z debug(replica): 2n: execute_op: executing view=1 primary=false op=168 checksum=40da3fa1320312aee202b927adb46b22 (lookup_accounts)
2026-01-23 19:44:34.173Z debug(replica): 0n: append: appending to journal op=169
2026-01-23 19:44:34.173Z debug(replica): 2n: execute_op: commit_timestamp=1769197471685577697 prepare.header.timestamp=1769197474131015563
2026-01-23 19:44:34.173Z debug(journal): 0: write: view=1 slot=169 op=169 len=874880: ede03ad241a74ffbd5111869f7746158 starting
2026-01-23 19:44:34.173Z debug(journal): 0: write_sectors: ring=vsr.journal.Ring.prepares offset=177209344 len=876544 locked
2026-01-23 19:44:34.173Z debug(replica): 0n: commit_start_journal: cached prepare op=168 checksum=40da3fa1320312aee202b927adb46b22
2026-01-23 19:44:34.173Z debug(replica): 2n: client_table_entry_update: client=60324011015611665437153036865704073740 session=2 request=166
2026-01-23 19:44:34.173Z debug(forest): entering forest.compact() op=168 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2026-01-23 19:44:34.173Z debug(replica): 0n: repair_prepare: op=169 checksum=ede03ad241a74ffbd5111869f7746158 (already writing)
2026-01-23 19:44:34.173Z debug(replica): 0n: commit_journal: already committing (prefetch; commit_min=167)
2026-01-23 19:44:34.173Z debug(replica): 0n: execute_op: executing view=1 primary=false op=168 checksum=40da3fa1320312aee202b927adb46b22 (lookup_accounts)
2026-01-23 19:44:34.173Z debug(replica): 0n: execute_op: commit_timestamp=1769197471685577697 prepare.header.timestamp=1769197474131015563
2026-01-23 19:44:34.173Z debug(replica): 0n: client_table_entry_update: client=60324011015611665437153036865704073740 session=2 request=166
2026-01-23 19:44:34.173Z debug(replica): 0n: execute_op: replying to client: Reply{ .checksum=3450106eab10a67c0fece38679549202, .checksum_body=47bd3eb550008c851a6fcb8d46c5fd51, .cluster=0, .size=16768, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.reply, .replica=1, .request_checksum=c9cb24c6fce0051c8a86058f7d942814, .context=dec11d0bfe3978da12dfc07bf978bb9b, .client=60324011015611665437153036865704073740, .op=168, .commit=168, .timestamp=1769197474131015563, .request=166, .operation=vsr.Operation(140) }
2026-01-23 19:44:34.173Z debug(replica): 0n: sending reply to client 60324011015611665437153036865704073740: Reply{ .checksum=3450106eab10a67c0fece38679549202, .checksum_body=47bd3eb550008c851a6fcb8d46c5fd51, .cluster=0, .size=16768, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.reply, .replica=1, .request_checksum=c9cb24c6fce0051c8a86058f7d942814, .context=dec11d0bfe3978da12dfc07bf978bb9b, .client=60324011015611665437153036865704073740, .op=168, .commit=168, .timestamp=1769197474131015563, .request=166, .operation=vsr.Operation(140) }
2026-01-23 19:44:34.173Z debug(forest): entering forest.compact() op=168 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2026-01-23 19:44:34.173Z debug(client_replies): 2: write_reply: wrote (client=60324011015611665437153036865704073740 request=166)
2026-01-23 19:44:34.174Z debug(vsr): 0: journal_repair_budget_timeout fired
2026-01-23 19:44:34.174Z debug(vsr): 0: journal_repair_budget_timeout reset
2026-01-23 19:44:34.174Z debug(client_replies): 0: write_reply: wrote (client=60324011015611665437153036865704073740 request=166)
2026-01-23 19:44:34.174Z debug(replica): 1N: on_message: view=1 status=normal Request{ .checksum=cce5eca12e7f8ec22de200730483e7be, .checksum_body=20d74cc1501619335b56668e6eb5382b, .cluster=0, .size=874880, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.request, .replica=0, .parent=dec11d0bfe3978da12dfc07bf978bb9b, .client=60324011015611665437153036865704073740, .session=2, .timestamp=0, .request=167, .operation=vsr.Operation(139), .previous_request_latency=19349758 }
2026-01-23 19:44:34.174Z debug(replica): 1N: on_request: new request
2026-01-23 19:44:34.174Z debug(replica): 1N: on_request: ignoring (already preparing)
2026-01-23 19:44:34.174Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.prepares offset=177209344 len=876544 unlocked
2026-01-23 19:44:34.174Z debug(journal): 1: write_header: op=169 sectors[40960..45056]
2026-01-23 19:44:34.174Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.headers offset=40960 len=4096 locked
2026-01-23 19:44:34.174Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.headers offset=40960 len=4096 unlocked
2026-01-23 19:44:34.174Z debug(journal): 1: write: view=1 slot=169 op=169 len=874880: ede03ad241a74ffbd5111869f7746158 complete, marking clean
2026-01-23 19:44:34.174Z debug(replica): 1N: send_prepare_ok: op=169 checksum=ede03ad241a74ffbd5111869f7746158
2026-01-23 19:44:34.174Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.prepares offset=177209344 len=876544 unlocked
2026-01-23 19:44:34.174Z debug(replica): 1N: sending prepare_ok to replica 1: PrepareOk{ .checksum=040789bcbe13b6b6eac9532e1e1b5a5b, .checksum_body=49f174618255402de6e7e3c40d60cc83, .cluster=0, .size=256, .epoch=0, .view=1, .release=0.0.0, .protocol=0, .command=vsr.Command.prepare_ok, .replica=1, .parent=40da3fa1320312aee202b927adb46b22, .prepare_checksum=ede03ad241a74ffbd5111869f7746158, .checkpoint_id=00000000000000000000000000000000, .client=60324011015611665437153036865704073740, .op=169, .commit_min=168, .timestamp=1769197474164316910, .request=167, .operation=vsr.Operation(139) }
2026-01-23 19:44:34.174Z debug(journal): 2: write_header: op=169 sectors[40960..45056]
2026-01-23 19:44:34.174Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.headers offset=40960 len=4096 locked
2026-01-23 19:44:34.174Z debug(replica): 1N: on_message: view=1 status=normal PrepareOk{ .checksum=040789bcbe13b6b6eac9532e1e1b5a5b, .checksum_body=49f174618255402de6e7e3c40d60cc83, .cluster=0, .size=256, .epoch=0, .view=1, .release=0.0.0, .protocol=0, .command=vsr.Command.prepare_ok, .replica=1, .parent=40da3fa1320312aee202b927adb46b22, .prepare_checksum=ede03ad241a74ffbd5111869f7746158, .checkpoint_id=00000000000000000000000000000000, .client=60324011015611665437153036865704073740, .op=169, .commit_min=168, .timestamp=1769197474164316910, .request=167, .operation=vsr.Operation(139) }
2026-01-23 19:44:34.174Z debug(vsr): 1: primary_abdicate_timeout reset
2026-01-23 19:44:34.174Z debug(replica): 1N: on_prepare_ok: 1 message(s)
2026-01-23 19:44:34.174Z debug(replica): 1N: on_prepare_ok: waiting for quorum
2026-01-23 19:44:34.174Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.headers offset=40960 len=4096 unlocked
2026-01-23 19:44:34.174Z debug(journal): 2: write: view=1 slot=169 op=169 len=874880: ede03ad241a74ffbd5111869f7746158 complete, marking clean
2026-01-23 19:44:34.174Z debug(replica): 2n: send_prepare_ok: op=169 checksum=ede03ad241a74ffbd5111869f7746158
2026-01-23 19:44:34.174Z debug(journal): 0: write_sectors: ring=vsr.journal.Ring.prepares offset=177209344 len=876544 unlocked
2026-01-23 19:44:34.174Z debug(journal): 0: write_header: op=169 sectors[40960..45056]
2026-01-23 19:44:34.174Z debug(journal): 0: write_sectors: ring=vsr.journal.Ring.headers offset=40960 len=4096 locked
2026-01-23 19:44:34.174Z debug(replica): 2n: sending prepare_ok to replica 1: PrepareOk{ .checksum=85b8868bfdf4f91b2944e4526a4ab050, .checksum_body=49f174618255402de6e7e3c40d60cc83, .cluster=0, .size=256, .epoch=0, .view=1, .release=0.0.0, .protocol=0, .command=vsr.Command.prepare_ok, .replica=2, .parent=40da3fa1320312aee202b927adb46b22, .prepare_checksum=ede03ad241a74ffbd5111869f7746158, .checkpoint_id=00000000000000000000000000000000, .client=60324011015611665437153036865704073740, .op=169, .commit_min=168, .timestamp=1769197474164316910, .request=167, .operation=vsr.Operation(139) }
2026-01-23 19:44:34.174Z debug(journal): 0: write_sectors: ring=vsr.journal.Ring.headers offset=40960 len=4096 unlocked
2026-01-23 19:44:34.174Z debug(journal): 0: write: view=1 slot=169 op=169 len=874880: ede03ad241a74ffbd5111869f7746158 complete, marking clean
2026-01-23 19:44:34.174Z debug(replica): 0n: send_prepare_ok: op=169 checksum=ede03ad241a74ffbd5111869f7746158
2026-01-23 19:44:34.174Z debug(replica): 1N: on_message: view=1 status=normal PrepareOk{ .checksum=85b8868bfdf4f91b2944e4526a4ab050, .checksum_body=49f174618255402de6e7e3c40d60cc83, .cluster=0, .size=256, .epoch=0, .view=1, .release=0.0.0, .protocol=0, .command=vsr.Command.prepare_ok, .replica=2, .parent=40da3fa1320312aee202b927adb46b22, .prepare_checksum=ede03ad241a74ffbd5111869f7746158, .checkpoint_id=00000000000000000000000000000000, .client=60324011015611665437153036865704073740, .op=169, .commit_min=168, .timestamp=1769197474164316910, .request=167, .operation=vsr.Operation(139) }
2026-01-23 19:44:34.174Z debug(vsr): 1: primary_abdicate_timeout reset
2026-01-23 19:44:34.174Z debug(replica): 0n: sending prepare_ok to replica 1: PrepareOk{ .checksum=ffc03b3c5081dcb3ca358aa7d05583e1, .checksum_body=49f174618255402de6e7e3c40d60cc83, .cluster=0, .size=256, .epoch=0, .view=1, .release=0.0.0, .protocol=0, .command=vsr.Command.prepare_ok, .replica=0, .parent=40da3fa1320312aee202b927adb46b22, .prepare_checksum=ede03ad241a74ffbd5111869f7746158, .checkpoint_id=00000000000000000000000000000000, .client=60324011015611665437153036865704073740, .op=169, .commit_min=168, .timestamp=1769197474164316910, .request=167, .operation=vsr.Operation(139) }
2026-01-23 19:44:34.174Z debug(replica): 1N: on_prepare_ok: 2 message(s)
2026-01-23 19:44:34.175Z debug(replica): 1N: on_prepare_ok: quorum received, prepare_checksum=ede03ad241a74ffbd5111869f7746158
2026-01-23 19:44:34.175Z debug(vsr): 1: prepare_timeout stopped
2026-01-23 19:44:34.175Z debug(vsr): 1: primary_abdicate_timeout stopped
2026-01-23 19:44:34.180Z debug(replica): 1N: execute_op: executing view=1 primary=true op=169 checksum=ede03ad241a74ffbd5111869f7746158 (create_transfers)
2026-01-23 19:44:34.180Z debug(replica): 1N: execute_op: commit_timestamp=1769197474131015563 prepare.header.timestamp=1769197474164316910
2026-01-23 19:44:34.185Z debug(vsr): 2: journal_repair_budget_timeout fired
2026-01-23 19:44:34.185Z debug(vsr): 2: journal_repair_budget_timeout reset
2026-01-23 19:44:34.194Z debug(vsr): 0: journal_repair_budget_timeout fired
2026-01-23 19:44:34.194Z debug(vsr): 0: journal_repair_budget_timeout reset
2026-01-23 19:44:34.205Z debug(vsr): 2: journal_repair_budget_timeout fired
2026-01-23 19:44:34.205Z debug(vsr): 2: journal_repair_budget_timeout reset
2026-01-23 19:44:34.205Z debug(replica): 1N: execute_op: advancing commit_max=168..169
2026-01-23 19:44:34.205Z debug(replica): 1N: client_table_entry_update: client=60324011015611665437153036865704073740 session=2 request=167
2026-01-23 19:44:34.205Z debug(replica): 1N: execute_op: replying to client: Reply{ .checksum=96da4d1a08b589e2adedb46342834ed9, .checksum_body=ea896edcb0f638197c53a5b6a59e1ab2, .cluster=0, .size=264, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.reply, .replica=1, .request_checksum=cce5eca12e7f8ec22de200730483e7be, .context=2d0caa39cf8a82001ba2998349275d8d, .client=60324011015611665437153036865704073740, .op=169, .commit=169, .timestamp=1769197474164316910, .request=167, .operation=vsr.Operation(139) }
2026-01-23 19:44:34.205Z debug(replica): 1N: sending reply to client 60324011015611665437153036865704073740: Reply{ .checksum=96da4d1a08b589e2adedb46342834ed9, .checksum_body=ea896edcb0f638197c53a5b6a59e1ab2, .cluster=0, .size=264, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.reply, .replica=1, .request_checksum=cce5eca12e7f8ec22de200730483e7be, .context=2d0caa39cf8a82001ba2998349275d8d, .client=60324011015611665437153036865704073740, .op=169, .commit=169, .timestamp=1769197474164316910, .request=167, .operation=vsr.Operation(139) }
2026-01-23 19:44:34.205Z debug(forest): entering forest.compact() op=169 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2026-01-23 19:44:34.214Z debug(vsr): 0: journal_repair_budget_timeout fired
2026-01-23 19:44:34.214Z debug(vsr): 0: journal_repair_budget_timeout reset
2026-01-23 19:44:34.225Z debug(vsr): 2: journal_repair_budget_timeout fired
2026-01-23 19:44:34.225Z debug(vsr): 2: journal_repair_budget_timeout reset
2026-01-23 19:44:34.224Z debug(replica): 1N: on_message: view=1 status=normal PrepareOk{ .checksum=ffc03b3c5081dcb3ca358aa7d05583e1, .checksum_body=49f174618255402de6e7e3c40d60cc83, .cluster=0, .size=256, .epoch=0, .view=1, .release=0.0.0, .protocol=0, .command=vsr.Command.prepare_ok, .replica=0, .parent=40da3fa1320312aee202b927adb46b22, .prepare_checksum=ede03ad241a74ffbd5111869f7746158, .checkpoint_id=00000000000000000000000000000000, .client=60324011015611665437153036865704073740, .op=169, .commit_min=168, .timestamp=1769197474164316910, .request=167, .operation=vsr.Operation(139) }
2026-01-23 19:44:34.233Z debug(replica): 0n: on_message: view=1 status=normal Request{ .checksum=2b98348af4feb899c5987e289b63e8d9, .checksum_body=05818375add20fa5892afe2394de4b74, .cluster=0, .size=2320, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.request, .replica=0, .parent=2d0caa39cf8a82001ba2998349275d8d, .client=60324011015611665437153036865704073740, .session=2, .timestamp=0, .request=168, .operation=vsr.Operation(140), .previous_request_latency=50158855 }
2026-01-23 19:44:36.873Z debug(replica): 1N: on_prepare_ok: not preparing op=169 checksum=ede03ad241a74ffbd5111869f7746158
2026-01-23 19:44:36.873Z debug(replica): 0n: on_request: forwarding new request to primary (view=1)
2026-01-23 19:44:36.874Z debug(replica): 0n: sending request to replica 1: Request{ .checksum=2b98348af4feb899c5987e289b63e8d9, .checksum_body=05818375add20fa5892afe2394de4b74, .cluster=0, .size=2320, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.request, .replica=0, .parent=2d0caa39cf8a82001ba2998349275d8d, .client=60324011015611665437153036865704073740, .session=2, .timestamp=0, .request=168, .operation=vsr.Operation(140), .previous_request_latency=50158855 }
2026-01-23 19:44:36.874Z debug(vsr): 1: journal_repair_budget_timeout fired
2026-01-23 19:44:36.874Z debug(vsr): 1: journal_repair_budget_timeout reset
2026-01-23 19:44:36.874Z debug(client_replies): 1: write_reply: wrote (client=60324011015611665437153036865704073740 request=167)
2026-01-23 19:44:36.874Z debug(replica): 0n: on_message: view=1 status=normal Request{ .checksum=2b98348af4feb899c5987e289b63e8d9, .checksum_body=05818375add20fa5892afe2394de4b74, .cluster=0, .size=2320, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.request, .replica=0, .parent=2d0caa39cf8a82001ba2998349275d8d, .client=60324011015611665437153036865704073740, .session=2, .timestamp=0, .request=168, .operation=vsr.Operation(140), .previous_request_latency=50158855 }
2026-01-23 19:44:36.874Z debug(replica): 1N: on_message: view=1 status=normal Request{ .checksum=2b98348af4feb899c5987e289b63e8d9, .checksum_body=05818375add20fa5892afe2394de4b74, .cluster=0, .size=2320, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.request, .replica=0, .parent=2d0caa39cf8a82001ba2998349275d8d, .client=60324011015611665437153036865704073740, .session=2, .timestamp=0, .request=168, .operation=vsr.Operation(140), .previous_request_latency=50158855 }
2026-01-23 19:44:36.874Z debug(replica): 0n: on_request: forwarding new request to primary (view=1)
2026-01-23 19:44:36.874Z debug(replica): 0n: sending request to replica 1: Request{ .checksum=2b98348af4feb899c5987e289b63e8d9, .checksum_body=05818375add20fa5892afe2394de4b74, .cluster=0, .size=2320, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.request, .replica=0, .parent=2d0caa39cf8a82001ba2998349275d8d, .client=60324011015611665437153036865704073740, .session=2, .timestamp=0, .request=168, .operation=vsr.Operation(140), .previous_request_latency=50158855 }
2026-01-23 19:44:36.874Z debug(replica): 1N: on_request: new request
2026-01-23 19:44:36.874Z debug(replica): 1N: primary_pipeline_prepare: request checksum=2b98348af4feb899c5987e289b63e8d9 client=60324011015611665437153036865704073740
2026-01-23 19:44:36.874Z debug(replica): 1N: primary_pipeline_prepare: prepare checksum=3536376b179e4562b6e11c9f3cefd6f8 op=170
2026-01-23 19:44:36.874Z debug(vsr): 1: prepare_timeout started
2026-01-23 19:44:36.874Z debug(vsr): 1: primary_abdicate_timeout started
2026-01-23 19:44:36.874Z debug(vsr): 1: pulse_timeout reset
2026-01-23 19:44:36.874Z debug(replica): 1N: replicate: replicating op=170 to replica 0
2026-01-23 19:44:36.874Z debug(replica): 1N: sending prepare to replica 0: Prepare{ .checksum=3536376b179e4562b6e11c9f3cefd6f8, .checksum_body=05818375add20fa5892afe2394de4b74, .cluster=0, .size=2320, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.prepare, .replica=1, .parent=ede03ad241a74ffbd5111869f7746158, .request_checksum=2b98348af4feb899c5987e289b63e8d9, .checkpoint_id=00000000000000000000000000000000, .client=60324011015611665437153036865704073740, .op=170, .commit=169, .timestamp=1769197476874265006, .request=168, .operation=vsr.Operation(140) }
2026-01-23 19:44:36.874Z debug(vsr): 0: journal_repair_budget_timeout fired
2026-01-23 19:44:36.874Z debug(vsr): 0: journal_repair_budget_timeout reset
2026-01-23 19:44:36.874Z debug(replica): 1N: replicate: replicating op=170 to replica 2
2026-01-23 19:44:36.874Z debug(replica): 1N: sending prepare to replica 2: Prepare{ .checksum=3536376b179e4562b6e11c9f3cefd6f8, .checksum_body=05818375add20fa5892afe2394de4b74, .cluster=0, .size=2320, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.prepare, .replica=1, .parent=ede03ad241a74ffbd5111869f7746158, .request_checksum=2b98348af4feb899c5987e289b63e8d9, .checkpoint_id=00000000000000000000000000000000, .client=60324011015611665437153036865704073740, .op=170, .commit=169, .timestamp=1769197476874265006, .request=168, .operation=vsr.Operation(140) }
2026-01-23 19:44:36.874Z debug(replica): 1N: on_prepare: advancing: op=169..170 checksum=ede03ad241a74ffbd5111869f7746158..3536376b179e4562b6e11c9f3cefd6f8
2026-01-23 19:44:36.874Z debug(journal): 1: set_header_as_dirty: op=170 checksum=3536376b179e4562b6e11c9f3cefd6f8
2026-01-23 19:44:36.874Z debug(replica): 1N: append: appending to journal op=170
2026-01-23 19:44:36.874Z debug(replica): 0n: on_message: view=1 status=normal Prepare{ .checksum=3536376b179e4562b6e11c9f3cefd6f8, .checksum_body=05818375add20fa5892afe2394de4b74, .cluster=0, .size=2320, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.prepare, .replica=1, .parent=ede03ad241a74ffbd5111869f7746158, .request_checksum=2b98348af4feb899c5987e289b63e8d9, .checkpoint_id=00000000000000000000000000000000, .client=60324011015611665437153036865704073740, .op=170, .commit=169, .timestamp=1769197476874265006, .request=168, .operation=vsr.Operation(140) }
2026-01-23 19:44:36.874Z debug(journal): 1: write: view=1 slot=170 op=170 len=2320: 3536376b179e4562b6e11c9f3cefd6f8 starting
2026-01-23 19:44:36.874Z debug(replica): 0n: on_prepare: advancing commit_max=168..169
2026-01-23 19:44:36.874Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.prepares offset=178257920 len=4096 locked
2026-01-23 19:44:36.874Z debug(replica): 0n: on_prepare: caching prepare.op=170 (commit_min=168 op=169 commit_max=169 prepare_max=1007)
2026-01-23 19:44:36.874Z debug(replica): 0n: on_prepare: advancing: op=169..170 checksum=ede03ad241a74ffbd5111869f7746158..3536376b179e4562b6e11c9f3cefd6f8
2026-01-23 19:44:36.874Z debug(journal): 0: set_header_as_dirty: op=170 checksum=3536376b179e4562b6e11c9f3cefd6f8
2026-01-23 19:44:36.874Z debug(replica): 0n: append: appending to journal op=170
2026-01-23 19:44:36.874Z debug(journal): 0: write: view=1 slot=170 op=170 len=2320: 3536376b179e4562b6e11c9f3cefd6f8 starting
2026-01-23 19:44:36.874Z debug(journal): 0: write_sectors: ring=vsr.journal.Ring.prepares offset=178257920 len=4096 locked
2026-01-23 19:44:36.874Z debug(replica): 0n: commit_start_journal: cached prepare op=169 checksum=ede03ad241a74ffbd5111869f7746158
2026-01-23 19:44:36.874Z debug(replica): 2n: on_message: view=1 status=normal Prepare{ .checksum=3536376b179e4562b6e11c9f3cefd6f8, .checksum_body=05818375add20fa5892afe2394de4b74, .cluster=0, .size=2320, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.prepare, .replica=1, .parent=ede03ad241a74ffbd5111869f7746158, .request_checksum=2b98348af4feb899c5987e289b63e8d9, .checkpoint_id=00000000000000000000000000000000, .client=60324011015611665437153036865704073740, .op=170, .commit=169, .timestamp=1769197476874265006, .request=168, .operation=vsr.Operation(140) }
2026-01-23 19:44:36.874Z debug(replica): 2n: on_prepare: advancing commit_max=168..169
2026-01-23 19:44:36.874Z debug(replica): 2n: on_prepare: caching prepare.op=170 (commit_min=168 op=169 commit_max=169 prepare_max=1007)
2026-01-23 19:44:36.874Z debug(replica): 2n: on_prepare: advancing: op=169..170 checksum=ede03ad241a74ffbd5111869f7746158..3536376b179e4562b6e11c9f3cefd6f8
2026-01-23 19:44:36.874Z debug(journal): 2: set_header_as_dirty: op=170 checksum=3536376b179e4562b6e11c9f3cefd6f8
2026-01-23 19:44:36.874Z debug(replica): 1N: on_message: view=1 status=normal Request{ .checksum=2b98348af4feb899c5987e289b63e8d9, .checksum_body=05818375add20fa5892afe2394de4b74, .cluster=0, .size=2320, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.request, .replica=0, .parent=2d0caa39cf8a82001ba2998349275d8d, .client=60324011015611665437153036865704073740, .session=2, .timestamp=0, .request=168, .operation=vsr.Operation(140), .previous_request_latency=50158855 }
2026-01-23 19:44:36.874Z debug(replica): 2n: append: appending to journal op=170
2026-01-23 19:44:36.874Z debug(replica): 1N: on_request: new request
2026-01-23 19:44:36.874Z debug(journal): 2: write: view=1 slot=170 op=170 len=2320: 3536376b179e4562b6e11c9f3cefd6f8 starting
2026-01-23 19:44:36.874Z debug(replica): 1N: on_request: ignoring (already preparing)
2026-01-23 19:44:36.874Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.prepares offset=178257920 len=4096 locked
2026-01-23 19:44:36.874Z debug(replica): 2n: commit_start_journal: cached prepare op=169 checksum=ede03ad241a74ffbd5111869f7746158
2026-01-23 19:44:36.874Z debug(replica): 1N: on_message: view=1 status=normal Request{ .checksum=2b98348af4feb899c5987e289b63e8d9, .checksum_body=05818375add20fa5892afe2394de4b74, .cluster=0, .size=2320, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.request, .replica=0, .parent=2d0caa39cf8a82001ba2998349275d8d, .client=60324011015611665437153036865704073740, .session=2, .timestamp=0, .request=168, .operation=vsr.Operation(140), .previous_request_latency=50158855 }
2026-01-23 19:44:36.874Z debug(replica): 1N: on_request: new request
2026-01-23 19:44:36.874Z debug(replica): 1N: on_request: ignoring (already preparing)
2026-01-23 19:44:36.874Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.prepares offset=178257920 len=4096 unlocked
2026-01-23 19:44:36.874Z debug(journal): 1: write_header: op=170 sectors[40960..45056]
2026-01-23 19:44:36.874Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.headers offset=40960 len=4096 locked
2026-01-23 19:44:36.874Z debug(replica): 1N: on_message: view=1 status=normal Request{ .checksum=2b98348af4feb899c5987e289b63e8d9, .checksum_body=05818375add20fa5892afe2394de4b74, .cluster=0, .size=2320, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.request, .replica=0, .parent=2d0caa39cf8a82001ba2998349275d8d, .client=60324011015611665437153036865704073740, .session=2, .timestamp=0, .request=168, .operation=vsr.Operation(140), .previous_request_latency=50158855 }
2026-01-23 19:44:36.874Z debug(replica): 1N: on_request: new request
2026-01-23 19:44:36.874Z debug(replica): 1N: on_request: ignoring (already preparing)
2026-01-23 19:44:36.875Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.headers offset=40960 len=4096 unlocked
2026-01-23 19:44:36.875Z debug(journal): 1: write: view=1 slot=170 op=170 len=2320: 3536376b179e4562b6e11c9f3cefd6f8 complete, marking clean
2026-01-23 19:44:36.875Z debug(replica): 1N: send_prepare_ok: op=170 checksum=3536376b179e4562b6e11c9f3cefd6f8
2026-01-23 19:44:36.875Z debug(replica): 1N: sending prepare_ok to replica 1: PrepareOk{ .checksum=aa12265d862f0db4694ad56653d7124f, .checksum_body=49f174618255402de6e7e3c40d60cc83, .cluster=0, .size=256, .epoch=0, .view=1, .release=0.0.0, .protocol=0, .command=vsr.Command.prepare_ok, .replica=1, .parent=ede03ad241a74ffbd5111869f7746158, .prepare_checksum=3536376b179e4562b6e11c9f3cefd6f8, .checkpoint_id=00000000000000000000000000000000, .client=60324011015611665437153036865704073740, .op=170, .commit_min=169, .timestamp=1769197476874265006, .request=168, .operation=vsr.Operation(140) }
2026-01-23 19:44:36.875Z debug(replica): 1N: on_message: view=1 status=normal PrepareOk{ .checksum=aa12265d862f0db4694ad56653d7124f, .checksum_body=49f174618255402de6e7e3c40d60cc83, .cluster=0, .size=256, .epoch=0, .view=1, .release=0.0.0, .protocol=0, .command=vsr.Command.prepare_ok, .replica=1, .parent=ede03ad241a74ffbd5111869f7746158, .prepare_checksum=3536376b179e4562b6e11c9f3cefd6f8, .checkpoint_id=00000000000000000000000000000000, .client=60324011015611665437153036865704073740, .op=170, .commit_min=169, .timestamp=1769197476874265006, .request=168, .operation=vsr.Operation(140) }
2026-01-23 19:44:36.875Z debug(vsr): 1: primary_abdicate_timeout reset
2026-01-23 19:44:36.875Z debug(replica): 1N: on_prepare_ok: 1 message(s)
2026-01-23 19:44:36.875Z debug(replica): 1N: on_prepare_ok: waiting for quorum
2026-01-23 19:44:36.878Z debug(replica): 0n: repair_prepare: op=170 checksum=3536376b179e4562b6e11c9f3cefd6f8 (already writing)
2026-01-23 19:44:36.878Z debug(replica): 0n: commit_journal: already committing (prefetch; commit_min=168)
2026-01-23 19:44:36.878Z debug(replica): 2n: repair_prepare: op=170 checksum=3536376b179e4562b6e11c9f3cefd6f8 (already writing)
2026-01-23 19:44:36.878Z debug(replica): 2n: commit_journal: already committing (prefetch; commit_min=168)
2026-01-23 19:44:36.880Z debug(replica): 0n: execute_op: executing view=1 primary=false op=169 checksum=ede03ad241a74ffbd5111869f7746158 (create_transfers)
2026-01-23 19:44:36.880Z debug(replica): 0n: execute_op: commit_timestamp=1769197474131015563 prepare.header.timestamp=1769197474164316910
2026-01-23 19:44:36.880Z debug(replica): 2n: execute_op: executing view=1 primary=false op=169 checksum=ede03ad241a74ffbd5111869f7746158 (create_transfers)
2026-01-23 19:44:36.880Z debug(replica): 2n: execute_op: commit_timestamp=1769197474131015563 prepare.header.timestamp=1769197474164316910
2026-01-23 19:44:36.894Z debug(vsr): 1: journal_repair_budget_timeout fired
2026-01-23 19:44:36.894Z debug(vsr): 1: journal_repair_budget_timeout reset
2026-01-23 19:44:36.905Z debug(replica): 0n: client_table_entry_update: client=60324011015611665437153036865704073740 session=2 request=167
2026-01-23 19:44:36.905Z debug(forest): entering forest.compact() op=169 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2026-01-23 19:44:36.905Z debug(replica): 2n: client_table_entry_update: client=60324011015611665437153036865704073740 session=2 request=167
2026-01-23 19:44:36.905Z debug(replica): 2n: execute_op: replying to client: Reply{ .checksum=96da4d1a08b589e2adedb46342834ed9, .checksum_body=ea896edcb0f638197c53a5b6a59e1ab2, .cluster=0, .size=264, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.reply, .replica=1, .request_checksum=cce5eca12e7f8ec22de200730483e7be, .context=2d0caa39cf8a82001ba2998349275d8d, .client=60324011015611665437153036865704073740, .op=169, .commit=169, .timestamp=1769197474164316910, .request=167, .operation=vsr.Operation(139) }
2026-01-23 19:44:36.906Z debug(replica): 2n: sending reply to client 60324011015611665437153036865704073740: Reply{ .checksum=96da4d1a08b589e2adedb46342834ed9, .checksum_body=ea896edcb0f638197c53a5b6a59e1ab2, .cluster=0, .size=264, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.reply, .replica=1, .request_checksum=cce5eca12e7f8ec22de200730483e7be, .context=2d0caa39cf8a82001ba2998349275d8d, .client=60324011015611665437153036865704073740, .op=169, .commit=169, .timestamp=1769197474164316910, .request=167, .operation=vsr.Operation(139) }
2026-01-23 19:44:36.906Z debug(forest): entering forest.compact() op=169 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2026-01-23 19:44:36.914Z debug(vsr): 1: journal_repair_budget_timeout fired
2026-01-23 19:44:36.914Z debug(vsr): 1: journal_repair_budget_timeout reset
2026-01-23 19:44:36.925Z debug(journal): 0: write_sectors: ring=vsr.journal.Ring.prepares offset=178257920 len=4096 unlocked
2026-01-23 19:44:36.925Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.prepares offset=178257920 len=4096 unlocked
2026-01-23 19:44:36.925Z debug(journal): 0: write_header: op=170 sectors[40960..45056]
2026-01-23 19:44:36.925Z debug(journal): 2: write_header: op=170 sectors[40960..45056]
2026-01-23 19:44:36.925Z debug(journal): 0: write_sectors: ring=vsr.journal.Ring.headers offset=40960 len=4096 locked
2026-01-23 19:44:36.925Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.headers offset=40960 len=4096 locked
2026-01-23 19:44:36.925Z debug(client_replies): 0: write_reply: wrote (client=60324011015611665437153036865704073740 request=167)
2026-01-23 19:44:36.925Z debug(client_replies): 2: write_reply: wrote (client=60324011015611665437153036865704073740 request=167)
2026-01-23 19:44:36.925Z debug(journal): 0: write_sectors: ring=vsr.journal.Ring.headers offset=40960 len=4096 unlocked
2026-01-23 19:44:36.925Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.headers offset=40960 len=4096 unlocked
2026-01-23 19:44:36.925Z debug(journal): 0: write: view=1 slot=170 op=170 len=2320: 3536376b179e4562b6e11c9f3cefd6f8 complete, marking clean
2026-01-23 19:44:36.925Z debug(journal): 2: write: view=1 slot=170 op=170 len=2320: 3536376b179e4562b6e11c9f3cefd6f8 complete, marking clean
2026-01-23 19:44:36.925Z debug(replica): 0n: send_prepare_ok: op=170 checksum=3536376b179e4562b6e11c9f3cefd6f8
2026-01-23 19:44:36.925Z debug(replica): 2n: send_prepare_ok: op=170 checksum=3536376b179e4562b6e11c9f3cefd6f8
2026-01-23 19:44:36.925Z debug(replica): 0n: sending prepare_ok to replica 1: PrepareOk{ .checksum=39a2f4395118e4ee57195f9c8e9084be, .checksum_body=49f174618255402de6e7e3c40d60cc83, .cluster=0, .size=256, .epoch=0, .view=1, .release=0.0.0, .protocol=0, .command=vsr.Command.prepare_ok, .replica=0, .parent=ede03ad241a74ffbd5111869f7746158, .prepare_checksum=3536376b179e4562b6e11c9f3cefd6f8, .checkpoint_id=00000000000000000000000000000000, .client=60324011015611665437153036865704073740, .op=170, .commit_min=169, .timestamp=1769197476874265006, .request=168, .operation=vsr.Operation(140) }
2026-01-23 19:44:36.925Z debug(replica): 2n: sending prepare_ok to replica 1: PrepareOk{ .checksum=c9de5df71e458f3b2358da4bbe965c53, .checksum_body=49f174618255402de6e7e3c40d60cc83, .cluster=0, .size=256, .epoch=0, .view=1, .release=0.0.0, .protocol=0, .command=vsr.Command.prepare_ok, .replica=2, .parent=ede03ad241a74ffbd5111869f7746158, .prepare_checksum=3536376b179e4562b6e11c9f3cefd6f8, .checkpoint_id=00000000000000000000000000000000, .client=60324011015611665437153036865704073740, .op=170, .commit_min=169, .timestamp=1769197476874265006, .request=168, .operation=vsr.Operation(140) }
2026-01-23 19:44:36.925Z debug(replica): 1N: on_message: view=1 status=normal PrepareOk{ .checksum=c9de5df71e458f3b2358da4bbe965c53, .checksum_body=49f174618255402de6e7e3c40d60cc83, .cluster=0, .size=256, .epoch=0, .view=1, .release=0.0.0, .protocol=0, .command=vsr.Command.prepare_ok, .replica=2, .parent=ede03ad241a74ffbd5111869f7746158, .prepare_checksum=3536376b179e4562b6e11c9f3cefd6f8, .checkpoint_id=00000000000000000000000000000000, .client=60324011015611665437153036865704073740, .op=170, .commit_min=169, .timestamp=1769197476874265006, .request=168, .operation=vsr.Operation(140) }
2026-01-23 19:44:36.925Z debug(vsr): 1: primary_abdicate_timeout reset
2026-01-23 19:44:36.925Z debug(replica): 1N: on_prepare_ok: 2 message(s)
2026-01-23 19:44:36.925Z debug(replica): 1N: on_prepare_ok: quorum received, prepare_checksum=3536376b179e4562b6e11c9f3cefd6f8
2026-01-23 19:44:36.925Z debug(vsr): 1: prepare_timeout stopped
2026-01-23 19:44:36.925Z debug(vsr): 1: primary_abdicate_timeout stopped
2026-01-23 19:44:36.926Z debug(replica): 1N: execute_op: executing view=1 primary=true op=170 checksum=3536376b179e4562b6e11c9f3cefd6f8 (lookup_accounts)
2026-01-23 19:44:36.926Z debug(replica): 1N: execute_op: commit_timestamp=1769197474164316910 prepare.header.timestamp=1769197476874265006
2026-01-23 19:44:36.926Z debug(replica): 1N: execute_op: advancing commit_max=169..170
2026-01-23 19:44:36.926Z debug(replica): 1N: client_table_entry_update: client=60324011015611665437153036865704073740 session=2 request=168
2026-01-23 19:44:36.926Z debug(replica): 1N: execute_op: replying to client: Reply{ .checksum=5c34f703b77ac0fbdd4d274ea3b5e0cd, .checksum_body=29cc94860eb520eda4b4e9f2c3508d70, .cluster=0, .size=16768, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.reply, .replica=1, .request_checksum=2b98348af4feb899c5987e289b63e8d9, .context=909484bf2b7df48d7f846e3ad50e5a91, .client=60324011015611665437153036865704073740, .op=170, .commit=170, .timestamp=1769197476874265006, .request=168, .operation=vsr.Operation(140) }
2026-01-23 19:44:36.926Z debug(replica): 1N: sending reply to client 60324011015611665437153036865704073740: Reply{ .checksum=5c34f703b77ac0fbdd4d274ea3b5e0cd, .checksum_body=29cc94860eb520eda4b4e9f2c3508d70, .cluster=0, .size=16768, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.reply, .replica=1, .request_checksum=2b98348af4feb899c5987e289b63e8d9, .context=909484bf2b7df48d7f846e3ad50e5a91, .client=60324011015611665437153036865704073740, .op=170, .commit=170, .timestamp=1769197476874265006, .request=168, .operation=vsr.Operation(140) }
2026-01-23 19:44:36.926Z debug(forest): entering forest.compact() op=170 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2026-01-23 19:44:36.926Z info(workload): accounts created = 128, transfers = 196973, pending transfers = 0, commands run = 84
2026-01-23 19:44:36.926Z debug(replica): 1N: on_message: view=1 status=normal PrepareOk{ .checksum=39a2f4395118e4ee57195f9c8e9084be, .checksum_body=49f174618255402de6e7e3c40d60cc83, .cluster=0, .size=256, .epoch=0, .view=1, .release=0.0.0, .protocol=0, .command=vsr.Command.prepare_ok, .replica=0, .parent=ede03ad241a74ffbd5111869f7746158, .prepare_checksum=3536376b179e4562b6e11c9f3cefd6f8, .checkpoint_id=00000000000000000000000000000000, .client=60324011015611665437153036865704073740, .op=170, .commit_min=169, .timestamp=1769197476874265006, .request=168, .operation=vsr.Operation(140) }
2026-01-23 19:44:36.926Z debug(replica): 1N: on_prepare_ok: not preparing op=170 checksum=3536376b179e4562b6e11c9f3cefd6f8
2026-01-23 19:44:36.926Z debug(client_replies): 1: write_reply: wrote (client=60324011015611665437153036865704073740 request=168)
2026-01-23 19:44:36.928Z debug(replica): 2n: on_message: view=1 status=normal Request{ .checksum=0a1f461ad423ee459680382f316f71b7, .checksum_body=5938be226f59d53135769df8bfebdb81, .cluster=0, .size=72576, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.request, .replica=0, .parent=909484bf2b7df48d7f846e3ad50e5a91, .client=60324011015611665437153036865704073740, .session=2, .timestamp=0, .request=169, .operation=vsr.Operation(139), .previous_request_latency=2693570664 }
2026-01-23 19:44:36.928Z debug(replica): 2n: on_request: forwarding new request to primary (view=1)
2026-01-23 19:44:36.928Z debug(replica): 1N: on_message: view=1 status=normal Request{ .checksum=0a1f461ad423ee459680382f316f71b7, .checksum_body=5938be226f59d53135769df8bfebdb81, .cluster=0, .size=72576, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.request, .replica=0, .parent=909484bf2b7df48d7f846e3ad50e5a91, .client=60324011015611665437153036865704073740, .session=2, .timestamp=0, .request=169, .operation=vsr.Operation(139), .previous_request_latency=2693570664 }
2026-01-23 19:44:36.928Z debug(replica): 2n: sending request to replica 1: Request{ .checksum=0a1f461ad423ee459680382f316f71b7, .checksum_body=5938be226f59d53135769df8bfebdb81, .cluster=0, .size=72576, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.request, .replica=0, .parent=909484bf2b7df48d7f846e3ad50e5a91, .client=60324011015611665437153036865704073740, .session=2, .timestamp=0, .request=169, .operation=vsr.Operation(139), .previous_request_latency=2693570664 }
2026-01-23 19:44:36.928Z debug(replica): 1N: on_request: new request
2026-01-23 19:44:36.928Z debug(replica): 1N: primary_pipeline_prepare: request checksum=0a1f461ad423ee459680382f316f71b7 client=60324011015611665437153036865704073740
2026-01-23 19:44:36.928Z debug(replica): 1N: primary_pipeline_prepare: prepare checksum=1430f50a1757218a272306aa5dea8270 op=171
2026-01-23 19:44:36.928Z debug(vsr): 1: prepare_timeout started
2026-01-23 19:44:36.928Z debug(vsr): 1: primary_abdicate_timeout started
2026-01-23 19:44:36.928Z debug(vsr): 1: pulse_timeout reset
2026-01-23 19:44:36.928Z debug(replica): 1N: replicate: replicating op=171 to replica 0
2026-01-23 19:44:36.928Z debug(replica): 1N: sending prepare to replica 0: Prepare{ .checksum=1430f50a1757218a272306aa5dea8270, .checksum_body=5938be226f59d53135769df8bfebdb81, .cluster=0, .size=72576, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.prepare, .replica=1, .parent=3536376b179e4562b6e11c9f3cefd6f8, .request_checksum=0a1f461ad423ee459680382f316f71b7, .checkpoint_id=00000000000000000000000000000000, .client=60324011015611665437153036865704073740, .op=171, .commit=170, .timestamp=1769197476928185257, .request=169, .operation=vsr.Operation(139) }
2026-01-23 19:44:36.928Z debug(replica): 1N: replicate: replicating op=171 to replica 2
2026-01-23 19:44:36.928Z debug(replica): 1N: sending prepare to replica 2: Prepare{ .checksum=1430f50a1757218a272306aa5dea8270, .checksum_body=5938be226f59d53135769df8bfebdb81, .cluster=0, .size=72576, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.prepare, .replica=1, .parent=3536376b179e4562b6e11c9f3cefd6f8, .request_checksum=0a1f461ad423ee459680382f316f71b7, .checkpoint_id=00000000000000000000000000000000, .client=60324011015611665437153036865704073740, .op=171, .commit=170, .timestamp=1769197476928185257, .request=169, .operation=vsr.Operation(139) }
2026-01-23 19:44:36.928Z debug(replica): 1N: on_prepare: advancing: op=170..171 checksum=3536376b179e4562b6e11c9f3cefd6f8..1430f50a1757218a272306aa5dea8270
2026-01-23 19:44:36.928Z debug(journal): 1: set_header_as_dirty: op=171 checksum=1430f50a1757218a272306aa5dea8270
2026-01-23 19:44:36.928Z debug(replica): 1N: append: appending to journal op=171
2026-01-23 19:44:36.928Z debug(journal): 1: write: view=1 slot=171 op=171 len=72576: 1430f50a1757218a272306aa5dea8270 starting
2026-01-23 19:44:36.928Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.prepares offset=179306496 len=73728 locked
2026-01-23 19:44:36.929Z debug(replica): 2n: on_message: view=1 status=normal Prepare{ .checksum=1430f50a1757218a272306aa5dea8270, .checksum_body=5938be226f59d53135769df8bfebdb81, .cluster=0, .size=72576, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.prepare, .replica=1, .parent=3536376b179e4562b6e11c9f3cefd6f8, .request_checksum=0a1f461ad423ee459680382f316f71b7, .checkpoint_id=00000000000000000000000000000000, .client=60324011015611665437153036865704073740, .op=171, .commit=170, .timestamp=1769197476928185257, .request=169, .operation=vsr.Operation(139) }
2026-01-23 19:44:36.929Z debug(replica): 2n: on_prepare: advancing commit_max=169..170
2026-01-23 19:44:36.929Z debug(replica): 2n: on_prepare: caching prepare.op=171 (commit_min=169 op=170 commit_max=170 prepare_max=1007)
2026-01-23 19:44:36.929Z debug(replica): 0n: on_message: view=1 status=normal Prepare{ .checksum=1430f50a1757218a272306aa5dea8270, .checksum_body=5938be226f59d53135769df8bfebdb81, .cluster=0, .size=72576, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.prepare, .replica=1, .parent=3536376b179e4562b6e11c9f3cefd6f8, .request_checksum=0a1f461ad423ee459680382f316f71b7, .checkpoint_id=00000000000000000000000000000000, .client=60324011015611665437153036865704073740, .op=171, .commit=170, .timestamp=1769197476928185257, .request=169, .operation=vsr.Operation(139) }
2026-01-23 19:44:36.929Z debug(replica): 1N: on_message: view=1 status=normal Request{ .checksum=0a1f461ad423ee459680382f316f71b7, .checksum_body=5938be226f59d53135769df8bfebdb81, .cluster=0, .size=72576, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.request, .replica=0, .parent=909484bf2b7df48d7f846e3ad50e5a91, .client=60324011015611665437153036865704073740, .session=2, .timestamp=0, .request=169, .operation=vsr.Operation(139), .previous_request_latency=2693570664 }
2026-01-23 19:44:36.929Z debug(replica): 1N: on_request: new request
2026-01-23 19:44:36.929Z debug(replica): 0n: on_prepare: advancing commit_max=169..170
2026-01-23 19:44:36.929Z debug(replica): 1N: on_request: ignoring (already preparing)
2026-01-23 19:44:36.929Z debug(replica): 0n: on_prepare: caching prepare.op=171 (commit_min=169 op=170 commit_max=170 prepare_max=1007)
2026-01-23 19:44:36.929Z debug(replica): 2n: on_prepare: advancing: op=170..171 checksum=3536376b179e4562b6e11c9f3cefd6f8..1430f50a1757218a272306aa5dea8270
2026-01-23 19:44:36.929Z debug(journal): 2: set_header_as_dirty: op=171 checksum=1430f50a1757218a272306aa5dea8270
2026-01-23 19:44:36.929Z debug(replica): 2n: append: appending to journal op=171
2026-01-23 19:44:36.929Z debug(journal): 2: write: view=1 slot=171 op=171 len=72576: 1430f50a1757218a272306aa5dea8270 starting
2026-01-23 19:44:36.929Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.prepares offset=179306496 len=73728 locked
2026-01-23 19:44:36.929Z debug(replica): 0n: on_prepare: advancing: op=170..171 checksum=3536376b179e4562b6e11c9f3cefd6f8..1430f50a1757218a272306aa5dea8270
2026-01-23 19:44:36.929Z debug(journal): 0: set_header_as_dirty: op=171 checksum=1430f50a1757218a272306aa5dea8270
2026-01-23 19:44:36.929Z debug(replica): 2n: commit_start_journal: cached prepare op=170 checksum=3536376b179e4562b6e11c9f3cefd6f8
2026-01-23 19:44:36.929Z debug(replica): 0n: append: appending to journal op=171
2026-01-23 19:44:36.929Z debug(journal): 0: write: view=1 slot=171 op=171 len=72576: 1430f50a1757218a272306aa5dea8270 starting
2026-01-23 19:44:36.929Z debug(journal): 0: write_sectors: ring=vsr.journal.Ring.prepares offset=179306496 len=73728 locked
2026-01-23 19:44:36.929Z debug(replica): 0n: commit_start_journal: cached prepare op=170 checksum=3536376b179e4562b6e11c9f3cefd6f8
2026-01-23 19:44:36.929Z debug(replica): 2n: repair_prepare: op=171 checksum=1430f50a1757218a272306aa5dea8270 (already writing)
2026-01-23 19:44:36.929Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.prepares offset=179306496 len=73728 unlocked
2026-01-23 19:44:36.929Z debug(replica): 2n: commit_journal: already committing (prefetch; commit_min=169)
2026-01-23 19:44:36.929Z debug(journal): 1: write_header: op=171 sectors[40960..45056]
2026-01-23 19:44:36.929Z debug(replica): 0n: repair_prepare: op=171 checksum=1430f50a1757218a272306aa5dea8270 (already writing)
2026-01-23 19:44:36.929Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.headers offset=40960 len=4096 locked
2026-01-23 19:44:36.929Z debug(replica): 2n: execute_op: executing view=1 primary=false op=170 checksum=3536376b179e4562b6e11c9f3cefd6f8 (lookup_accounts)
2026-01-23 19:44:36.929Z debug(replica): 2n: execute_op: commit_timestamp=1769197474164316910 prepare.header.timestamp=1769197476874265006
2026-01-23 19:44:36.929Z debug(replica): 0n: commit_journal: already committing (prefetch; commit_min=169)
2026-01-23 19:44:36.929Z debug(replica): 0n: execute_op: executing view=1 primary=false op=170 checksum=3536376b179e4562b6e11c9f3cefd6f8 (lookup_accounts)
2026-01-23 19:44:36.929Z debug(replica): 0n: execute_op: commit_timestamp=1769197474164316910 prepare.header.timestamp=1769197476874265006
2026-01-23 19:44:36.929Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.headers offset=40960 len=4096 unlocked
2026-01-23 19:44:36.929Z debug(journal): 1: write: view=1 slot=171 op=171 len=72576: 1430f50a1757218a272306aa5dea8270 complete, marking clean
2026-01-23 19:44:36.929Z debug(replica): 1N: send_prepare_ok: op=171 checksum=1430f50a1757218a272306aa5dea8270
2026-01-23 19:44:36.929Z debug(replica): 1N: sending prepare_ok to replica 1: PrepareOk{ .checksum=095f2c54b0b18be9777d08858ab916e5, .checksum_body=49f174618255402de6e7e3c40d60cc83, .cluster=0, .size=256, .epoch=0, .view=1, .release=0.0.0, .protocol=0, .command=vsr.Command.prepare_ok, .replica=1, .parent=3536376b179e4562b6e11c9f3cefd6f8, .prepare_checksum=1430f50a1757218a272306aa5dea8270, .checkpoint_id=00000000000000000000000000000000, .client=60324011015611665437153036865704073740, .op=171, .commit_min=170, .timestamp=1769197476928185257, .request=169, .operation=vsr.Operation(139) }
2026-01-23 19:44:36.929Z debug(replica): 1N: on_message: view=1 status=normal PrepareOk{ .checksum=095f2c54b0b18be9777d08858ab916e5, .checksum_body=49f174618255402de6e7e3c40d60cc83, .cluster=0, .size=256, .epoch=0, .view=1, .release=0.0.0, .protocol=0, .command=vsr.Command.prepare_ok, .replica=1, .parent=3536376b179e4562b6e11c9f3cefd6f8, .prepare_checksum=1430f50a1757218a272306aa5dea8270, .checkpoint_id=00000000000000000000000000000000, .client=60324011015611665437153036865704073740, .op=171, .commit_min=170, .timestamp=1769197476928185257, .request=169, .operation=vsr.Operation(139) }
2026-01-23 19:44:36.929Z debug(vsr): 1: primary_abdicate_timeout reset
2026-01-23 19:44:36.929Z debug(replica): 1N: on_prepare_ok: 1 message(s)
2026-01-23 19:44:36.929Z debug(replica): 2n: client_table_entry_update: client=60324011015611665437153036865704073740 session=2 request=168
2026-01-23 19:44:36.929Z debug(replica): 1N: on_prepare_ok: waiting for quorum
2026-01-23 19:44:36.929Z debug(forest): entering forest.compact() op=170 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2026-01-23 19:44:36.929Z debug(replica): 0n: client_table_entry_update: client=60324011015611665437153036865704073740 session=2 request=168
2026-01-23 19:44:36.929Z debug(replica): 0n: execute_op: replying to client: Reply{ .checksum=5c34f703b77ac0fbdd4d274ea3b5e0cd, .checksum_body=29cc94860eb520eda4b4e9f2c3508d70, .cluster=0, .size=16768, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.reply, .replica=1, .request_checksum=2b98348af4feb899c5987e289b63e8d9, .context=909484bf2b7df48d7f846e3ad50e5a91, .client=60324011015611665437153036865704073740, .op=170, .commit=170, .timestamp=1769197476874265006, .request=168, .operation=vsr.Operation(140) }
2026-01-23 19:44:36.929Z debug(replica): 0n: sending reply to client 60324011015611665437153036865704073740: Reply{ .checksum=5c34f703b77ac0fbdd4d274ea3b5e0cd, .checksum_body=29cc94860eb520eda4b4e9f2c3508d70, .cluster=0, .size=16768, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.reply, .replica=1, .request_checksum=2b98348af4feb899c5987e289b63e8d9, .context=909484bf2b7df48d7f846e3ad50e5a91, .client=60324011015611665437153036865704073740, .op=170, .commit=170, .timestamp=1769197476874265006, .request=168, .operation=vsr.Operation(140) }
2026-01-23 19:44:36.929Z debug(forest): entering forest.compact() op=170 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2026-01-23 19:44:36.929Z debug(client_replies): 2: write_reply: wrote (client=60324011015611665437153036865704073740 request=168)
2026-01-23 19:44:36.930Z debug(client_replies): 0: write_reply: wrote (client=60324011015611665437153036865704073740 request=168)
2026-01-23 19:44:36.930Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.prepares offset=179306496 len=73728 unlocked
2026-01-23 19:44:36.930Z debug(journal): 2: write_header: op=171 sectors[40960..45056]
2026-01-23 19:44:36.930Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.headers offset=40960 len=4096 locked
2026-01-23 19:44:36.930Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.headers offset=40960 len=4096 unlocked
2026-01-23 19:44:36.930Z debug(journal): 2: write: view=1 slot=171 op=171 len=72576: 1430f50a1757218a272306aa5dea8270 complete, marking clean
2026-01-23 19:44:36.930Z debug(replica): 2n: send_prepare_ok: op=171 checksum=1430f50a1757218a272306aa5dea8270
2026-01-23 19:44:36.930Z debug(journal): 0: write_sectors: ring=vsr.journal.Ring.prepares offset=179306496 len=73728 unlocked
2026-01-23 19:44:36.930Z debug(journal): 0: write_header: op=171 sectors[40960..45056]
2026-01-23 19:44:36.930Z debug(replica): 2n: sending prepare_ok to replica 1: PrepareOk{ .checksum=9472c180e958171dc0dac6561d74e740, .checksum_body=49f174618255402de6e7e3c40d60cc83, .cluster=0, .size=256, .epoch=0, .view=1, .release=0.0.0, .protocol=0, .command=vsr.Command.prepare_ok, .replica=2, .parent=3536376b179e4562b6e11c9f3cefd6f8, .prepare_checksum=1430f50a1757218a272306aa5dea8270, .checkpoint_id=00000000000000000000000000000000, .client=60324011015611665437153036865704073740, .op=171, .commit_min=170, .timestamp=1769197476928185257, .request=169, .operation=vsr.Operation(139) }
2026-01-23 19:44:36.930Z debug(journal): 0: write_sectors: ring=vsr.journal.Ring.headers offset=40960 len=4096 locked
2026-01-23 19:44:36.930Z debug(journal): 0: write_sectors: ring=vsr.journal.Ring.headers offset=40960 len=4096 unlocked
2026-01-23 19:44:36.930Z debug(journal): 0: write: view=1 slot=171 op=171 len=72576: 1430f50a1757218a272306aa5dea8270 complete, marking clean
2026-01-23 19:44:36.930Z debug(replica): 0n: send_prepare_ok: op=171 checksum=1430f50a1757218a272306aa5dea8270
2026-01-23 19:44:36.930Z debug(replica): 1N: on_message: view=1 status=normal PrepareOk{ .checksum=9472c180e958171dc0dac6561d74e740, .checksum_body=49f174618255402de6e7e3c40d60cc83, .cluster=0, .size=256, .epoch=0, .view=1, .release=0.0.0, .protocol=0, .command=vsr.Command.prepare_ok, .replica=2, .parent=3536376b179e4562b6e11c9f3cefd6f8, .prepare_checksum=1430f50a1757218a272306aa5dea8270, .checkpoint_id=00000000000000000000000000000000, .client=60324011015611665437153036865704073740, .op=171, .commit_min=170, .timestamp=1769197476928185257, .request=169, .operation=vsr.Operation(139) }
2026-01-23 19:44:36.930Z debug(vsr): 1: primary_abdicate_timeout reset
2026-01-23 19:44:36.930Z debug(replica): 0n: sending prepare_ok to replica 1: PrepareOk{ .checksum=2fe17f9f11f900bf50e69840a2b0bf2e, .checksum_body=49f174618255402de6e7e3c40d60cc83, .cluster=0, .size=256, .epoch=0, .view=1, .release=0.0.0, .protocol=0, .command=vsr.Command.prepare_ok, .replica=0, .parent=3536376b179e4562b6e11c9f3cefd6f8, .prepare_checksum=1430f50a1757218a272306aa5dea8270, .checkpoint_id=00000000000000000000000000000000, .client=60324011015611665437153036865704073740, .op=171, .commit_min=170, .timestamp=1769197476928185257, .request=169, .operation=vsr.Operation(139) }
2026-01-23 19:44:36.930Z debug(replica): 1N: on_prepare_ok: 2 message(s)
2026-01-23 19:44:36.930Z debug(replica): 1N: on_prepare_ok: quorum received, prepare_checksum=1430f50a1757218a272306aa5dea8270
2026-01-23 19:44:36.930Z debug(vsr): 1: prepare_timeout stopped
2026-01-23 19:44:36.930Z debug(vsr): 1: primary_abdicate_timeout stopped
2026-01-23 19:44:36.931Z debug(replica): 1N: execute_op: executing view=1 primary=true op=171 checksum=1430f50a1757218a272306aa5dea8270 (create_transfers)
2026-01-23 19:44:36.931Z debug(replica): 1N: execute_op: commit_timestamp=1769197476874265006 prepare.header.timestamp=1769197476928185257
2026-01-23 19:44:36.933Z debug(replica): 1N: execute_op: advancing commit_max=170..171
2026-01-23 19:44:36.933Z debug(replica): 1N: client_table_entry_update: client=60324011015611665437153036865704073740 session=2 request=169
2026-01-23 19:44:36.933Z debug(replica): 1N: execute_op: replying to client: Reply{ .checksum=25094d1265eeff1507b83f8fd3121ebf, .checksum_body=ea896edcb0f638197c53a5b6a59e1ab2, .cluster=0, .size=264, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.reply, .replica=1, .request_checksum=0a1f461ad423ee459680382f316f71b7, .context=605ed1156a8831f622c734eb421b66a4, .client=60324011015611665437153036865704073740, .op=171, .commit=171, .timestamp=1769197476928185257, .request=169, .operation=vsr.Operation(139) }
2026-01-23 19:44:36.933Z debug(replica): 1N: sending reply to client 60324011015611665437153036865704073740: Reply{ .checksum=25094d1265eeff1507b83f8fd3121ebf, .checksum_body=ea896edcb0f638197c53a5b6a59e1ab2, .cluster=0, .size=264, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.reply, .replica=1, .request_checksum=0a1f461ad423ee459680382f316f71b7, .context=605ed1156a8831f622c734eb421b66a4, .client=60324011015611665437153036865704073740, .op=171, .commit=171, .timestamp=1769197476928185257, .request=169, .operation=vsr.Operation(139) }
2026-01-23 19:44:36.933Z debug(forest): entering forest.compact() op=171 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2026-01-23 19:44:36.935Z debug(replica): 1N: on_message: view=1 status=normal PrepareOk{ .checksum=2fe17f9f11f900bf50e69840a2b0bf2e, .checksum_body=49f174618255402de6e7e3c40d60cc83, .cluster=0, .size=256, .epoch=0, .view=1, .release=0.0.0, .protocol=0, .command=vsr.Command.prepare_ok, .replica=0, .parent=3536376b179e4562b6e11c9f3cefd6f8, .prepare_checksum=1430f50a1757218a272306aa5dea8270, .checkpoint_id=00000000000000000000000000000000, .client=60324011015611665437153036865704073740, .op=171, .commit_min=170, .timestamp=1769197476928185257, .request=169, .operation=vsr.Operation(139) }
2026-01-23 19:44:36.935Z debug(replica): 1N: on_prepare_ok: not preparing op=171 checksum=1430f50a1757218a272306aa5dea8270
2026-01-23 19:44:36.935Z debug(vsr): 1: journal_repair_budget_timeout fired
2026-01-23 19:44:36.935Z debug(vsr): 1: journal_repair_budget_timeout reset
2026-01-23 19:44:36.935Z debug(client_replies): 1: write_reply: wrote (client=60324011015611665437153036865704073740 request=169)
2026-01-23 19:44:36.935Z debug(vsr): 0: journal_repair_budget_timeout fired
2026-01-23 19:44:36.935Z debug(vsr): 0: journal_repair_budget_timeout reset
2026-01-23 19:44:36.935Z debug(vsr): 2: journal_repair_budget_timeout fired
2026-01-23 19:44:36.935Z debug(vsr): 2: journal_repair_budget_timeout reset
2026-01-23 19:44:36.935Z debug(replica): 1N: on_message: view=1 status=normal Request{ .checksum=8377cc3540470660d2b0148fab7184c5, .checksum_body=05818375add20fa5892afe2394de4b74, .cluster=0, .size=2320, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.request, .replica=0, .parent=605ed1156a8831f622c734eb421b66a4, .client=60324011015611665437153036865704073740, .session=2, .timestamp=0, .request=170, .operation=vsr.Operation(140), .previous_request_latency=6289866 }
2026-01-23 19:44:36.935Z debug(replica): 1N: on_request: new request
2026-01-23 19:44:36.935Z debug(replica): 1N: primary_pipeline_prepare: request checksum=8377cc3540470660d2b0148fab7184c5 client=60324011015611665437153036865704073740
2026-01-23 19:44:36.935Z debug(replica): 0n: on_message: view=1 status=normal Request{ .checksum=8377cc3540470660d2b0148fab7184c5, .checksum_body=05818375add20fa5892afe2394de4b74, .cluster=0, .size=2320, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.request, .replica=0, .parent=605ed1156a8831f622c734eb421b66a4, .client=60324011015611665437153036865704073740, .session=2, .timestamp=0, .request=170, .operation=vsr.Operation(140), .previous_request_latency=6289866 }
2026-01-23 19:44:36.935Z debug(replica): 0n: on_request: forwarding new request to primary (view=1)
2026-01-23 19:44:36.935Z debug(replica): 1N: primary_pipeline_prepare: prepare checksum=37a085fc9cba3313a4ff95974e311753 op=172
2026-01-23 19:44:36.935Z debug(vsr): 1: prepare_timeout started
2026-01-23 19:44:36.935Z debug(replica): 0n: sending request to replica 1: Request{ .checksum=8377cc3540470660d2b0148fab7184c5, .checksum_body=05818375add20fa5892afe2394de4b74, .cluster=0, .size=2320, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.request, .replica=0, .parent=605ed1156a8831f622c734eb421b66a4, .client=60324011015611665437153036865704073740, .session=2, .timestamp=0, .request=170, .operation=vsr.Operation(140), .previous_request_latency=6289866 }
2026-01-23 19:44:36.935Z debug(vsr): 1: primary_abdicate_timeout started
2026-01-23 19:44:36.936Z debug(vsr): 1: pulse_timeout reset
2026-01-23 19:44:36.936Z debug(replica): 1N: replicate: replicating op=172 to replica 0
2026-01-23 19:44:36.936Z debug(replica): 1N: sending prepare to replica 0: Prepare{ .checksum=37a085fc9cba3313a4ff95974e311753, .checksum_body=05818375add20fa5892afe2394de4b74, .cluster=0, .size=2320, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.prepare, .replica=1, .parent=1430f50a1757218a272306aa5dea8270, .request_checksum=8377cc3540470660d2b0148fab7184c5, .checkpoint_id=00000000000000000000000000000000, .client=60324011015611665437153036865704073740, .op=172, .commit=171, .timestamp=1769197476935955801, .request=170, .operation=vsr.Operation(140) }
2026-01-23 19:44:36.936Z debug(replica): 1N: replicate: replicating op=172 to replica 2
2026-01-23 19:44:36.936Z debug(replica): 1N: sending prepare to replica 2: Prepare{ .checksum=37a085fc9cba3313a4ff95974e311753, .checksum_body=05818375add20fa5892afe2394de4b74, .cluster=0, .size=2320, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.prepare, .replica=1, .parent=1430f50a1757218a272306aa5dea8270, .request_checksum=8377cc3540470660d2b0148fab7184c5, .checkpoint_id=00000000000000000000000000000000, .client=60324011015611665437153036865704073740, .op=172, .commit=171, .timestamp=1769197476935955801, .request=170, .operation=vsr.Operation(140) }
2026-01-23 19:44:36.936Z debug(replica): 1N: on_prepare: advancing: op=171..172 checksum=1430f50a1757218a272306aa5dea8270..37a085fc9cba3313a4ff95974e311753
2026-01-23 19:44:36.936Z debug(replica): 0n: on_message: view=1 status=normal Prepare{ .checksum=37a085fc9cba3313a4ff95974e311753, .checksum_body=05818375add20fa5892afe2394de4b74, .cluster=0, .size=2320, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.prepare, .replica=1, .parent=1430f50a1757218a272306aa5dea8270, .request_checksum=8377cc3540470660d2b0148fab7184c5, .checkpoint_id=00000000000000000000000000000000, .client=60324011015611665437153036865704073740, .op=172, .commit=171, .timestamp=1769197476935955801, .request=170, .operation=vsr.Operation(140) }
2026-01-23 19:44:36.936Z debug(journal): 1: set_header_as_dirty: op=172 checksum=37a085fc9cba3313a4ff95974e311753
2026-01-23 19:44:36.936Z debug(replica): 1N: append: appending to journal op=172
2026-01-23 19:44:36.936Z debug(replica): 0n: on_prepare: advancing commit_max=170..171
2026-01-23 19:44:36.936Z debug(replica): 0n: on_prepare: caching prepare.op=172 (commit_min=170 op=171 commit_max=171 prepare_max=1007)
2026-01-23 19:44:36.936Z debug(journal): 1: write: view=1 slot=172 op=172 len=2320: 37a085fc9cba3313a4ff95974e311753 starting
2026-01-23 19:44:36.936Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.prepares offset=180355072 len=4096 locked
2026-01-23 19:44:36.936Z debug(replica): 2n: on_message: view=1 status=normal Prepare{ .checksum=37a085fc9cba3313a4ff95974e311753, .checksum_body=05818375add20fa5892afe2394de4b74, .cluster=0, .size=2320, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.prepare, .replica=1, .parent=1430f50a1757218a272306aa5dea8270, .request_checksum=8377cc3540470660d2b0148fab7184c5, .checkpoint_id=00000000000000000000000000000000, .client=60324011015611665437153036865704073740, .op=172, .commit=171, .timestamp=1769197476935955801, .request=170, .operation=vsr.Operation(140) }
2026-01-23 19:44:36.936Z debug(replica): 2n: on_prepare: advancing commit_max=170..171
2026-01-23 19:44:36.936Z debug(replica): 2n: on_prepare: caching prepare.op=172 (commit_min=170 op=171 commit_max=171 prepare_max=1007)
2026-01-23 19:44:36.936Z debug(replica): 0n: on_prepare: advancing: op=171..172 checksum=1430f50a1757218a272306aa5dea8270..37a085fc9cba3313a4ff95974e311753
2026-01-23 19:44:36.936Z debug(journal): 0: set_header_as_dirty: op=172 checksum=37a085fc9cba3313a4ff95974e311753
2026-01-23 19:44:36.936Z debug(replica): 0n: append: appending to journal op=172
2026-01-23 19:44:36.936Z debug(journal): 0: write: view=1 slot=172 op=172 len=2320: 37a085fc9cba3313a4ff95974e311753 starting
2026-01-23 19:44:36.936Z debug(journal): 0: write_sectors: ring=vsr.journal.Ring.prepares offset=180355072 len=4096 locked
2026-01-23 19:44:36.936Z debug(replica): 0n: commit_start_journal: cached prepare op=171 checksum=1430f50a1757218a272306aa5dea8270
2026-01-23 19:44:36.936Z debug(replica): 1N: on_message: view=1 status=normal Request{ .checksum=8377cc3540470660d2b0148fab7184c5, .checksum_body=05818375add20fa5892afe2394de4b74, .cluster=0, .size=2320, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.request, .replica=0, .parent=605ed1156a8831f622c734eb421b66a4, .client=60324011015611665437153036865704073740, .session=2, .timestamp=0, .request=170, .operation=vsr.Operation(140), .previous_request_latency=6289866 }
2026-01-23 19:44:36.936Z debug(replica): 2n: on_prepare: advancing: op=171..172 checksum=1430f50a1757218a272306aa5dea8270..37a085fc9cba3313a4ff95974e311753
2026-01-23 19:44:36.936Z debug(journal): 2: set_header_as_dirty: op=172 checksum=37a085fc9cba3313a4ff95974e311753
2026-01-23 19:44:36.936Z debug(replica): 1N: on_request: new request
2026-01-23 19:44:36.936Z debug(replica): 2n: append: appending to journal op=172
2026-01-23 19:44:36.936Z debug(replica): 1N: on_request: ignoring (already preparing)
2026-01-23 19:44:36.936Z debug(journal): 2: write: view=1 slot=172 op=172 len=2320: 37a085fc9cba3313a4ff95974e311753 starting
2026-01-23 19:44:36.936Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.prepares offset=180355072 len=4096 locked
2026-01-23 19:44:36.936Z debug(replica): 2n: commit_start_journal: cached prepare op=171 checksum=1430f50a1757218a272306aa5dea8270
2026-01-23 19:44:36.936Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.prepares offset=180355072 len=4096 unlocked
2026-01-23 19:44:36.936Z debug(journal): 1: write_header: op=172 sectors[40960..45056]
2026-01-23 19:44:36.936Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.headers offset=40960 len=4096 locked
2026-01-23 19:44:36.936Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.headers offset=40960 len=4096 unlocked
2026-01-23 19:44:36.936Z debug(journal): 1: write: view=1 slot=172 op=172 len=2320: 37a085fc9cba3313a4ff95974e311753 complete, marking clean
2026-01-23 19:44:36.936Z debug(replica): 1N: send_prepare_ok: op=172 checksum=37a085fc9cba3313a4ff95974e311753
2026-01-23 19:44:36.936Z debug(replica): 1N: sending prepare_ok to replica 1: PrepareOk{ .checksum=2a7dc9886893321796bb407ba1a43750, .checksum_body=49f174618255402de6e7e3c40d60cc83, .cluster=0, .size=256, .epoch=0, .view=1, .release=0.0.0, .protocol=0, .command=vsr.Command.prepare_ok, .replica=1, .parent=1430f50a1757218a272306aa5dea8270, .prepare_checksum=37a085fc9cba3313a4ff95974e311753, .checkpoint_id=00000000000000000000000000000000, .client=60324011015611665437153036865704073740, .op=172, .commit_min=171, .timestamp=1769197476935955801, .request=170, .operation=vsr.Operation(140) }
2026-01-23 19:44:36.936Z debug(replica): 1N: on_message: view=1 status=normal PrepareOk{ .checksum=2a7dc9886893321796bb407ba1a43750, .checksum_body=49f174618255402de6e7e3c40d60cc83, .cluster=0, .size=256, .epoch=0, .view=1, .release=0.0.0, .protocol=0, .command=vsr.Command.prepare_ok, .replica=1, .parent=1430f50a1757218a272306aa5dea8270, .prepare_checksum=37a085fc9cba3313a4ff95974e311753, .checkpoint_id=00000000000000000000000000000000, .client=60324011015611665437153036865704073740, .op=172, .commit_min=171, .timestamp=1769197476935955801, .request=170, .operation=vsr.Operation(140) }
2026-01-23 19:44:36.936Z debug(vsr): 1: primary_abdicate_timeout reset
2026-01-23 19:44:36.936Z debug(replica): 1N: on_prepare_ok: 1 message(s)
2026-01-23 19:44:36.936Z debug(replica): 1N: on_prepare_ok: waiting for quorum
2026-01-23 19:44:36.936Z debug(replica): 0n: repair_prepare: op=172 checksum=37a085fc9cba3313a4ff95974e311753 (already writing)
2026-01-23 19:44:36.936Z debug(replica): 2n: repair_prepare: op=172 checksum=37a085fc9cba3313a4ff95974e311753 (already writing)
2026-01-23 19:44:36.936Z debug(replica): 0n: commit_journal: already committing (prefetch; commit_min=170)
2026-01-23 19:44:36.936Z debug(replica): 2n: commit_journal: already committing (prefetch; commit_min=170)
2026-01-23 19:44:36.936Z debug(replica): 0n: execute_op: executing view=1 primary=false op=171 checksum=1430f50a1757218a272306aa5dea8270 (create_transfers)
2026-01-23 19:44:36.936Z debug(replica): 0n: execute_op: commit_timestamp=1769197476874265006 prepare.header.timestamp=1769197476928185257
2026-01-23 19:44:36.936Z debug(replica): 2n: execute_op: executing view=1 primary=false op=171 checksum=1430f50a1757218a272306aa5dea8270 (create_transfers)
2026-01-23 19:44:36.936Z debug(replica): 2n: execute_op: commit_timestamp=1769197476874265006 prepare.header.timestamp=1769197476928185257
2026-01-23 19:44:36.939Z debug(replica): 2n: client_table_entry_update: client=60324011015611665437153036865704073740 session=2 request=169
2026-01-23 19:44:36.939Z debug(forest): entering forest.compact() op=171 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2026-01-23 19:44:36.939Z debug(replica): 0n: client_table_entry_update: client=60324011015611665437153036865704073740 session=2 request=169
2026-01-23 19:44:36.939Z debug(replica): 0n: execute_op: replying to client: Reply{ .checksum=25094d1265eeff1507b83f8fd3121ebf, .checksum_body=ea896edcb0f638197c53a5b6a59e1ab2, .cluster=0, .size=264, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.reply, .replica=1, .request_checksum=0a1f461ad423ee459680382f316f71b7, .context=605ed1156a8831f622c734eb421b66a4, .client=60324011015611665437153036865704073740, .op=171, .commit=171, .timestamp=1769197476928185257, .request=169, .operation=vsr.Operation(139) }
2026-01-23 19:44:36.939Z debug(replica): 0n: sending reply to client 60324011015611665437153036865704073740: Reply{ .checksum=25094d1265eeff1507b83f8fd3121ebf, .checksum_body=ea896edcb0f638197c53a5b6a59e1ab2, .cluster=0, .size=264, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.reply, .replica=1, .request_checksum=0a1f461ad423ee459680382f316f71b7, .context=605ed1156a8831f622c734eb421b66a4, .client=60324011015611665437153036865704073740, .op=171, .commit=171, .timestamp=1769197476928185257, .request=169, .operation=vsr.Operation(139) }
2026-01-23 19:44:36.939Z debug(forest): entering forest.compact() op=171 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2026-01-23 19:44:36.940Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.prepares offset=180355072 len=4096 unlocked
2026-01-23 19:44:36.940Z debug(journal): 2: write_header: op=172 sectors[40960..45056]
2026-01-23 19:44:36.940Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.headers offset=40960 len=4096 locked
2026-01-23 19:44:36.940Z debug(client_replies): 2: write_reply: wrote (client=60324011015611665437153036865704073740 request=169)
2026-01-23 19:44:36.940Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.headers offset=40960 len=4096 unlocked
2026-01-23 19:44:36.940Z debug(journal): 2: write: view=1 slot=172 op=172 len=2320: 37a085fc9cba3313a4ff95974e311753 complete, marking clean
2026-01-23 19:44:36.940Z debug(replica): 2n: send_prepare_ok: op=172 checksum=37a085fc9cba3313a4ff95974e311753
2026-01-23 19:44:36.940Z debug(replica): 2n: sending prepare_ok to replica 1: PrepareOk{ .checksum=b74f27305c70008dab34482a7df24151, .checksum_body=49f174618255402de6e7e3c40d60cc83, .cluster=0, .size=256, .epoch=0, .view=1, .release=0.0.0, .protocol=0, .command=vsr.Command.prepare_ok, .replica=2, .parent=1430f50a1757218a272306aa5dea8270, .prepare_checksum=37a085fc9cba3313a4ff95974e311753, .checkpoint_id=00000000000000000000000000000000, .client=60324011015611665437153036865704073740, .op=172, .commit_min=171, .timestamp=1769197476935955801, .request=170, .operation=vsr.Operation(140) }
2026-01-23 19:44:36.940Z debug(replica): 1N: on_message: view=1 status=normal PrepareOk{ .checksum=b74f27305c70008dab34482a7df24151, .checksum_body=49f174618255402de6e7e3c40d60cc83, .cluster=0, .size=256, .epoch=0, .view=1, .release=0.0.0, .protocol=0, .command=vsr.Command.prepare_ok, .replica=2, .parent=1430f50a1757218a272306aa5dea8270, .prepare_checksum=37a085fc9cba3313a4ff95974e311753, .checkpoint_id=00000000000000000000000000000000, .client=60324011015611665437153036865704073740, .op=172, .commit_min=171, .timestamp=1769197476935955801, .request=170, .operation=vsr.Operation(140) }
2026-01-23 19:44:36.940Z debug(journal): 0: write_sectors: ring=vsr.journal.Ring.prepares offset=180355072 len=4096 unlocked
2026-01-23 19:44:36.940Z debug(vsr): 1: primary_abdicate_timeout reset
2026-01-23 19:44:36.940Z debug(replica): 1N: on_prepare_ok: 2 message(s)
2026-01-23 19:44:36.940Z debug(journal): 0: write_header: op=172 sectors[40960..45056]
2026-01-23 19:44:36.940Z debug(replica): 1N: on_prepare_ok: quorum received, prepare_checksum=37a085fc9cba3313a4ff95974e311753
2026-01-23 19:44:36.940Z debug(journal): 0: write_sectors: ring=vsr.journal.Ring.headers offset=40960 len=4096 locked
2026-01-23 19:44:36.940Z debug(vsr): 1: prepare_timeout stopped
2026-01-23 19:44:36.940Z debug(vsr): 1: primary_abdicate_timeout stopped
2026-01-23 19:44:36.955Z debug(vsr): 2: journal_repair_budget_timeout fired
2026-01-23 19:44:36.941Z debug(replica): 1N: execute_op: executing view=1 primary=true op=172 checksum=37a085fc9cba3313a4ff95974e311753 (lookup_accounts)
2026-01-23 19:44:39.706Z debug(vsr): 2: journal_repair_budget_timeout reset
2026-01-23 19:44:36.940Z debug(client_replies): 0: write_reply: wrote (client=60324011015611665437153036865704073740 request=169)
2026-01-23 19:44:39.706Z debug(vsr): 2: journal_repair_timeout fired
2026-01-23 19:44:39.706Z debug(vsr): 2: journal_repair_timeout reset
2026-01-23 19:44:39.706Z debug(replica): 1N: execute_op: commit_timestamp=1769197476928185257 prepare.header.timestamp=1769197476935955801
2026-01-23 19:44:39.706Z debug(replica): 1N: execute_op: advancing commit_max=171..172
2026-01-23 19:44:39.706Z debug(replica): 1N: client_table_entry_update: client=60324011015611665437153036865704073740 session=2 request=170
2026-01-23 19:44:39.706Z debug(replica): 1N: execute_op: replying to client: Reply{ .checksum=d1bc15a108f20c4d77715c12410901ef, .checksum_body=f1245aa5d7337d3117358f9fb399cd0a, .cluster=0, .size=16768, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.reply, .replica=1, .request_checksum=8377cc3540470660d2b0148fab7184c5, .context=03773713f035760ca49dd706549a7dc9, .client=60324011015611665437153036865704073740, .op=172, .commit=172, .timestamp=1769197476935955801, .request=170, .operation=vsr.Operation(140) }
2026-01-23 19:44:39.706Z debug(replica): 1N: sending reply to client 60324011015611665437153036865704073740: Reply{ .checksum=d1bc15a108f20c4d77715c12410901ef, .checksum_body=f1245aa5d7337d3117358f9fb399cd0a, .cluster=0, .size=16768, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.reply, .replica=1, .request_checksum=8377cc3540470660d2b0148fab7184c5, .context=03773713f035760ca49dd706549a7dc9, .client=60324011015611665437153036865704073740, .op=172, .commit=172, .timestamp=1769197476935955801, .request=170, .operation=vsr.Operation(140) }
2026-01-23 19:44:39.706Z debug(forest): entering forest.compact() op=172 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2026-01-23 19:44:39.706Z debug(replica): 0n: on_message: view=1 status=normal Request{ .checksum=8377cc3540470660d2b0148fab7184c5, .checksum_body=05818375add20fa5892afe2394de4b74, .cluster=0, .size=2320, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.request, .replica=0, .parent=605ed1156a8831f622c734eb421b66a4, .client=60324011015611665437153036865704073740, .session=2, .timestamp=0, .request=170, .operation=vsr.Operation(140), .previous_request_latency=6289866 }
2026-01-23 19:44:39.706Z debug(replica): 0n: on_request: forwarding new request to primary (view=1)
2026-01-23 19:44:39.706Z debug(replica): 0n: sending request to replica 1: Request{ .checksum=8377cc3540470660d2b0148fab7184c5, .checksum_body=05818375add20fa5892afe2394de4b74, .cluster=0, .size=2320, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.request, .replica=0, .parent=605ed1156a8831f622c734eb421b66a4, .client=60324011015611665437153036865704073740, .session=2, .timestamp=0, .request=170, .operation=vsr.Operation(140), .previous_request_latency=6289866 }
2026-01-23 19:44:39.706Z debug(journal): 0: write_sectors: ring=vsr.journal.Ring.headers offset=40960 len=4096 unlocked
2026-01-23 19:44:39.706Z debug(journal): 0: write: view=1 slot=172 op=172 len=2320: 37a085fc9cba3313a4ff95974e311753 complete, marking clean
2026-01-23 19:44:39.706Z debug(replica): 0n: send_prepare_ok: op=172 checksum=37a085fc9cba3313a4ff95974e311753
2026-01-23 19:44:39.706Z debug(replica): 0n: sending prepare_ok to replica 1: PrepareOk{ .checksum=2bd451241081dc614a6a98668c02783c, .checksum_body=49f174618255402de6e7e3c40d60cc83, .cluster=0, .size=256, .epoch=0, .view=1, .release=0.0.0, .protocol=0, .command=vsr.Command.prepare_ok, .replica=0, .parent=1430f50a1757218a272306aa5dea8270, .prepare_checksum=37a085fc9cba3313a4ff95974e311753, .checkpoint_id=00000000000000000000000000000000, .client=60324011015611665437153036865704073740, .op=172, .commit_min=171, .timestamp=1769197476935955801, .request=170, .operation=vsr.Operation(140) }
2026-01-23 19:44:39.706Z debug(vsr): 0: journal_repair_timeout fired
2026-01-23 19:44:39.706Z debug(vsr): 0: journal_repair_timeout reset
2026-01-23 19:44:39.707Z info(workload): accounts created = 128, transfers = 197537, pending transfers = 0, commands run = 85
2026-01-23 19:44:39.707Z debug(replica): 1N: on_message: view=1 status=normal Request{ .checksum=8377cc3540470660d2b0148fab7184c5, .checksum_body=05818375add20fa5892afe2394de4b74, .cluster=0, .size=2320, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.request, .replica=0, .parent=605ed1156a8831f622c734eb421b66a4, .client=60324011015611665437153036865704073740, .session=2, .timestamp=0, .request=170, .operation=vsr.Operation(140), .previous_request_latency=6289866 }
2026-01-23 19:44:39.707Z debug(replica): 1N: on_request: replying to duplicate request
2026-01-23 19:44:39.707Z debug(replica): 1N: on_request: repeat reply (client=60324011015611665437153036865704073740 request=170)
2026-01-23 19:44:39.707Z debug(replica): 1N: sending reply to client 60324011015611665437153036865704073740: Reply{ .checksum=d1bc15a108f20c4d77715c12410901ef, .checksum_body=f1245aa5d7337d3117358f9fb399cd0a, .cluster=0, .size=16768, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.reply, .replica=1, .request_checksum=8377cc3540470660d2b0148fab7184c5, .context=03773713f035760ca49dd706549a7dc9, .client=60324011015611665437153036865704073740, .op=172, .commit=172, .timestamp=1769197476935955801, .request=170, .operation=vsr.Operation(140) }
2026-01-23 19:44:39.707Z debug(replica): 1N: on_message: view=1 status=normal Request{ .checksum=8377cc3540470660d2b0148fab7184c5, .checksum_body=05818375add20fa5892afe2394de4b74, .cluster=0, .size=2320, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.request, .replica=0, .parent=605ed1156a8831f622c734eb421b66a4, .client=60324011015611665437153036865704073740, .session=2, .timestamp=0, .request=170, .operation=vsr.Operation(140), .previous_request_latency=6289866 }
2026-01-23 19:44:39.707Z debug(replica): 1N: on_request: replying to duplicate request
2026-01-23 19:44:39.707Z debug(replica): 1N: on_request: repeat reply (client=60324011015611665437153036865704073740 request=170)
2026-01-23 19:44:39.707Z debug(replica): 1N: sending reply to client 60324011015611665437153036865704073740: Reply{ .checksum=d1bc15a108f20c4d77715c12410901ef, .checksum_body=f1245aa5d7337d3117358f9fb399cd0a, .cluster=0, .size=16768, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.reply, .replica=1, .request_checksum=8377cc3540470660d2b0148fab7184c5, .context=03773713f035760ca49dd706549a7dc9, .client=60324011015611665437153036865704073740, .op=172, .commit=172, .timestamp=1769197476935955801, .request=170, .operation=vsr.Operation(140) }
2026-01-23 19:44:39.707Z debug(client_replies): 1: write_reply: wrote (client=60324011015611665437153036865704073740 request=170)
2026-01-23 19:44:39.707Z debug(replica): 1N: on_message: view=1 status=normal PrepareOk{ .checksum=2bd451241081dc614a6a98668c02783c, .checksum_body=49f174618255402de6e7e3c40d60cc83, .cluster=0, .size=256, .epoch=0, .view=1, .release=0.0.0, .protocol=0, .command=vsr.Command.prepare_ok, .replica=0, .parent=1430f50a1757218a272306aa5dea8270, .prepare_checksum=37a085fc9cba3313a4ff95974e311753, .checkpoint_id=00000000000000000000000000000000, .client=60324011015611665437153036865704073740, .op=172, .commit_min=171, .timestamp=1769197476935955801, .request=170, .operation=vsr.Operation(140) }
2026-01-23 19:44:39.707Z debug(replica): 1N: on_prepare_ok: not preparing op=172 checksum=37a085fc9cba3313a4ff95974e311753
2026-01-23 19:44:39.708Z debug(replica): 2n: on_message: view=1 status=normal Request{ .checksum=e88091f4d4fad513c8d32303e5539b1f, .checksum_body=3b573b2f7446de1d349310d14b9cd899, .cluster=0, .size=124928, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.request, .replica=0, .parent=03773713f035760ca49dd706549a7dc9, .client=60324011015611665437153036865704073740, .session=2, .timestamp=0, .request=171, .operation=vsr.Operation(141), .previous_request_latency=2771114774 }
2026-01-23 19:44:39.708Z debug(replica): 2n: on_request: forwarding new request to primary (view=1)
2026-01-23 19:44:39.708Z debug(replica): 2n: sending request to replica 1: Request{ .checksum=e88091f4d4fad513c8d32303e5539b1f, .checksum_body=3b573b2f7446de1d349310d14b9cd899, .cluster=0, .size=124928, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.request, .replica=0, .parent=03773713f035760ca49dd706549a7dc9, .client=60324011015611665437153036865704073740, .session=2, .timestamp=0, .request=171, .operation=vsr.Operation(141), .previous_request_latency=2771114774 }
2026-01-23 19:44:39.708Z debug(replica): 1N: on_message: view=1 status=normal Request{ .checksum=e88091f4d4fad513c8d32303e5539b1f, .checksum_body=3b573b2f7446de1d349310d14b9cd899, .cluster=0, .size=124928, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.request, .replica=0, .parent=03773713f035760ca49dd706549a7dc9, .client=60324011015611665437153036865704073740, .session=2, .timestamp=0, .request=171, .operation=vsr.Operation(141), .previous_request_latency=2771114774 }
2026-01-23 19:44:39.708Z debug(replica): 1N: on_request: new request
2026-01-23 19:44:39.708Z debug(replica): 1N: primary_pipeline_prepare: request checksum=e88091f4d4fad513c8d32303e5539b1f client=60324011015611665437153036865704073740
2026-01-23 19:44:39.709Z debug(replica): 1N: primary_pipeline_prepare: prepare checksum=3f0abef5dbe7f2b8bb97f2d331c928a6 op=173
2026-01-23 19:44:39.709Z debug(vsr): 1: prepare_timeout started
2026-01-23 19:44:39.709Z debug(vsr): 1: primary_abdicate_timeout started
2026-01-23 19:44:39.709Z debug(vsr): 1: pulse_timeout reset
2026-01-23 19:44:39.709Z debug(replica): 1N: replicate: replicating op=173 to replica 0
2026-01-23 19:44:39.709Z debug(replica): 1N: sending prepare to replica 0: Prepare{ .checksum=3f0abef5dbe7f2b8bb97f2d331c928a6, .checksum_body=3b573b2f7446de1d349310d14b9cd899, .cluster=0, .size=124928, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.prepare, .replica=1, .parent=37a085fc9cba3313a4ff95974e311753, .request_checksum=e88091f4d4fad513c8d32303e5539b1f, .checkpoint_id=00000000000000000000000000000000, .client=60324011015611665437153036865704073740, .op=173, .commit=172, .timestamp=1769197479708967226, .request=171, .operation=vsr.Operation(141) }
2026-01-23 19:44:39.709Z debug(replica): 1N: replicate: replicating op=173 to replica 2
2026-01-23 19:44:39.709Z debug(replica): 1N: sending prepare to replica 2: Prepare{ .checksum=3f0abef5dbe7f2b8bb97f2d331c928a6, .checksum_body=3b573b2f7446de1d349310d14b9cd899, .cluster=0, .size=124928, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.prepare, .replica=1, .parent=37a085fc9cba3313a4ff95974e311753, .request_checksum=e88091f4d4fad513c8d32303e5539b1f, .checkpoint_id=00000000000000000000000000000000, .client=60324011015611665437153036865704073740, .op=173, .commit=172, .timestamp=1769197479708967226, .request=171, .operation=vsr.Operation(141) }
2026-01-23 19:44:39.709Z debug(replica): 1N: on_prepare: advancing: op=172..173 checksum=37a085fc9cba3313a4ff95974e311753..3f0abef5dbe7f2b8bb97f2d331c928a6
2026-01-23 19:44:39.709Z debug(journal): 1: set_header_as_dirty: op=173 checksum=3f0abef5dbe7f2b8bb97f2d331c928a6
2026-01-23 19:44:39.709Z debug(replica): 1N: append: appending to journal op=173
2026-01-23 19:44:39.709Z debug(journal): 1: write: view=1 slot=173 op=173 len=124928: 3f0abef5dbe7f2b8bb97f2d331c928a6 starting
2026-01-23 19:44:39.709Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.prepares offset=181403648 len=126976 locked
2026-01-23 19:44:39.710Z debug(replica): 0n: on_message: view=1 status=normal Prepare{ .checksum=3f0abef5dbe7f2b8bb97f2d331c928a6, .checksum_body=3b573b2f7446de1d349310d14b9cd899, .cluster=0, .size=124928, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.prepare, .replica=1, .parent=37a085fc9cba3313a4ff95974e311753, .request_checksum=e88091f4d4fad513c8d32303e5539b1f, .checkpoint_id=00000000000000000000000000000000, .client=60324011015611665437153036865704073740, .op=173, .commit=172, .timestamp=1769197479708967226, .request=171, .operation=vsr.Operation(141) }
2026-01-23 19:44:39.710Z debug(replica): 1N: on_message: view=1 status=normal Request{ .checksum=e88091f4d4fad513c8d32303e5539b1f, .checksum_body=3b573b2f7446de1d349310d14b9cd899, .cluster=0, .size=124928, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.request, .replica=0, .parent=03773713f035760ca49dd706549a7dc9, .client=60324011015611665437153036865704073740, .session=2, .timestamp=0, .request=171, .operation=vsr.Operation(141), .previous_request_latency=2771114774 }
2026-01-23 19:44:39.710Z debug(replica): 0n: on_prepare: advancing commit_max=171..172
2026-01-23 19:44:39.710Z debug(replica): 1N: on_request: new request
2026-01-23 19:44:39.710Z debug(replica): 1N: on_request: ignoring (already preparing)
2026-01-23 19:44:39.710Z debug(replica): 0n: on_prepare: caching prepare.op=173 (commit_min=171 op=172 commit_max=172 prepare_max=1007)
2026-01-23 19:44:39.710Z debug(replica): 0n: on_prepare: advancing: op=172..173 checksum=37a085fc9cba3313a4ff95974e311753..3f0abef5dbe7f2b8bb97f2d331c928a6
2026-01-23 19:44:39.710Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.prepares offset=181403648 len=126976 unlocked
2026-01-23 19:44:39.710Z debug(journal): 0: set_header_as_dirty: op=173 checksum=3f0abef5dbe7f2b8bb97f2d331c928a6
2026-01-23 19:44:39.710Z debug(journal): 1: write_header: op=173 sectors[40960..45056]
2026-01-23 19:44:39.710Z debug(replica): 0n: append: appending to journal op=173
2026-01-23 19:44:39.710Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.headers offset=40960 len=4096 locked
2026-01-23 19:44:39.710Z debug(journal): 0: write: view=1 slot=173 op=173 len=124928: 3f0abef5dbe7f2b8bb97f2d331c928a6 starting
2026-01-23 19:44:39.710Z debug(journal): 0: write_sectors: ring=vsr.journal.Ring.prepares offset=181403648 len=126976 locked
2026-01-23 19:44:39.710Z debug(replica): 0n: commit_start_journal: cached prepare op=172 checksum=37a085fc9cba3313a4ff95974e311753
2026-01-23 19:44:39.710Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.headers offset=40960 len=4096 unlocked
2026-01-23 19:44:39.710Z debug(journal): 1: write: view=1 slot=173 op=173 len=124928: 3f0abef5dbe7f2b8bb97f2d331c928a6 complete, marking clean
2026-01-23 19:44:39.710Z debug(replica): 1N: send_prepare_ok: op=173 checksum=3f0abef5dbe7f2b8bb97f2d331c928a6
2026-01-23 19:44:39.710Z debug(replica): 1N: sending prepare_ok to replica 1: PrepareOk{ .checksum=ab8b3e46dce929c58a9aaac80d9eb704, .checksum_body=49f174618255402de6e7e3c40d60cc83, .cluster=0, .size=256, .epoch=0, .view=1, .release=0.0.0, .protocol=0, .command=vsr.Command.prepare_ok, .replica=1, .parent=37a085fc9cba3313a4ff95974e311753, .prepare_checksum=3f0abef5dbe7f2b8bb97f2d331c928a6, .checkpoint_id=00000000000000000000000000000000, .client=60324011015611665437153036865704073740, .op=173, .commit_min=172, .timestamp=1769197479708967226, .request=171, .operation=vsr.Operation(141) }
2026-01-23 19:44:39.710Z debug(replica): 0n: repair_prepare: op=173 checksum=3f0abef5dbe7f2b8bb97f2d331c928a6 (already writing)
2026-01-23 19:44:39.710Z debug(replica): 1N: on_message: view=1 status=normal PrepareOk{ .checksum=ab8b3e46dce929c58a9aaac80d9eb704, .checksum_body=49f174618255402de6e7e3c40d60cc83, .cluster=0, .size=256, .epoch=0, .view=1, .release=0.0.0, .protocol=0, .command=vsr.Command.prepare_ok, .replica=1, .parent=37a085fc9cba3313a4ff95974e311753, .prepare_checksum=3f0abef5dbe7f2b8bb97f2d331c928a6, .checkpoint_id=00000000000000000000000000000000, .client=60324011015611665437153036865704073740, .op=173, .commit_min=172, .timestamp=1769197479708967226, .request=171, .operation=vsr.Operation(141) }
2026-01-23 19:44:39.710Z debug(vsr): 1: primary_abdicate_timeout reset
2026-01-23 19:44:39.710Z debug(replica): 1N: on_prepare_ok: 1 message(s)
2026-01-23 19:44:39.710Z debug(replica): 1N: on_prepare_ok: waiting for quorum
2026-01-23 19:44:39.710Z debug(replica): 0n: commit_journal: already committing (prefetch; commit_min=171)
2026-01-23 19:44:39.710Z debug(replica): 0n: execute_op: executing view=1 primary=false op=172 checksum=37a085fc9cba3313a4ff95974e311753 (lookup_accounts)
2026-01-23 19:44:39.710Z debug(replica): 0n: execute_op: commit_timestamp=1769197476928185257 prepare.header.timestamp=1769197476935955801
2026-01-23 19:44:39.710Z debug(replica): 0n: client_table_entry_update: client=60324011015611665437153036865704073740 session=2 request=170
2026-01-23 19:44:39.710Z debug(forest): entering forest.compact() op=172 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2026-01-23 19:44:39.711Z debug(client_replies): 0: write_reply: wrote (client=60324011015611665437153036865704073740 request=170)
2026-01-23 19:44:39.711Z debug(journal): 0: write_sectors: ring=vsr.journal.Ring.prepares offset=181403648 len=126976 unlocked
2026-01-23 19:44:39.711Z debug(journal): 0: write_header: op=173 sectors[40960..45056]
2026-01-23 19:44:39.711Z debug(journal): 0: write_sectors: ring=vsr.journal.Ring.headers offset=40960 len=4096 locked
2026-01-23 19:44:39.711Z debug(replica): 2n: on_message: view=1 status=normal Prepare{ .checksum=3f0abef5dbe7f2b8bb97f2d331c928a6, .checksum_body=3b573b2f7446de1d349310d14b9cd899, .cluster=0, .size=124928, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.prepare, .replica=1, .parent=37a085fc9cba3313a4ff95974e311753, .request_checksum=e88091f4d4fad513c8d32303e5539b1f, .checkpoint_id=00000000000000000000000000000000, .client=60324011015611665437153036865704073740, .op=173, .commit=172, .timestamp=1769197479708967226, .request=171, .operation=vsr.Operation(141) }
2026-01-23 19:44:39.711Z debug(journal): 0: write_sectors: ring=vsr.journal.Ring.headers offset=40960 len=4096 unlocked
2026-01-23 19:44:39.711Z debug(journal): 0: write: view=1 slot=173 op=173 len=124928: 3f0abef5dbe7f2b8bb97f2d331c928a6 complete, marking clean
2026-01-23 19:44:39.711Z debug(replica): 2n: on_prepare: advancing commit_max=171..172
2026-01-23 19:44:39.711Z debug(replica): 0n: send_prepare_ok: op=173 checksum=3f0abef5dbe7f2b8bb97f2d331c928a6
2026-01-23 19:44:39.711Z debug(replica): 2n: on_prepare: caching prepare.op=173 (commit_min=171 op=172 commit_max=172 prepare_max=1007)
2026-01-23 19:44:39.711Z debug(replica): 0n: sending prepare_ok to replica 1: PrepareOk{ .checksum=befa5b3eeb3074a5987dad0191036e3b, .checksum_body=49f174618255402de6e7e3c40d60cc83, .cluster=0, .size=256, .epoch=0, .view=1, .release=0.0.0, .protocol=0, .command=vsr.Command.prepare_ok, .replica=0, .parent=37a085fc9cba3313a4ff95974e311753, .prepare_checksum=3f0abef5dbe7f2b8bb97f2d331c928a6, .checkpoint_id=00000000000000000000000000000000, .client=60324011015611665437153036865704073740, .op=173, .commit_min=172, .timestamp=1769197479708967226, .request=171, .operation=vsr.Operation(141) }
2026-01-23 19:44:39.711Z debug(replica): 2n: on_prepare: advancing: op=172..173 checksum=37a085fc9cba3313a4ff95974e311753..3f0abef5dbe7f2b8bb97f2d331c928a6
2026-01-23 19:44:39.711Z debug(journal): 2: set_header_as_dirty: op=173 checksum=3f0abef5dbe7f2b8bb97f2d331c928a6
2026-01-23 19:44:39.711Z debug(replica): 2n: append: appending to journal op=173
2026-01-23 19:44:39.711Z debug(journal): 2: write: view=1 slot=173 op=173 len=124928: 3f0abef5dbe7f2b8bb97f2d331c928a6 starting
2026-01-23 19:44:39.711Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.prepares offset=181403648 len=126976 locked
2026-01-23 19:44:39.711Z debug(replica): 1N: on_message: view=1 status=normal PrepareOk{ .checksum=befa5b3eeb3074a5987dad0191036e3b, .checksum_body=49f174618255402de6e7e3c40d60cc83, .cluster=0, .size=256, .epoch=0, .view=1, .release=0.0.0, .protocol=0, .command=vsr.Command.prepare_ok, .replica=0, .parent=37a085fc9cba3313a4ff95974e311753, .prepare_checksum=3f0abef5dbe7f2b8bb97f2d331c928a6, .checkpoint_id=00000000000000000000000000000000, .client=60324011015611665437153036865704073740, .op=173, .commit_min=172, .timestamp=1769197479708967226, .request=171, .operation=vsr.Operation(141) }
2026-01-23 19:44:39.711Z debug(vsr): 1: primary_abdicate_timeout reset
2026-01-23 19:44:39.711Z debug(replica): 2n: commit_start_journal: cached prepare op=172 checksum=37a085fc9cba3313a4ff95974e311753
2026-01-23 19:44:39.711Z debug(replica): 1N: on_prepare_ok: 2 message(s)
2026-01-23 19:44:39.711Z debug(replica): 1N: on_prepare_ok: quorum received, prepare_checksum=3f0abef5dbe7f2b8bb97f2d331c928a6
2026-01-23 19:44:39.711Z debug(vsr): 1: prepare_timeout stopped
2026-01-23 19:44:39.711Z debug(vsr): 1: primary_abdicate_timeout stopped
2026-01-23 19:44:39.711Z debug(replica): 2n: repair_prepare: op=173 checksum=3f0abef5dbe7f2b8bb97f2d331c928a6 (already writing)
2026-01-23 19:44:39.711Z debug(replica): 2n: commit_journal: already committing (prefetch; commit_min=171)
2026-01-23 19:44:39.711Z debug(replica): 2n: execute_op: executing view=1 primary=false op=172 checksum=37a085fc9cba3313a4ff95974e311753 (lookup_accounts)
2026-01-23 19:44:39.711Z debug(replica): 2n: execute_op: commit_timestamp=1769197476928185257 prepare.header.timestamp=1769197476935955801
2026-01-23 19:44:39.711Z debug(replica): 2n: client_table_entry_update: client=60324011015611665437153036865704073740 session=2 request=170
2026-01-23 19:44:39.711Z debug(replica): 2n: execute_op: replying to client: Reply{ .checksum=d1bc15a108f20c4d77715c12410901ef, .checksum_body=f1245aa5d7337d3117358f9fb399cd0a, .cluster=0, .size=16768, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.reply, .replica=1, .request_checksum=8377cc3540470660d2b0148fab7184c5, .context=03773713f035760ca49dd706549a7dc9, .client=60324011015611665437153036865704073740, .op=172, .commit=172, .timestamp=1769197476935955801, .request=170, .operation=vsr.Operation(140) }
2026-01-23 19:44:39.711Z debug(replica): 2n: sending reply to client 60324011015611665437153036865704073740: Reply{ .checksum=d1bc15a108f20c4d77715c12410901ef, .checksum_body=f1245aa5d7337d3117358f9fb399cd0a, .cluster=0, .size=16768, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.reply, .replica=1, .request_checksum=8377cc3540470660d2b0148fab7184c5, .context=03773713f035760ca49dd706549a7dc9, .client=60324011015611665437153036865704073740, .op=172, .commit=172, .timestamp=1769197476935955801, .request=170, .operation=vsr.Operation(140) }
2026-01-23 19:44:39.711Z debug(forest): entering forest.compact() op=172 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2026-01-23 19:44:39.712Z debug(client_replies): 2: write_reply: wrote (client=60324011015611665437153036865704073740 request=170)
2026-01-23 19:44:39.712Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.prepares offset=181403648 len=126976 unlocked
2026-01-23 19:44:39.712Z debug(journal): 2: write_header: op=173 sectors[40960..45056]
2026-01-23 19:44:39.712Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.headers offset=40960 len=4096 locked
2026-01-23 19:44:39.712Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.headers offset=40960 len=4096 unlocked
2026-01-23 19:44:39.712Z debug(journal): 2: write: view=1 slot=173 op=173 len=124928: 3f0abef5dbe7f2b8bb97f2d331c928a6 complete, marking clean
2026-01-23 19:44:39.712Z debug(replica): 2n: send_prepare_ok: op=173 checksum=3f0abef5dbe7f2b8bb97f2d331c928a6
2026-01-23 19:44:39.712Z debug(replica): 2n: sending prepare_ok to replica 1: PrepareOk{ .checksum=68b157e8ba960792fa514c2fbd232169, .checksum_body=49f174618255402de6e7e3c40d60cc83, .cluster=0, .size=256, .epoch=0, .view=1, .release=0.0.0, .protocol=0, .command=vsr.Command.prepare_ok, .replica=2, .parent=37a085fc9cba3313a4ff95974e311753, .prepare_checksum=3f0abef5dbe7f2b8bb97f2d331c928a6, .checkpoint_id=00000000000000000000000000000000, .client=60324011015611665437153036865704073740, .op=173, .commit_min=172, .timestamp=1769197479708967226, .request=171, .operation=vsr.Operation(141) }
2026-01-23 19:44:39.713Z debug(replica): 1N: execute_op: executing view=1 primary=true op=173 checksum=3f0abef5dbe7f2b8bb97f2d331c928a6 (lookup_transfers)
2026-01-23 19:44:39.713Z debug(replica): 1N: execute_op: commit_timestamp=1769197476935955801 prepare.header.timestamp=1769197479708967226
2026-01-23 19:44:39.715Z debug(replica): 1N: execute_op: advancing commit_max=172..173
2026-01-23 19:44:39.717Z debug(vsr): 0: journal_repair_budget_timeout fired
2026-01-23 19:44:39.717Z debug(vsr): 0: journal_repair_budget_timeout reset
2026-01-23 19:44:39.720Z debug(replica): 1N: client_table_entry_update: client=60324011015611665437153036865704073740 session=2 request=171
2026-01-23 19:44:39.720Z debug(replica): 1N: execute_op: replying to client: Reply{ .checksum=e751e10955e81a8f14a642988827db1e, .checksum_body=0c197103e1c0423f1208ae785f4aa138, .cluster=0, .size=997632, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.reply, .replica=1, .request_checksum=e88091f4d4fad513c8d32303e5539b1f, .context=ccd90f6e9d2da4221c45b41c39233f0c, .client=60324011015611665437153036865704073740, .op=173, .commit=173, .timestamp=1769197479708967226, .request=171, .operation=vsr.Operation(141) }
2026-01-23 19:44:39.720Z debug(replica): 1N: sending reply to client 60324011015611665437153036865704073740: Reply{ .checksum=e751e10955e81a8f14a642988827db1e, .checksum_body=0c197103e1c0423f1208ae785f4aa138, .cluster=0, .size=997632, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.reply, .replica=1, .request_checksum=e88091f4d4fad513c8d32303e5539b1f, .context=ccd90f6e9d2da4221c45b41c39233f0c, .client=60324011015611665437153036865704073740, .op=173, .commit=173, .timestamp=1769197479708967226, .request=171, .operation=vsr.Operation(141) }
2026-01-23 19:44:39.720Z debug(forest): entering forest.compact() op=173 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2026-01-23 19:44:39.721Z debug(replica): 1N: on_message: view=1 status=normal PrepareOk{ .checksum=68b157e8ba960792fa514c2fbd232169, .checksum_body=49f174618255402de6e7e3c40d60cc83, .cluster=0, .size=256, .epoch=0, .view=1, .release=0.0.0, .protocol=0, .command=vsr.Command.prepare_ok, .replica=2, .parent=37a085fc9cba3313a4ff95974e311753, .prepare_checksum=3f0abef5dbe7f2b8bb97f2d331c928a6, .checkpoint_id=00000000000000000000000000000000, .client=60324011015611665437153036865704073740, .op=173, .commit_min=172, .timestamp=1769197479708967226, .request=171, .operation=vsr.Operation(141) }
2026-01-23 19:44:39.721Z debug(replica): 1N: on_prepare_ok: not preparing op=173 checksum=3f0abef5dbe7f2b8bb97f2d331c928a6
2026-01-23 19:44:39.721Z debug(vsr): 1: ping_timeout fired
2026-01-23 19:44:39.721Z debug(vsr): 1: ping_timeout reset
2026-01-23 19:44:39.721Z debug(replica): 1N: sending ping to replica 0: Ping{ .checksum=4c129c05534c6155343258a6a9f17065, .checksum_body=74730330cb75ecd4a42c51968e55e4bd, .cluster=0, .size=512, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.ping, .replica=1, .checkpoint_id=f222e9ce156b309eaeb4af665242ac18, .checkpoint_op=0, .ping_timestamp_monotonic=41313048495668090, .release_count=1, .route=18446744073692905728 }
2026-01-23 19:44:39.721Z debug(replica): 1N: sending ping to replica 2: Ping{ .checksum=4c129c05534c6155343258a6a9f17065, .checksum_body=74730330cb75ecd4a42c51968e55e4bd, .cluster=0, .size=512, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.ping, .replica=1, .checkpoint_id=f222e9ce156b309eaeb4af665242ac18, .checkpoint_op=0, .ping_timestamp_monotonic=41313048495668090, .release_count=1, .route=18446744073692905728 }
2026-01-23 19:44:39.721Z debug(vsr): 1: commit_message_timeout fired
2026-01-23 19:44:39.721Z debug(vsr): 1: commit_message_timeout reset
2026-01-23 19:44:39.721Z debug(replica): 0n: on_message: view=1 status=normal Ping{ .checksum=4c129c05534c6155343258a6a9f17065, .checksum_body=74730330cb75ecd4a42c51968e55e4bd, .cluster=0, .size=512, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.ping, .replica=1, .checkpoint_id=f222e9ce156b309eaeb4af665242ac18, .checkpoint_op=0, .ping_timestamp_monotonic=41313048495668090, .release_count=1, .route=18446744073692905728 }
2026-01-23 19:44:39.721Z debug(replica): 1N: sending commit to replica 0: Commit{ .checksum=bdc27b428465d866201ca365caa36d87, .checksum_body=49f174618255402de6e7e3c40d60cc83, .cluster=0, .size=256, .epoch=0, .view=1, .release=0.0.0, .protocol=0, .command=vsr.Command.commit, .replica=1, .commit_checksum=3f0abef5dbe7f2b8bb97f2d331c928a6, .checkpoint_id=f222e9ce156b309eaeb4af665242ac18, .checkpoint_op=0, .commit=173, .timestamp_monotonic=41313048495780360 }
2026-01-23 19:44:39.721Z debug(replica): 2n: on_message: view=1 status=normal Ping{ .checksum=4c129c05534c6155343258a6a9f17065, .checksum_body=74730330cb75ecd4a42c51968e55e4bd, .cluster=0, .size=512, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.ping, .replica=1, .checkpoint_id=f222e9ce156b309eaeb4af665242ac18, .checkpoint_op=0, .ping_timestamp_monotonic=41313048495668090, .release_count=1, .route=18446744073692905728 }
2026-01-23 19:44:39.721Z debug(replica): 0n: sending pong to replica 1: Pong{ .checksum=18a45ac26fee85b78df276998da1cd01, .checksum_body=49f174618255402de6e7e3c40d60cc83, .cluster=0, .size=256, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.pong, .replica=0, .ping_timestamp_monotonic=41313048495668090, .pong_timestamp_wall=1769197479721683948 }
2026-01-23 19:44:39.721Z debug(replica): 1N: sending commit to replica 2: Commit{ .checksum=bdc27b428465d866201ca365caa36d87, .checksum_body=49f174618255402de6e7e3c40d60cc83, .cluster=0, .size=256, .epoch=0, .view=1, .release=0.0.0, .protocol=0, .command=vsr.Command.commit, .replica=1, .commit_checksum=3f0abef5dbe7f2b8bb97f2d331c928a6, .checkpoint_id=f222e9ce156b309eaeb4af665242ac18, .checkpoint_op=0, .commit=173, .timestamp_monotonic=41313048495780360 }
2026-01-23 19:44:39.721Z debug(replica): 2n: sending pong to replica 1: Pong{ .checksum=e48b0a0771bdf797e87803f63e17a55f, .checksum_body=49f174618255402de6e7e3c40d60cc83, .cluster=0, .size=256, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.pong, .replica=2, .ping_timestamp_monotonic=41313048495668090, .pong_timestamp_wall=1769197479721690599 }
2026-01-23 19:44:39.721Z debug(vsr): 1: start_view_change_message_timeout fired
2026-01-23 19:44:39.721Z debug(vsr): 1: start_view_change_message_timeout reset
2026-01-23 19:44:39.721Z debug(vsr): 1: journal_repair_budget_timeout fired
2026-01-23 19:44:39.721Z debug(vsr): 1: journal_repair_budget_timeout reset
2026-01-23 19:44:39.721Z debug(vsr): 1: journal_repair_timeout fired
2026-01-23 19:44:39.721Z debug(vsr): 1: journal_repair_timeout reset
2026-01-23 19:44:39.721Z debug(replica): 2n: on_message: view=1 status=normal Commit{ .checksum=bdc27b428465d866201ca365caa36d87, .checksum_body=49f174618255402de6e7e3c40d60cc83, .cluster=0, .size=256, .epoch=0, .view=1, .release=0.0.0, .protocol=0, .command=vsr.Command.commit, .replica=1, .commit_checksum=3f0abef5dbe7f2b8bb97f2d331c928a6, .checkpoint_id=f222e9ce156b309eaeb4af665242ac18, .checkpoint_op=0, .commit=173, .timestamp_monotonic=41313048495780360 }
2026-01-23 19:44:39.721Z debug(replica): 0n: on_message: view=1 status=normal Commit{ .checksum=bdc27b428465d866201ca365caa36d87, .checksum_body=49f174618255402de6e7e3c40d60cc83, .cluster=0, .size=256, .epoch=0, .view=1, .release=0.0.0, .protocol=0, .command=vsr.Command.commit, .replica=1, .commit_checksum=3f0abef5dbe7f2b8bb97f2d331c928a6, .checkpoint_id=f222e9ce156b309eaeb4af665242ac18, .checkpoint_op=0, .commit=173, .timestamp_monotonic=41313048495780360 }
2026-01-23 19:44:39.721Z debug(vsr): 2: normal_heartbeat_timeout reset
2026-01-23 19:44:39.721Z debug(replica): 2n: on_commit: checksum verified
2026-01-23 19:44:39.721Z debug(vsr): 0: normal_heartbeat_timeout reset
2026-01-23 19:44:39.721Z debug(replica): 2n: on_commit: advancing commit_max=172..173
2026-01-23 19:44:39.721Z debug(replica): 0n: on_commit: checksum verified
2026-01-23 19:44:39.721Z debug(replica): 0n: on_commit: advancing commit_max=172..173
2026-01-23 19:44:39.721Z debug(replica): 2n: commit_start_journal: cached prepare op=173 checksum=3f0abef5dbe7f2b8bb97f2d331c928a6
2026-01-23 19:44:39.721Z debug(vsr): 1: grid_repair_budget_timeout fired
2026-01-23 19:44:39.721Z debug(vsr): 1: grid_repair_budget_timeout reset
2026-01-23 19:44:39.721Z debug(replica): 0n: commit_start_journal: cached prepare op=173 checksum=3f0abef5dbe7f2b8bb97f2d331c928a6
2026-01-23 19:44:39.721Z debug(replica): 1N: on_message: view=1 status=normal Pong{ .checksum=18a45ac26fee85b78df276998da1cd01, .checksum_body=49f174618255402de6e7e3c40d60cc83, .cluster=0, .size=256, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.pong, .replica=0, .ping_timestamp_monotonic=41313048495668090, .pong_timestamp_wall=1769197479721683948 }
2026-01-23 19:44:39.721Z debug(clock): 1: learn: replica=0 m0=41313048495668090 t1=1769197479721683948 m2=41313048496099478 t2=1769197479721960227 one_way_delay=215694 asymmetric_delay=0 clock_offset=-60585
2026-01-23 19:44:39.722Z debug(replica): 1N: on_message: view=1 status=normal Pong{ .checksum=e48b0a0771bdf797e87803f63e17a55f, .checksum_body=49f174618255402de6e7e3c40d60cc83, .cluster=0, .size=256, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.pong, .replica=2, .ping_timestamp_monotonic=41313048495668090, .pong_timestamp_wall=1769197479721690599 }
2026-01-23 19:44:39.722Z debug(clock): 1: learn: replica=2 m0=41313048495668090 t1=1769197479721690599 m2=41313048496164088 t2=1769197479722024837 one_way_delay=247999 asymmetric_delay=0 clock_offset=-86239
2026-01-23 19:44:39.722Z debug(client_replies): 1: write_reply: wrote (client=60324011015611665437153036865704073740 request=171)
2026-01-23 19:44:39.723Z debug(replica): 0n: execute_op: executing view=1 primary=false op=173 checksum=3f0abef5dbe7f2b8bb97f2d331c928a6 (lookup_transfers)
2026-01-23 19:44:39.724Z debug(replica): 0n: execute_op: commit_timestamp=1769197476935955801 prepare.header.timestamp=1769197479708967226
2026-01-23 19:44:39.724Z debug(replica): 2n: execute_op: executing view=1 primary=false op=173 checksum=3f0abef5dbe7f2b8bb97f2d331c928a6 (lookup_transfers)
2026-01-23 19:44:39.724Z debug(replica): 2n: execute_op: commit_timestamp=1769197476935955801 prepare.header.timestamp=1769197479708967226
2026-01-23 19:44:39.729Z debug(replica): 0n: client_table_entry_update: client=60324011015611665437153036865704073740 session=2 request=171
2026-01-23 19:44:39.729Z debug(replica): 0n: execute_op: replying to client: Reply{ .checksum=e751e10955e81a8f14a642988827db1e, .checksum_body=0c197103e1c0423f1208ae785f4aa138, .cluster=0, .size=997632, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.reply, .replica=1, .request_checksum=e88091f4d4fad513c8d32303e5539b1f, .context=ccd90f6e9d2da4221c45b41c39233f0c, .client=60324011015611665437153036865704073740, .op=173, .commit=173, .timestamp=1769197479708967226, .request=171, .operation=vsr.Operation(141) }
2026-01-23 19:44:39.729Z debug(replica): 0n: sending reply to client 60324011015611665437153036865704073740: Reply{ .checksum=e751e10955e81a8f14a642988827db1e, .checksum_body=0c197103e1c0423f1208ae785f4aa138, .cluster=0, .size=997632, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.reply, .replica=1, .request_checksum=e88091f4d4fad513c8d32303e5539b1f, .context=ccd90f6e9d2da4221c45b41c39233f0c, .client=60324011015611665437153036865704073740, .op=173, .commit=173, .timestamp=1769197479708967226, .request=171, .operation=vsr.Operation(141) }
2026-01-23 19:44:39.730Z debug(forest): entering forest.compact() op=173 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2026-01-23 19:44:39.730Z debug(replica): 2n: client_table_entry_update: client=60324011015611665437153036865704073740 session=2 request=171
2026-01-23 19:44:39.730Z debug(forest): entering forest.compact() op=173 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2026-01-23 19:44:39.730Z debug(vsr): 2: journal_repair_budget_timeout fired
2026-01-23 19:44:39.730Z debug(vsr): 2: journal_repair_budget_timeout reset
2026-01-23 19:44:39.731Z debug(client_replies): 0: write_reply: wrote (client=60324011015611665437153036865704073740 request=171)
2026-01-23 19:44:39.731Z debug(clock): 1: synchronized: truechimers=3/3 clock_offset=0ns..0ns accuracy=0ns
2026-01-23 19:44:39.731Z debug(clock): 1: system time is 240ns behind
2026-01-23 19:44:39.732Z debug(client_replies): 2: write_reply: wrote (client=60324011015611665437153036865704073740 request=171)
2026-01-23 19:44:39.740Z debug(replica): 1N: on_message: view=1 status=normal Request{ .checksum=1e245f2faef9fe37c038e436973913d2, .checksum_body=05818375add20fa5892afe2394de4b74, .cluster=0, .size=2320, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.request, .replica=0, .parent=ccd90f6e9d2da4221c45b41c39233f0c, .client=60324011015611665437153036865704073740, .session=2, .timestamp=0, .request=172, .operation=vsr.Operation(140), .previous_request_latency=22843380 }
2026-01-23 19:44:39.740Z debug(replica): 2n: on_message: view=1 status=normal Request{ .checksum=1e245f2faef9fe37c038e436973913d2, .checksum_body=05818375add20fa5892afe2394de4b74, .cluster=0, .size=2320, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.request, .replica=0, .parent=ccd90f6e9d2da4221c45b41c39233f0c, .client=60324011015611665437153036865704073740, .session=2, .timestamp=0, .request=172, .operation=vsr.Operation(140), .previous_request_latency=22843380 }
2026-01-23 19:44:39.740Z debug(replica): 2n: on_request: forwarding new request to primary (view=1)
2026-01-23 19:44:39.740Z debug(replica): 1N: on_request: new request
2026-01-23 19:44:39.740Z debug(replica): 2n: sending request to replica 1: Request{ .checksum=1e245f2faef9fe37c038e436973913d2, .checksum_body=05818375add20fa5892afe2394de4b74, .cluster=0, .size=2320, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.request, .replica=0, .parent=ccd90f6e9d2da4221c45b41c39233f0c, .client=60324011015611665437153036865704073740, .session=2, .timestamp=0, .request=172, .operation=vsr.Operation(140), .previous_request_latency=22843380 }
2026-01-23 19:44:39.740Z debug(replica): 1N: primary_pipeline_prepare: request checksum=1e245f2faef9fe37c038e436973913d2 client=60324011015611665437153036865704073740
2026-01-23 19:44:39.740Z debug(replica): 1N: primary_pipeline_prepare: prepare checksum=903c6a7c5e7fe946f3a01fe4526f0248 op=174
2026-01-23 19:44:39.740Z debug(vsr): 1: prepare_timeout started
2026-01-23 19:44:39.740Z debug(vsr): 1: primary_abdicate_timeout started
2026-01-23 19:44:39.740Z debug(vsr): 1: pulse_timeout reset
2026-01-23 19:44:39.740Z debug(replica): 1N: replicate: replicating op=174 to replica 0
2026-01-23 19:44:39.740Z debug(replica): 1N: sending prepare to replica 0: Prepare{ .checksum=903c6a7c5e7fe946f3a01fe4526f0248, .checksum_body=05818375add20fa5892afe2394de4b74, .cluster=0, .size=2320, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.prepare, .replica=1, .parent=3f0abef5dbe7f2b8bb97f2d331c928a6, .request_checksum=1e245f2faef9fe37c038e436973913d2, .checkpoint_id=00000000000000000000000000000000, .client=60324011015611665437153036865704073740, .op=174, .commit=173, .timestamp=1769197479740509710, .request=172, .operation=vsr.Operation(140) }
2026-01-23 19:44:39.740Z debug(replica): 1N: replicate: replicating op=174 to replica 2
2026-01-23 19:44:39.740Z debug(replica): 1N: sending prepare to replica 2: Prepare{ .checksum=903c6a7c5e7fe946f3a01fe4526f0248, .checksum_body=05818375add20fa5892afe2394de4b74, .cluster=0, .size=2320, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.prepare, .replica=1, .parent=3f0abef5dbe7f2b8bb97f2d331c928a6, .request_checksum=1e245f2faef9fe37c038e436973913d2, .checkpoint_id=00000000000000000000000000000000, .client=60324011015611665437153036865704073740, .op=174, .commit=173, .timestamp=1769197479740509710, .request=172, .operation=vsr.Operation(140) }
2026-01-23 19:44:39.740Z debug(replica): 1N: on_prepare: advancing: op=173..174 checksum=3f0abef5dbe7f2b8bb97f2d331c928a6..903c6a7c5e7fe946f3a01fe4526f0248
2026-01-23 19:44:39.740Z debug(journal): 1: set_header_as_dirty: op=174 checksum=903c6a7c5e7fe946f3a01fe4526f0248
2026-01-23 19:44:39.740Z debug(replica): 1N: append: appending to journal op=174
2026-01-23 19:44:39.740Z debug(journal): 1: write: view=1 slot=174 op=174 len=2320: 903c6a7c5e7fe946f3a01fe4526f0248 starting
2026-01-23 19:44:39.740Z debug(replica): 2n: on_message: view=1 status=normal Prepare{ .checksum=903c6a7c5e7fe946f3a01fe4526f0248, .checksum_body=05818375add20fa5892afe2394de4b74, .cluster=0, .size=2320, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.prepare, .replica=1, .parent=3f0abef5dbe7f2b8bb97f2d331c928a6, .request_checksum=1e245f2faef9fe37c038e436973913d2, .checkpoint_id=00000000000000000000000000000000, .client=60324011015611665437153036865704073740, .op=174, .commit=173, .timestamp=1769197479740509710, .request=172, .operation=vsr.Operation(140) }
2026-01-23 19:44:39.740Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.prepares offset=182452224 len=4096 locked
2026-01-23 19:44:39.740Z debug(replica): 2n: on_prepare: caching prepare.op=174 (commit_min=173 op=173 commit_max=173 prepare_max=1007)
2026-01-23 19:44:39.740Z debug(vsr): 0: journal_repair_budget_timeout fired
2026-01-23 19:44:39.740Z debug(replica): 2n: on_prepare: advancing: op=173..174 checksum=3f0abef5dbe7f2b8bb97f2d331c928a6..903c6a7c5e7fe946f3a01fe4526f0248
2026-01-23 19:44:39.740Z debug(vsr): 0: journal_repair_budget_timeout reset
2026-01-23 19:44:39.740Z debug(journal): 2: set_header_as_dirty: op=174 checksum=903c6a7c5e7fe946f3a01fe4526f0248
2026-01-23 19:44:39.740Z debug(replica): 2n: append: appending to journal op=174
2026-01-23 19:44:39.740Z debug(journal): 2: write: view=1 slot=174 op=174 len=2320: 903c6a7c5e7fe946f3a01fe4526f0248 starting
2026-01-23 19:44:39.740Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.prepares offset=182452224 len=4096 locked
2026-01-23 19:44:39.740Z debug(replica): 1N: on_message: view=1 status=normal Request{ .checksum=1e245f2faef9fe37c038e436973913d2, .checksum_body=05818375add20fa5892afe2394de4b74, .cluster=0, .size=2320, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.request, .replica=0, .parent=ccd90f6e9d2da4221c45b41c39233f0c, .client=60324011015611665437153036865704073740, .session=2, .timestamp=0, .request=172, .operation=vsr.Operation(140), .previous_request_latency=22843380 }
2026-01-23 19:44:39.740Z debug(replica): 1N: on_request: new request
2026-01-23 19:44:39.740Z debug(replica): 1N: on_request: ignoring (already preparing)
2026-01-23 19:44:39.740Z debug(replica): 2n: repair_prepare: op=174 checksum=903c6a7c5e7fe946f3a01fe4526f0248 (already writing)
2026-01-23 19:44:39.740Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.prepares offset=182452224 len=4096 unlocked
2026-01-23 19:44:39.740Z debug(journal): 1: write_header: op=174 sectors[40960..45056]
2026-01-23 19:44:39.740Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.headers offset=40960 len=4096 locked
2026-01-23 19:44:39.740Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.headers offset=40960 len=4096 unlocked
2026-01-23 19:44:39.741Z debug(journal): 1: write: view=1 slot=174 op=174 len=2320: 903c6a7c5e7fe946f3a01fe4526f0248 complete, marking clean
2026-01-23 19:44:39.741Z debug(replica): 1N: send_prepare_ok: op=174 checksum=903c6a7c5e7fe946f3a01fe4526f0248
2026-01-23 19:44:39.741Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.prepares offset=182452224 len=4096 unlocked
2026-01-23 19:44:39.741Z debug(journal): 2: write_header: op=174 sectors[40960..45056]
2026-01-23 19:44:39.741Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.headers offset=40960 len=4096 locked
2026-01-23 19:44:39.741Z debug(replica): 1N: sending prepare_ok to replica 1: PrepareOk{ .checksum=dfbac629fc24fb9005cc7d8937c3ce3f, .checksum_body=49f174618255402de6e7e3c40d60cc83, .cluster=0, .size=256, .epoch=0, .view=1, .release=0.0.0, .protocol=0, .command=vsr.Command.prepare_ok, .replica=1, .parent=3f0abef5dbe7f2b8bb97f2d331c928a6, .prepare_checksum=903c6a7c5e7fe946f3a01fe4526f0248, .checkpoint_id=00000000000000000000000000000000, .client=60324011015611665437153036865704073740, .op=174, .commit_min=173, .timestamp=1769197479740509710, .request=172, .operation=vsr.Operation(140) }
2026-01-23 19:44:39.741Z debug(replica): 1N: on_message: view=1 status=normal PrepareOk{ .checksum=dfbac629fc24fb9005cc7d8937c3ce3f, .checksum_body=49f174618255402de6e7e3c40d60cc83, .cluster=0, .size=256, .epoch=0, .view=1, .release=0.0.0, .protocol=0, .command=vsr.Command.prepare_ok, .replica=1, .parent=3f0abef5dbe7f2b8bb97f2d331c928a6, .prepare_checksum=903c6a7c5e7fe946f3a01fe4526f0248, .checkpoint_id=00000000000000000000000000000000, .client=60324011015611665437153036865704073740, .op=174, .commit_min=173, .timestamp=1769197479740509710, .request=172, .operation=vsr.Operation(140) }
2026-01-23 19:44:39.741Z debug(vsr): 1: primary_abdicate_timeout reset
2026-01-23 19:44:39.741Z debug(replica): 1N: on_prepare_ok: 1 message(s)
2026-01-23 19:44:39.741Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.headers offset=40960 len=4096 unlocked
2026-01-23 19:44:39.741Z debug(replica): 1N: on_prepare_ok: waiting for quorum
2026-01-23 19:44:39.741Z debug(journal): 2: write: view=1 slot=174 op=174 len=2320: 903c6a7c5e7fe946f3a01fe4526f0248 complete, marking clean
2026-01-23 19:44:39.741Z debug(replica): 2n: send_prepare_ok: op=174 checksum=903c6a7c5e7fe946f3a01fe4526f0248
2026-01-23 19:44:39.741Z debug(replica): 2n: sending prepare_ok to replica 1: PrepareOk{ .checksum=2ec097093267b1248b3abd4f8a316f5d, .checksum_body=49f174618255402de6e7e3c40d60cc83, .cluster=0, .size=256, .epoch=0, .view=1, .release=0.0.0, .protocol=0, .command=vsr.Command.prepare_ok, .replica=2, .parent=3f0abef5dbe7f2b8bb97f2d331c928a6, .prepare_checksum=903c6a7c5e7fe946f3a01fe4526f0248, .checkpoint_id=00000000000000000000000000000000, .client=60324011015611665437153036865704073740, .op=174, .commit_min=173, .timestamp=1769197479740509710, .request=172, .operation=vsr.Operation(140) }
2026-01-23 19:44:39.742Z debug(vsr): 1: journal_repair_budget_timeout fired
2026-01-23 19:44:39.742Z debug(vsr): 1: journal_repair_budget_timeout reset
2026-01-23 19:44:39.750Z debug(vsr): 2: journal_repair_budget_timeout fired
2026-01-23 19:44:39.751Z debug(vsr): 2: journal_repair_budget_timeout reset
2026-01-23 19:44:39.760Z debug(vsr): 0: journal_repair_budget_timeout fired
2026-01-23 19:44:39.760Z debug(vsr): 0: journal_repair_budget_timeout reset
2026-01-23 19:44:39.761Z debug(replica): 0n: on_message: view=1 status=normal Prepare{ .checksum=903c6a7c5e7fe946f3a01fe4526f0248, .checksum_body=05818375add20fa5892afe2394de4b74, .cluster=0, .size=2320, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.prepare, .replica=1, .parent=3f0abef5dbe7f2b8bb97f2d331c928a6, .request_checksum=1e245f2faef9fe37c038e436973913d2, .checkpoint_id=00000000000000000000000000000000, .client=60324011015611665437153036865704073740, .op=174, .commit=173, .timestamp=1769197479740509710, .request=172, .operation=vsr.Operation(140) }
2026-01-23 19:44:39.762Z debug(replica): 0n: on_prepare: caching prepare.op=174 (commit_min=173 op=173 commit_max=173 prepare_max=1007)
2026-01-23 19:44:39.762Z debug(replica): 0n: on_prepare: advancing: op=173..174 checksum=3f0abef5dbe7f2b8bb97f2d331c928a6..903c6a7c5e7fe946f3a01fe4526f0248
2026-01-23 19:44:39.762Z debug(journal): 0: set_header_as_dirty: op=174 checksum=903c6a7c5e7fe946f3a01fe4526f0248
2026-01-23 19:44:39.762Z debug(replica): 0n: append: appending to journal op=174
2026-01-23 19:44:39.762Z debug(journal): 0: write: view=1 slot=174 op=174 len=2320: 903c6a7c5e7fe946f3a01fe4526f0248 starting
2026-01-23 19:44:39.762Z debug(journal): 0: write_sectors: ring=vsr.journal.Ring.prepares offset=182452224 len=4096 locked
2026-01-23 19:44:39.762Z debug(vsr): 1: journal_repair_budget_timeout fired
2026-01-23 19:44:39.762Z debug(vsr): 1: journal_repair_budget_timeout reset
2026-01-23 19:44:39.762Z debug(replica): 0n: repair_prepare: op=174 checksum=903c6a7c5e7fe946f3a01fe4526f0248 (already writing)
2026-01-23 19:44:39.762Z debug(journal): 0: write_sectors: ring=vsr.journal.Ring.prepares offset=182452224 len=4096 unlocked
2026-01-23 19:44:39.762Z debug(journal): 0: write_header: op=174 sectors[40960..45056]
2026-01-23 19:44:39.762Z debug(journal): 0: write_sectors: ring=vsr.journal.Ring.headers offset=40960 len=4096 locked
2026-01-23 19:44:39.762Z debug(journal): 0: write_sectors: ring=vsr.journal.Ring.headers offset=40960 len=4096 unlocked
2026-01-23 19:44:39.762Z debug(journal): 0: write: view=1 slot=174 op=174 len=2320: 903c6a7c5e7fe946f3a01fe4526f0248 complete, marking clean
2026-01-23 19:44:39.762Z debug(replica): 0n: send_prepare_ok: op=174 checksum=903c6a7c5e7fe946f3a01fe4526f0248
2026-01-23 19:44:39.762Z debug(replica): 0n: sending prepare_ok to replica 1: PrepareOk{ .checksum=97539db3593c1ff3ffda7e5b519944ed, .checksum_body=49f174618255402de6e7e3c40d60cc83, .cluster=0, .size=256, .epoch=0, .view=1, .release=0.0.0, .protocol=0, .command=vsr.Command.prepare_ok, .replica=0, .parent=3f0abef5dbe7f2b8bb97f2d331c928a6, .prepare_checksum=903c6a7c5e7fe946f3a01fe4526f0248, .checkpoint_id=00000000000000000000000000000000, .client=60324011015611665437153036865704073740, .op=174, .commit_min=173, .timestamp=1769197479740509710, .request=172, .operation=vsr.Operation(140) }
2026-01-23 19:44:39.762Z debug(replica): 1N: on_message: view=1 status=normal PrepareOk{ .checksum=97539db3593c1ff3ffda7e5b519944ed, .checksum_body=49f174618255402de6e7e3c40d60cc83, .cluster=0, .size=256, .epoch=0, .view=1, .release=0.0.0, .protocol=0, .command=vsr.Command.prepare_ok, .replica=0, .parent=3f0abef5dbe7f2b8bb97f2d331c928a6, .prepare_checksum=903c6a7c5e7fe946f3a01fe4526f0248, .checkpoint_id=00000000000000000000000000000000, .client=60324011015611665437153036865704073740, .op=174, .commit_min=173, .timestamp=1769197479740509710, .request=172, .operation=vsr.Operation(140) }
2026-01-23 19:44:39.762Z debug(vsr): 1: primary_abdicate_timeout reset
2026-01-23 19:44:39.762Z debug(replica): 1N: on_prepare_ok: 2 message(s)
2026-01-23 19:44:39.762Z debug(replica): 1N: on_prepare_ok: quorum received, prepare_checksum=903c6a7c5e7fe946f3a01fe4526f0248
2026-01-23 19:44:39.762Z debug(vsr): 1: prepare_timeout stopped
2026-01-23 19:44:39.762Z debug(vsr): 1: primary_abdicate_timeout stopped
2026-01-23 19:44:39.763Z debug(replica): 1N: execute_op: executing view=1 primary=true op=174 checksum=903c6a7c5e7fe946f3a01fe4526f0248 (lookup_accounts)
2026-01-23 19:44:39.763Z debug(replica): 1N: execute_op: commit_timestamp=1769197479708967226 prepare.header.timestamp=1769197479740509710
2026-01-23 19:44:39.763Z debug(replica): 1N: execute_op: advancing commit_max=173..174
2026-01-23 19:44:39.763Z debug(replica): 1N: client_table_entry_update: client=60324011015611665437153036865704073740 session=2 request=172
2026-01-23 19:44:39.763Z debug(replica): 1N: execute_op: replying to client: Reply{ .checksum=0f5aab791c652ef4ff9d3f2b202420a0, .checksum_body=f1245aa5d7337d3117358f9fb399cd0a, .cluster=0, .size=16768, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.reply, .replica=1, .request_checksum=1e245f2faef9fe37c038e436973913d2, .context=bb49da210e88efa3759762a30a2a0057, .client=60324011015611665437153036865704073740, .op=174, .commit=174, .timestamp=1769197479740509710, .request=172, .operation=vsr.Operation(140) }
2026-01-23 19:44:39.763Z debug(replica): 1N: sending reply to client 60324011015611665437153036865704073740: Reply{ .checksum=0f5aab791c652ef4ff9d3f2b202420a0, .checksum_body=f1245aa5d7337d3117358f9fb399cd0a, .cluster=0, .size=16768, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.reply, .replica=1, .request_checksum=1e245f2faef9fe37c038e436973913d2, .context=bb49da210e88efa3759762a30a2a0057, .client=60324011015611665437153036865704073740, .op=174, .commit=174, .timestamp=1769197479740509710, .request=172, .operation=vsr.Operation(140) }
2026-01-23 19:44:39.763Z debug(forest): entering forest.compact() op=174 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2026-01-23 19:44:39.763Z info(workload): accounts created = 128, transfers = 197537, pending transfers = 0, commands run = 86
2026-01-23 19:44:39.764Z debug(client_replies): 1: write_reply: wrote (client=60324011015611665437153036865704073740 request=172)
2026-01-23 19:44:39.771Z debug(vsr): 2: journal_repair_budget_timeout fired
2026-01-23 19:44:39.771Z debug(vsr): 2: journal_repair_budget_timeout reset
2026-01-23 19:44:39.780Z debug(replica): 1N: on_message: view=1 status=normal Request{ .checksum=d40536dfa21dc1f3be1f116ac61430a0, .checksum_body=44510b889687a9b53ed375ba4f7c758e, .cluster=0, .size=1015168, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.request, .replica=0, .parent=bb49da210e88efa3759762a30a2a0057, .client=60324011015611665437153036865704073740, .session=2, .timestamp=0, .request=173, .operation=vsr.Operation(139), .previous_request_latency=23517186 }
2026-01-23 19:44:39.780Z debug(replica): 1N: on_request: new request
2026-01-23 19:44:39.780Z debug(replica): 1N: primary_pipeline_prepare: request checksum=d40536dfa21dc1f3be1f116ac61430a0 client=60324011015611665437153036865704073740
2026-01-23 19:44:39.780Z debug(replica): 0n: on_message: view=1 status=normal Request{ .checksum=d40536dfa21dc1f3be1f116ac61430a0, .checksum_body=44510b889687a9b53ed375ba4f7c758e, .cluster=0, .size=1015168, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.request, .replica=0, .parent=bb49da210e88efa3759762a30a2a0057, .client=60324011015611665437153036865704073740, .session=2, .timestamp=0, .request=173, .operation=vsr.Operation(139), .previous_request_latency=23517186 }
2026-01-23 19:44:39.780Z debug(replica): 0n: on_request: forwarding new request to primary (view=1)
2026-01-23 19:44:39.780Z debug(replica): 0n: sending request to replica 1: Request{ .checksum=d40536dfa21dc1f3be1f116ac61430a0, .checksum_body=44510b889687a9b53ed375ba4f7c758e, .cluster=0, .size=1015168, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.request, .replica=0, .parent=bb49da210e88efa3759762a30a2a0057, .client=60324011015611665437153036865704073740, .session=2, .timestamp=0, .request=173, .operation=vsr.Operation(139), .previous_request_latency=23517186 }
2026-01-23 19:44:39.781Z debug(vsr): 0: journal_repair_budget_timeout fired
2026-01-23 19:44:39.781Z debug(vsr): 0: journal_repair_budget_timeout reset
2026-01-23 19:44:39.784Z debug(replica): 1N: primary_pipeline_prepare: prepare checksum=8021b09f3efb26cd35f32257145057d1 op=175
2026-01-23 19:44:39.784Z debug(vsr): 1: prepare_timeout started
2026-01-23 19:44:39.784Z debug(vsr): 1: primary_abdicate_timeout started
2026-01-23 19:44:39.784Z debug(vsr): 1: pulse_timeout reset
2026-01-23 19:44:39.784Z debug(replica): 1N: replicate: replicating op=175 to replica 0
2026-01-23 19:44:39.784Z debug(replica): 1N: sending prepare to replica 0: Prepare{ .checksum=8021b09f3efb26cd35f32257145057d1, .checksum_body=44510b889687a9b53ed375ba4f7c758e, .cluster=0, .size=1015168, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.prepare, .replica=1, .parent=903c6a7c5e7fe946f3a01fe4526f0248, .request_checksum=d40536dfa21dc1f3be1f116ac61430a0, .checkpoint_id=00000000000000000000000000000000, .client=60324011015611665437153036865704073740, .op=175, .commit=174, .timestamp=1769197479780158100, .request=173, .operation=vsr.Operation(139) }
2026-01-23 19:44:39.784Z debug(replica): 1N: replicate: replicating op=175 to replica 2
2026-01-23 19:44:39.784Z debug(replica): 1N: sending prepare to replica 2: Prepare{ .checksum=8021b09f3efb26cd35f32257145057d1, .checksum_body=44510b889687a9b53ed375ba4f7c758e, .cluster=0, .size=1015168, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.prepare, .replica=1, .parent=903c6a7c5e7fe946f3a01fe4526f0248, .request_checksum=d40536dfa21dc1f3be1f116ac61430a0, .checkpoint_id=00000000000000000000000000000000, .client=60324011015611665437153036865704073740, .op=175, .commit=174, .timestamp=1769197479780158100, .request=173, .operation=vsr.Operation(139) }
2026-01-23 19:44:39.785Z debug(replica): 1N: on_prepare: advancing: op=174..175 checksum=903c6a7c5e7fe946f3a01fe4526f0248..8021b09f3efb26cd35f32257145057d1
2026-01-23 19:44:39.785Z debug(journal): 1: set_header_as_dirty: op=175 checksum=8021b09f3efb26cd35f32257145057d1
2026-01-23 19:44:39.785Z debug(replica): 1N: append: appending to journal op=175
2026-01-23 19:44:39.785Z debug(journal): 1: write: view=1 slot=175 op=175 len=1015168: 8021b09f3efb26cd35f32257145057d1 starting
2026-01-23 19:44:39.785Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.prepares offset=183500800 len=1015808 locked
2026-01-23 19:44:39.785Z debug(replica): 1N: on_message: view=1 status=normal PrepareOk{ .checksum=2ec097093267b1248b3abd4f8a316f5d, .checksum_body=49f174618255402de6e7e3c40d60cc83, .cluster=0, .size=256, .epoch=0, .view=1, .release=0.0.0, .protocol=0, .command=vsr.Command.prepare_ok, .replica=2, .parent=3f0abef5dbe7f2b8bb97f2d331c928a6, .prepare_checksum=903c6a7c5e7fe946f3a01fe4526f0248, .checkpoint_id=00000000000000000000000000000000, .client=60324011015611665437153036865704073740, .op=174, .commit_min=173, .timestamp=1769197479740509710, .request=172, .operation=vsr.Operation(140) }
2026-01-23 19:44:39.786Z debug(replica): 1N: on_prepare_ok: not preparing op=174 checksum=903c6a7c5e7fe946f3a01fe4526f0248
2026-01-23 19:44:39.790Z debug(replica): 2n: on_message: view=1 status=normal Prepare{ .checksum=8021b09f3efb26cd35f32257145057d1, .checksum_body=44510b889687a9b53ed375ba4f7c758e, .cluster=0, .size=1015168, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.prepare, .replica=1, .parent=903c6a7c5e7fe946f3a01fe4526f0248, .request_checksum=d40536dfa21dc1f3be1f116ac61430a0, .checkpoint_id=00000000000000000000000000000000, .client=60324011015611665437153036865704073740, .op=175, .commit=174, .timestamp=1769197479780158100, .request=173, .operation=vsr.Operation(139) }
2026-01-23 19:44:39.790Z debug(replica): 2n: on_prepare: advancing commit_max=173..174
2026-01-23 19:44:39.790Z debug(replica): 2n: on_prepare: caching prepare.op=175 (commit_min=173 op=174 commit_max=174 prepare_max=1007)
2026-01-23 19:44:39.790Z debug(replica): 2n: on_prepare: advancing: op=174..175 checksum=903c6a7c5e7fe946f3a01fe4526f0248..8021b09f3efb26cd35f32257145057d1
2026-01-23 19:44:39.790Z debug(journal): 2: set_header_as_dirty: op=175 checksum=8021b09f3efb26cd35f32257145057d1
2026-01-23 19:44:39.790Z debug(replica): 1N: on_message: view=1 status=normal Request{ .checksum=d40536dfa21dc1f3be1f116ac61430a0, .checksum_body=44510b889687a9b53ed375ba4f7c758e, .cluster=0, .size=1015168, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.request, .replica=0, .parent=bb49da210e88efa3759762a30a2a0057, .client=60324011015611665437153036865704073740, .session=2, .timestamp=0, .request=173, .operation=vsr.Operation(139), .previous_request_latency=23517186 }
2026-01-23 19:44:39.790Z debug(replica): 2n: append: appending to journal op=175
2026-01-23 19:44:39.790Z debug(replica): 0n: on_message: view=1 status=normal Prepare{ .checksum=8021b09f3efb26cd35f32257145057d1, .checksum_body=44510b889687a9b53ed375ba4f7c758e, .cluster=0, .size=1015168, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.prepare, .replica=1, .parent=903c6a7c5e7fe946f3a01fe4526f0248, .request_checksum=d40536dfa21dc1f3be1f116ac61430a0, .checkpoint_id=00000000000000000000000000000000, .client=60324011015611665437153036865704073740, .op=175, .commit=174, .timestamp=1769197479780158100, .request=173, .operation=vsr.Operation(139) }
2026-01-23 19:48:33.925Z debug(journal): 2: write: view=1 slot=175 op=175 len=1015168: 8021b09f3efb26cd35f32257145057d1 starting
2026-01-23 19:48:33.925Z debug(replica): 1N: on_request: new request
2026-01-23 19:48:33.925Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.prepares offset=183500800 len=1015808 locked
warning(message_bus): 60324011015611665437153036865704073740: on_recv: from=vsr.Peer{ .replica = 1 } error.ConnectionTimedOut
2026-01-23 19:48:33.925Z debug(replica): 0n: on_prepare: advancing commit_max=173..174
2026-01-23 19:48:33.925Z debug(replica): 1N: on_request: ignoring (already preparing)
2026-01-23 19:48:33.925Z debug(replica): 2n: commit_start_journal: cached prepare op=174 checksum=903c6a7c5e7fe946f3a01fe4526f0248
2026-01-23 19:48:33.925Z debug(replica): 0n: on_prepare: caching prepare.op=175 (commit_min=173 op=174 commit_max=174 prepare_max=1007)
2026-01-23 19:48:03.008Z info(supervisor): 2: terminating replica
2026-01-23 19:48:33.925Z debug(replica): 0n: on_prepare: advancing: op=174..175 checksum=903c6a7c5e7fe946f3a01fe4526f0248..8021b09f3efb26cd35f32257145057d1
2026-01-23 19:48:33.925Z debug(journal): 0: set_header_as_dirty: op=175 checksum=8021b09f3efb26cd35f32257145057d1
2026-01-23 19:48:33.925Z debug(replica): 0n: append: appending to journal op=175
2026-01-23 19:48:33.925Z debug(journal): 0: write: view=1 slot=175 op=175 len=1015168: 8021b09f3efb26cd35f32257145057d1 starting
2026-01-23 19:48:33.925Z debug(journal): 0: write_sectors: ring=vsr.journal.Ring.prepares offset=183500800 len=1015808 locked
2026-01-23 19:48:33.925Z debug(replica): 0n: commit_start_journal: cached prepare op=174 checksum=903c6a7c5e7fe946f3a01fe4526f0248
2026-01-23 19:48:33.925Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.prepares offset=183500800 len=1015808 unlocked
2026-01-23 19:48:33.925Z debug(journal): 1: write_header: op=175 sectors[40960..45056]
2026-01-23 19:48:33.925Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.headers offset=40960 len=4096 locked
2026-01-23 19:48:33.925Z warning(clock): 1: synchronization failed, partitioned (sources=1 samples=1)
2026-01-23 19:48:33.925Z error(clock): 1: no agreement on cluster time (partitioned or too many clock faults)
2026-01-23 19:48:33.925Z debug(vsr): 1: journal_repair_budget_timeout fired
2026-01-23 19:48:33.925Z debug(vsr): 1: journal_repair_budget_timeout reset
2026-01-23 19:48:33.926Z debug(replica): 0n: repair_prepare: op=175 checksum=8021b09f3efb26cd35f32257145057d1 (already writing)
2026-01-23 19:48:33.926Z debug(replica): 0n: commit_journal: already committing (prefetch; commit_min=173)
2026-01-23 19:48:33.926Z debug(replica): 0n: execute_op: executing view=1 primary=false op=174 checksum=903c6a7c5e7fe946f3a01fe4526f0248 (lookup_accounts)
2026-01-23 19:48:33.926Z debug(replica): 0n: execute_op: commit_timestamp=1769197479708967226 prepare.header.timestamp=1769197479740509710
2026-01-23 19:48:33.926Z debug(replica): 0n: client_table_entry_update: client=60324011015611665437153036865704073740 session=2 request=172
2026-01-23 19:48:33.926Z debug(forest): entering forest.compact() op=174 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2026-01-23 19:48:33.926Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.headers offset=40960 len=4096 unlocked
2026-01-23 19:48:33.926Z debug(journal): 1: write: view=1 slot=175 op=175 len=1015168: 8021b09f3efb26cd35f32257145057d1 complete, marking clean
2026-01-23 19:48:33.926Z debug(replica): 1N: send_prepare_ok: op=175 checksum=8021b09f3efb26cd35f32257145057d1
2026-01-23 19:48:33.926Z debug(replica): 1N: sending prepare_ok to replica 1: PrepareOk{ .checksum=ab3c63457ffa4ac78cac55908bd29d92, .checksum_body=49f174618255402de6e7e3c40d60cc83, .cluster=0, .size=256, .epoch=0, .view=1, .release=0.0.0, .protocol=0, .command=vsr.Command.prepare_ok, .replica=1, .parent=903c6a7c5e7fe946f3a01fe4526f0248, .prepare_checksum=8021b09f3efb26cd35f32257145057d1, .checkpoint_id=00000000000000000000000000000000, .client=60324011015611665437153036865704073740, .op=175, .commit_min=174, .timestamp=1769197479780158100, .request=173, .operation=vsr.Operation(139) }
2026-01-23 19:48:33.926Z warning(clock): 0: synchronization failed, partitioned (sources=1 samples=1)
2026-01-23 19:48:33.926Z debug(replica): 1N: on_message: view=1 status=normal PrepareOk{ .checksum=ab3c63457ffa4ac78cac55908bd29d92, .checksum_body=49f174618255402de6e7e3c40d60cc83, .cluster=0, .size=256, .epoch=0, .view=1, .release=0.0.0, .protocol=0, .command=vsr.Command.prepare_ok, .replica=1, .parent=903c6a7c5e7fe946f3a01fe4526f0248, .prepare_checksum=8021b09f3efb26cd35f32257145057d1, .checkpoint_id=00000000000000000000000000000000, .client=60324011015611665437153036865704073740, .op=175, .commit_min=174, .timestamp=1769197479780158100, .request=173, .operation=vsr.Operation(139) }
2026-01-23 19:48:33.926Z error(clock): 0: no agreement on cluster time (partitioned or too many clock faults)
2026-01-23 19:48:33.926Z debug(vsr): 1: primary_abdicate_timeout reset
2026-01-23 19:48:33.926Z debug(replica): 1N: on_prepare_ok: 1 message(s)
2026-01-23 19:48:33.926Z debug(replica): 1N: on_prepare_ok: waiting for quorum
2026-01-23 19:48:33.926Z debug(client_replies): 0: write_reply: wrote (client=60324011015611665437153036865704073740 request=172)
2026-01-23 19:48:33.930Z debug(replica): 0n: on_message: view=1 status=normal Request{ .checksum=d40536dfa21dc1f3be1f116ac61430a0, .checksum_body=44510b889687a9b53ed375ba4f7c758e, .cluster=0, .size=1015168, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.request, .replica=0, .parent=bb49da210e88efa3759762a30a2a0057, .client=60324011015611665437153036865704073740, .session=2, .timestamp=0, .request=173, .operation=vsr.Operation(139), .previous_request_latency=23517186 }
2026-01-23 19:48:33.930Z debug(replica): 0n: on_request: forwarding new request to primary (view=1)
2026-01-23 19:48:33.930Z debug(replica): 0n: sending request to replica 1: Request{ .checksum=d40536dfa21dc1f3be1f116ac61430a0, .checksum_body=44510b889687a9b53ed375ba4f7c758e, .cluster=0, .size=1015168, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.request, .replica=0, .parent=bb49da210e88efa3759762a30a2a0057, .client=60324011015611665437153036865704073740, .session=2, .timestamp=0, .request=173, .operation=vsr.Operation(139), .previous_request_latency=23517186 }
2026-01-23 19:48:33.931Z debug(journal): 0: write_sectors: ring=vsr.journal.Ring.prepares offset=183500800 len=1015808 unlocked
2026-01-23 19:48:33.931Z debug(journal): 0: write_header: op=175 sectors[40960..45056]
2026-01-23 19:48:33.931Z debug(journal): 0: write_sectors: ring=vsr.journal.Ring.headers offset=40960 len=4096 locked
2026-01-23 19:48:33.931Z debug(journal): 0: write_sectors: ring=vsr.journal.Ring.headers offset=40960 len=4096 unlocked
2026-01-23 19:48:33.931Z debug(journal): 0: write: view=1 slot=175 op=175 len=1015168: 8021b09f3efb26cd35f32257145057d1 complete, marking clean
2026-01-23 19:48:33.931Z debug(replica): 0n: send_prepare_ok: op=175 checksum=8021b09f3efb26cd35f32257145057d1
2026-01-23 19:48:33.931Z debug(replica): 0n: sending prepare_ok to replica 1: PrepareOk{ .checksum=c958348e519d202ade6d6aa6fe881645, .checksum_body=49f174618255402de6e7e3c40d60cc83, .cluster=0, .size=256, .epoch=0, .view=1, .release=0.0.0, .protocol=0, .command=vsr.Command.prepare_ok, .replica=0, .parent=903c6a7c5e7fe946f3a01fe4526f0248, .prepare_checksum=8021b09f3efb26cd35f32257145057d1, .checkpoint_id=00000000000000000000000000000000, .client=60324011015611665437153036865704073740, .op=175, .commit_min=174, .timestamp=1769197479780158100, .request=173, .operation=vsr.Operation(139) }
2026-01-23 19:48:33.934Z info(message_bus): 0: set_and_verify_peer connection from client=60324011015611665437153036865704073740
2026-01-23 19:48:33.934Z debug(replica): 0n: on_message: view=1 status=normal Request{ .checksum=d40536dfa21dc1f3be1f116ac61430a0, .checksum_body=44510b889687a9b53ed375ba4f7c758e, .cluster=0, .size=1015168, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.request, .replica=0, .parent=bb49da210e88efa3759762a30a2a0057, .client=60324011015611665437153036865704073740, .session=2, .timestamp=0, .request=173, .operation=vsr.Operation(139), .previous_request_latency=23517186 }
2026-01-23 19:48:33.934Z debug(replica): 0n: on_request: forwarding new request to primary (view=1)
2026-01-23 19:48:33.934Z debug(replica): 0n: sending request to replica 1: Request{ .checksum=d40536dfa21dc1f3be1f116ac61430a0, .checksum_body=44510b889687a9b53ed375ba4f7c758e, .cluster=0, .size=1015168, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.request, .replica=0, .parent=bb49da210e88efa3759762a30a2a0057, .client=60324011015611665437153036865704073740, .session=2, .timestamp=0, .request=173, .operation=vsr.Operation(139), .previous_request_latency=23517186 }
2026-01-23 19:48:33.934Z debug(replica): 0n: on_message: view=1 status=normal PingClient{ .checksum=75c807827e102d6b3f6fdd619155ab62, .checksum_body=49f174618255402de6e7e3c40d60cc83, .cluster=0, .size=256, .epoch=0, .view=0, .release=0.0.1, .protocol=0, .command=vsr.Command.ping_client, .replica=0, .client=60324011015611665437153036865704073740, .ping_timestamp_monotonic=41313069923428448 }
2026-01-23 19:48:33.934Z debug(replica): 0n: sending pong_client to client 60324011015611665437153036865704073740: PongClient{ .checksum=a75faff4f0963670a3d509744c6e213e, .checksum_body=49f174618255402de6e7e3c40d60cc83, .cluster=0, .size=256, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.pong_client, .replica=0, .ping_timestamp_monotonic=41313069923428448 }
2026-01-23 19:48:33.936Z debug(replica): 1N: on_message: view=1 status=normal Request{ .checksum=d40536dfa21dc1f3be1f116ac61430a0, .checksum_body=44510b889687a9b53ed375ba4f7c758e, .cluster=0, .size=1015168, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.request, .replica=0, .parent=bb49da210e88efa3759762a30a2a0057, .client=60324011015611665437153036865704073740, .session=2, .timestamp=0, .request=173, .operation=vsr.Operation(139), .previous_request_latency=23517186 }
2026-01-23 19:48:33.936Z debug(replica): 1N: on_request: new request
2026-01-23 19:48:33.936Z debug(replica): 1N: on_request: ignoring (already preparing)
2026-01-23 19:48:33.936Z debug(vsr): 0: journal_repair_budget_timeout fired
2026-01-23 19:48:33.936Z debug(vsr): 0: journal_repair_budget_timeout reset
2026-01-23 19:48:33.938Z warning(faulty_network): recv error (2,6): error.ConnectionResetByPeer
2026-01-23 19:48:33.939Z info(message_bus): 0: on_recv: from=vsr.Peer{ .replica = 2 } orderly shutdown
2026-01-23 19:48:33.943Z debug(replica): 0n: on_message: view=1 status=normal Request{ .checksum=d40536dfa21dc1f3be1f116ac61430a0, .checksum_body=44510b889687a9b53ed375ba4f7c758e, .cluster=0, .size=1015168, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.request, .replica=0, .parent=bb49da210e88efa3759762a30a2a0057, .client=60324011015611665437153036865704073740, .session=2, .timestamp=0, .request=173, .operation=vsr.Operation(139), .previous_request_latency=23517186 }
2026-01-23 19:48:33.943Z debug(replica): 0n: on_request: forwarding new request to primary (view=1)
2026-01-23 19:48:33.943Z debug(replica): 0n: sending request to replica 1: Request{ .checksum=d40536dfa21dc1f3be1f116ac61430a0, .checksum_body=44510b889687a9b53ed375ba4f7c758e, .cluster=0, .size=1015168, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.request, .replica=0, .parent=bb49da210e88efa3759762a30a2a0057, .client=60324011015611665437153036865704073740, .session=2, .timestamp=0, .request=173, .operation=vsr.Operation(139), .previous_request_latency=23517186 }
2026-01-23 19:48:33.945Z debug(replica): 1N: on_message: view=1 status=normal Request{ .checksum=d40536dfa21dc1f3be1f116ac61430a0, .checksum_body=44510b889687a9b53ed375ba4f7c758e, .cluster=0, .size=1015168, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.request, .replica=0, .parent=bb49da210e88efa3759762a30a2a0057, .client=60324011015611665437153036865704073740, .session=2, .timestamp=0, .request=173, .operation=vsr.Operation(139), .previous_request_latency=23517186 }
2026-01-23 19:48:33.945Z debug(replica): 1N: on_request: new request
2026-01-23 19:48:33.945Z debug(replica): 1N: on_request: ignoring (already preparing)
2026-01-23 19:48:33.945Z info(message_bus): 1: on_recv: from=vsr.Peer{ .replica = 2 } orderly shutdown
2026-01-23 19:48:33.948Z debug(replica): 0n: on_message: view=1 status=normal Request{ .checksum=d40536dfa21dc1f3be1f116ac61430a0, .checksum_body=44510b889687a9b53ed375ba4f7c758e, .cluster=0, .size=1015168, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.request, .replica=0, .parent=bb49da210e88efa3759762a30a2a0057, .client=60324011015611665437153036865704073740, .session=2, .timestamp=0, .request=173, .operation=vsr.Operation(139), .previous_request_latency=23517186 }
2026-01-23 19:48:33.948Z debug(replica): 0n: on_request: forwarding new request to primary (view=1)
2026-01-23 19:48:33.948Z debug(replica): 0n: sending request to replica 1: Request{ .checksum=d40536dfa21dc1f3be1f116ac61430a0, .checksum_body=44510b889687a9b53ed375ba4f7c758e, .cluster=0, .size=1015168, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.request, .replica=0, .parent=bb49da210e88efa3759762a30a2a0057, .client=60324011015611665437153036865704073740, .session=2, .timestamp=0, .request=173, .operation=vsr.Operation(139), .previous_request_latency=23517186 }
2026-01-23 19:48:33.948Z debug(replica): 0n: on_message: view=1 status=normal PingClient{ .checksum=2d3f056a5cd6eb4ad377006aa64527dc, .checksum_body=49f174618255402de6e7e3c40d60cc83, .cluster=0, .size=256, .epoch=0, .view=0, .release=0.0.1, .protocol=0, .command=vsr.Command.ping_client, .replica=0, .client=60324011015611665437153036865704073740, .ping_timestamp_monotonic=41313100057478280 }
2026-01-23 19:48:33.948Z debug(replica): 0n: sending pong_client to client 60324011015611665437153036865704073740: PongClient{ .checksum=b3e443eb4f0b4571eb5a4ff8c9af3459, .checksum_body=49f174618255402de6e7e3c40d60cc83, .cluster=0, .size=256, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.pong_client, .replica=0, .ping_timestamp_monotonic=41313100057478280 }
2026-01-23 19:48:33.948Z info(supervisor): sleeping for 3.894s
2026-01-23 19:48:33.952Z debug(replica): 0n: on_message: view=1 status=normal Request{ .checksum=d40536dfa21dc1f3be1f116ac61430a0, .checksum_body=44510b889687a9b53ed375ba4f7c758e, .cluster=0, .size=1015168, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.request, .replica=0, .parent=bb49da210e88efa3759762a30a2a0057, .client=60324011015611665437153036865704073740, .session=2, .timestamp=0, .request=173, .operation=vsr.Operation(139), .previous_request_latency=23517186 }
2026-01-23 19:48:33.952Z debug(replica): 0n: on_request: forwarding new request to primary (view=1)
2026-01-23 19:48:33.952Z debug(replica): 0n: sending request to replica 1: Request{ .checksum=d40536dfa21dc1f3be1f116ac61430a0, .checksum_body=44510b889687a9b53ed375ba4f7c758e, .cluster=0, .size=1015168, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.request, .replica=0, .parent=bb49da210e88efa3759762a30a2a0057, .client=60324011015611665437153036865704073740, .session=2, .timestamp=0, .request=173, .operation=vsr.Operation(139), .previous_request_latency=23517186 }
2026-01-23 19:48:33.952Z debug(message_bus): 0: connect_to_replica: connecting to=2 after=68ms
2026-01-23 19:48:33.952Z debug(vsr): 0: journal_repair_timeout fired
2026-01-23 19:48:33.952Z debug(vsr): 0: journal_repair_timeout reset
2026-01-23 19:48:33.954Z debug(replica): 1N: on_message: view=1 status=normal Request{ .checksum=d40536dfa21dc1f3be1f116ac61430a0, .checksum_body=44510b889687a9b53ed375ba4f7c758e, .cluster=0, .size=1015168, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.request, .replica=0, .parent=bb49da210e88efa3759762a30a2a0057, .client=60324011015611665437153036865704073740, .session=2, .timestamp=0, .request=173, .operation=vsr.Operation(139), .previous_request_latency=23517186 }
2026-01-23 19:48:33.954Z debug(replica): 1N: on_request: new request
2026-01-23 19:48:33.954Z debug(replica): 1N: on_request: ignoring (already preparing)
2026-01-23 19:48:33.954Z debug(replica): 1N: on_message: view=1 status=normal PrepareOk{ .checksum=c958348e519d202ade6d6aa6fe881645, .checksum_body=49f174618255402de6e7e3c40d60cc83, .cluster=0, .size=256, .epoch=0, .view=1, .release=0.0.0, .protocol=0, .command=vsr.Command.prepare_ok, .replica=0, .parent=903c6a7c5e7fe946f3a01fe4526f0248, .prepare_checksum=8021b09f3efb26cd35f32257145057d1, .checkpoint_id=00000000000000000000000000000000, .client=60324011015611665437153036865704073740, .op=175, .commit_min=174, .timestamp=1769197479780158100, .request=173, .operation=vsr.Operation(139) }
2026-01-23 19:48:33.955Z debug(vsr): 1: primary_abdicate_timeout reset
2026-01-23 19:48:33.955Z debug(replica): 1N: on_prepare_ok: 2 message(s)
2026-01-23 19:48:33.955Z debug(replica): 1N: on_prepare_ok: quorum received, prepare_checksum=8021b09f3efb26cd35f32257145057d1
2026-01-23 19:48:33.955Z debug(vsr): 1: prepare_timeout stopped
2026-01-23 19:48:33.955Z debug(vsr): 1: primary_abdicate_timeout stopped
2026-01-23 19:48:33.962Z debug(vsr): 0: journal_repair_budget_timeout fired
2026-01-23 19:48:33.962Z debug(vsr): 0: journal_repair_budget_timeout reset
2026-01-23 19:48:33.968Z debug(replica): 1N: on_message: view=1 status=normal Request{ .checksum=d40536dfa21dc1f3be1f116ac61430a0, .checksum_body=44510b889687a9b53ed375ba4f7c758e, .cluster=0, .size=1015168, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.request, .replica=0, .parent=bb49da210e88efa3759762a30a2a0057, .client=60324011015611665437153036865704073740, .session=2, .timestamp=0, .request=173, .operation=vsr.Operation(139), .previous_request_latency=23517186 }
2026-01-23 19:48:33.968Z debug(replica): 1N: on_request: new request
2026-01-23 19:48:33.968Z debug(replica): 1N: on_request: ignoring (already preparing)
2026-01-23 19:48:33.968Z debug(replica): 1N: on_message: view=1 status=normal PingClient{ .checksum=75c807827e102d6b3f6fdd619155ab62, .checksum_body=49f174618255402de6e7e3c40d60cc83, .cluster=0, .size=256, .epoch=0, .view=0, .release=0.0.1, .protocol=0, .command=vsr.Command.ping_client, .replica=0, .client=60324011015611665437153036865704073740, .ping_timestamp_monotonic=41313069923428448 }
2026-01-23 19:48:33.968Z debug(replica): 1N: sending pong_client to client 60324011015611665437153036865704073740: PongClient{ .checksum=fd98d8569747698fe9d244f55016cc23, .checksum_body=49f174618255402de6e7e3c40d60cc83, .cluster=0, .size=256, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.pong_client, .replica=1, .ping_timestamp_monotonic=41313069923428448 }
2026-01-23 19:48:33.968Z warning(faulty_network): send error (1,5): error.ConnectionResetByPeer
2026-01-23 19:48:33.971Z debug(replica): 1N: execute_op: executing view=1 primary=true op=175 checksum=8021b09f3efb26cd35f32257145057d1 (create_transfers)
2026-01-23 19:48:33.971Z debug(replica): 1N: execute_op: commit_timestamp=1769197479740509710 prepare.header.timestamp=1769197479780158100
2026-01-23 19:48:33.982Z debug(vsr): 0: journal_repair_budget_timeout fired
2026-01-23 19:48:33.982Z debug(vsr): 0: journal_repair_budget_timeout reset
2026-01-23 19:48:33.996Z debug(replica): 1N: execute_op: advancing commit_max=174..175
2026-01-23 19:48:33.996Z debug(replica): 1N: client_table_entry_update: client=60324011015611665437153036865704073740 session=2 request=173
2026-01-23 19:48:33.996Z debug(replica): 1N: execute_op: replying to client: Reply{ .checksum=d030b40673fd9b6bdf71be9ed0d07db4, .checksum_body=ea896edcb0f638197c53a5b6a59e1ab2, .cluster=0, .size=264, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.reply, .replica=1, .request_checksum=d40536dfa21dc1f3be1f116ac61430a0, .context=a88165edd9b58e18081879141998082f, .client=60324011015611665437153036865704073740, .op=175, .commit=175, .timestamp=1769197479780158100, .request=173, .operation=vsr.Operation(139) }
2026-01-23 19:48:33.996Z debug(replica): 1N: sending reply to client 60324011015611665437153036865704073740: Reply{ .checksum=d030b40673fd9b6bdf71be9ed0d07db4, .checksum_body=ea896edcb0f638197c53a5b6a59e1ab2, .cluster=0, .size=264, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.reply, .replica=1, .request_checksum=d40536dfa21dc1f3be1f116ac61430a0, .context=a88165edd9b58e18081879141998082f, .client=60324011015611665437153036865704073740, .op=175, .commit=175, .timestamp=1769197479780158100, .request=173, .operation=vsr.Operation(139) }
2026-01-23 19:48:33.997Z debug(forest): entering forest.compact() op=175 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=true half_beat=false last_beat=false
2026-01-23 19:48:33.997Z debug(manifest_log): 1: flush: writing 0 block(s)
2026-01-23 19:48:34.002Z debug(vsr): 0: journal_repair_budget_timeout fired
2026-01-23 19:48:34.002Z debug(vsr): 0: journal_repair_budget_timeout reset
2026-01-23 19:48:34.006Z warning(message_bus): 1: on_recv: from=vsr.Peer{ .client = 60324011015611665437153036865704073740 } error.ConnectionResetByPeer
2026-01-23 19:48:34.006Z debug(client_replies): 1: write_reply: wrote (client=60324011015611665437153036865704073740 request=173)
2026-01-23 19:48:34.009Z debug(replica): 1N: on_message: view=1 status=normal Request{ .checksum=d40536dfa21dc1f3be1f116ac61430a0, .checksum_body=44510b889687a9b53ed375ba4f7c758e, .cluster=0, .size=1015168, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.request, .replica=0, .parent=bb49da210e88efa3759762a30a2a0057, .client=60324011015611665437153036865704073740, .session=2, .timestamp=0, .request=173, .operation=vsr.Operation(139), .previous_request_latency=23517186 }
2026-01-23 19:48:34.009Z debug(replica): 1N: on_request: replying to duplicate request
2026-01-23 19:48:34.009Z debug(client_replies): 1: read_reply: start (client=60324011015611665437153036865704073740 reply=d030b40673fd9b6bdf71be9ed0d07db4)
2026-01-23 19:48:34.010Z debug(client_replies): 1: read_reply: done (client=60324011015611665437153036865704073740 reply=d030b40673fd9b6bdf71be9ed0d07db4)
2026-01-23 19:48:34.010Z debug(replica): 1N: on_request: repeat reply (client=60324011015611665437153036865704073740 request=173)
2026-01-23 19:48:34.010Z debug(replica): 1N: sending reply to client 60324011015611665437153036865704073740: Reply{ .checksum=d030b40673fd9b6bdf71be9ed0d07db4, .checksum_body=ea896edcb0f638197c53a5b6a59e1ab2, .cluster=0, .size=264, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.reply, .replica=1, .request_checksum=d40536dfa21dc1f3be1f116ac61430a0, .context=a88165edd9b58e18081879141998082f, .client=60324011015611665437153036865704073740, .op=175, .commit=175, .timestamp=1769197479780158100, .request=173, .operation=vsr.Operation(139) }
2026-01-23 19:48:34.010Z debug(message_bus): 1: send_message_to_client: no connection to=60324011015611665437153036865704073740
2026-01-23 19:48:34.013Z debug(replica): 1N: on_message: view=1 status=normal Request{ .checksum=d40536dfa21dc1f3be1f116ac61430a0, .checksum_body=44510b889687a9b53ed375ba4f7c758e, .cluster=0, .size=1015168, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.request, .replica=0, .parent=bb49da210e88efa3759762a30a2a0057, .client=60324011015611665437153036865704073740, .session=2, .timestamp=0, .request=173, .operation=vsr.Operation(139), .previous_request_latency=23517186 }
2026-01-23 19:48:34.013Z debug(replica): 1N: on_request: replying to duplicate request
2026-01-23 19:48:34.013Z debug(client_replies): 1: read_reply: start (client=60324011015611665437153036865704073740 reply=d030b40673fd9b6bdf71be9ed0d07db4)
2026-01-23 19:48:34.013Z debug(client_replies): 1: read_reply: done (client=60324011015611665437153036865704073740 reply=d030b40673fd9b6bdf71be9ed0d07db4)
2026-01-23 19:48:34.013Z debug(replica): 1N: on_request: repeat reply (client=60324011015611665437153036865704073740 request=173)
2026-01-23 19:48:34.013Z debug(replica): 1N: sending reply to client 60324011015611665437153036865704073740: Reply{ .checksum=d030b40673fd9b6bdf71be9ed0d07db4, .checksum_body=ea896edcb0f638197c53a5b6a59e1ab2, .cluster=0, .size=264, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.reply, .replica=1, .request_checksum=d40536dfa21dc1f3be1f116ac61430a0, .context=a88165edd9b58e18081879141998082f, .client=60324011015611665437153036865704073740, .op=175, .commit=175, .timestamp=1769197479780158100, .request=173, .operation=vsr.Operation(139) }
2026-01-23 19:48:34.013Z debug(message_bus): 1: send_message_to_client: no connection to=60324011015611665437153036865704073740
2026-01-23 19:48:34.017Z debug(replica): 1N: on_message: view=1 status=normal Request{ .checksum=d40536dfa21dc1f3be1f116ac61430a0, .checksum_body=44510b889687a9b53ed375ba4f7c758e, .cluster=0, .size=1015168, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.request, .replica=0, .parent=bb49da210e88efa3759762a30a2a0057, .client=60324011015611665437153036865704073740, .session=2, .timestamp=0, .request=173, .operation=vsr.Operation(139), .previous_request_latency=23517186 }
2026-01-23 19:48:34.017Z debug(replica): 1N: on_request: replying to duplicate request
2026-01-23 19:48:34.017Z debug(client_replies): 1: read_reply: start (client=60324011015611665437153036865704073740 reply=d030b40673fd9b6bdf71be9ed0d07db4)
2026-01-23 19:48:34.017Z debug(client_replies): 1: read_reply: done (client=60324011015611665437153036865704073740 reply=d030b40673fd9b6bdf71be9ed0d07db4)
2026-01-23 19:48:34.017Z debug(replica): 1N: on_request: repeat reply (client=60324011015611665437153036865704073740 request=173)
2026-01-23 19:48:34.017Z debug(replica): 1N: sending reply to client 60324011015611665437153036865704073740: Reply{ .checksum=d030b40673fd9b6bdf71be9ed0d07db4, .checksum_body=ea896edcb0f638197c53a5b6a59e1ab2, .cluster=0, .size=264, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.reply, .replica=1, .request_checksum=d40536dfa21dc1f3be1f116ac61430a0, .context=a88165edd9b58e18081879141998082f, .client=60324011015611665437153036865704073740, .op=175, .commit=175, .timestamp=1769197479780158100, .request=173, .operation=vsr.Operation(139) }
2026-01-23 19:48:34.017Z debug(message_bus): 1: send_message_to_client: no connection to=60324011015611665437153036865704073740
2026-01-23 19:48:34.020Z debug(message_bus): 0: on_connect_with_exponential_backoff: to=2
2026-01-23 19:48:34.020Z info(message_bus): 0: on_connect: connected to=2
2026-01-23 19:48:34.021Z warning(faulty_network): connect failed (2,9): error.ConnectionRefused
2026-01-23 19:48:34.021Z info(message_bus): 0: on_recv: from=vsr.Peer{ .replica = 2 } orderly shutdown
2026-01-23 19:48:34.021Z debug(replica): 1N: on_message: view=1 status=normal Request{ .checksum=d40536dfa21dc1f3be1f116ac61430a0, .checksum_body=44510b889687a9b53ed375ba4f7c758e, .cluster=0, .size=1015168, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.request, .replica=0, .parent=bb49da210e88efa3759762a30a2a0057, .client=60324011015611665437153036865704073740, .session=2, .timestamp=0, .request=173, .operation=vsr.Operation(139), .previous_request_latency=23517186 }
2026-01-23 19:48:34.021Z debug(replica): 1N: on_request: replying to duplicate request
2026-01-23 19:48:34.021Z debug(client_replies): 1: read_reply: start (client=60324011015611665437153036865704073740 reply=d030b40673fd9b6bdf71be9ed0d07db4)
2026-01-23 19:48:34.021Z debug(message_bus): 1: connect_to_replica: connecting to=2 after=88ms
2026-01-23 19:48:34.021Z debug(client_replies): 1: read_reply: done (client=60324011015611665437153036865704073740 reply=d030b40673fd9b6bdf71be9ed0d07db4)
2026-01-23 19:48:34.021Z debug(replica): 1N: on_request: repeat reply (client=60324011015611665437153036865704073740 request=173)
2026-01-23 19:48:34.021Z debug(replica): 1N: sending reply to client 60324011015611665437153036865704073740: Reply{ .checksum=d030b40673fd9b6bdf71be9ed0d07db4, .checksum_body=ea896edcb0f638197c53a5b6a59e1ab2, .cluster=0, .size=264, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.reply, .replica=1, .request_checksum=d40536dfa21dc1f3be1f116ac61430a0, .context=a88165edd9b58e18081879141998082f, .client=60324011015611665437153036865704073740, .op=175, .commit=175, .timestamp=1769197479780158100, .request=173, .operation=vsr.Operation(139) }
2026-01-23 19:48:34.021Z debug(message_bus): 1: send_message_to_client: no connection to=60324011015611665437153036865704073740
2026-01-23 19:48:34.022Z debug(message_bus): 0: connect_to_replica: connecting to=2 after=50ms
2026-01-23 19:48:34.022Z debug(vsr): 0: journal_repair_budget_timeout fired
2026-01-23 19:48:34.022Z debug(vsr): 0: journal_repair_budget_timeout reset
2026-01-23 19:48:34.031Z debug(vsr): 1: journal_repair_budget_timeout fired
2026-01-23 19:48:34.031Z debug(vsr): 1: journal_repair_budget_timeout reset
2026-01-23 19:48:34.038Z warning(faulty_network): connect failed (2,0): error.ConnectionRefused
2026-01-23 19:48:34.043Z debug(vsr): 0: journal_repair_budget_timeout fired
2026-01-23 19:48:34.043Z debug(vsr): 0: journal_repair_budget_timeout reset
2026-01-23 19:48:34.051Z debug(vsr): 1: journal_repair_budget_timeout fired
2026-01-23 19:48:34.051Z debug(vsr): 1: journal_repair_budget_timeout reset
2026-01-23 19:48:34.051Z debug(vsr): 1: journal_repair_timeout fired
2026-01-23 19:48:34.051Z debug(vsr): 1: journal_repair_timeout reset
2026-01-23 19:48:34.053Z debug(vsr): 0: journal_repair_timeout fired
2026-01-23 19:48:34.053Z debug(vsr): 0: journal_repair_timeout reset
2026-01-23 19:48:34.063Z debug(vsr): 0: journal_repair_budget_timeout fired
2026-01-23 19:48:34.063Z debug(vsr): 0: journal_repair_budget_timeout reset
2026-01-23 19:48:34.071Z debug(vsr): 1: journal_repair_budget_timeout fired
2026-01-23 19:48:34.071Z debug(vsr): 1: journal_repair_budget_timeout reset
2026-01-23 19:48:34.073Z debug(message_bus): 0: on_connect_with_exponential_backoff: to=2
2026-01-23 19:48:34.073Z info(message_bus): 0: on_connect: connected to=2
2026-01-23 19:48:34.073Z warning(faulty_network): connect failed (2,1): error.ConnectionRefused
2026-01-23 19:48:34.073Z info(message_bus): 0: on_recv: from=vsr.Peer{ .replica = 2 } orderly shutdown
2026-01-23 19:48:34.073Z debug(message_bus): 0: connect_to_replica: connecting to=2 after=75ms
2026-01-23 19:48:34.083Z debug(vsr): 0: journal_repair_budget_timeout fired
2026-01-23 19:48:34.083Z debug(vsr): 0: journal_repair_budget_timeout reset
2026-01-23 19:48:34.091Z debug(vsr): 1: journal_repair_budget_timeout fired
2026-01-23 19:48:34.091Z debug(vsr): 1: journal_repair_budget_timeout reset
2026-01-23 19:48:34.101Z debug(vsr): 1: pulse_timeout fired
2026-01-23 19:48:34.101Z debug(vsr): 1: pulse_timeout reset
2026-01-23 19:48:34.103Z debug(vsr): 0: journal_repair_budget_timeout fired
2026-01-23 19:48:34.103Z debug(vsr): 0: journal_repair_budget_timeout reset
2026-01-23 19:48:34.109Z debug(message_bus): 1: on_connect_with_exponential_backoff: to=2
2026-01-23 19:48:34.109Z info(message_bus): 1: on_connect: connected to=2
2026-01-23 19:48:34.109Z warning(faulty_network): connect failed (2,2): error.ConnectionRefused
2026-01-23 19:48:34.109Z info(message_bus): 1: on_recv: from=vsr.Peer{ .replica = 2 } orderly shutdown
2026-01-23 19:48:34.111Z debug(message_bus): 1: connect_to_replica: connecting to=2 after=55ms
2026-01-23 19:48:34.111Z debug(vsr): 1: journal_repair_budget_timeout fired
2026-01-23 19:48:34.111Z debug(vsr): 1: journal_repair_budget_timeout reset
2026-01-23 19:48:34.116Z warning(faulty_network): connect failed (2,3): error.ConnectionRefused
2026-01-23 19:48:34.123Z debug(vsr): 0: journal_repair_budget_timeout fired
2026-01-23 19:48:34.123Z debug(vsr): 0: journal_repair_budget_timeout reset
2026-01-23 19:48:34.131Z debug(vsr): 1: journal_repair_budget_timeout fired
2026-01-23 19:48:34.131Z debug(vsr): 1: journal_repair_budget_timeout reset
2026-01-23 19:48:34.143Z debug(vsr): 0: journal_repair_budget_timeout fired
2026-01-23 19:48:34.143Z debug(vsr): 0: journal_repair_budget_timeout reset
2026-01-23 19:48:34.148Z debug(message_bus): 0: on_connect_with_exponential_backoff: to=2
2026-01-23 19:48:34.148Z info(message_bus): 0: on_connect: connected to=2
2026-01-23 19:48:34.148Z warning(faulty_network): connect failed (2,4): error.ConnectionRefused
2026-01-23 19:48:34.148Z info(message_bus): 0: on_recv: from=vsr.Peer{ .replica = 2 } orderly shutdown
2026-01-23 19:48:34.151Z debug(vsr): 1: journal_repair_budget_timeout fired
2026-01-23 19:48:34.151Z debug(vsr): 1: journal_repair_budget_timeout reset
2026-01-23 19:48:34.151Z debug(vsr): 1: journal_repair_timeout fired
2026-01-23 19:48:34.151Z debug(vsr): 1: journal_repair_timeout reset
2026-01-23 19:48:34.153Z debug(message_bus): 0: connect_to_replica: connecting to=2 after=51ms
2026-01-23 19:48:34.153Z debug(vsr): 0: journal_repair_timeout fired
2026-01-23 19:48:34.153Z debug(vsr): 0: journal_repair_timeout reset
2026-01-23 19:48:34.163Z debug(vsr): 0: journal_repair_budget_timeout fired
2026-01-23 19:48:34.163Z debug(vsr): 0: journal_repair_budget_timeout reset
2026-01-23 19:48:34.166Z debug(message_bus): 1: on_connect_with_exponential_backoff: to=2
2026-01-23 19:48:34.166Z info(message_bus): 1: on_connect: connected to=2
2026-01-23 19:48:34.166Z warning(faulty_network): connect failed (2,5): error.ConnectionRefused
2026-01-23 19:48:34.166Z info(message_bus): 1: on_recv: from=vsr.Peer{ .replica = 2 } orderly shutdown
2026-01-23 19:48:34.171Z debug(message_bus): 1: connect_to_replica: connecting to=2 after=88ms
2026-01-23 19:48:34.171Z debug(vsr): 1: journal_repair_budget_timeout fired
2026-01-23 19:48:34.171Z debug(vsr): 1: journal_repair_budget_timeout reset
2026-01-23 19:48:34.183Z debug(vsr): 0: journal_repair_budget_timeout fired
2026-01-23 19:48:34.183Z debug(vsr): 0: journal_repair_budget_timeout reset
2026-01-23 19:48:34.192Z debug(vsr): 1: journal_repair_budget_timeout fired
2026-01-23 19:48:34.192Z debug(vsr): 1: journal_repair_budget_timeout reset
2026-01-23 19:48:34.202Z debug(vsr): 1: pulse_timeout fired
2026-01-23 19:48:34.202Z debug(vsr): 1: pulse_timeout reset
2026-01-23 19:48:34.203Z debug(vsr): 0: journal_repair_budget_timeout fired
2026-01-23 19:48:34.203Z debug(vsr): 0: journal_repair_budget_timeout reset
2026-01-23 19:48:34.204Z debug(message_bus): 0: on_connect_with_exponential_backoff: to=2
2026-01-23 19:48:34.204Z info(message_bus): 0: on_connect: connected to=2
2026-01-23 19:48:34.204Z warning(faulty_network): connect failed (2,6): error.ConnectionRefused
2026-01-23 19:48:34.204Z info(message_bus): 0: on_recv: from=vsr.Peer{ .replica = 2 } orderly shutdown
2026-01-23 19:48:34.212Z debug(vsr): 1: journal_repair_budget_timeout fired
2026-01-23 19:48:34.212Z debug(vsr): 1: journal_repair_budget_timeout reset
2026-01-23 19:48:34.213Z debug(message_bus): 0: connect_to_replica: connecting to=2 after=93ms
2026-01-23 19:48:34.214Z warning(faulty_network): connect failed (2,7): error.ConnectionRefused
2026-01-23 19:48:34.223Z debug(vsr): 0: journal_repair_budget_timeout fired
2026-01-23 19:48:34.223Z debug(vsr): 0: journal_repair_budget_timeout reset
2026-01-23 19:48:34.232Z debug(vsr): 1: journal_repair_budget_timeout fired
2026-01-23 19:48:34.232Z debug(vsr): 1: journal_repair_budget_timeout reset
2026-01-23 19:48:34.243Z debug(vsr): 0: journal_repair_budget_timeout fired
2026-01-23 19:48:34.243Z debug(vsr): 0: journal_repair_budget_timeout reset
2026-01-23 19:48:34.252Z debug(vsr): 1: journal_repair_budget_timeout fired
2026-01-23 19:48:34.252Z debug(vsr): 1: journal_repair_budget_timeout reset
2026-01-23 19:48:34.252Z debug(vsr): 1: journal_repair_timeout fired
2026-01-23 19:48:34.252Z debug(vsr): 1: journal_repair_timeout reset
2026-01-23 19:48:34.254Z debug(vsr): 0: ping_timeout fired
2026-01-23 19:48:34.254Z debug(vsr): 0: ping_timeout reset
2026-01-23 19:48:34.254Z debug(replica): 0n: sending ping to replica 1: Ping{ .checksum=b454550daf30353b8bb77e6075a65ae3, .checksum_body=74730330cb75ecd4a42c51968e55e4bd, .cluster=0, .size=512, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.ping, .replica=0, .checkpoint_id=f222e9ce156b309eaeb4af665242ac18, .checkpoint_op=0, .ping_timestamp_monotonic=41313283028219103, .release_count=1, .route=0 }
2026-01-23 19:48:34.254Z debug(replica): 0n: sending ping to replica 2: Ping{ .checksum=b454550daf30353b8bb77e6075a65ae3, .checksum_body=74730330cb75ecd4a42c51968e55e4bd, .cluster=0, .size=512, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.ping, .replica=0, .checkpoint_id=f222e9ce156b309eaeb4af665242ac18, .checkpoint_op=0, .ping_timestamp_monotonic=41313283028219103, .release_count=1, .route=0 }
2026-01-23 19:48:34.254Z debug(vsr): 0: start_view_change_message_timeout fired
2026-01-23 19:48:34.254Z debug(vsr): 0: start_view_change_message_timeout reset
2026-01-23 19:48:34.254Z debug(vsr): 0: journal_repair_timeout fired
2026-01-23 19:48:34.254Z debug(vsr): 0: journal_repair_timeout reset
2026-01-23 19:48:34.254Z debug(replica): 1N: on_message: view=1 status=normal Ping{ .checksum=b454550daf30353b8bb77e6075a65ae3, .checksum_body=74730330cb75ecd4a42c51968e55e4bd, .cluster=0, .size=512, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.ping, .replica=0, .checkpoint_id=f222e9ce156b309eaeb4af665242ac18, .checkpoint_op=0, .ping_timestamp_monotonic=41313283028219103, .release_count=1, .route=0 }
2026-01-23 19:48:34.254Z debug(replica): 1N: sending pong to replica 0: Pong{ .checksum=6a463d8e7718d2928ab535b899135291, .checksum_body=49f174618255402de6e7e3c40d60cc83, .cluster=0, .size=256, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.pong, .replica=1, .ping_timestamp_monotonic=41313283028219103, .pong_timestamp_wall=1769197714254310951 }
2026-01-23 19:48:34.254Z debug(vsr): 0: grid_repair_budget_timeout fired
2026-01-23 19:48:34.254Z debug(vsr): 0: grid_repair_budget_timeout reset
2026-01-23 19:48:34.254Z debug(replica): 0n: on_message: view=1 status=normal Pong{ .checksum=6a463d8e7718d2928ab535b899135291, .checksum_body=49f174618255402de6e7e3c40d60cc83, .cluster=0, .size=256, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.pong, .replica=1, .ping_timestamp_monotonic=41313283028219103, .pong_timestamp_wall=1769197714254310951 }
2026-01-23 19:48:34.254Z debug(clock): 0: learn: replica=1 m0=41313283028219103 t1=1769197714254310951 m2=41313283028587542 t2=1769197714254448031 one_way_delay=184219 asymmetric_delay=0 clock_offset=47139
2026-01-23 19:48:34.260Z debug(message_bus): 1: on_connect_with_exponential_backoff: to=2
2026-01-23 19:48:34.260Z info(message_bus): 1: on_connect: connected to=2
2026-01-23 19:48:34.260Z warning(faulty_network): connect failed (2,8): error.ConnectionRefused
2026-01-23 19:48:34.260Z info(message_bus): 1: on_recv: from=vsr.Peer{ .replica = 2 } orderly shutdown
2026-01-23 19:48:34.262Z debug(message_bus): 1: connect_to_replica: connecting to=2 after=59ms
2026-01-23 19:48:34.264Z debug(vsr): 0: journal_repair_budget_timeout fired
2026-01-23 19:48:34.264Z debug(vsr): 0: journal_repair_budget_timeout reset
2026-01-23 19:48:34.272Z debug(vsr): 1: journal_repair_budget_timeout fired
2026-01-23 19:48:34.272Z debug(vsr): 1: journal_repair_budget_timeout reset
2026-01-23 19:48:34.284Z debug(vsr): 0: journal_repair_budget_timeout fired
2026-01-23 19:48:34.284Z debug(vsr): 0: journal_repair_budget_timeout reset
2026-01-23 19:48:34.292Z debug(vsr): 1: journal_repair_budget_timeout fired
2026-01-23 19:48:34.292Z debug(vsr): 1: journal_repair_budget_timeout reset
2026-01-23 19:48:34.302Z debug(vsr): 1: pulse_timeout fired
2026-01-23 19:48:34.302Z debug(vsr): 1: pulse_timeout reset
2026-01-23 19:48:34.304Z debug(vsr): 0: journal_repair_budget_timeout fired
2026-01-23 19:48:34.304Z debug(vsr): 0: journal_repair_budget_timeout reset
2026-01-23 19:48:34.305Z warning(faulty_network): connect failed (2,9): error.ConnectionRefused
2026-01-23 19:48:34.306Z debug(message_bus): 0: on_connect_with_exponential_backoff: to=2
2026-01-23 19:48:34.307Z info(message_bus): 0: on_connect: connected to=2
2026-01-23 19:48:34.307Z warning(faulty_network): connect failed (2,0): error.ConnectionRefused
2026-01-23 19:48:34.307Z warning(message_bus): 0: on_recv: from=vsr.Peer{ .replica = 2 } error.ConnectionResetByPeer
2026-01-23 19:48:34.312Z debug(vsr): 1: journal_repair_budget_timeout fired
2026-01-23 19:48:34.312Z debug(vsr): 1: journal_repair_budget_timeout reset
2026-01-23 19:48:34.314Z debug(message_bus): 0: connect_to_replica: connecting to=2 after=93ms
2026-01-23 19:48:34.321Z debug(message_bus): 1: on_connect_with_exponential_backoff: to=2
2026-01-23 19:48:34.321Z info(message_bus): 1: on_connect: connected to=2
2026-01-23 19:48:34.321Z warning(faulty_network): connect failed (2,1): error.ConnectionRefused
2026-01-23 19:48:34.321Z info(message_bus): 1: on_recv: from=vsr.Peer{ .replica = 2 } orderly shutdown
2026-01-23 19:48:34.322Z debug(message_bus): 1: connect_to_replica: connecting to=2 after=80ms
2026-01-23 19:48:34.324Z debug(vsr): 0: journal_repair_budget_timeout fired
2026-01-23 19:48:34.324Z debug(vsr): 0: journal_repair_budget_timeout reset
2026-01-23 19:48:34.332Z debug(vsr): 1: journal_repair_budget_timeout fired
2026-01-23 19:48:34.332Z debug(vsr): 1: journal_repair_budget_timeout reset
2026-01-23 19:48:34.344Z debug(vsr): 0: journal_repair_budget_timeout fired
2026-01-23 19:48:34.344Z debug(vsr): 0: journal_repair_budget_timeout reset
2026-01-23 19:48:34.352Z debug(vsr): 1: journal_repair_budget_timeout fired
2026-01-23 19:48:34.352Z debug(vsr): 1: journal_repair_budget_timeout reset
2026-01-23 19:48:34.352Z debug(vsr): 1: journal_repair_timeout fired
2026-01-23 19:48:34.352Z debug(vsr): 1: journal_repair_timeout reset
2026-01-23 19:48:34.354Z debug(vsr): 0: journal_repair_timeout fired
2026-01-23 19:48:34.354Z debug(vsr): 0: journal_repair_timeout reset
2026-01-23 19:48:34.365Z debug(vsr): 0: journal_repair_budget_timeout fired
2026-01-23 19:48:34.365Z debug(vsr): 0: journal_repair_budget_timeout reset
2026-01-23 19:48:34.373Z debug(vsr): 1: journal_repair_budget_timeout fired
2026-01-23 19:48:34.373Z debug(vsr): 1: journal_repair_budget_timeout reset
2026-01-23 19:48:34.385Z debug(vsr): 0: journal_repair_budget_timeout fired
2026-01-23 19:48:34.385Z debug(vsr): 0: journal_repair_budget_timeout reset
2026-01-23 19:48:34.393Z debug(vsr): 1: journal_repair_budget_timeout fired
2026-01-23 19:48:34.393Z debug(vsr): 1: journal_repair_budget_timeout reset
2026-01-23 19:48:34.396Z warning(faulty_network): connect failed (2,2): error.ConnectionRefused
2026-01-23 19:48:34.402Z debug(message_bus): 1: on_connect_with_exponential_backoff: to=2
2026-01-23 19:48:34.402Z info(message_bus): 1: on_connect: connected to=2
2026-01-23 19:48:34.403Z warning(faulty_network): connect failed (2,3): error.ConnectionRefused
2026-01-23 19:48:34.403Z info(message_bus): 1: on_recv: from=vsr.Peer{ .replica = 2 } orderly shutdown
2026-01-23 19:48:34.403Z debug(message_bus): 1: connect_to_replica: connecting to=2 after=100ms
2026-01-23 19:48:34.403Z debug(vsr): 1: pulse_timeout fired
2026-01-23 19:48:34.403Z debug(vsr): 1: pulse_timeout reset
2026-01-23 19:48:34.405Z debug(vsr): 0: journal_repair_budget_timeout fired
2026-01-23 19:48:34.405Z debug(vsr): 0: journal_repair_budget_timeout reset
2026-01-23 19:48:34.407Z debug(message_bus): 0: on_connect_with_exponential_backoff: to=2
2026-01-23 19:48:34.407Z info(message_bus): 0: on_connect: connected to=2
2026-01-23 19:48:34.407Z warning(faulty_network): connect failed (2,4): error.ConnectionRefused
2026-01-23 19:48:34.407Z info(message_bus): 0: on_recv: from=vsr.Peer{ .replica = 2 } orderly shutdown
2026-01-23 19:48:34.413Z debug(vsr): 1: journal_repair_budget_timeout fired
2026-01-23 19:48:34.413Z debug(vsr): 1: journal_repair_budget_timeout reset
2026-01-23 19:48:34.415Z debug(message_bus): 0: connect_to_replica: connecting to=2 after=65ms
2026-01-23 19:48:34.425Z debug(vsr): 0: journal_repair_budget_timeout fired
2026-01-23 19:48:34.425Z debug(vsr): 0: journal_repair_budget_timeout reset
2026-01-23 19:48:34.433Z debug(vsr): 1: journal_repair_budget_timeout fired
2026-01-23 19:48:34.433Z debug(vsr): 1: journal_repair_budget_timeout reset
2026-01-23 19:48:34.445Z debug(vsr): 0: journal_repair_budget_timeout fired
2026-01-23 19:48:34.445Z debug(vsr): 0: journal_repair_budget_timeout reset
2026-01-23 19:48:34.449Z warning(faulty_network): connect failed (2,5): error.ConnectionRefused
2026-01-23 19:48:34.453Z debug(vsr): 1: commit_message_timeout fired
2026-01-23 19:48:34.453Z debug(vsr): 1: commit_message_timeout reset
2026-01-23 19:48:34.453Z debug(replica): 1N: sending commit to replica 0: Commit{ .checksum=1bf617fc02972b661152903225ad075f, .checksum_body=49f174618255402de6e7e3c40d60cc83, .cluster=0, .size=256, .epoch=0, .view=1, .release=0.0.0, .protocol=0, .command=vsr.Command.commit, .replica=1, .commit_checksum=8021b09f3efb26cd35f32257145057d1, .checkpoint_id=f222e9ce156b309eaeb4af665242ac18, .checkpoint_op=0, .commit=175, .timestamp_monotonic=41313283227692488 }
2026-01-23 19:48:34.453Z debug(replica): 1N: sending commit to replica 2: Commit{ .checksum=1bf617fc02972b661152903225ad075f, .checksum_body=49f174618255402de6e7e3c40d60cc83, .cluster=0, .size=256, .epoch=0, .view=1, .release=0.0.0, .protocol=0, .command=vsr.Command.commit, .replica=1, .commit_checksum=8021b09f3efb26cd35f32257145057d1, .checkpoint_id=f222e9ce156b309eaeb4af665242ac18, .checkpoint_op=0, .commit=175, .timestamp_monotonic=41313283227692488 }
2026-01-23 19:48:34.453Z debug(vsr): 1: start_view_change_message_timeout fired
2026-01-23 19:48:34.453Z debug(vsr): 1: start_view_change_message_timeout reset
2026-01-23 19:48:34.453Z debug(vsr): 1: journal_repair_budget_timeout fired
2026-01-23 19:48:34.453Z debug(vsr): 1: journal_repair_budget_timeout reset
2026-01-23 19:48:34.453Z debug(vsr): 1: journal_repair_timeout fired
2026-01-23 19:48:34.453Z debug(vsr): 1: journal_repair_timeout reset
2026-01-23 19:48:34.453Z debug(replica): 0n: on_message: view=1 status=normal Commit{ .checksum=1bf617fc02972b661152903225ad075f, .checksum_body=49f174618255402de6e7e3c40d60cc83, .cluster=0, .size=256, .epoch=0, .view=1, .release=0.0.0, .protocol=0, .command=vsr.Command.commit, .replica=1, .commit_checksum=8021b09f3efb26cd35f32257145057d1, .checkpoint_id=f222e9ce156b309eaeb4af665242ac18, .checkpoint_op=0, .commit=175, .timestamp_monotonic=41313283227692488 }
2026-01-23 19:48:34.453Z debug(vsr): 0: normal_heartbeat_timeout reset
2026-01-23 19:48:34.453Z debug(replica): 0n: on_commit: checksum verified
2026-01-23 19:48:34.453Z debug(replica): 0n: on_commit: advancing commit_max=174..175
2026-01-23 19:48:34.453Z debug(replica): 0n: commit_start_journal: cached prepare op=175 checksum=8021b09f3efb26cd35f32257145057d1
2026-01-23 19:48:34.453Z debug(vsr): 1: grid_repair_budget_timeout fired
2026-01-23 19:48:34.453Z debug(vsr): 1: grid_repair_budget_timeout reset
2026-01-23 19:48:34.462Z debug(replica): 0n: execute_op: executing view=1 primary=false op=175 checksum=8021b09f3efb26cd35f32257145057d1 (create_transfers)
2026-01-23 19:48:34.462Z debug(replica): 0n: execute_op: commit_timestamp=1769197479740509710 prepare.header.timestamp=1769197479780158100
2026-01-23 19:48:34.474Z debug(vsr): 1: journal_repair_budget_timeout fired
2026-01-23 19:48:34.474Z debug(vsr): 1: journal_repair_budget_timeout reset
2026-01-23 19:48:34.494Z debug(vsr): 1: journal_repair_budget_timeout fired
2026-01-23 19:48:34.494Z debug(vsr): 1: journal_repair_budget_timeout reset
2026-01-23 19:48:34.502Z debug(replica): 0n: client_table_entry_update: client=60324011015611665437153036865704073740 session=2 request=173
2026-01-23 19:48:34.502Z debug(replica): 0n: execute_op: replying to client: Reply{ .checksum=d030b40673fd9b6bdf71be9ed0d07db4, .checksum_body=ea896edcb0f638197c53a5b6a59e1ab2, .cluster=0, .size=264, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.reply, .replica=1, .request_checksum=d40536dfa21dc1f3be1f116ac61430a0, .context=a88165edd9b58e18081879141998082f, .client=60324011015611665437153036865704073740, .op=175, .commit=175, .timestamp=1769197479780158100, .request=173, .operation=vsr.Operation(139) }
2026-01-23 19:48:34.502Z debug(replica): 0n: sending reply to client 60324011015611665437153036865704073740: Reply{ .checksum=d030b40673fd9b6bdf71be9ed0d07db4, .checksum_body=ea896edcb0f638197c53a5b6a59e1ab2, .cluster=0, .size=264, .epoch=0, .view=1, .release=0.0.1, .protocol=0, .command=vsr.Command.reply, .replica=1, .request_checksum=d40536dfa21dc1f3be1f116ac61430a0, .context=a88165edd9b58e18081879141998082f, .client=60324011015611665437153036865704073740, .op=175, .commit=175, .timestamp=1769197479780158100, .request=173, .operation=vsr.Operation(139) }
2026-01-23 19:48:34.502Z debug(forest): entering forest.compact() op=175 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=true half_beat=false last_beat=false
2026-01-23 19:48:34.502Z debug(manifest_log): 0: flush: writing 0 block(s)
2026-01-23 19:48:34.503Z debug(message_bus): 1: on_connect_with_exponential_backoff: to=2
2026-01-23 19:48:34.503Z info(message_bus): 1: on_connect: connected to=2
2026-01-23 19:48:34.503Z warning(faulty_network): connect failed (2,6): error.ConnectionRefused
2026-01-23 19:48:34.503Z warning(message_bus): 1: on_recv: from=vsr.Peer{ .replica = 2 } error.ConnectionResetByPeer
2026-01-23 19:48:34.504Z debug(message_bus): 1: connect_to_replica: connecting to=2 after=76ms
2026-01-23 19:48:34.504Z debug(vsr): 1: pulse_timeout fired
2026-01-23 19:48:34.504Z debug(vsr): 1: pulse_timeout reset
2026-01-23 19:48:34.514Z debug(vsr): 1: journal_repair_budget_timeout fired
2026-01-23 19:48:34.514Z debug(vsr): 1: journal_repair_budget_timeout reset
2026-01-23 19:48:34.517Z debug(message_bus): 0: on_connect_with_exponential_backoff: to=2
2026-01-23 19:48:34.517Z debug(vsr): 0: journal_repair_timeout fired
2026-01-23 19:48:34.517Z debug(vsr): 0: journal_repair_timeout reset
2026-01-23 19:48:34.517Z debug(client_replies): 0: write_reply: wrote (client=60324011015611665437153036865704073740 request=173)
2026-01-23 19:48:34.517Z info(message_bus): 0: on_connect: connected to=2
2026-01-23 19:48:34.517Z warning(faulty_network): connect failed (2,7): error.ConnectionRefused
2026-01-23 19:48:34.517Z info(message_bus): 0: on_recv: from=vsr.Peer{ .replica = 2 } orderly shutdown
2026-01-23 19:48:34.527Z debug(message_bus): 0: connect_to_replica: connecting to=2 after=53ms
2026-01-23 19:48:34.527Z debug(vsr): 0: journal_repair_budget_timeout fired
2026-01-23 19:48:34.527Z debug(vsr): 0: journal_repair_budget_timeout reset
2026-01-23 19:48:34.534Z debug(vsr): 1: journal_repair_budget_timeout fired
2026-01-23 19:48:34.534Z debug(vsr): 1: journal_repair_budget_timeout reset
2026-01-23 19:48:34.547Z debug(vsr): 0: journal_repair_budget_timeout fired
2026-01-23 19:48:34.547Z debug(vsr): 0: journal_repair_budget_timeout reset
2026-01-23 19:48:34.550Z warning(faulty_network): connect failed (2,8): error.ConnectionRefused
2026-01-23 19:48:34.554Z debug(vsr): 1: journal_repair_budget_timeout fired
2026-01-23 19:48:34.554Z debug(vsr): 1: journal_repair_budget_timeout reset
2026-01-23 19:48:34.554Z debug(vsr): 1: journal_repair_timeout fired
2026-01-23 19:48:34.554Z debug(vsr): 1: journal_repair_timeout reset
2026-01-23 19:48:34.557Z info(message_bus): 1: set_and_verify_peer connection from client_likely=60324011015611665437153036865704073740
2026-01-23 19:48:34.560Z error(supervisor): liveness check: too slow request
2026-01-23 19:48:34.561Z info(supervisor): 0: terminating replica
2026-01-23 19:48:34.572Z info(supervisor): 1: terminating replica
2026-01-23 19:48:34.613Z error: TestFailed
/root/tigerbeetle/working/main/src/testing/vortex/supervisor.zig:296:21: warning(message_bus): 60324011015611665437153036865704073740: on_recv: from=vsr.Peer{ .replica = 2 } error.ConnectionResetByPeer
0x1308030 in run (vortex)
                    return error.TestFailed;
                    ^
/root/tigerbeetle/working/main/src/testing/vortex/supervisor.zig:208:5: 0x130cbe3 in main (vortex)
    try supervisor.run();
    ^
/root/tigerbeetle/working/main/src/vortex.zig:61:42: 0x1321844 in main (vortex)
        .supervisor => |supervisor_args| try Supervisor.main(allocator, supervisor_args),
                                         ^
warning(message_bus): 60324011015611665437153036865704073740: on_recv: from=vsr.Peer{ .replica = 1 } error.ConnectionResetByPeer
