peration(141), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 19677962, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:06:14.390Z debug(replica): 0N: on_request: replying to duplicate request
2025-11-24 15:06:14.390Z debug(replica): 0N: on_request: repeat reply (client=101421002854235361169396488099400081924 request=209)
2025-11-24 15:06:14.390Z debug(replica): 0N: sending reply to client 101421002854235361169396488099400081924: vsr.message_header.Header.Reply{ .checksum = 112885022171563031936178497488440041950, .checksum_padding = 0, .checksum_body = 183786391390144677555054401985151236491, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 1045376, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 235226851671671726055068791918324761811, .request_checksum_padding = 0, .context = 79196918911633558939602569747337120314, .context_padding = 0, .client = 101421002854235361169396488099400081924, .op = 211, .commit = 211, .timestamp = 1763996771917755984, .request = 209, .operation = vsr.Operation(141), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:06:14.391Z debug(client_replies): 0: write_reply: wrote (client=101421002854235361169396488099400081924 request=209)
2025-11-24 15:06:14.391Z debug(replica): 0N: on_message: view=3 status=normal vsr.message_header.Header.PrepareOk{ .checksum = 91073357026093701563038286151857627670, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 193226090453100317862414166645531597431, .parent_padding = 0, .prepare_checksum = 28385961313339947399459890811700440956, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 101421002854235361169396488099400081924, .op = 211, .commit_min = 210, .timestamp = 1763996771917755984, .request = 209, .operation = vsr.Operation(141), .reserved = { 0, 0, 0 } }
2025-11-24 15:06:14.391Z debug(replica): 0N: on_prepare_ok: not preparing op=211 checksum=28385961313339947399459890811700440956
2025-11-24 15:06:14.398Z debug(vsr): 2: journal_repair_budget_timeout fired
2025-11-24 15:06:14.398Z debug(vsr): 2: journal_repair_budget_timeout reset
warning(client): 101421002854235361169396488099400081924: on_reply: slow request, request=209 op=211 size=130896 lookup_transfers time=2482ms
2025-11-24 15:06:14.398Z debug(vsr): 1: journal_repair_budget_timeout fired
2025-11-24 15:06:14.398Z debug(vsr): 1: journal_repair_budget_timeout reset
2025-11-24 15:06:14.400Z debug(replica): 0N: on_message: view=3 status=normal vsr.message_header.Header.Request{ .checksum = 115449984928822751235730838531135597507, .checksum_padding = 0, .checksum_body = 144059847831243404350899927634767905925, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2320, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 79196918911633558939602569747337120314, .parent_padding = 0, .client = 101421002854235361169396488099400081924, .session = 2, .timestamp = 0, .request = 210, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 2482371244, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:06:14.400Z debug(replica): 0N: on_request: new request
2025-11-24 15:06:14.400Z debug(replica): 0N: primary_pipeline_prepare: request checksum=115449984928822751235730838531135597507 client=101421002854235361169396488099400081924
2025-11-24 15:06:14.400Z debug(replica): 0N: primary_pipeline_prepare: prepare checksum=94494074500428809951992260196372646368 op=212
2025-11-24 15:06:14.400Z debug(replica): 2n: on_message: view=3 status=normal vsr.message_header.Header.Request{ .checksum = 115449984928822751235730838531135597507, .checksum_padding = 0, .checksum_body = 144059847831243404350899927634767905925, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2320, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 79196918911633558939602569747337120314, .parent_padding = 0, .client = 101421002854235361169396488099400081924, .session = 2, .timestamp = 0, .request = 210, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 2482371244, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:06:14.400Z debug(vsr): 0: prepare_timeout started
2025-11-24 15:06:14.400Z debug(vsr): 0: primary_abdicate_timeout started
2025-11-24 15:06:14.400Z debug(vsr): 0: pulse_timeout reset
2025-11-24 15:06:14.400Z debug(replica): 2n: on_request: forwarding new request to primary (view=3)
2025-11-24 15:06:14.400Z debug(replica): 0N: replicate: replicating op=212 to replica 2
2025-11-24 15:06:14.400Z debug(replica): 2n: sending request to replica 0: vsr.message_header.Header.Request{ .checksum = 115449984928822751235730838531135597507, .checksum_padding = 0, .checksum_body = 144059847831243404350899927634767905925, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2320, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 79196918911633558939602569747337120314, .parent_padding = 0, .client = 101421002854235361169396488099400081924, .session = 2, .timestamp = 0, .request = 210, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 2482371244, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:06:14.400Z debug(replica): 0N: sending prepare to replica 2: vsr.message_header.Header.Prepare{ .checksum = 94494074500428809951992260196372646368, .checksum_padding = 0, .checksum_body = 144059847831243404350899927634767905925, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2320, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 28385961313339947399459890811700440956, .parent_padding = 0, .request_checksum = 115449984928822751235730838531135597507, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 101421002854235361169396488099400081924, .op = 212, .commit = 211, .timestamp = 1763996774400289677, .request = 210, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-11-24 15:06:14.400Z debug(replica): 0N: replicate: replicating op=212 to replica 1
2025-11-24 15:06:14.400Z debug(replica): 0N: sending prepare to replica 1: vsr.message_header.Header.Prepare{ .checksum = 94494074500428809951992260196372646368, .checksum_padding = 0, .checksum_body = 144059847831243404350899927634767905925, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2320, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 28385961313339947399459890811700440956, .parent_padding = 0, .request_checksum = 115449984928822751235730838531135597507, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 101421002854235361169396488099400081924, .op = 212, .commit = 211, .timestamp = 1763996774400289677, .request = 210, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-11-24 15:06:14.400Z debug(replica): 0N: on_prepare: advancing: op=211..212 checksum=28385961313339947399459890811700440956..94494074500428809951992260196372646368
2025-11-24 15:06:14.400Z debug(journal): 0: set_header_as_dirty: op=212 checksum=94494074500428809951992260196372646368
2025-11-24 15:06:14.400Z debug(replica): 0N: append: appending to journal op=212
2025-11-24 15:06:14.400Z debug(journal): 0: write: view=3 slot=212 op=212 len=2320: 94494074500428809951992260196372646368 starting
2025-11-24 15:06:14.400Z debug(journal): 0: write_sectors: ring=vsr.journal.Ring.prepares offset=222298112 len=4096 locked
2025-11-24 15:06:14.400Z debug(replica): 2n: on_message: view=3 status=normal vsr.message_header.Header.Prepare{ .checksum = 94494074500428809951992260196372646368, .checksum_padding = 0, .checksum_body = 144059847831243404350899927634767905925, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2320, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 28385961313339947399459890811700440956, .parent_padding = 0, .request_checksum = 115449984928822751235730838531135597507, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 101421002854235361169396488099400081924, .op = 212, .commit = 211, .timestamp = 1763996774400289677, .request = 210, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-11-24 15:06:14.400Z debug(replica): 2n: on_prepare: advancing commit_max=210..211
2025-11-24 15:06:14.400Z debug(replica): 2n: on_prepare: caching prepare.op=212 (commit_min=210 op=211 commit_max=211 prepare_max=1007)
2025-11-24 15:06:14.400Z debug(replica): 1n: on_message: view=3 status=normal vsr.message_header.Header.Prepare{ .checksum = 94494074500428809951992260196372646368, .checksum_padding = 0, .checksum_body = 144059847831243404350899927634767905925, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2320, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 28385961313339947399459890811700440956, .parent_padding = 0, .request_checksum = 115449984928822751235730838531135597507, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 101421002854235361169396488099400081924, .op = 212, .commit = 211, .timestamp = 1763996774400289677, .request = 210, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-11-24 15:06:14.400Z debug(replica): 1n: on_prepare: advancing commit_max=210..211
2025-11-24 15:06:14.400Z debug(replica): 1n: on_prepare: caching prepare.op=212 (commit_min=210 op=211 commit_max=211 prepare_max=1007)
2025-11-24 15:06:14.400Z debug(replica): 2n: on_prepare: advancing: op=211..212 checksum=28385961313339947399459890811700440956..94494074500428809951992260196372646368
2025-11-24 15:06:14.400Z debug(journal): 2: set_header_as_dirty: op=212 checksum=94494074500428809951992260196372646368
2025-11-24 15:06:14.400Z debug(replica): 0N: on_message: view=3 status=normal vsr.message_header.Header.Request{ .checksum = 115449984928822751235730838531135597507, .checksum_padding = 0, .checksum_body = 144059847831243404350899927634767905925, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2320, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 79196918911633558939602569747337120314, .parent_padding = 0, .client = 101421002854235361169396488099400081924, .session = 2, .timestamp = 0, .request = 210, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 2482371244, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:06:14.400Z debug(replica): 2n: append: appending to journal op=212
2025-11-24 15:06:14.400Z debug(replica): 0N: on_request: new request
2025-11-24 15:06:14.400Z debug(journal): 2: write: view=3 slot=212 op=212 len=2320: 94494074500428809951992260196372646368 starting
2025-11-24 15:06:14.400Z debug(replica): 0N: on_request: ignoring (already preparing)
2025-11-24 15:06:14.400Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.prepares offset=222298112 len=4096 locked
2025-11-24 15:06:14.400Z debug(replica): 2n: commit_start_journal: cached prepare op=211 checksum=28385961313339947399459890811700440956
2025-11-24 15:06:14.400Z debug(replica): 1n: on_prepare: advancing: op=211..212 checksum=28385961313339947399459890811700440956..94494074500428809951992260196372646368
2025-11-24 15:06:14.400Z debug(journal): 1: set_header_as_dirty: op=212 checksum=94494074500428809951992260196372646368
2025-11-24 15:06:14.400Z debug(replica): 1n: append: appending to journal op=212
2025-11-24 15:06:14.400Z debug(journal): 1: write: view=3 slot=212 op=212 len=2320: 94494074500428809951992260196372646368 starting
2025-11-24 15:06:14.400Z debug(journal): 0: write_sectors: ring=vsr.journal.Ring.prepares offset=222298112 len=4096 unlocked
2025-11-24 15:06:14.400Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.prepares offset=222298112 len=4096 locked
2025-11-24 15:06:14.400Z debug(journal): 0: write_header: op=212 sectors[53248..57344]
2025-11-24 15:06:14.400Z debug(journal): 0: write_sectors: ring=vsr.journal.Ring.headers offset=53248 len=4096 locked
2025-11-24 15:06:14.400Z debug(replica): 1n: commit_start_journal: cached prepare op=211 checksum=28385961313339947399459890811700440956
2025-11-24 15:06:14.400Z debug(journal): 0: write_sectors: ring=vsr.journal.Ring.headers offset=53248 len=4096 unlocked
2025-11-24 15:06:14.400Z debug(journal): 0: write: view=3 slot=212 op=212 len=2320: 94494074500428809951992260196372646368 complete, marking clean
2025-11-24 15:06:14.400Z debug(replica): 0N: send_prepare_ok: op=212 checksum=94494074500428809951992260196372646368
2025-11-24 15:06:14.400Z debug(replica): 0N: sending prepare_ok to replica 0: vsr.message_header.Header.PrepareOk{ .checksum = 201791365988467902866233860155442714653, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 28385961313339947399459890811700440956, .parent_padding = 0, .prepare_checksum = 94494074500428809951992260196372646368, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 101421002854235361169396488099400081924, .op = 212, .commit_min = 211, .timestamp = 1763996774400289677, .request = 210, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-11-24 15:06:14.400Z debug(replica): 0N: on_message: view=3 status=normal vsr.message_header.Header.PrepareOk{ .checksum = 201791365988467902866233860155442714653, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 28385961313339947399459890811700440956, .parent_padding = 0, .prepare_checksum = 94494074500428809951992260196372646368, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 101421002854235361169396488099400081924, .op = 212, .commit_min = 211, .timestamp = 1763996774400289677, .request = 210, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-11-24 15:06:14.400Z debug(vsr): 0: primary_abdicate_timeout reset
2025-11-24 15:06:14.400Z debug(replica): 0N: on_prepare_ok: 1 message(s)
2025-11-24 15:06:14.400Z debug(replica): 0N: on_prepare_ok: waiting for quorum
2025-11-24 15:06:14.402Z debug(vsr): 0: journal_repair_budget_timeout fired
2025-11-24 15:06:14.402Z debug(vsr): 0: journal_repair_budget_timeout reset
2025-11-24 15:06:14.403Z debug(replica): 2n: repair_prepare: op=212 checksum=94494074500428809951992260196372646368 (already writing)
2025-11-24 15:06:14.403Z debug(replica): 2n: commit_journal: already committing (prefetch; commit_min=210)
2025-11-24 15:06:14.403Z debug(replica): 2n: execute_op: executing view=3 primary=false op=211 checksum=28385961313339947399459890811700440956 (lookup_transfers)
2025-11-24 15:06:14.403Z debug(replica): 2n: execute_op: commit_timestamp=1763996771896318402 prepare.header.timestamp=1763996771917755984
2025-11-24 15:06:14.403Z debug(replica): 1n: repair_prepare: op=212 checksum=94494074500428809951992260196372646368 (already writing)
2025-11-24 15:06:14.403Z debug(replica): 1n: commit_journal: already committing (prefetch; commit_min=210)
2025-11-24 15:06:14.403Z debug(replica): 1n: execute_op: executing view=3 primary=false op=211 checksum=28385961313339947399459890811700440956 (lookup_transfers)
2025-11-24 15:06:14.403Z debug(replica): 1n: execute_op: commit_timestamp=1763996771896318402 prepare.header.timestamp=1763996771917755984
2025-11-24 15:06:14.411Z debug(replica): 2n: client_table_entry_update: client=101421002854235361169396488099400081924 session=2 request=209
2025-11-24 15:06:14.411Z debug(forest): entering forest.compact() op=211 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2025-11-24 15:06:14.411Z debug(replica): 1n: client_table_entry_update: client=101421002854235361169396488099400081924 session=2 request=209
2025-11-24 15:06:14.411Z debug(replica): 1n: execute_op: replying to client: vsr.message_header.Header.Reply{ .checksum = 112885022171563031936178497488440041950, .checksum_padding = 0, .checksum_body = 183786391390144677555054401985151236491, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 1045376, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 235226851671671726055068791918324761811, .request_checksum_padding = 0, .context = 79196918911633558939602569747337120314, .context_padding = 0, .client = 101421002854235361169396488099400081924, .op = 211, .commit = 211, .timestamp = 1763996771917755984, .request = 209, .operation = vsr.Operation(141), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:06:14.411Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.prepares offset=222298112 len=4096 unlocked
2025-11-24 15:06:14.411Z debug(journal): 2: write_header: op=212 sectors[53248..57344]
2025-11-24 15:06:14.411Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.headers offset=53248 len=4096 locked
2025-11-24 15:06:14.411Z debug(replica): 1n: sending reply to client 101421002854235361169396488099400081924: vsr.message_header.Header.Reply{ .checksum = 112885022171563031936178497488440041950, .checksum_padding = 0, .checksum_body = 183786391390144677555054401985151236491, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 1045376, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 235226851671671726055068791918324761811, .request_checksum_padding = 0, .context = 79196918911633558939602569747337120314, .context_padding = 0, .client = 101421002854235361169396488099400081924, .op = 211, .commit = 211, .timestamp = 1763996771917755984, .request = 209, .operation = vsr.Operation(141), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:06:14.412Z debug(forest): entering forest.compact() op=211 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2025-11-24 15:06:14.412Z debug(client_replies): 2: write_reply: wrote (client=101421002854235361169396488099400081924 request=209)
2025-11-24 15:06:14.412Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.headers offset=53248 len=4096 unlocked
2025-11-24 15:06:14.412Z debug(journal): 2: write: view=3 slot=212 op=212 len=2320: 94494074500428809951992260196372646368 complete, marking clean
2025-11-24 15:06:14.412Z debug(replica): 2n: send_prepare_ok: op=212 checksum=94494074500428809951992260196372646368
2025-11-24 15:06:14.412Z debug(replica): 2n: sending prepare_ok to replica 0: vsr.message_header.Header.PrepareOk{ .checksum = 126387586964381160847484476472295204544, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 28385961313339947399459890811700440956, .parent_padding = 0, .prepare_checksum = 94494074500428809951992260196372646368, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 101421002854235361169396488099400081924, .op = 212, .commit_min = 211, .timestamp = 1763996774400289677, .request = 210, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-11-24 15:06:14.412Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.prepares offset=222298112 len=4096 unlocked
2025-11-24 15:06:14.412Z debug(journal): 1: write_header: op=212 sectors[53248..57344]
2025-11-24 15:06:14.412Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.headers offset=53248 len=4096 locked
2025-11-24 15:06:14.412Z debug(client_replies): 1: write_reply: wrote (client=101421002854235361169396488099400081924 request=209)
2025-11-24 15:06:14.412Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.headers offset=53248 len=4096 unlocked
2025-11-24 15:06:14.412Z debug(journal): 1: write: view=3 slot=212 op=212 len=2320: 94494074500428809951992260196372646368 complete, marking clean
2025-11-24 15:06:14.412Z debug(replica): 1n: send_prepare_ok: op=212 checksum=94494074500428809951992260196372646368
2025-11-24 15:06:14.412Z debug(replica): 1n: sending prepare_ok to replica 0: vsr.message_header.Header.PrepareOk{ .checksum = 324357511690542346079089279507382990788, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 28385961313339947399459890811700440956, .parent_padding = 0, .prepare_checksum = 94494074500428809951992260196372646368, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 101421002854235361169396488099400081924, .op = 212, .commit_min = 211, .timestamp = 1763996774400289677, .request = 210, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-11-24 15:06:14.413Z debug(replica): 0N: on_message: view=3 status=normal vsr.message_header.Header.PrepareOk{ .checksum = 324357511690542346079089279507382990788, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 28385961313339947399459890811700440956, .parent_padding = 0, .prepare_checksum = 94494074500428809951992260196372646368, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 101421002854235361169396488099400081924, .op = 212, .commit_min = 211, .timestamp = 1763996774400289677, .request = 210, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-11-24 15:06:14.413Z debug(vsr): 0: primary_abdicate_timeout reset
2025-11-24 15:06:14.413Z debug(replica): 0N: on_prepare_ok: 2 message(s)
2025-11-24 15:06:14.413Z debug(replica): 0N: on_prepare_ok: quorum received, context=94494074500428809951992260196372646368
2025-11-24 15:06:14.413Z debug(vsr): 0: prepare_timeout stopped
2025-11-24 15:06:14.413Z debug(vsr): 0: primary_abdicate_timeout stopped
2025-11-24 15:06:14.413Z debug(replica): 0N: execute_op: executing view=3 primary=true op=212 checksum=94494074500428809951992260196372646368 (lookup_accounts)
2025-11-24 15:06:14.413Z debug(replica): 0N: execute_op: commit_timestamp=1763996771917755984 prepare.header.timestamp=1763996774400289677
2025-11-24 15:06:14.413Z debug(replica): 0N: execute_op: advancing commit_max=211..212
2025-11-24 15:06:14.413Z debug(replica): 0N: client_table_entry_update: client=101421002854235361169396488099400081924 session=2 request=210
2025-11-24 15:06:14.413Z debug(replica): 0N: execute_op: replying to client: vsr.message_header.Header.Reply{ .checksum = 298938184093517837143799942585926542657, .checksum_padding = 0, .checksum_body = 312103870462265314276609012122658931960, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 16768, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 115449984928822751235730838531135597507, .request_checksum_padding = 0, .context = 4124587946810031268522261023791146686, .context_padding = 0, .client = 101421002854235361169396488099400081924, .op = 212, .commit = 212, .timestamp = 1763996774400289677, .request = 210, .operation = vsr.Operation(140), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:06:14.413Z debug(replica): 0N: sending reply to client 101421002854235361169396488099400081924: vsr.message_header.Header.Reply{ .checksum = 298938184093517837143799942585926542657, .checksum_padding = 0, .checksum_body = 312103870462265314276609012122658931960, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 16768, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 115449984928822751235730838531135597507, .request_checksum_padding = 0, .context = 4124587946810031268522261023791146686, .context_padding = 0, .client = 101421002854235361169396488099400081924, .op = 212, .commit = 212, .timestamp = 1763996774400289677, .request = 210, .operation = vsr.Operation(140), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:06:14.413Z debug(forest): entering forest.compact() op=212 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2025-11-24 15:06:14.413Z debug(client_replies): 0: write_reply: wrote (client=101421002854235361169396488099400081924 request=210)
2025-11-24 15:06:14.419Z info(workload): accounts created = 128, transfers = 260331, pending transfers = 0, commands run = 105
2025-11-24 15:06:14.421Z debug(vsr): 2: journal_repair_budget_timeout fired
2025-11-24 15:06:14.421Z debug(vsr): 2: journal_repair_budget_timeout reset
2025-11-24 15:06:14.422Z debug(vsr): 0: journal_repair_budget_timeout fired
2025-11-24 15:06:14.422Z debug(vsr): 0: journal_repair_budget_timeout reset
2025-11-24 15:06:14.422Z debug(vsr): 1: journal_repair_budget_timeout fired
2025-11-24 15:06:14.422Z debug(vsr): 1: journal_repair_budget_timeout reset
2025-11-24 15:06:14.430Z debug(replica): 0N: on_message: view=3 status=normal vsr.message_header.Header.Request{ .checksum = 132290692373440502538877136281720168916, .checksum_padding = 0, .checksum_body = 56525685457247885145574699820695529471, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 130896, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 4124587946810031268522261023791146686, .parent_padding = 0, .client = 101421002854235361169396488099400081924, .session = 2, .timestamp = 0, .request = 211, .operation = vsr.Operation(141), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 19197063, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:06:14.430Z debug(replica): 0N: on_request: new request
2025-11-24 15:06:14.430Z debug(replica): 2n: on_message: view=3 status=normal vsr.message_header.Header.Request{ .checksum = 132290692373440502538877136281720168916, .checksum_padding = 0, .checksum_body = 56525685457247885145574699820695529471, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 130896, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 4124587946810031268522261023791146686, .parent_padding = 0, .client = 101421002854235361169396488099400081924, .session = 2, .timestamp = 0, .request = 211, .operation = vsr.Operation(141), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 19197063, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:06:14.430Z debug(replica): 0N: primary_pipeline_prepare: request checksum=132290692373440502538877136281720168916 client=101421002854235361169396488099400081924
2025-11-24 15:06:14.430Z debug(replica): 2n: on_request: forwarding new request to primary (view=3)
2025-11-24 15:06:14.430Z debug(replica): 2n: sending request to replica 0: vsr.message_header.Header.Request{ .checksum = 132290692373440502538877136281720168916, .checksum_padding = 0, .checksum_body = 56525685457247885145574699820695529471, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 130896, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 4124587946810031268522261023791146686, .parent_padding = 0, .client = 101421002854235361169396488099400081924, .session = 2, .timestamp = 0, .request = 211, .operation = vsr.Operation(141), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 19197063, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:06:14.430Z debug(replica): 0N: primary_pipeline_prepare: prepare checksum=24895070543608533096765633283485941163 op=213
2025-11-24 15:06:14.430Z debug(vsr): 0: prepare_timeout started
2025-11-24 15:06:14.430Z debug(vsr): 0: primary_abdicate_timeout started
2025-11-24 15:06:14.430Z debug(vsr): 0: pulse_timeout reset
2025-11-24 15:06:14.430Z debug(replica): 0N: replicate: replicating op=213 to replica 2
2025-11-24 15:06:14.431Z debug(vsr): 2: journal_repair_timeout fired
2025-11-24 15:06:14.431Z debug(vsr): 2: journal_repair_timeout reset
2025-11-24 15:06:14.442Z debug(vsr): 2: journal_repair_budget_timeout fired
2025-11-24 15:06:14.442Z debug(vsr): 2: journal_repair_budget_timeout reset
2025-11-24 15:06:14.442Z debug(vsr): 1: journal_repair_budget_timeout fired
2025-11-24 15:06:14.442Z debug(vsr): 1: journal_repair_budget_timeout reset
2025-11-24 15:06:14.430Z debug(replica): 0N: sending prepare to replica 2: vsr.message_header.Header.Prepare{ .checksum = 24895070543608533096765633283485941163, .checksum_padding = 0, .checksum_body = 56525685457247885145574699820695529471, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 130896, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 94494074500428809951992260196372646368, .parent_padding = 0, .request_checksum = 132290692373440502538877136281720168916, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 101421002854235361169396488099400081924, .op = 213, .commit = 212, .timestamp = 1763996774430084126, .request = 211, .operation = vsr.Operation(141), .reserved = { 0, 0, 0 } }
2025-11-24 15:06:14.462Z debug(vsr): 2: journal_repair_budget_timeout fired
2025-11-24 15:06:14.442Z debug(vsr): 1: journal_repair_timeout fired
2025-11-24 15:06:16.720Z debug(vsr): 2: journal_repair_budget_timeout reset
2025-11-24 15:06:16.720Z debug(vsr): 1: journal_repair_timeout reset
2025-11-24 15:06:16.720Z debug(replica): 0N: replicate: replicating op=213 to replica 1
2025-11-24 15:06:16.720Z debug(replica): 0N: sending prepare to replica 1: vsr.message_header.Header.Prepare{ .checksum = 24895070543608533096765633283485941163, .checksum_padding = 0, .checksum_body = 56525685457247885145574699820695529471, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 130896, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 94494074500428809951992260196372646368, .parent_padding = 0, .request_checksum = 132290692373440502538877136281720168916, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 101421002854235361169396488099400081924, .op = 213, .commit = 212, .timestamp = 1763996774430084126, .request = 211, .operation = vsr.Operation(141), .reserved = { 0, 0, 0 } }
2025-11-24 15:06:16.720Z debug(replica): 0N: on_prepare: advancing: op=212..213 checksum=94494074500428809951992260196372646368..24895070543608533096765633283485941163
2025-11-24 15:06:16.720Z debug(journal): 0: set_header_as_dirty: op=213 checksum=24895070543608533096765633283485941163
2025-11-24 15:06:16.720Z debug(replica): 0N: append: appending to journal op=213
2025-11-24 15:06:16.721Z debug(journal): 0: write: view=3 slot=213 op=213 len=130896: 24895070543608533096765633283485941163 starting
2025-11-24 15:06:16.721Z debug(journal): 0: write_sectors: ring=vsr.journal.Ring.prepares offset=223346688 len=131072 locked
2025-11-24 15:06:16.721Z debug(replica): 0N: on_message: view=3 status=normal vsr.message_header.Header.PrepareOk{ .checksum = 126387586964381160847484476472295204544, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 28385961313339947399459890811700440956, .parent_padding = 0, .prepare_checksum = 94494074500428809951992260196372646368, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 101421002854235361169396488099400081924, .op = 212, .commit_min = 211, .timestamp = 1763996774400289677, .request = 210, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-11-24 15:06:16.721Z debug(replica): 0N: on_prepare_ok: not preparing op=212 checksum=94494074500428809951992260196372646368
2025-11-24 15:06:16.721Z debug(replica): 2n: on_message: view=3 status=normal vsr.message_header.Header.Request{ .checksum = 132290692373440502538877136281720168916, .checksum_padding = 0, .checksum_body = 56525685457247885145574699820695529471, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 130896, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 4124587946810031268522261023791146686, .parent_padding = 0, .client = 101421002854235361169396488099400081924, .session = 2, .timestamp = 0, .request = 211, .operation = vsr.Operation(141), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 19197063, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:06:16.721Z debug(replica): 2n: on_request: forwarding new request to primary (view=3)
2025-11-24 15:06:16.721Z debug(replica): 2n: sending request to replica 0: vsr.message_header.Header.Request{ .checksum = 132290692373440502538877136281720168916, .checksum_padding = 0, .checksum_body = 56525685457247885145574699820695529471, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 130896, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 4124587946810031268522261023791146686, .parent_padding = 0, .client = 101421002854235361169396488099400081924, .session = 2, .timestamp = 0, .request = 211, .operation = vsr.Operation(141), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 19197063, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:06:16.721Z debug(replica): 1n: on_message: view=3 status=normal vsr.message_header.Header.Request{ .checksum = 132290692373440502538877136281720168916, .checksum_padding = 0, .checksum_body = 56525685457247885145574699820695529471, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 130896, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 4124587946810031268522261023791146686, .parent_padding = 0, .client = 101421002854235361169396488099400081924, .session = 2, .timestamp = 0, .request = 211, .operation = vsr.Operation(141), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 19197063, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:06:16.721Z debug(replica): 1n: on_request: forwarding new request to primary (view=3)
2025-11-24 15:06:16.721Z debug(replica): 1n: sending request to replica 0: vsr.message_header.Header.Request{ .checksum = 132290692373440502538877136281720168916, .checksum_padding = 0, .checksum_body = 56525685457247885145574699820695529471, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 130896, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 4124587946810031268522261023791146686, .parent_padding = 0, .client = 101421002854235361169396488099400081924, .session = 2, .timestamp = 0, .request = 211, .operation = vsr.Operation(141), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 19197063, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:06:16.722Z debug(replica): 2n: on_message: view=3 status=normal vsr.message_header.Header.Prepare{ .checksum = 24895070543608533096765633283485941163, .checksum_padding = 0, .checksum_body = 56525685457247885145574699820695529471, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 130896, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 94494074500428809951992260196372646368, .parent_padding = 0, .request_checksum = 132290692373440502538877136281720168916, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 101421002854235361169396488099400081924, .op = 213, .commit = 212, .timestamp = 1763996774430084126, .request = 211, .operation = vsr.Operation(141), .reserved = { 0, 0, 0 } }
2025-11-24 15:06:16.722Z debug(replica): 2n: on_prepare: advancing commit_max=211..212
2025-11-24 15:06:16.722Z debug(replica): 2n: on_prepare: caching prepare.op=213 (commit_min=211 op=212 commit_max=212 prepare_max=1007)
2025-11-24 15:06:16.722Z debug(replica): 2n: on_prepare: advancing: op=212..213 checksum=94494074500428809951992260196372646368..24895070543608533096765633283485941163
2025-11-24 15:06:16.722Z debug(journal): 2: set_header_as_dirty: op=213 checksum=24895070543608533096765633283485941163
2025-11-24 15:06:16.722Z debug(replica): 2n: append: appending to journal op=213
2025-11-24 15:06:16.722Z debug(journal): 2: write: view=3 slot=213 op=213 len=130896: 24895070543608533096765633283485941163 starting
2025-11-24 15:06:16.722Z debug(replica): 1n: on_message: view=3 status=normal vsr.message_header.Header.Prepare{ .checksum = 24895070543608533096765633283485941163, .checksum_padding = 0, .checksum_body = 56525685457247885145574699820695529471, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 130896, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 94494074500428809951992260196372646368, .parent_padding = 0, .request_checksum = 132290692373440502538877136281720168916, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 101421002854235361169396488099400081924, .op = 213, .commit = 212, .timestamp = 1763996774430084126, .request = 211, .operation = vsr.Operation(141), .reserved = { 0, 0, 0 } }
2025-11-24 15:06:16.722Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.prepares offset=223346688 len=131072 locked
2025-11-24 15:06:16.722Z debug(replica): 1n: on_prepare: advancing commit_max=211..212
2025-11-24 15:06:16.722Z debug(replica): 2n: commit_start_journal: cached prepare op=212 checksum=94494074500428809951992260196372646368
2025-11-24 15:06:16.722Z debug(replica): 1n: on_prepare: caching prepare.op=213 (commit_min=211 op=212 commit_max=212 prepare_max=1007)
2025-11-24 15:06:16.722Z debug(replica): 1n: on_prepare: advancing: op=212..213 checksum=94494074500428809951992260196372646368..24895070543608533096765633283485941163
2025-11-24 15:06:16.722Z debug(journal): 1: set_header_as_dirty: op=213 checksum=24895070543608533096765633283485941163
2025-11-24 15:06:16.722Z debug(replica): 1n: append: appending to journal op=213
2025-11-24 15:06:16.722Z debug(journal): 1: write: view=3 slot=213 op=213 len=130896: 24895070543608533096765633283485941163 starting
2025-11-24 15:06:16.722Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.prepares offset=223346688 len=131072 locked
2025-11-24 15:06:16.722Z debug(replica): 1n: commit_start_journal: cached prepare op=212 checksum=94494074500428809951992260196372646368
2025-11-24 15:06:16.722Z debug(replica): 0N: on_message: view=3 status=normal vsr.message_header.Header.Request{ .checksum = 132290692373440502538877136281720168916, .checksum_padding = 0, .checksum_body = 56525685457247885145574699820695529471, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 130896, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 4124587946810031268522261023791146686, .parent_padding = 0, .client = 101421002854235361169396488099400081924, .session = 2, .timestamp = 0, .request = 211, .operation = vsr.Operation(141), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 19197063, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:06:16.722Z debug(replica): 0N: on_request: new request
2025-11-24 15:06:16.722Z debug(replica): 0N: on_request: ignoring (already preparing)
2025-11-24 15:06:16.722Z debug(replica): 2n: repair_prepare: op=213 checksum=24895070543608533096765633283485941163 (already writing)
2025-11-24 15:06:16.722Z debug(replica): 2n: commit_journal: already committing (prefetch; commit_min=211)
2025-11-24 15:06:16.722Z debug(replica): 0N: on_message: view=3 status=normal vsr.message_header.Header.Request{ .checksum = 132290692373440502538877136281720168916, .checksum_padding = 0, .checksum_body = 56525685457247885145574699820695529471, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 130896, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 4124587946810031268522261023791146686, .parent_padding = 0, .client = 101421002854235361169396488099400081924, .session = 2, .timestamp = 0, .request = 211, .operation = vsr.Operation(141), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 19197063, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:06:16.722Z debug(replica): 0N: on_request: new request
2025-11-24 15:06:16.722Z debug(replica): 2n: execute_op: executing view=3 primary=false op=212 checksum=94494074500428809951992260196372646368 (lookup_accounts)
2025-11-24 15:06:16.722Z debug(replica): 0N: on_request: ignoring (already preparing)
2025-11-24 15:06:16.722Z debug(replica): 2n: execute_op: commit_timestamp=1763996771917755984 prepare.header.timestamp=1763996774400289677
2025-11-24 15:06:16.722Z debug(replica): 1n: repair_prepare: op=213 checksum=24895070543608533096765633283485941163 (already writing)
2025-11-24 15:06:16.722Z debug(journal): 0: write_sectors: ring=vsr.journal.Ring.prepares offset=223346688 len=131072 unlocked
2025-11-24 15:06:16.722Z debug(replica): 1n: commit_journal: already committing (prefetch; commit_min=211)
2025-11-24 15:06:16.722Z debug(journal): 0: write_header: op=213 sectors[53248..57344]
2025-11-24 15:06:16.722Z debug(journal): 0: write_sectors: ring=vsr.journal.Ring.headers offset=53248 len=4096 locked
2025-11-24 15:06:16.722Z debug(replica): 1n: execute_op: executing view=3 primary=false op=212 checksum=94494074500428809951992260196372646368 (lookup_accounts)
2025-11-24 15:06:16.722Z debug(replica): 1n: execute_op: commit_timestamp=1763996771917755984 prepare.header.timestamp=1763996774400289677
2025-11-24 15:06:16.722Z debug(replica): 2n: client_table_entry_update: client=101421002854235361169396488099400081924 session=2 request=210
2025-11-24 15:06:16.722Z debug(forest): entering forest.compact() op=212 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2025-11-24 15:06:16.722Z debug(replica): 1n: client_table_entry_update: client=101421002854235361169396488099400081924 session=2 request=210
2025-11-24 15:06:16.722Z debug(replica): 1n: execute_op: replying to client: vsr.message_header.Header.Reply{ .checksum = 298938184093517837143799942585926542657, .checksum_padding = 0, .checksum_body = 312103870462265314276609012122658931960, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 16768, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 115449984928822751235730838531135597507, .request_checksum_padding = 0, .context = 4124587946810031268522261023791146686, .context_padding = 0, .client = 101421002854235361169396488099400081924, .op = 212, .commit = 212, .timestamp = 1763996774400289677, .request = 210, .operation = vsr.Operation(140), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:06:16.722Z debug(replica): 1n: sending reply to client 101421002854235361169396488099400081924: vsr.message_header.Header.Reply{ .checksum = 298938184093517837143799942585926542657, .checksum_padding = 0, .checksum_body = 312103870462265314276609012122658931960, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 16768, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 115449984928822751235730838531135597507, .request_checksum_padding = 0, .context = 4124587946810031268522261023791146686, .context_padding = 0, .client = 101421002854235361169396488099400081924, .op = 212, .commit = 212, .timestamp = 1763996774400289677, .request = 210, .operation = vsr.Operation(140), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:06:16.722Z debug(forest): entering forest.compact() op=212 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2025-11-24 15:06:16.723Z debug(client_replies): 2: write_reply: wrote (client=101421002854235361169396488099400081924 request=210)
2025-11-24 15:06:16.723Z debug(client_replies): 1: write_reply: wrote (client=101421002854235361169396488099400081924 request=210)
2025-11-24 15:06:16.723Z debug(replica): 0N: on_message: view=3 status=normal vsr.message_header.Header.Request{ .checksum = 132290692373440502538877136281720168916, .checksum_padding = 0, .checksum_body = 56525685457247885145574699820695529471, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 130896, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 4124587946810031268522261023791146686, .parent_padding = 0, .client = 101421002854235361169396488099400081924, .session = 2, .timestamp = 0, .request = 211, .operation = vsr.Operation(141), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 19197063, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:06:16.723Z debug(replica): 0N: on_request: new request
2025-11-24 15:06:16.723Z debug(replica): 0N: on_request: ignoring (already preparing)
2025-11-24 15:06:16.723Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.prepares offset=223346688 len=131072 unlocked
2025-11-24 15:06:16.723Z debug(journal): 2: write_header: op=213 sectors[53248..57344]
2025-11-24 15:06:16.723Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.headers offset=53248 len=4096 locked
2025-11-24 15:06:16.723Z debug(journal): 0: write_sectors: ring=vsr.journal.Ring.headers offset=53248 len=4096 unlocked
2025-11-24 15:06:16.723Z debug(journal): 0: write: view=3 slot=213 op=213 len=130896: 24895070543608533096765633283485941163 complete, marking clean
2025-11-24 15:06:16.723Z debug(replica): 0N: send_prepare_ok: op=213 checksum=24895070543608533096765633283485941163
2025-11-24 15:06:16.723Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.headers offset=53248 len=4096 unlocked
2025-11-24 15:06:16.723Z debug(journal): 2: write: view=3 slot=213 op=213 len=130896: 24895070543608533096765633283485941163 complete, marking clean
2025-11-24 15:06:16.723Z debug(replica): 0N: sending prepare_ok to replica 0: vsr.message_header.Header.PrepareOk{ .checksum = 67595575248761493994703812304631568519, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 94494074500428809951992260196372646368, .parent_padding = 0, .prepare_checksum = 24895070543608533096765633283485941163, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 101421002854235361169396488099400081924, .op = 213, .commit_min = 212, .timestamp = 1763996774430084126, .request = 211, .operation = vsr.Operation(141), .reserved = { 0, 0, 0 } }
2025-11-24 15:06:16.723Z debug(replica): 2n: send_prepare_ok: op=213 checksum=24895070543608533096765633283485941163
2025-11-24 15:06:16.723Z debug(replica): 0N: on_message: view=3 status=normal vsr.message_header.Header.PrepareOk{ .checksum = 67595575248761493994703812304631568519, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 94494074500428809951992260196372646368, .parent_padding = 0, .prepare_checksum = 24895070543608533096765633283485941163, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 101421002854235361169396488099400081924, .op = 213, .commit_min = 212, .timestamp = 1763996774430084126, .request = 211, .operation = vsr.Operation(141), .reserved = { 0, 0, 0 } }
2025-11-24 15:06:16.723Z debug(vsr): 0: primary_abdicate_timeout reset
2025-11-24 15:06:16.723Z debug(replica): 2n: sending prepare_ok to replica 0: vsr.message_header.Header.PrepareOk{ .checksum = 259270917259995363528396267029111061269, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 94494074500428809951992260196372646368, .parent_padding = 0, .prepare_checksum = 24895070543608533096765633283485941163, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 101421002854235361169396488099400081924, .op = 213, .commit_min = 212, .timestamp = 1763996774430084126, .request = 211, .operation = vsr.Operation(141), .reserved = { 0, 0, 0 } }
2025-11-24 15:06:16.723Z debug(replica): 0N: on_prepare_ok: 1 message(s)
2025-11-24 15:06:16.723Z debug(replica): 0N: on_prepare_ok: waiting for quorum
2025-11-24 15:06:16.723Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.prepares offset=223346688 len=131072 unlocked
2025-11-24 15:06:16.723Z debug(journal): 1: write_header: op=213 sectors[53248..57344]
2025-11-24 15:06:16.723Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.headers offset=53248 len=4096 locked
2025-11-24 15:06:16.723Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.headers offset=53248 len=4096 unlocked
2025-11-24 15:06:16.723Z debug(journal): 1: write: view=3 slot=213 op=213 len=130896: 24895070543608533096765633283485941163 complete, marking clean
2025-11-24 15:06:16.723Z debug(replica): 1n: send_prepare_ok: op=213 checksum=24895070543608533096765633283485941163
2025-11-24 15:06:16.723Z debug(replica): 1n: sending prepare_ok to replica 0: vsr.message_header.Header.PrepareOk{ .checksum = 243041359368946798017258206084003510751, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 94494074500428809951992260196372646368, .parent_padding = 0, .prepare_checksum = 24895070543608533096765633283485941163, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 101421002854235361169396488099400081924, .op = 213, .commit_min = 212, .timestamp = 1763996774430084126, .request = 211, .operation = vsr.Operation(141), .reserved = { 0, 0, 0 } }
2025-11-24 15:06:16.724Z debug(replica): 0N: on_message: view=3 status=normal vsr.message_header.Header.Request{ .checksum = 132290692373440502538877136281720168916, .checksum_padding = 0, .checksum_body = 56525685457247885145574699820695529471, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 130896, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 4124587946810031268522261023791146686, .parent_padding = 0, .client = 101421002854235361169396488099400081924, .session = 2, .timestamp = 0, .request = 211, .operation = vsr.Operation(141), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 19197063, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:06:16.724Z debug(replica): 0N: on_request: new request
2025-11-24 15:06:16.724Z debug(replica): 0N: on_request: ignoring (already preparing)
2025-11-24 15:06:16.724Z debug(replica): 0N: on_message: view=3 status=normal vsr.message_header.Header.Request{ .checksum = 132290692373440502538877136281720168916, .checksum_padding = 0, .checksum_body = 56525685457247885145574699820695529471, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 130896, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 4124587946810031268522261023791146686, .parent_padding = 0, .client = 101421002854235361169396488099400081924, .session = 2, .timestamp = 0, .request = 211, .operation = vsr.Operation(141), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 19197063, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:06:16.724Z debug(replica): 0N: on_request: new request
2025-11-24 15:06:16.724Z debug(replica): 0N: on_request: ignoring (already preparing)
2025-11-24 15:06:16.724Z debug(replica): 0N: on_message: view=3 status=normal vsr.message_header.Header.PrepareOk{ .checksum = 243041359368946798017258206084003510751, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 94494074500428809951992260196372646368, .parent_padding = 0, .prepare_checksum = 24895070543608533096765633283485941163, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 101421002854235361169396488099400081924, .op = 213, .commit_min = 212, .timestamp = 1763996774430084126, .request = 211, .operation = vsr.Operation(141), .reserved = { 0, 0, 0 } }
2025-11-24 15:06:16.724Z debug(vsr): 0: primary_abdicate_timeout reset
2025-11-24 15:06:16.724Z debug(replica): 0N: on_prepare_ok: 2 message(s)
2025-11-24 15:06:16.724Z debug(replica): 0N: on_prepare_ok: quorum received, context=24895070543608533096765633283485941163
2025-11-24 15:06:16.724Z debug(vsr): 0: prepare_timeout stopped
2025-11-24 15:06:16.724Z debug(vsr): 0: primary_abdicate_timeout stopped
2025-11-24 15:06:16.726Z debug(replica): 0N: on_message: view=3 status=normal vsr.message_header.Header.PrepareOk{ .checksum = 259270917259995363528396267029111061269, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 94494074500428809951992260196372646368, .parent_padding = 0, .prepare_checksum = 24895070543608533096765633283485941163, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 101421002854235361169396488099400081924, .op = 213, .commit_min = 212, .timestamp = 1763996774430084126, .request = 211, .operation = vsr.Operation(141), .reserved = { 0, 0, 0 } }
2025-11-24 15:06:16.726Z debug(replica): 0N: on_prepare_ok: 3 message(s)
2025-11-24 15:06:16.726Z debug(replica): 0N: on_prepare_ok: ignoring (quorum received already)
2025-11-24 15:06:16.726Z debug(replica): 0N: execute_op: executing view=3 primary=true op=213 checksum=24895070543608533096765633283485941163 (lookup_transfers)
2025-11-24 15:06:16.727Z debug(replica): 0N: execute_op: commit_timestamp=1763996774400289677 prepare.header.timestamp=1763996774430084126
2025-11-24 15:06:16.729Z debug(replica): 0N: execute_op: advancing commit_max=212..213
2025-11-24 15:06:16.733Z debug(replica): 0N: client_table_entry_update: client=101421002854235361169396488099400081924 session=2 request=211
2025-11-24 15:06:16.733Z debug(replica): 0N: execute_op: replying to client: vsr.message_header.Header.Reply{ .checksum = 267913234010283296333708080957048000519, .checksum_padding = 0, .checksum_body = 183786391390144677555054401985151236491, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 1045376, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 132290692373440502538877136281720168916, .request_checksum_padding = 0, .context = 145487027829527872618736832457941229613, .context_padding = 0, .client = 101421002854235361169396488099400081924, .op = 213, .commit = 213, .timestamp = 1763996774430084126, .request = 211, .operation = vsr.Operation(141), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:06:16.733Z debug(replica): 0N: sending reply to client 101421002854235361169396488099400081924: vsr.message_header.Header.Reply{ .checksum = 267913234010283296333708080957048000519, .checksum_padding = 0, .checksum_body = 183786391390144677555054401985151236491, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 1045376, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 132290692373440502538877136281720168916, .request_checksum_padding = 0, .context = 145487027829527872618736832457941229613, .context_padding = 0, .client = 101421002854235361169396488099400081924, .op = 213, .commit = 213, .timestamp = 1763996774430084126, .request = 211, .operation = vsr.Operation(141), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:06:16.733Z debug(forest): entering forest.compact() op=213 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2025-11-24 15:06:16.734Z debug(vsr): 0: commit_message_timeout fired
2025-11-24 15:06:16.734Z debug(vsr): 0: commit_message_timeout reset
2025-11-24 15:06:16.734Z debug(replica): 0N: sending commit to replica 1: vsr.message_header.Header.Commit{ .checksum = 308579299510724980463796446442994874320, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.0, .protocol = 0, .command = vsr.Command.commit, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .commit_checksum = 24895070543608533096765633283485941163, .commit_checksum_padding = 0, .checkpoint_id = 321854455202207724029466302309042662424, .checkpoint_op = 0, .commit = 213, .timestamp_monotonic = 36112340254135645, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:06:16.734Z debug(replica): 0N: sending commit to replica 2: vsr.message_header.Header.Commit{ .checksum = 308579299510724980463796446442994874320, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.0, .protocol = 0, .command = vsr.Command.commit, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .commit_checksum = 24895070543608533096765633283485941163, .commit_checksum_padding = 0, .checkpoint_id = 321854455202207724029466302309042662424, .checkpoint_op = 0, .commit = 213, .timestamp_monotonic = 36112340254135645, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:06:16.734Z debug(vsr): 0: start_view_change_message_timeout fired
2025-11-24 15:06:16.734Z debug(replica): 1n: on_message: view=3 status=normal vsr.message_header.Header.Commit{ .checksum = 308579299510724980463796446442994874320, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.0, .protocol = 0, .command = vsr.Command.commit, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .commit_checksum = 24895070543608533096765633283485941163, .commit_checksum_padding = 0, .checkpoint_id = 321854455202207724029466302309042662424, .checkpoint_op = 0, .commit = 213, .timestamp_monotonic = 36112340254135645, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:06:16.734Z debug(vsr): 0: start_view_change_message_timeout reset
2025-11-24 15:06:16.734Z debug(vsr): 0: journal_repair_budget_timeout fired
2025-11-24 15:06:16.734Z debug(vsr): 1: normal_heartbeat_timeout reset
2025-11-24 15:06:16.734Z debug(vsr): 0: journal_repair_budget_timeout reset
2025-11-24 15:06:16.734Z debug(replica): 1n: on_commit: checksum verified
2025-11-24 15:06:16.734Z debug(vsr): 0: journal_repair_timeout fired
2025-11-24 15:06:16.734Z debug(vsr): 0: journal_repair_timeout reset
2025-11-24 15:06:16.734Z debug(replica): 1n: on_commit: advancing commit_max=212..213
2025-11-24 15:06:16.734Z debug(replica): 2n: on_message: view=3 status=normal vsr.message_header.Header.Commit{ .checksum = 308579299510724980463796446442994874320, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.0, .protocol = 0, .command = vsr.Command.commit, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .commit_checksum = 24895070543608533096765633283485941163, .commit_checksum_padding = 0, .checkpoint_id = 321854455202207724029466302309042662424, .checkpoint_op = 0, .commit = 213, .timestamp_monotonic = 36112340254135645, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:06:16.734Z debug(replica): 1n: commit_start_journal: cached prepare op=213 checksum=24895070543608533096765633283485941163
2025-11-24 15:06:16.734Z debug(vsr): 2: normal_heartbeat_timeout reset
2025-11-24 15:06:16.734Z debug(replica): 2n: on_commit: checksum verified
2025-11-24 15:06:16.734Z debug(replica): 2n: on_commit: advancing commit_max=212..213
2025-11-24 15:06:16.734Z debug(replica): 2n: commit_start_journal: cached prepare op=213 checksum=24895070543608533096765633283485941163
2025-11-24 15:06:16.734Z debug(vsr): 0: grid_repair_budget_timeout fired
2025-11-24 15:06:16.734Z debug(vsr): 0: grid_repair_budget_timeout reset
2025-11-24 15:06:16.734Z debug(client_replies): 0: write_reply: wrote (client=101421002854235361169396488099400081924 request=211)
2025-11-24 15:06:16.736Z debug(replica): 2n: execute_op: executing view=3 primary=false op=213 checksum=24895070543608533096765633283485941163 (lookup_transfers)
2025-11-24 15:06:16.736Z debug(replica): 2n: execute_op: commit_timestamp=1763996774400289677 prepare.header.timestamp=1763996774430084126
2025-11-24 15:06:16.736Z debug(replica): 1n: execute_op: executing view=3 primary=false op=213 checksum=24895070543608533096765633283485941163 (lookup_transfers)
2025-11-24 15:06:16.736Z debug(replica): 1n: execute_op: commit_timestamp=1763996774400289677 prepare.header.timestamp=1763996774430084126
2025-11-24 15:06:16.743Z debug(replica): 2n: client_table_entry_update: client=101421002854235361169396488099400081924 session=2 request=211
2025-11-24 15:06:16.743Z debug(forest): entering forest.compact() op=213 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2025-11-24 15:06:16.743Z debug(replica): 1n: client_table_entry_update: client=101421002854235361169396488099400081924 session=2 request=211
2025-11-24 15:06:16.743Z debug(replica): 1n: execute_op: replying to client: vsr.message_header.Header.Reply{ .checksum = 267913234010283296333708080957048000519, .checksum_padding = 0, .checksum_body = 183786391390144677555054401985151236491, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 1045376, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 132290692373440502538877136281720168916, .request_checksum_padding = 0, .context = 145487027829527872618736832457941229613, .context_padding = 0, .client = 101421002854235361169396488099400081924, .op = 213, .commit = 213, .timestamp = 1763996774430084126, .request = 211, .operation = vsr.Operation(141), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:06:16.743Z debug(replica): 1n: sending reply to client 101421002854235361169396488099400081924: vsr.message_header.Header.Reply{ .checksum = 267913234010283296333708080957048000519, .checksum_padding = 0, .checksum_body = 183786391390144677555054401985151236491, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 1045376, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 132290692373440502538877136281720168916, .request_checksum_padding = 0, .context = 145487027829527872618736832457941229613, .context_padding = 0, .client = 101421002854235361169396488099400081924, .op = 213, .commit = 213, .timestamp = 1763996774430084126, .request = 211, .operation = vsr.Operation(141), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
warning(client): 101421002854235361169396488099400081924: on_reply: slow request, request=211 op=213 size=130896 lookup_transfers time=2315ms
2025-11-24 15:06:16.743Z debug(forest): entering forest.compact() op=213 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2025-11-24 15:06:16.743Z debug(vsr): 2: journal_repair_budget_timeout fired
2025-11-24 15:06:16.743Z debug(vsr): 2: journal_repair_budget_timeout reset
2025-11-24 15:06:16.744Z debug(client_replies): 2: write_reply: wrote (client=101421002854235361169396488099400081924 request=211)
2025-11-24 15:06:16.744Z debug(vsr): 1: journal_repair_budget_timeout fired
2025-11-24 15:06:16.744Z debug(vsr): 1: journal_repair_budget_timeout reset
2025-11-24 15:06:16.744Z debug(client_replies): 1: write_reply: wrote (client=101421002854235361169396488099400081924 request=211)
2025-11-24 15:06:16.753Z debug(replica): 0N: on_message: view=3 status=normal vsr.message_header.Header.Request{ .checksum = 162724913295304424774237299589034425067, .checksum_padding = 0, .checksum_body = 144059847831243404350899927634767905925, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2320, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 145487027829527872618736832457941229613, .parent_padding = 0, .client = 101421002854235361169396488099400081924, .session = 2, .timestamp = 0, .request = 212, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 2315146964, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:06:16.753Z debug(replica): 2n: on_message: view=3 status=normal vsr.message_header.Header.Request{ .checksum = 162724913295304424774237299589034425067, .checksum_padding = 0, .checksum_body = 144059847831243404350899927634767905925, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2320, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 145487027829527872618736832457941229613, .parent_padding = 0, .client = 101421002854235361169396488099400081924, .session = 2, .timestamp = 0, .request = 212, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 2315146964, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:06:16.754Z debug(replica): 0N: on_request: new request
2025-11-24 15:06:16.754Z debug(replica): 2n: on_request: forwarding new request to primary (view=3)
2025-11-24 15:06:16.754Z debug(replica): 0N: primary_pipeline_prepare: request checksum=162724913295304424774237299589034425067 client=101421002854235361169396488099400081924
2025-11-24 15:06:16.754Z debug(replica): 2n: sending request to replica 0: vsr.message_header.Header.Request{ .checksum = 162724913295304424774237299589034425067, .checksum_padding = 0, .checksum_body = 144059847831243404350899927634767905925, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2320, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 145487027829527872618736832457941229613, .parent_padding = 0, .client = 101421002854235361169396488099400081924, .session = 2, .timestamp = 0, .request = 212, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 2315146964, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:06:16.754Z debug(replica): 0N: primary_pipeline_prepare: prepare checksum=301240085492021140447661009064759594965 op=214
2025-11-24 15:06:16.754Z debug(vsr): 0: prepare_timeout started
2025-11-24 15:06:16.754Z debug(vsr): 0: primary_abdicate_timeout started
2025-11-24 15:06:16.754Z debug(vsr): 0: pulse_timeout reset
2025-11-24 15:06:16.754Z debug(replica): 0N: replicate: replicating op=214 to replica 2
2025-11-24 15:06:16.754Z debug(replica): 0N: sending prepare to replica 2: vsr.message_header.Header.Prepare{ .checksum = 301240085492021140447661009064759594965, .checksum_padding = 0, .checksum_body = 144059847831243404350899927634767905925, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2320, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 24895070543608533096765633283485941163, .parent_padding = 0, .request_checksum = 162724913295304424774237299589034425067, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 101421002854235361169396488099400081924, .op = 214, .commit = 213, .timestamp = 1763996776754025556, .request = 212, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-11-24 15:06:16.754Z debug(replica): 0N: replicate: replicating op=214 to replica 1
2025-11-24 15:06:16.754Z debug(replica): 0N: sending prepare to replica 1: vsr.message_header.Header.Prepare{ .checksum = 301240085492021140447661009064759594965, .checksum_padding = 0, .checksum_body = 144059847831243404350899927634767905925, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2320, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 24895070543608533096765633283485941163, .parent_padding = 0, .request_checksum = 162724913295304424774237299589034425067, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 101421002854235361169396488099400081924, .op = 214, .commit = 213, .timestamp = 1763996776754025556, .request = 212, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-11-24 15:06:16.754Z debug(replica): 0N: on_prepare: advancing: op=213..214 checksum=24895070543608533096765633283485941163..301240085492021140447661009064759594965
2025-11-24 15:06:16.754Z debug(journal): 0: set_header_as_dirty: op=214 checksum=301240085492021140447661009064759594965
2025-11-24 15:06:16.754Z debug(replica): 2n: on_message: view=3 status=normal vsr.message_header.Header.Prepare{ .checksum = 301240085492021140447661009064759594965, .checksum_padding = 0, .checksum_body = 144059847831243404350899927634767905925, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2320, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 24895070543608533096765633283485941163, .parent_padding = 0, .request_checksum = 162724913295304424774237299589034425067, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 101421002854235361169396488099400081924, .op = 214, .commit = 213, .timestamp = 1763996776754025556, .request = 212, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-11-24 15:06:16.754Z debug(replica): 0N: append: appending to journal op=214
2025-11-24 15:06:16.754Z debug(journal): 0: write: view=3 slot=214 op=214 len=2320: 301240085492021140447661009064759594965 starting
2025-11-24 15:06:16.754Z debug(replica): 2n: on_prepare: caching prepare.op=214 (commit_min=213 op=213 commit_max=213 prepare_max=1007)
2025-11-24 15:06:16.754Z debug(journal): 0: write_sectors: ring=vsr.journal.Ring.prepares offset=224395264 len=4096 locked
2025-11-24 15:06:16.754Z debug(replica): 2n: on_prepare: advancing: op=213..214 checksum=24895070543608533096765633283485941163..301240085492021140447661009064759594965
2025-11-24 15:06:16.754Z debug(journal): 2: set_header_as_dirty: op=214 checksum=301240085492021140447661009064759594965
2025-11-24 15:06:16.754Z debug(replica): 2n: append: appending to journal op=214
2025-11-24 15:06:16.754Z debug(journal): 2: write: view=3 slot=214 op=214 len=2320: 301240085492021140447661009064759594965 starting
2025-11-24 15:06:16.754Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.prepares offset=224395264 len=4096 locked
2025-11-24 15:06:16.754Z debug(replica): 0N: on_message: view=3 status=normal vsr.message_header.Header.Request{ .checksum = 162724913295304424774237299589034425067, .checksum_padding = 0, .checksum_body = 144059847831243404350899927634767905925, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2320, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 145487027829527872618736832457941229613, .parent_padding = 0, .client = 101421002854235361169396488099400081924, .session = 2, .timestamp = 0, .request = 212, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 2315146964, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:06:16.754Z debug(replica): 0N: on_request: new request
2025-11-24 15:06:16.754Z debug(replica): 0N: on_request: ignoring (already preparing)
2025-11-24 15:06:16.754Z debug(replica): 2n: repair_prepare: op=214 checksum=301240085492021140447661009064759594965 (already writing)
2025-11-24 15:06:16.754Z debug(journal): 0: write_sectors: ring=vsr.journal.Ring.prepares offset=224395264 len=4096 unlocked
2025-11-24 15:06:16.754Z debug(journal): 0: write_header: op=214 sectors[53248..57344]
2025-11-24 15:06:16.754Z debug(journal): 0: write_sectors: ring=vsr.journal.Ring.headers offset=53248 len=4096 locked
2025-11-24 15:06:16.754Z debug(journal): 0: write_sectors: ring=vsr.journal.Ring.headers offset=53248 len=4096 unlocked
2025-11-24 15:06:16.754Z debug(journal): 0: write: view=3 slot=214 op=214 len=2320: 301240085492021140447661009064759594965 complete, marking clean
2025-11-24 15:06:16.754Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.prepares offset=224395264 len=4096 unlocked
2025-11-24 15:06:16.754Z debug(replica): 0N: send_prepare_ok: op=214 checksum=301240085492021140447661009064759594965
2025-11-24 15:06:16.754Z debug(journal): 2: write_header: op=214 sectors[53248..57344]
2025-11-24 15:06:16.754Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.headers offset=53248 len=4096 locked
2025-11-24 15:06:16.754Z debug(replica): 0N: sending prepare_ok to replica 0: vsr.message_header.Header.PrepareOk{ .checksum = 240408600699244755887958080867700203560, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 24895070543608533096765633283485941163, .parent_padding = 0, .prepare_checksum = 301240085492021140447661009064759594965, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 101421002854235361169396488099400081924, .op = 214, .commit_min = 213, .timestamp = 1763996776754025556, .request = 212, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-11-24 15:06:16.754Z debug(replica): 0N: on_message: view=3 status=normal vsr.message_header.Header.PrepareOk{ .checksum = 240408600699244755887958080867700203560, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 24895070543608533096765633283485941163, .parent_padding = 0, .prepare_checksum = 301240085492021140447661009064759594965, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 101421002854235361169396488099400081924, .op = 214, .commit_min = 213, .timestamp = 1763996776754025556, .request = 212, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-11-24 15:06:16.754Z debug(vsr): 0: primary_abdicate_timeout reset
2025-11-24 15:06:16.754Z debug(replica): 0N: on_prepare_ok: 1 message(s)
2025-11-24 15:06:16.754Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.headers offset=53248 len=4096 unlocked
2025-11-24 15:06:16.754Z debug(replica): 0N: on_prepare_ok: waiting for quorum
2025-11-24 15:06:16.754Z debug(journal): 2: write: view=3 slot=214 op=214 len=2320: 301240085492021140447661009064759594965 complete, marking clean
2025-11-24 15:06:16.754Z debug(replica): 2n: send_prepare_ok: op=214 checksum=301240085492021140447661009064759594965
2025-11-24 15:06:16.754Z debug(replica): 2n: sending prepare_ok to replica 0: vsr.message_header.Header.PrepareOk{ .checksum = 34984889155407144589933723880061361714, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 24895070543608533096765633283485941163, .parent_padding = 0, .prepare_checksum = 301240085492021140447661009064759594965, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 101421002854235361169396488099400081924, .op = 214, .commit_min = 213, .timestamp = 1763996776754025556, .request = 212, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-11-24 15:06:16.754Z debug(replica): 0N: on_message: view=3 status=normal vsr.message_header.Header.PrepareOk{ .checksum = 34984889155407144589933723880061361714, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 24895070543608533096765633283485941163, .parent_padding = 0, .prepare_checksum = 301240085492021140447661009064759594965, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 101421002854235361169396488099400081924, .op = 214, .commit_min = 213, .timestamp = 1763996776754025556, .request = 212, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-11-24 15:06:16.754Z debug(vsr): 0: primary_abdicate_timeout reset
2025-11-24 15:06:16.754Z debug(replica): 0N: on_prepare_ok: 2 message(s)
2025-11-24 15:06:16.754Z debug(replica): 0N: on_prepare_ok: quorum received, context=301240085492021140447661009064759594965
2025-11-24 15:06:16.754Z debug(vsr): 0: prepare_timeout stopped
2025-11-24 15:06:16.754Z debug(vsr): 0: primary_abdicate_timeout stopped
2025-11-24 15:06:16.754Z debug(replica): 0N: execute_op: executing view=3 primary=true op=214 checksum=301240085492021140447661009064759594965 (lookup_accounts)
2025-11-24 15:06:16.754Z debug(replica): 0N: execute_op: commit_timestamp=1763996774430084126 prepare.header.timestamp=1763996776754025556
2025-11-24 15:06:16.754Z debug(replica): 0N: execute_op: advancing commit_max=213..214
2025-11-24 15:06:16.754Z debug(replica): 0N: client_table_entry_update: client=101421002854235361169396488099400081924 session=2 request=212
2025-11-24 15:06:16.754Z debug(replica): 0N: execute_op: replying to client: vsr.message_header.Header.Reply{ .checksum = 252973094473727395593549801099673081793, .checksum_padding = 0, .checksum_body = 312103870462265314276609012122658931960, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 16768, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 162724913295304424774237299589034425067, .request_checksum_padding = 0, .context = 223624135566741300173096434648540110866, .context_padding = 0, .client = 101421002854235361169396488099400081924, .op = 214, .commit = 214, .timestamp = 1763996776754025556, .request = 212, .operation = vsr.Operation(140), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:06:16.754Z debug(replica): 0N: sending reply to client 101421002854235361169396488099400081924: vsr.message_header.Header.Reply{ .checksum = 252973094473727395593549801099673081793, .checksum_padding = 0, .checksum_body = 312103870462265314276609012122658931960, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 16768, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 162724913295304424774237299589034425067, .request_checksum_padding = 0, .context = 223624135566741300173096434648540110866, .context_padding = 0, .client = 101421002854235361169396488099400081924, .op = 214, .commit = 214, .timestamp = 1763996776754025556, .request = 212, .operation = vsr.Operation(140), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:06:16.754Z debug(forest): entering forest.compact() op=214 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2025-11-24 15:06:16.755Z info(workload): accounts created = 128, transfers = 260331, pending transfers = 0, commands run = 106
2025-11-24 15:06:16.755Z debug(vsr): 0: journal_repair_budget_timeout fired
2025-11-24 15:06:16.755Z debug(vsr): 0: journal_repair_budget_timeout reset
2025-11-24 15:06:16.755Z debug(client_replies): 0: write_reply: wrote (client=101421002854235361169396488099400081924 request=212)
2025-11-24 15:06:16.761Z debug(replica): 2n: on_message: view=3 status=normal vsr.message_header.Header.Request{ .checksum = 36693962140251088650422001759891473089, .checksum_padding = 0, .checksum_body = 116765146132965795175400597766962998046, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 394496, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 223624135566741300173096434648540110866, .parent_padding = 0, .client = 101421002854235361169396488099400081924, .session = 2, .timestamp = 0, .request = 213, .operation = vsr.Operation(139), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 1303070, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:06:16.764Z debug(vsr): 1: journal_repair_budget_timeout fired
2025-11-24 15:06:19.352Z debug(vsr): 1: journal_repair_budget_timeout reset
2025-11-24 15:06:19.352Z debug(replica): 2n: on_request: forwarding new request to primary (view=3)
2025-11-24 15:06:19.352Z debug(replica): 2n: sending request to replica 0: vsr.message_header.Header.Request{ .checksum = 36693962140251088650422001759891473089, .checksum_padding = 0, .checksum_body = 116765146132965795175400597766962998046, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 394496, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 223624135566741300173096434648540110866, .parent_padding = 0, .client = 101421002854235361169396488099400081924, .session = 2, .timestamp = 0, .request = 213, .operation = vsr.Operation(139), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 1303070, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:06:19.352Z debug(replica): 1n: on_message: view=3 status=normal vsr.message_header.Header.Prepare{ .checksum = 301240085492021140447661009064759594965, .checksum_padding = 0, .checksum_body = 144059847831243404350899927634767905925, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2320, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 24895070543608533096765633283485941163, .parent_padding = 0, .request_checksum = 162724913295304424774237299589034425067, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 101421002854235361169396488099400081924, .op = 214, .commit = 213, .timestamp = 1763996776754025556, .request = 212, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-11-24 15:06:19.352Z debug(replica): 1n: on_prepare: caching prepare.op=214 (commit_min=213 op=213 commit_max=213 prepare_max=1007)
2025-11-24 15:06:19.352Z debug(replica): 1n: on_prepare: advancing: op=213..214 checksum=24895070543608533096765633283485941163..301240085492021140447661009064759594965
2025-11-24 15:06:19.352Z debug(journal): 1: set_header_as_dirty: op=214 checksum=301240085492021140447661009064759594965
2025-11-24 15:06:19.352Z debug(replica): 1n: append: appending to journal op=214
2025-11-24 15:06:19.352Z debug(journal): 1: write: view=3 slot=214 op=214 len=2320: 301240085492021140447661009064759594965 starting
2025-11-24 15:06:19.352Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.prepares offset=224395264 len=4096 locked
2025-11-24 15:06:19.352Z debug(replica): 1n: repair_prepare: op=214 checksum=301240085492021140447661009064759594965 (already writing)
2025-11-24 15:06:19.352Z debug(replica): 1n: on_message: view=3 status=normal vsr.message_header.Header.PingClient{ .checksum = 248249782418069230318438092887415273540, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 0, .release = 0.0.1, .protocol = 0, .command = vsr.Command.ping_client, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .client = 101421002854235361169396488099400081924, .ping_timestamp_monotonic = 36112342309786464, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:06:19.352Z debug(replica): 1n: sending pong_client to client 101421002854235361169396488099400081924: vsr.message_header.Header.PongClient{ .checksum = 224241318701317067051910114864174093686, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.pong_client, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .ping_timestamp_monotonic = 36112342309786464, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:06:19.353Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.prepares offset=224395264 len=4096 unlocked
2025-11-24 15:06:19.353Z debug(journal): 1: write_header: op=214 sectors[53248..57344]
2025-11-24 15:06:19.353Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.headers offset=53248 len=4096 locked
2025-11-24 15:06:19.353Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.headers offset=53248 len=4096 unlocked
2025-11-24 15:06:19.353Z debug(journal): 1: write: view=3 slot=214 op=214 len=2320: 301240085492021140447661009064759594965 complete, marking clean
2025-11-24 15:06:19.353Z debug(replica): 1n: send_prepare_ok: op=214 checksum=301240085492021140447661009064759594965
2025-11-24 15:06:19.353Z debug(replica): 1n: sending prepare_ok to replica 0: vsr.message_header.Header.PrepareOk{ .checksum = 114442419659036215778419516526591143495, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 24895070543608533096765633283485941163, .parent_padding = 0, .prepare_checksum = 301240085492021140447661009064759594965, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 101421002854235361169396488099400081924, .op = 214, .commit_min = 213, .timestamp = 1763996776754025556, .request = 212, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-11-24 15:06:19.354Z debug(replica): 0N: on_message: view=3 status=normal vsr.message_header.Header.Request{ .checksum = 36693962140251088650422001759891473089, .checksum_padding = 0, .checksum_body = 116765146132965795175400597766962998046, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 394496, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 223624135566741300173096434648540110866, .parent_padding = 0, .client = 101421002854235361169396488099400081924, .session = 2, .timestamp = 0, .request = 213, .operation = vsr.Operation(139), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 1303070, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:06:19.354Z debug(replica): 0N: on_request: new request
2025-11-24 15:06:19.354Z debug(replica): 0N: primary_pipeline_prepare: request checksum=36693962140251088650422001759891473089 client=101421002854235361169396488099400081924
2025-11-24 15:06:19.354Z debug(replica): 2n: on_message: view=3 status=normal vsr.message_header.Header.Request{ .checksum = 36693962140251088650422001759891473089, .checksum_padding = 0, .checksum_body = 116765146132965795175400597766962998046, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 394496, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 223624135566741300173096434648540110866, .parent_padding = 0, .client = 101421002854235361169396488099400081924, .session = 2, .timestamp = 0, .request = 213, .operation = vsr.Operation(139), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 1303070, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:06:19.354Z debug(replica): 2n: on_request: forwarding new request to primary (view=3)
2025-11-24 15:06:19.354Z debug(replica): 2n: sending request to replica 0: vsr.message_header.Header.Request{ .checksum = 36693962140251088650422001759891473089, .checksum_padding = 0, .checksum_body = 116765146132965795175400597766962998046, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 394496, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 223624135566741300173096434648540110866, .parent_padding = 0, .client = 101421002854235361169396488099400081924, .session = 2, .timestamp = 0, .request = 213, .operation = vsr.Operation(139), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 1303070, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:06:19.355Z debug(replica): 0N: primary_pipeline_prepare: prepare checksum=167518648183311212171522326560367878953 op=215
2025-11-24 15:06:19.355Z debug(vsr): 0: prepare_timeout started
2025-11-24 15:06:19.355Z debug(vsr): 0: primary_abdicate_timeout started
2025-11-24 15:06:19.355Z debug(vsr): 0: pulse_timeout reset
2025-11-24 15:06:19.355Z debug(replica): 0N: replicate: replicating op=215 to replica 2
2025-11-24 15:06:19.355Z debug(replica): 0N: sending prepare to replica 2: vsr.message_header.Header.Prepare{ .checksum = 167518648183311212171522326560367878953, .checksum_padding = 0, .checksum_body = 116765146132965795175400597766962998046, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 394496, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 301240085492021140447661009064759594965, .parent_padding = 0, .request_checksum = 36693962140251088650422001759891473089, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 101421002854235361169396488099400081924, .op = 215, .commit = 214, .timestamp = 1763996779354175499, .request = 213, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-11-24 15:06:19.356Z debug(replica): 0N: replicate: replicating op=215 to replica 1
2025-11-24 15:06:19.356Z debug(replica): 0N: sending prepare to replica 1: vsr.message_header.Header.Prepare{ .checksum = 167518648183311212171522326560367878953, .checksum_padding = 0, .checksum_body = 116765146132965795175400597766962998046, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 394496, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 301240085492021140447661009064759594965, .parent_padding = 0, .request_checksum = 36693962140251088650422001759891473089, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 101421002854235361169396488099400081924, .op = 215, .commit = 214, .timestamp = 1763996779354175499, .request = 213, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-11-24 15:06:19.356Z debug(replica): 0N: on_prepare: advancing: op=214..215 checksum=301240085492021140447661009064759594965..167518648183311212171522326560367878953
2025-11-24 15:06:19.356Z debug(journal): 0: set_header_as_dirty: op=215 checksum=167518648183311212171522326560367878953
2025-11-24 15:06:19.356Z debug(replica): 0N: append: appending to journal op=215
2025-11-24 15:06:19.356Z debug(journal): 0: write: view=3 slot=215 op=215 len=394496: 167518648183311212171522326560367878953 starting
2025-11-24 15:06:19.356Z debug(journal): 0: write_sectors: ring=vsr.journal.Ring.prepares offset=225443840 len=397312 locked
2025-11-24 15:06:19.356Z debug(replica): 2n: on_message: view=3 status=normal vsr.message_header.Header.Request{ .checksum = 36693962140251088650422001759891473089, .checksum_padding = 0, .checksum_body = 116765146132965795175400597766962998046, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 394496, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 223624135566741300173096434648540110866, .parent_padding = 0, .client = 101421002854235361169396488099400081924, .session = 2, .timestamp = 0, .request = 213, .operation = vsr.Operation(139), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 1303070, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:06:19.356Z debug(replica): 2n: on_request: forwarding new request to primary (view=3)
2025-11-24 15:06:19.356Z debug(replica): 2n: sending request to replica 0: vsr.message_header.Header.Request{ .checksum = 36693962140251088650422001759891473089, .checksum_padding = 0, .checksum_body = 116765146132965795175400597766962998046, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 394496, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 223624135566741300173096434648540110866, .parent_padding = 0, .client = 101421002854235361169396488099400081924, .session = 2, .timestamp = 0, .request = 213, .operation = vsr.Operation(139), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 1303070, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:06:19.356Z debug(replica): 0N: on_message: view=3 status=normal vsr.message_header.Header.PrepareOk{ .checksum = 114442419659036215778419516526591143495, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 24895070543608533096765633283485941163, .parent_padding = 0, .prepare_checksum = 301240085492021140447661009064759594965, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 101421002854235361169396488099400081924, .op = 214, .commit_min = 213, .timestamp = 1763996776754025556, .request = 212, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-11-24 15:06:19.356Z debug(replica): 0N: on_prepare_ok: not preparing op=214 checksum=301240085492021140447661009064759594965
2025-11-24 15:06:19.356Z debug(journal): 0: write_sectors: ring=vsr.journal.Ring.prepares offset=225443840 len=397312 unlocked
2025-11-24 15:06:19.356Z debug(journal): 0: write_header: op=215 sectors[53248..57344]
2025-11-24 15:06:19.356Z debug(journal): 0: write_sectors: ring=vsr.journal.Ring.headers offset=53248 len=4096 locked
2025-11-24 15:06:19.357Z debug(replica): 2n: on_message: view=3 status=normal vsr.message_header.Header.PingClient{ .checksum = 248249782418069230318438092887415273540, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 0, .release = 0.0.1, .protocol = 0, .command = vsr.Command.ping_client, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .client = 101421002854235361169396488099400081924, .ping_timestamp_monotonic = 36112342309786464, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:06:19.357Z debug(replica): 2n: sending pong_client to client 101421002854235361169396488099400081924: vsr.message_header.Header.PongClient{ .checksum = 36489613921245648553756928221293832523, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.pong_client, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .ping_timestamp_monotonic = 36112342309786464, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:06:19.357Z warning(clock): 2: synchronization failed, partitioned (sources=1 samples=1)
2025-11-24 15:06:19.357Z error(clock): 2: no agreement on cluster time (partitioned or too many clock faults)
2025-11-24 15:06:19.357Z debug(vsr): 2: journal_repair_budget_timeout fired
2025-11-24 15:06:19.357Z debug(vsr): 2: journal_repair_budget_timeout reset
2025-11-24 15:06:19.358Z debug(replica): 1n: on_message: view=3 status=normal vsr.message_header.Header.Prepare{ .checksum = 167518648183311212171522326560367878953, .checksum_padding = 0, .checksum_body = 116765146132965795175400597766962998046, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 394496, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 301240085492021140447661009064759594965, .parent_padding = 0, .request_checksum = 36693962140251088650422001759891473089, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 101421002854235361169396488099400081924, .op = 215, .commit = 214, .timestamp = 1763996779354175499, .request = 213, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-11-24 15:06:19.358Z debug(replica): 1n: on_prepare: advancing commit_max=213..214
2025-11-24 15:06:19.358Z debug(replica): 1n: on_prepare: caching prepare.op=215 (commit_min=213 op=214 commit_max=214 prepare_max=1007)
2025-11-24 15:06:19.358Z debug(replica): 1n: on_prepare: advancing: op=214..215 checksum=301240085492021140447661009064759594965..167518648183311212171522326560367878953
2025-11-24 15:06:19.358Z debug(journal): 1: set_header_as_dirty: op=215 checksum=167518648183311212171522326560367878953
2025-11-24 15:06:19.358Z debug(replica): 1n: append: appending to journal op=215
2025-11-24 15:06:19.358Z debug(journal): 1: write: view=3 slot=215 op=215 len=394496: 167518648183311212171522326560367878953 starting
2025-11-24 15:06:19.358Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.prepares offset=225443840 len=397312 locked
2025-11-24 15:06:19.358Z debug(replica): 1n: commit_start_journal: cached prepare op=214 checksum=301240085492021140447661009064759594965
2025-11-24 15:06:19.358Z debug(replica): 1n: repair_prepare: op=215 checksum=167518648183311212171522326560367878953 (already writing)
2025-11-24 15:06:19.358Z debug(replica): 1n: commit_journal: already committing (prefetch; commit_min=213)
2025-11-24 15:06:19.358Z debug(replica): 1n: execute_op: executing view=3 primary=false op=214 checksum=301240085492021140447661009064759594965 (lookup_accounts)
2025-11-24 15:06:19.358Z debug(replica): 1n: execute_op: commit_timestamp=1763996774430084126 prepare.header.timestamp=1763996776754025556
2025-11-24 15:06:19.358Z debug(replica): 0N: on_message: view=3 status=normal vsr.message_header.Header.Request{ .checksum = 36693962140251088650422001759891473089, .checksum_padding = 0, .checksum_body = 116765146132965795175400597766962998046, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 394496, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 223624135566741300173096434648540110866, .parent_padding = 0, .client = 101421002854235361169396488099400081924, .session = 2, .timestamp = 0, .request = 213, .operation = vsr.Operation(139), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 1303070, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:06:19.358Z debug(replica): 0N: on_request: new request
2025-11-24 15:06:19.358Z debug(replica): 0N: on_request: ignoring (already preparing)
2025-11-24 15:06:19.358Z debug(replica): 1n: client_table_entry_update: client=101421002854235361169396488099400081924 session=2 request=212
2025-11-24 15:06:19.358Z debug(replica): 1n: execute_op: replying to client: vsr.message_header.Header.Reply{ .checksum = 252973094473727395593549801099673081793, .checksum_padding = 0, .checksum_body = 312103870462265314276609012122658931960, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 16768, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 162724913295304424774237299589034425067, .request_checksum_padding = 0, .context = 223624135566741300173096434648540110866, .context_padding = 0, .client = 101421002854235361169396488099400081924, .op = 214, .commit = 214, .timestamp = 1763996776754025556, .request = 212, .operation = vsr.Operation(140), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:06:19.358Z debug(replica): 1n: sending reply to client 101421002854235361169396488099400081924: vsr.message_header.Header.Reply{ .checksum = 252973094473727395593549801099673081793, .checksum_padding = 0, .checksum_body = 312103870462265314276609012122658931960, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 16768, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 162724913295304424774237299589034425067, .request_checksum_padding = 0, .context = 223624135566741300173096434648540110866, .context_padding = 0, .client = 101421002854235361169396488099400081924, .op = 214, .commit = 214, .timestamp = 1763996776754025556, .request = 212, .operation = vsr.Operation(140), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:06:19.358Z debug(forest): entering forest.compact() op=214 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2025-11-24 15:06:19.359Z debug(journal): 0: write_sectors: ring=vsr.journal.Ring.headers offset=53248 len=4096 unlocked
2025-11-24 15:06:19.359Z debug(journal): 0: write: view=3 slot=215 op=215 len=394496: 167518648183311212171522326560367878953 complete, marking clean
2025-11-24 15:06:19.359Z debug(replica): 0N: send_prepare_ok: op=215 checksum=167518648183311212171522326560367878953
2025-11-24 15:06:19.359Z debug(replica): 2n: on_message: view=3 status=normal vsr.message_header.Header.Prepare{ .checksum = 167518648183311212171522326560367878953, .checksum_padding = 0, .checksum_body = 116765146132965795175400597766962998046, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 394496, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 301240085492021140447661009064759594965, .parent_padding = 0, .request_checksum = 36693962140251088650422001759891473089, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 101421002854235361169396488099400081924, .op = 215, .commit = 214, .timestamp = 1763996779354175499, .request = 213, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-11-24 15:06:19.359Z debug(replica): 2n: on_prepare: advancing commit_max=213..214
2025-11-24 15:06:19.359Z debug(replica): 0N: sending prepare_ok to replica 0: vsr.message_header.Header.PrepareOk{ .checksum = 36126708157202998949927833383147709530, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 301240085492021140447661009064759594965, .parent_padding = 0, .prepare_checksum = 167518648183311212171522326560367878953, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 101421002854235361169396488099400081924, .op = 215, .commit_min = 214, .timestamp = 1763996779354175499, .request = 213, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-11-24 15:06:19.359Z debug(replica): 2n: on_prepare: caching prepare.op=215 (commit_min=213 op=214 commit_max=214 prepare_max=1007)
2025-11-24 15:06:19.359Z debug(replica): 0N: on_message: view=3 status=normal vsr.message_header.Header.PrepareOk{ .checksum = 36126708157202998949927833383147709530, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 301240085492021140447661009064759594965, .parent_padding = 0, .prepare_checksum = 167518648183311212171522326560367878953, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 101421002854235361169396488099400081924, .op = 215, .commit_min = 214, .timestamp = 1763996779354175499, .request = 213, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-11-24 15:06:19.359Z debug(vsr): 0: primary_abdicate_timeout reset
2025-11-24 15:06:19.359Z debug(replica): 0N: on_prepare_ok: 1 message(s)
2025-11-24 15:06:19.359Z debug(replica): 0N: on_prepare_ok: waiting for quorum
2025-11-24 15:06:19.359Z debug(replica): 2n: on_prepare: advancing: op=214..215 checksum=301240085492021140447661009064759594965..167518648183311212171522326560367878953
2025-11-24 15:06:19.359Z debug(journal): 2: set_header_as_dirty: op=215 checksum=167518648183311212171522326560367878953
2025-11-24 15:06:19.359Z debug(replica): 2n: append: appending to journal op=215
2025-11-24 15:06:19.359Z debug(journal): 2: write: view=3 slot=215 op=215 len=394496: 167518648183311212171522326560367878953 starting
2025-11-24 15:06:19.359Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.prepares offset=225443840 len=397312 locked
2025-11-24 15:06:19.359Z debug(replica): 2n: commit_start_journal: cached prepare op=214 checksum=301240085492021140447661009064759594965
2025-11-24 15:06:19.359Z debug(replica): 2n: repair_prepare: op=215 checksum=167518648183311212171522326560367878953 (already writing)
2025-11-24 15:06:19.359Z debug(client_replies): 1: write_reply: wrote (client=101421002854235361169396488099400081924 request=212)
2025-11-24 15:06:19.359Z debug(replica): 2n: commit_journal: already committing (prefetch; commit_min=213)
2025-11-24 15:06:19.359Z debug(replica): 2n: execute_op: executing view=3 primary=false op=214 checksum=301240085492021140447661009064759594965 (lookup_accounts)
2025-11-24 15:06:19.359Z debug(replica): 2n: execute_op: commit_timestamp=1763996774430084126 prepare.header.timestamp=1763996776754025556
2025-11-24 15:06:19.359Z debug(replica): 2n: client_table_entry_update: client=101421002854235361169396488099400081924 session=2 request=212
2025-11-24 15:06:19.359Z debug(forest): entering forest.compact() op=214 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2025-11-24 15:06:19.359Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.prepares offset=225443840 len=397312 unlocked
2025-11-24 15:06:19.359Z debug(journal): 1: write_header: op=215 sectors[53248..57344]
2025-11-24 15:06:19.359Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.headers offset=53248 len=4096 locked
2025-11-24 15:06:19.359Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.headers offset=53248 len=4096 unlocked
2025-11-24 15:06:19.359Z debug(journal): 1: write: view=3 slot=215 op=215 len=394496: 167518648183311212171522326560367878953 complete, marking clean
2025-11-24 15:06:19.359Z debug(replica): 1n: send_prepare_ok: op=215 checksum=167518648183311212171522326560367878953
2025-11-24 15:06:19.359Z debug(replica): 1n: sending prepare_ok to replica 0: vsr.message_header.Header.PrepareOk{ .checksum = 142100125029338021968647445144362197656, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 301240085492021140447661009064759594965, .parent_padding = 0, .prepare_checksum = 167518648183311212171522326560367878953, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 101421002854235361169396488099400081924, .op = 215, .commit_min = 214, .timestamp = 1763996779354175499, .request = 213, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-11-24 15:06:19.359Z debug(client_replies): 2: write_reply: wrote (client=101421002854235361169396488099400081924 request=212)
2025-11-24 15:06:19.360Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.prepares offset=225443840 len=397312 unlocked
2025-11-24 15:06:19.360Z debug(journal): 2: write_header: op=215 sectors[53248..57344]
2025-11-24 15:06:19.360Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.headers offset=53248 len=4096 locked
2025-11-24 15:06:19.360Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.headers offset=53248 len=4096 unlocked
2025-11-24 15:06:19.360Z debug(journal): 2: write: view=3 slot=215 op=215 len=394496: 167518648183311212171522326560367878953 complete, marking clean
2025-11-24 15:06:19.360Z debug(replica): 2n: send_prepare_ok: op=215 checksum=167518648183311212171522326560367878953
2025-11-24 15:06:19.360Z debug(replica): 2n: sending prepare_ok to replica 0: vsr.message_header.Header.PrepareOk{ .checksum = 184439789317798133718506787948388652098, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 301240085492021140447661009064759594965, .parent_padding = 0, .prepare_checksum = 167518648183311212171522326560367878953, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 101421002854235361169396488099400081924, .op = 215, .commit_min = 214, .timestamp = 1763996779354175499, .request = 213, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-11-24 15:06:19.360Z debug(replica): 0N: on_message: view=3 status=normal vsr.message_header.Header.Request{ .checksum = 36693962140251088650422001759891473089, .checksum_padding = 0, .checksum_body = 116765146132965795175400597766962998046, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 394496, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 223624135566741300173096434648540110866, .parent_padding = 0, .client = 101421002854235361169396488099400081924, .session = 2, .timestamp = 0, .request = 213, .operation = vsr.Operation(139), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 1303070, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:06:19.360Z debug(replica): 0N: on_request: new request
2025-11-24 15:06:19.360Z debug(replica): 0N: on_request: ignoring (already preparing)
2025-11-24 15:06:19.361Z debug(replica): 0N: on_message: view=3 status=normal vsr.message_header.Header.PrepareOk{ .checksum = 142100125029338021968647445144362197656, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 301240085492021140447661009064759594965, .parent_padding = 0, .prepare_checksum = 167518648183311212171522326560367878953, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 101421002854235361169396488099400081924, .op = 215, .commit_min = 214, .timestamp = 1763996779354175499, .request = 213, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-11-24 15:06:19.361Z debug(vsr): 0: primary_abdicate_timeout reset
2025-11-24 15:06:19.361Z debug(replica): 0N: on_prepare_ok: 2 message(s)
2025-11-24 15:06:19.361Z debug(replica): 0N: on_prepare_ok: quorum received, context=167518648183311212171522326560367878953
2025-11-24 15:06:19.361Z debug(vsr): 0: prepare_timeout stopped
2025-11-24 15:06:19.361Z debug(vsr): 0: primary_abdicate_timeout stopped
2025-11-24 15:06:19.363Z debug(replica): 0N: execute_op: executing view=3 primary=true op=215 checksum=167518648183311212171522326560367878953 (create_transfers)
2025-11-24 15:06:19.363Z debug(replica): 0N: execute_op: commit_timestamp=1763996776754025556 prepare.header.timestamp=1763996779354175499
2025-11-24 15:06:19.372Z debug(vsr): 1: journal_repair_budget_timeout fired
2025-11-24 15:06:19.372Z debug(vsr): 1: journal_repair_budget_timeout reset
2025-11-24 15:06:19.374Z debug(replica): 0N: execute_op: advancing commit_max=214..215
2025-11-24 15:06:19.374Z debug(replica): 0N: client_table_entry_update: client=101421002854235361169396488099400081924 session=2 request=213
2025-11-24 15:06:19.374Z debug(replica): 0N: execute_op: replying to client: vsr.message_header.Header.Reply{ .checksum = 179654285882777228976869830971971184436, .checksum_padding = 0, .checksum_body = 280389260678910035616807846124571220344, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 280, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 36693962140251088650422001759891473089, .request_checksum_padding = 0, .context = 139181995639685761956576437996683153970, .context_padding = 0, .client = 101421002854235361169396488099400081924, .op = 215, .commit = 215, .timestamp = 1763996779354175499, .request = 213, .operation = vsr.Operation(139), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:06:19.375Z debug(replica): 0N: sending reply to client 101421002854235361169396488099400081924: vsr.message_header.Header.Reply{ .checksum = 179654285882777228976869830971971184436, .checksum_padding = 0, .checksum_body = 280389260678910035616807846124571220344, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 280, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 36693962140251088650422001759891473089, .request_checksum_padding = 0, .context = 139181995639685761956576437996683153970, .context_padding = 0, .client = 101421002854235361169396488099400081924, .op = 215, .commit = 215, .timestamp = 1763996779354175499, .request = 213, .operation = vsr.Operation(139), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:06:19.375Z debug(forest): entering forest.compact() op=215 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
warning(client): 101421002854235361169396488099400081924: on_reply: slow request, request=213 op=215 size=394496 create_transfers time=2617ms
2025-11-24 15:06:19.377Z debug(vsr): 2: journal_repair_budget_timeout fired
2025-11-24 15:06:19.377Z debug(vsr): 2: journal_repair_budget_timeout reset
2025-11-24 15:06:19.383Z debug(replica): 0N: on_message: view=3 status=normal vsr.message_header.Header.Request{ .checksum = 36693962140251088650422001759891473089, .checksum_padding = 0, .checksum_body = 116765146132965795175400597766962998046, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 394496, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 223624135566741300173096434648540110866, .parent_padding = 0, .client = 101421002854235361169396488099400081924, .session = 2, .timestamp = 0, .request = 213, .operation = vsr.Operation(139), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 1303070, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:06:19.383Z debug(replica): 0N: on_request: replying to duplicate request
2025-11-24 15:06:19.383Z debug(replica): 0N: on_request: repeat reply (client=101421002854235361169396488099400081924 request=213)
2025-11-24 15:06:19.383Z debug(replica): 0N: sending reply to client 101421002854235361169396488099400081924: vsr.message_header.Header.Reply{ .checksum = 179654285882777228976869830971971184436, .checksum_padding = 0, .checksum_body = 280389260678910035616807846124571220344, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 280, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 36693962140251088650422001759891473089, .request_checksum_padding = 0, .context = 139181995639685761956576437996683153970, .context_padding = 0, .client = 101421002854235361169396488099400081924, .op = 215, .commit = 215, .timestamp = 1763996779354175499, .request = 213, .operation = vsr.Operation(139), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:06:19.385Z debug(replica): 0N: on_message: view=3 status=normal vsr.message_header.Header.Request{ .checksum = 36693962140251088650422001759891473089, .checksum_padding = 0, .checksum_body = 116765146132965795175400597766962998046, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 394496, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 223624135566741300173096434648540110866, .parent_padding = 0, .client = 101421002854235361169396488099400081924, .session = 2, .timestamp = 0, .request = 213, .operation = vsr.Operation(139), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 1303070, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:06:19.385Z debug(replica): 0N: on_request: replying to duplicate request
2025-11-24 15:06:19.385Z debug(replica): 0N: on_request: repeat reply (client=101421002854235361169396488099400081924 request=213)
2025-11-24 15:06:19.385Z debug(replica): 0N: sending reply to client 101421002854235361169396488099400081924: vsr.message_header.Header.Reply{ .checksum = 179654285882777228976869830971971184436, .checksum_padding = 0, .checksum_body = 280389260678910035616807846124571220344, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 280, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 36693962140251088650422001759891473089, .request_checksum_padding = 0, .context = 139181995639685761956576437996683153970, .context_padding = 0, .client = 101421002854235361169396488099400081924, .op = 215, .commit = 215, .timestamp = 1763996779354175499, .request = 213, .operation = vsr.Operation(139), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:06:19.385Z debug(replica): 0N: on_message: view=3 status=normal vsr.message_header.Header.PingClient{ .checksum = 248249782418069230318438092887415273540, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 0, .release = 0.0.1, .protocol = 0, .command = vsr.Command.ping_client, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .client = 101421002854235361169396488099400081924, .ping_timestamp_monotonic = 36112342309786464, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:06:19.385Z debug(replica): 0N: sending pong_client to client 101421002854235361169396488099400081924: vsr.message_header.Header.PongClient{ .checksum = 107424855529003270675647055034756382631, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.pong_client, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .ping_timestamp_monotonic = 36112342309786464, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:06:19.385Z debug(client_replies): 0: write_reply: wrote (client=101421002854235361169396488099400081924 request=213)
2025-11-24 15:06:19.387Z debug(replica): 2n: on_message: view=3 status=normal vsr.message_header.Header.Request{ .checksum = 248958360981229250101762850819705921646, .checksum_padding = 0, .checksum_body = 144059847831243404350899927634767905925, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2320, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 139181995639685761956576437996683153970, .parent_padding = 0, .client = 101421002854235361169396488099400081924, .session = 2, .timestamp = 0, .request = 214, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 2617628177, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:06:19.387Z debug(replica): 2n: on_request: forwarding new request to primary (view=3)
2025-11-24 15:06:19.387Z debug(replica): 2n: sending request to replica 0: vsr.message_header.Header.Request{ .checksum = 248958360981229250101762850819705921646, .checksum_padding = 0, .checksum_body = 144059847831243404350899927634767905925, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2320, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 139181995639685761956576437996683153970, .parent_padding = 0, .client = 101421002854235361169396488099400081924, .session = 2, .timestamp = 0, .request = 214, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 2617628177, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:06:19.387Z debug(vsr): 2: ping_timeout fired
2025-11-24 15:06:19.387Z debug(vsr): 2: ping_timeout reset
2025-11-24 15:06:19.387Z debug(replica): 2n: sending ping to replica 0: vsr.message_header.Header.Ping{ .checksum = 144728276303700702187007706959693407515, .checksum_padding = 0, .checksum_body = 154787626362930377789479683857780696253, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 512, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.ping, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .checkpoint_id = 321854455202207724029466302309042662424, .checkpoint_op = 0, .ping_timestamp_monotonic = 36112342907234970, .release_count = 1, .route_padding = { 0, 0, 0, 0, 0, 0 }, .route = 0, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:06:19.387Z debug(replica): 2n: sending ping to replica 1: vsr.message_header.Header.Ping{ .checksum = 144728276303700702187007706959693407515, .checksum_padding = 0, .checksum_body = 154787626362930377789479683857780696253, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 512, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.ping, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .checkpoint_id = 321854455202207724029466302309042662424, .checkpoint_op = 0, .ping_timestamp_monotonic = 36112342907234970, .release_count = 1, .route_padding = { 0, 0, 0, 0, 0, 0 }, .route = 0, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:06:19.387Z debug(replica): 0N: on_message: view=3 status=normal vsr.message_header.Header.Request{ .checksum = 36693962140251088650422001759891473089, .checksum_padding = 0, .checksum_body = 116765146132965795175400597766962998046, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 394496, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 223624135566741300173096434648540110866, .parent_padding = 0, .client = 101421002854235361169396488099400081924, .session = 2, .timestamp = 0, .request = 213, .operation = vsr.Operation(139), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 1303070, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:06:19.387Z debug(replica): 0N: on_request: replying to duplicate request
2025-11-24 15:06:19.387Z debug(client_replies): 0: read_reply: start (client=101421002854235361169396488099400081924 reply=179654285882777228976869830971971184436)
2025-11-24 15:06:19.387Z debug(vsr): 2: start_view_change_message_timeout fired
2025-11-24 15:06:19.387Z debug(vsr): 2: start_view_change_message_timeout reset
2025-11-24 15:06:19.387Z debug(vsr): 2: journal_repair_timeout fired
2025-11-24 15:06:19.387Z debug(vsr): 2: journal_repair_timeout reset
2025-11-24 15:06:19.387Z debug(replica): 0N: on_message: view=3 status=normal vsr.message_header.Header.PrepareOk{ .checksum = 184439789317798133718506787948388652098, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 301240085492021140447661009064759594965, .parent_padding = 0, .prepare_checksum = 167518648183311212171522326560367878953, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 101421002854235361169396488099400081924, .op = 215, .commit_min = 214, .timestamp = 1763996779354175499, .request = 213, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-11-24 15:06:19.387Z debug(replica): 1n: on_message: view=3 status=normal vsr.message_header.Header.Ping{ .checksum = 144728276303700702187007706959693407515, .checksum_padding = 0, .checksum_body = 154787626362930377789479683857780696253, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 512, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.ping, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .checkpoint_id = 321854455202207724029466302309042662424, .checkpoint_op = 0, .ping_timestamp_monotonic = 36112342907234970, .release_count = 1, .route_padding = { 0, 0, 0, 0, 0, 0 }, .route = 0, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:06:19.387Z debug(replica): 0N: on_prepare_ok: not preparing op=215 checksum=167518648183311212171522326560367878953
2025-11-24 15:06:19.387Z debug(replica): 1n: sending pong to replica 2: vsr.message_header.Header.Pong{ .checksum = 247784676733778277050613900967281276851, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.pong, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .ping_timestamp_monotonic = 36112342907234970, .pong_timestamp_wall = 1763996779387571478, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:06:19.387Z debug(vsr): 2: grid_repair_budget_timeout fired
2025-11-24 15:06:19.387Z debug(vsr): 2: grid_repair_budget_timeout reset
2025-11-24 15:06:19.387Z debug(replica): 0N: on_message: view=3 status=normal vsr.message_header.Header.Request{ .checksum = 248958360981229250101762850819705921646, .checksum_padding = 0, .checksum_body = 144059847831243404350899927634767905925, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2320, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 139181995639685761956576437996683153970, .parent_padding = 0, .client = 101421002854235361169396488099400081924, .session = 2, .timestamp = 0, .request = 214, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 2617628177, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:06:19.387Z debug(replica): 0N: on_request: new request
2025-11-24 15:06:19.387Z debug(replica): 2n: on_message: view=3 status=normal vsr.message_header.Header.Pong{ .checksum = 247784676733778277050613900967281276851, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.pong, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .ping_timestamp_monotonic = 36112342907234970, .pong_timestamp_wall = 1763996779387571478, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:06:19.387Z debug(replica): 0N: primary_pipeline_prepare: request checksum=248958360981229250101762850819705921646 client=101421002854235361169396488099400081924
2025-11-24 15:06:19.387Z debug(clock): 2: learn: replica=1 m0=36112342907234970 t1=1763996779387571478 m2=36112342907563570 t2=1763996779387720628 one_way_delay=164300 asymmetric_delay=0 clock_offset=15150
2025-11-24 15:06:19.387Z debug(replica): 0N: primary_pipeline_prepare: prepare checksum=99037102129548232079275319312002273434 op=216
2025-11-24 15:06:19.387Z debug(vsr): 0: prepare_timeout started
2025-11-24 15:06:19.387Z debug(vsr): 0: primary_abdicate_timeout started
2025-11-24 15:06:19.387Z debug(vsr): 0: pulse_timeout reset
2025-11-24 15:06:19.387Z debug(replica): 0N: replicate: replicating op=216 to replica 2
2025-11-24 15:06:19.387Z debug(replica): 0N: sending prepare to replica 2: vsr.message_header.Header.Prepare{ .checksum = 99037102129548232079275319312002273434, .checksum_padding = 0, .checksum_body = 144059847831243404350899927634767905925, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2320, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 167518648183311212171522326560367878953, .parent_padding = 0, .request_checksum = 248958360981229250101762850819705921646, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 101421002854235361169396488099400081924, .op = 216, .commit = 215, .timestamp = 1763996779387713878, .request = 214, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-11-24 15:06:19.387Z debug(replica): 0N: replicate: replicating op=216 to replica 1
2025-11-24 15:06:19.392Z debug(vsr): 1: journal_repair_budget_timeout fired
2025-11-24 15:06:19.392Z debug(vsr): 1: journal_repair_budget_timeout reset
2025-11-24 15:06:19.412Z debug(vsr): 1: start_view_change_message_timeout fired
2025-11-24 15:06:19.412Z debug(vsr): 1: start_view_change_message_timeout reset
2025-11-24 15:06:19.412Z debug(vsr): 1: journal_repair_budget_timeout fired
2025-11-24 15:06:19.387Z debug(replica): 0N: sending prepare to replica 1: vsr.message_header.Header.Prepare{ .checksum = 99037102129548232079275319312002273434, .checksum_padding = 0, .checksum_body = 144059847831243404350899927634767905925, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2320, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 167518648183311212171522326560367878953, .parent_padding = 0, .request_checksum = 248958360981229250101762850819705921646, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 101421002854235361169396488099400081924, .op = 216, .commit = 215, .timestamp = 1763996779387713878, .request = 214, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-11-24 15:06:19.412Z debug(vsr): 1: journal_repair_budget_timeout reset
2025-11-24 15:06:19.387Z debug(replica): 2n: on_message: view=3 status=normal vsr.message_header.Header.Prepare{ .checksum = 99037102129548232079275319312002273434, .checksum_padding = 0, .checksum_body = 144059847831243404350899927634767905925, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2320, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 167518648183311212171522326560367878953, .parent_padding = 0, .request_checksum = 248958360981229250101762850819705921646, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 101421002854235361169396488099400081924, .op = 216, .commit = 215, .timestamp = 1763996779387713878, .request = 214, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-11-24 15:06:21.837Z debug(vsr): 1: journal_repair_timeout fired
2025-11-24 15:06:21.837Z debug(vsr): 1: journal_repair_timeout reset
2025-11-24 15:06:21.837Z debug(replica): 2n: on_prepare: advancing commit_max=214..215
2025-11-24 15:06:21.837Z debug(replica): 2n: on_prepare: caching prepare.op=216 (commit_min=214 op=215 commit_max=215 prepare_max=1007)
2025-11-24 15:06:21.837Z debug(replica): 0N: on_prepare: advancing: op=215..216 checksum=167518648183311212171522326560367878953..99037102129548232079275319312002273434
2025-11-24 15:06:21.837Z debug(journal): 0: set_header_as_dirty: op=216 checksum=99037102129548232079275319312002273434
2025-11-24 15:06:21.837Z debug(replica): 0N: append: appending to journal op=216
2025-11-24 15:06:21.837Z debug(journal): 0: write: view=3 slot=216 op=216 len=2320: 99037102129548232079275319312002273434 starting
2025-11-24 15:06:21.837Z debug(journal): 0: write_sectors: ring=vsr.journal.Ring.prepares offset=226492416 len=4096 locked
2025-11-24 15:06:21.837Z debug(replica): 2n: on_prepare: advancing: op=215..216 checksum=167518648183311212171522326560367878953..99037102129548232079275319312002273434
2025-11-24 15:06:21.837Z debug(journal): 2: set_header_as_dirty: op=216 checksum=99037102129548232079275319312002273434
2025-11-24 15:06:21.837Z debug(replica): 2n: append: appending to journal op=216
2025-11-24 15:06:21.837Z debug(journal): 2: write: view=3 slot=216 op=216 len=2320: 99037102129548232079275319312002273434 starting
2025-11-24 15:06:21.837Z debug(replica): 0N: on_message: view=3 status=normal vsr.message_header.Header.Request{ .checksum = 248958360981229250101762850819705921646, .checksum_padding = 0, .checksum_body = 144059847831243404350899927634767905925, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2320, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 139181995639685761956576437996683153970, .parent_padding = 0, .client = 101421002854235361169396488099400081924, .session = 2, .timestamp = 0, .request = 214, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 2617628177, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:06:21.837Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.prepares offset=226492416 len=4096 locked
2025-11-24 15:06:21.837Z debug(replica): 0N: on_request: new request
2025-11-24 15:06:21.837Z debug(vsr): 1: grid_repair_budget_timeout fired
2025-11-24 15:06:21.837Z debug(replica): 2n: commit_start_journal: cached prepare op=215 checksum=167518648183311212171522326560367878953
2025-11-24 15:06:21.837Z debug(replica): 0N: on_request: ignoring (already preparing)
2025-11-24 15:06:21.837Z debug(vsr): 1: grid_repair_budget_timeout reset
2025-11-24 15:06:21.837Z debug(replica): 1n: on_message: view=3 status=normal vsr.message_header.Header.Prepare{ .checksum = 99037102129548232079275319312002273434, .checksum_padding = 0, .checksum_body = 144059847831243404350899927634767905925, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2320, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 167518648183311212171522326560367878953, .parent_padding = 0, .request_checksum = 248958360981229250101762850819705921646, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 101421002854235361169396488099400081924, .op = 216, .commit = 215, .timestamp = 1763996779387713878, .request = 214, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-11-24 15:06:21.837Z debug(replica): 1n: on_prepare: advancing commit_max=214..215
2025-11-24 15:06:21.837Z debug(replica): 1n: on_prepare: caching prepare.op=216 (commit_min=214 op=215 commit_max=215 prepare_max=1007)
2025-11-24 15:06:21.837Z debug(replica): 1n: on_prepare: advancing: op=215..216 checksum=167518648183311212171522326560367878953..99037102129548232079275319312002273434
2025-11-24 15:06:21.837Z debug(journal): 1: set_header_as_dirty: op=216 checksum=99037102129548232079275319312002273434
2025-11-24 15:06:21.837Z debug(replica): 1n: append: appending to journal op=216
2025-11-24 15:06:21.837Z debug(journal): 1: write: view=3 slot=216 op=216 len=2320: 99037102129548232079275319312002273434 starting
2025-11-24 15:06:21.837Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.prepares offset=226492416 len=4096 locked
2025-11-24 15:06:21.837Z debug(replica): 1n: commit_start_journal: cached prepare op=215 checksum=167518648183311212171522326560367878953
2025-11-24 15:06:21.838Z debug(client_replies): 0: read_reply: done (client=101421002854235361169396488099400081924 reply=179654285882777228976869830971971184436)
2025-11-24 15:06:21.838Z debug(replica): 0N: on_request: repeat reply (client=101421002854235361169396488099400081924 request=213)
2025-11-24 15:06:21.838Z debug(replica): 0N: sending reply to client 101421002854235361169396488099400081924: vsr.message_header.Header.Reply{ .checksum = 179654285882777228976869830971971184436, .checksum_padding = 0, .checksum_body = 280389260678910035616807846124571220344, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 280, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 36693962140251088650422001759891473089, .request_checksum_padding = 0, .context = 139181995639685761956576437996683153970, .context_padding = 0, .client = 101421002854235361169396488099400081924, .op = 215, .commit = 215, .timestamp = 1763996779354175499, .request = 213, .operation = vsr.Operation(139), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:06:21.838Z debug(replica): 0N: on_message: view=3 status=normal vsr.message_header.Header.Request{ .checksum = 248958360981229250101762850819705921646, .checksum_padding = 0, .checksum_body = 144059847831243404350899927634767905925, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2320, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 139181995639685761956576437996683153970, .parent_padding = 0, .client = 101421002854235361169396488099400081924, .session = 2, .timestamp = 0, .request = 214, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 2617628177, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:06:21.838Z debug(replica): 0N: on_request: new request
2025-11-24 15:06:21.838Z debug(replica): 0N: on_request: ignoring (already preparing)
2025-11-24 15:06:21.838Z debug(replica): 0N: on_message: view=3 status=normal vsr.message_header.Header.Request{ .checksum = 248958360981229250101762850819705921646, .checksum_padding = 0, .checksum_body = 144059847831243404350899927634767905925, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2320, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 139181995639685761956576437996683153970, .parent_padding = 0, .client = 101421002854235361169396488099400081924, .session = 2, .timestamp = 0, .request = 214, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 2617628177, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:06:21.838Z debug(replica): 0N: on_request: new request
2025-11-24 15:06:21.838Z debug(replica): 0N: on_request: ignoring (already preparing)
2025-11-24 15:06:21.838Z debug(replica): 0N: on_message: view=3 status=normal vsr.message_header.Header.Ping{ .checksum = 144728276303700702187007706959693407515, .checksum_padding = 0, .checksum_body = 154787626362930377789479683857780696253, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 512, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.ping, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .checkpoint_id = 321854455202207724029466302309042662424, .checkpoint_op = 0, .ping_timestamp_monotonic = 36112342907234970, .release_count = 1, .route_padding = { 0, 0, 0, 0, 0, 0 }, .route = 0, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:06:21.838Z debug(replica): 0N: sending pong to replica 2: vsr.message_header.Header.Pong{ .checksum = 127354576853980787843053256048774288716, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.pong, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .ping_timestamp_monotonic = 36112342907234970, .pong_timestamp_wall = 1763996781838513456, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:06:21.838Z debug(journal): 0: write_sectors: ring=vsr.journal.Ring.prepares offset=226492416 len=4096 unlocked
2025-11-24 15:06:21.838Z debug(journal): 0: write_header: op=216 sectors[53248..57344]
2025-11-24 15:06:21.838Z debug(journal): 0: write_sectors: ring=vsr.journal.Ring.headers offset=53248 len=4096 locked
2025-11-24 15:06:21.839Z debug(journal): 0: write_sectors: ring=vsr.journal.Ring.headers offset=53248 len=4096 unlocked
2025-11-24 15:06:21.839Z debug(journal): 0: write: view=3 slot=216 op=216 len=2320: 99037102129548232079275319312002273434 complete, marking clean
2025-11-24 15:06:21.839Z debug(replica): 0N: send_prepare_ok: op=216 checksum=99037102129548232079275319312002273434
2025-11-24 15:06:21.839Z debug(replica): 0N: sending prepare_ok to replica 0: vsr.message_header.Header.PrepareOk{ .checksum = 233325183446000786713759459342123860761, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 167518648183311212171522326560367878953, .parent_padding = 0, .prepare_checksum = 99037102129548232079275319312002273434, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 101421002854235361169396488099400081924, .op = 216, .commit_min = 215, .timestamp = 1763996779387713878, .request = 214, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-11-24 15:06:21.839Z debug(replica): 0N: on_message: view=3 status=normal vsr.message_header.Header.PrepareOk{ .checksum = 233325183446000786713759459342123860761, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 167518648183311212171522326560367878953, .parent_padding = 0, .prepare_checksum = 99037102129548232079275319312002273434, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 101421002854235361169396488099400081924, .op = 216, .commit_min = 215, .timestamp = 1763996779387713878, .request = 214, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-11-24 15:06:21.839Z debug(vsr): 0: primary_abdicate_timeout reset
2025-11-24 15:06:21.839Z debug(replica): 0N: on_prepare_ok: 1 message(s)
2025-11-24 15:06:21.839Z debug(replica): 0N: on_prepare_ok: waiting for quorum
2025-11-24 15:06:21.839Z debug(vsr): 0: journal_repair_budget_timeout fired
2025-11-24 15:06:21.839Z debug(vsr): 0: journal_repair_budget_timeout reset
2025-11-24 15:06:21.839Z debug(replica): 2n: repair_prepare: op=216 checksum=99037102129548232079275319312002273434 (already writing)
2025-11-24 15:06:21.839Z debug(replica): 1n: repair_prepare: op=216 checksum=99037102129548232079275319312002273434 (already writing)
2025-11-24 15:06:21.839Z debug(replica): 1n: commit_journal: already committing (prefetch; commit_min=214)
2025-11-24 15:06:21.839Z debug(replica): 2n: commit_journal: already committing (prefetch; commit_min=214)
2025-11-24 15:06:21.841Z debug(replica): 1n: execute_op: executing view=3 primary=false op=215 checksum=167518648183311212171522326560367878953 (create_transfers)
2025-11-24 15:06:21.841Z debug(replica): 1n: execute_op: commit_timestamp=1763996776754025556 prepare.header.timestamp=1763996779354175499
2025-11-24 15:06:21.841Z debug(replica): 2n: execute_op: executing view=3 primary=false op=215 checksum=167518648183311212171522326560367878953 (create_transfers)
2025-11-24 15:06:21.841Z debug(replica): 2n: execute_op: commit_timestamp=1763996776754025556 prepare.header.timestamp=1763996779354175499
2025-11-24 15:06:21.850Z debug(replica): 2n: client_table_entry_update: client=101421002854235361169396488099400081924 session=2 request=213
2025-11-24 15:06:21.850Z debug(replica): 2n: execute_op: replying to client: vsr.message_header.Header.Reply{ .checksum = 179654285882777228976869830971971184436, .checksum_padding = 0, .checksum_body = 280389260678910035616807846124571220344, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 280, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 36693962140251088650422001759891473089, .request_checksum_padding = 0, .context = 139181995639685761956576437996683153970, .context_padding = 0, .client = 101421002854235361169396488099400081924, .op = 215, .commit = 215, .timestamp = 1763996779354175499, .request = 213, .operation = vsr.Operation(139), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:06:21.850Z debug(replica): 2n: sending reply to client 101421002854235361169396488099400081924: vsr.message_header.Header.Reply{ .checksum = 179654285882777228976869830971971184436, .checksum_padding = 0, .checksum_body = 280389260678910035616807846124571220344, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 280, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 36693962140251088650422001759891473089, .request_checksum_padding = 0, .context = 139181995639685761956576437996683153970, .context_padding = 0, .client = 101421002854235361169396488099400081924, .op = 215, .commit = 215, .timestamp = 1763996779354175499, .request = 213, .operation = vsr.Operation(139), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:06:21.850Z debug(forest): entering forest.compact() op=215 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2025-11-24 15:06:21.854Z debug(replica): 1n: client_table_entry_update: client=101421002854235361169396488099400081924 session=2 request=213
2025-11-24 15:06:21.854Z debug(forest): entering forest.compact() op=215 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2025-11-24 15:06:21.855Z debug(replica): 2n: on_message: view=3 status=normal vsr.message_header.Header.Request{ .checksum = 248958360981229250101762850819705921646, .checksum_padding = 0, .checksum_body = 144059847831243404350899927634767905925, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2320, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 139181995639685761956576437996683153970, .parent_padding = 0, .client = 101421002854235361169396488099400081924, .session = 2, .timestamp = 0, .request = 214, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 2617628177, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:06:21.855Z debug(replica): 2n: on_request: forwarding new request to primary (view=3)
2025-11-24 15:06:21.855Z debug(replica): 2n: sending request to replica 0: vsr.message_header.Header.Request{ .checksum = 248958360981229250101762850819705921646, .checksum_padding = 0, .checksum_body = 144059847831243404350899927634767905925, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2320, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 139181995639685761956576437996683153970, .parent_padding = 0, .client = 101421002854235361169396488099400081924, .session = 2, .timestamp = 0, .request = 214, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 2617628177, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:06:21.855Z debug(replica): 2n: on_message: view=3 status=normal vsr.message_header.Header.Pong{ .checksum = 127354576853980787843053256048774288716, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.pong, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .ping_timestamp_monotonic = 36112342907234970, .pong_timestamp_wall = 1763996781838513456, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:06:21.855Z debug(replica): 0N: on_message: view=3 status=normal vsr.message_header.Header.Request{ .checksum = 248958360981229250101762850819705921646, .checksum_padding = 0, .checksum_body = 144059847831243404350899927634767905925, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2320, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 139181995639685761956576437996683153970, .parent_padding = 0, .client = 101421002854235361169396488099400081924, .session = 2, .timestamp = 0, .request = 214, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 2617628177, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:06:21.855Z debug(clock): 2: learn: replica=0 m0=36112342907234970 t1=1763996781838513456 m2=36112345375646551 t2=1763996781855803609 one_way_delay=1234205790 asymmetric_delay=0 clock_offset=1216915637
2025-11-24 15:06:21.855Z debug(vsr): 2: prepare_timeout rtt=30..246
2025-11-24 15:06:21.855Z debug(replica): 0N: on_request: new request
2025-11-24 15:06:21.855Z debug(replica): 0N: on_request: ignoring (already preparing)
2025-11-24 15:06:21.855Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.prepares offset=226492416 len=4096 unlocked
2025-11-24 15:06:21.855Z debug(journal): 2: write_header: op=216 sectors[53248..57344]
2025-11-24 15:06:21.855Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.headers offset=53248 len=4096 locked
2025-11-24 15:06:21.855Z debug(client_replies): 2: write_reply: wrote (client=101421002854235361169396488099400081924 request=213)
2025-11-24 15:06:21.856Z debug(replica): 2n: on_message: view=3 status=normal vsr.message_header.Header.Request{ .checksum = 248958360981229250101762850819705921646, .checksum_padding = 0, .checksum_body = 144059847831243404350899927634767905925, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2320, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 139181995639685761956576437996683153970, .parent_padding = 0, .client = 101421002854235361169396488099400081924, .session = 2, .timestamp = 0, .request = 214, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 2617628177, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:06:21.856Z debug(replica): 2n: on_request: forwarding new request to primary (view=3)
2025-11-24 15:06:21.856Z debug(replica): 2n: sending request to replica 0: vsr.message_header.Header.Request{ .checksum = 248958360981229250101762850819705921646, .checksum_padding = 0, .checksum_body = 144059847831243404350899927634767905925, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2320, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 139181995639685761956576437996683153970, .parent_padding = 0, .client = 101421002854235361169396488099400081924, .session = 2, .timestamp = 0, .request = 214, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 2617628177, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:06:21.856Z debug(replica): 0N: on_message: view=3 status=normal vsr.message_header.Header.Request{ .checksum = 248958360981229250101762850819705921646, .checksum_padding = 0, .checksum_body = 144059847831243404350899927634767905925, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2320, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 139181995639685761956576437996683153970, .parent_padding = 0, .client = 101421002854235361169396488099400081924, .session = 2, .timestamp = 0, .request = 214, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 2617628177, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:06:21.856Z debug(replica): 0N: on_request: new request
2025-11-24 15:06:21.856Z debug(replica): 0N: on_request: ignoring (already preparing)
2025-11-24 15:06:21.856Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.headers offset=53248 len=4096 unlocked
2025-11-24 15:06:21.856Z debug(journal): 2: write: view=3 slot=216 op=216 len=2320: 99037102129548232079275319312002273434 complete, marking clean
2025-11-24 15:06:21.856Z debug(replica): 2n: send_prepare_ok: op=216 checksum=99037102129548232079275319312002273434
2025-11-24 15:06:21.856Z debug(replica): 2n: sending prepare_ok to replica 0: vsr.message_header.Header.PrepareOk{ .checksum = 258876925003018556368316237176157223289, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 167518648183311212171522326560367878953, .parent_padding = 0, .prepare_checksum = 99037102129548232079275319312002273434, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 101421002854235361169396488099400081924, .op = 216, .commit_min = 215, .timestamp = 1763996779387713878, .request = 214, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-11-24 15:06:21.856Z info(clock): 2: synchronized: accuracy=0ns
2025-11-24 15:06:21.856Z debug(clock): 2: synchronized: truechimers=3/3 clock_offset=0ns..0ns accuracy=0ns
2025-11-24 15:06:21.856Z debug(clock): 2: system time is 170ns behind
2025-11-24 15:06:21.856Z debug(vsr): 2: journal_repair_budget_timeout fired
2025-11-24 15:06:21.856Z debug(vsr): 2: journal_repair_budget_timeout reset
2025-11-24 15:06:21.859Z debug(vsr): 0: journal_repair_budget_timeout fired
2025-11-24 15:06:21.859Z debug(vsr): 0: journal_repair_budget_timeout reset
2025-11-24 15:06:21.862Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.prepares offset=226492416 len=4096 unlocked
2025-11-24 15:06:21.862Z debug(journal): 1: write_header: op=216 sectors[53248..57344]
2025-11-24 15:06:21.862Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.headers offset=53248 len=4096 locked
2025-11-24 15:06:21.862Z debug(client_replies): 1: write_reply: wrote (client=101421002854235361169396488099400081924 request=213)
2025-11-24 15:06:21.862Z warning(clock): 1: synchronization failed, partitioned (sources=1 samples=1)
2025-11-24 15:06:21.862Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.headers offset=53248 len=4096 unlocked
2025-11-24 15:06:21.862Z debug(journal): 1: write: view=3 slot=216 op=216 len=2320: 99037102129548232079275319312002273434 complete, marking clean
2025-11-24 15:06:21.862Z debug(replica): 1n: send_prepare_ok: op=216 checksum=99037102129548232079275319312002273434
2025-11-24 15:06:21.862Z debug(replica): 1n: sending prepare_ok to replica 0: vsr.message_header.Header.PrepareOk{ .checksum = 291024338496160064982390136547836229025, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 167518648183311212171522326560367878953, .parent_padding = 0, .prepare_checksum = 99037102129548232079275319312002273434, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 101421002854235361169396488099400081924, .op = 216, .commit_min = 215, .timestamp = 1763996779387713878, .request = 214, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-11-24 15:06:21.862Z debug(replica): 0N: on_message: view=3 status=normal vsr.message_header.Header.PrepareOk{ .checksum = 291024338496160064982390136547836229025, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 167518648183311212171522326560367878953, .parent_padding = 0, .prepare_checksum = 99037102129548232079275319312002273434, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 101421002854235361169396488099400081924, .op = 216, .commit_min = 215, .timestamp = 1763996779387713878, .request = 214, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-11-24 15:06:21.862Z debug(vsr): 0: primary_abdicate_timeout reset
2025-11-24 15:06:21.862Z debug(replica): 0N: on_prepare_ok: 2 message(s)
2025-11-24 15:06:21.862Z debug(replica): 0N: on_prepare_ok: quorum received, context=99037102129548232079275319312002273434
2025-11-24 15:06:21.862Z debug(vsr): 0: prepare_timeout stopped
2025-11-24 15:06:21.862Z debug(vsr): 0: primary_abdicate_timeout stopped
2025-11-24 15:06:21.862Z debug(replica): 0N: execute_op: executing view=3 primary=true op=216 checksum=99037102129548232079275319312002273434 (lookup_accounts)
2025-11-24 15:06:21.862Z debug(replica): 0N: execute_op: commit_timestamp=1763996779354175499 prepare.header.timestamp=1763996779387713878
2025-11-24 15:06:21.863Z debug(replica): 0N: execute_op: advancing commit_max=215..216
2025-11-24 15:06:21.863Z debug(replica): 0N: client_table_entry_update: client=101421002854235361169396488099400081924 session=2 request=214
2025-11-24 15:06:21.863Z debug(replica): 0N: execute_op: replying to client: vsr.message_header.Header.Reply{ .checksum = 328716309843731570778453509540666711245, .checksum_padding = 0, .checksum_body = 189610271883321161562449566723649409024, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 16768, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 248958360981229250101762850819705921646, .request_checksum_padding = 0, .context = 272150941072900534306056524688249254576, .context_padding = 0, .client = 101421002854235361169396488099400081924, .op = 216, .commit = 216, .timestamp = 1763996779387713878, .request = 214, .operation = vsr.Operation(140), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:06:21.863Z debug(replica): 0N: sending reply to client 101421002854235361169396488099400081924: vsr.message_header.Header.Reply{ .checksum = 328716309843731570778453509540666711245, .checksum_padding = 0, .checksum_body = 189610271883321161562449566723649409024, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 16768, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 248958360981229250101762850819705921646, .request_checksum_padding = 0, .context = 272150941072900534306056524688249254576, .context_padding = 0, .client = 101421002854235361169396488099400081924, .op = 216, .commit = 216, .timestamp = 1763996779387713878, .request = 214, .operation = vsr.Operation(140), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:06:21.863Z debug(forest): entering forest.compact() op=216 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
warning(client): 101421002854235361169396488099400081924: on_reply: slow request, request=214 op=216 size=2320 lookup_accounts time=2476ms
2025-11-24 15:06:21.863Z debug(client_replies): 0: write_reply: wrote (client=101421002854235361169396488099400081924 request=214)
2025-11-24 15:06:21.863Z info(workload): accounts created = 128, transfers = 263410, pending transfers = 0, commands run = 107
2025-11-24 15:06:21.867Z debug(replica): 0N: on_message: view=3 status=normal vsr.message_header.Header.Request{ .checksum = 117120712331201783637358421417106789438, .checksum_padding = 0, .checksum_body = 322263339554650050380922881321413982200, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 222336, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 272150941072900534306056524688249254576, .parent_padding = 0, .client = 101421002854235361169396488099400081924, .session = 2, .timestamp = 0, .request = 215, .operation = vsr.Operation(139), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 2476604798, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:06:21.867Z debug(replica): 0N: on_request: new request
2025-11-24 15:06:21.867Z debug(replica): 0N: primary_pipeline_prepare: request checksum=117120712331201783637358421417106789438 client=101421002854235361169396488099400081924
2025-11-24 15:06:21.867Z debug(replica): 1n: on_message: view=3 status=normal vsr.message_header.Header.Request{ .checksum = 117120712331201783637358421417106789438, .checksum_padding = 0, .checksum_body = 322263339554650050380922881321413982200, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 222336, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 272150941072900534306056524688249254576, .parent_padding = 0, .client = 101421002854235361169396488099400081924, .session = 2, .timestamp = 0, .request = 215, .operation = vsr.Operation(139), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 2476604798, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:06:21.867Z debug(replica): 1n: on_request: forwarding new request to primary (view=3)
2025-11-24 15:06:21.867Z debug(replica): 1n: sending request to replica 0: vsr.message_header.Header.Request{ .checksum = 117120712331201783637358421417106789438, .checksum_padding = 0, .checksum_body = 322263339554650050380922881321413982200, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 222336, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 272150941072900534306056524688249254576, .parent_padding = 0, .client = 101421002854235361169396488099400081924, .session = 2, .timestamp = 0, .request = 215, .operation = vsr.Operation(139), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 2476604798, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:06:21.868Z debug(replica): 0N: primary_pipeline_prepare: prepare checksum=190464554993171704940395981855707690071 op=217
2025-11-24 15:06:21.868Z debug(vsr): 0: prepare_timeout started
2025-11-24 15:06:21.868Z debug(vsr): 0: primary_abdicate_timeout started
2025-11-24 15:06:21.868Z debug(vsr): 0: pulse_timeout reset
2025-11-24 15:06:21.868Z debug(replica): 0N: replicate: replicating op=217 to replica 2
2025-11-24 15:06:21.868Z debug(replica): 0N: sending prepare to replica 2: vsr.message_header.Header.Prepare{ .checksum = 190464554993171704940395981855707690071, .checksum_padding = 0, .checksum_body = 322263339554650050380922881321413982200, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 222336, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 99037102129548232079275319312002273434, .parent_padding = 0, .request_checksum = 117120712331201783637358421417106789438, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 101421002854235361169396488099400081924, .op = 217, .commit = 216, .timestamp = 1763996781867376548, .request = 215, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-11-24 15:06:21.868Z debug(replica): 0N: replicate: replicating op=217 to replica 1
2025-11-24 15:06:21.868Z debug(replica): 0N: sending prepare to replica 1: vsr.message_header.Header.Prepare{ .checksum = 190464554993171704940395981855707690071, .checksum_padding = 0, .checksum_body = 322263339554650050380922881321413982200, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 222336, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 99037102129548232079275319312002273434, .parent_padding = 0, .request_checksum = 117120712331201783637358421417106789438, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 101421002854235361169396488099400081924, .op = 217, .commit = 216, .timestamp = 1763996781867376548, .request = 215, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-11-24 15:06:21.868Z debug(replica): 0N: on_prepare: advancing: op=216..217 checksum=99037102129548232079275319312002273434..190464554993171704940395981855707690071
2025-11-24 15:06:21.868Z debug(journal): 0: set_header_as_dirty: op=217 checksum=190464554993171704940395981855707690071
2025-11-24 15:06:21.868Z debug(replica): 0N: append: appending to journal op=217
2025-11-24 15:06:21.868Z debug(journal): 0: write: view=3 slot=217 op=217 len=222336: 190464554993171704940395981855707690071 starting
2025-11-24 15:06:21.868Z debug(journal): 0: write_sectors: ring=vsr.journal.Ring.prepares offset=227540992 len=225280 locked
2025-11-24 15:06:21.868Z debug(replica): 0N: on_message: view=3 status=normal vsr.message_header.Header.PrepareOk{ .checksum = 258876925003018556368316237176157223289, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 167518648183311212171522326560367878953, .parent_padding = 0, .prepare_checksum = 99037102129548232079275319312002273434, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 101421002854235361169396488099400081924, .op = 216, .commit_min = 215, .timestamp = 1763996779387713878, .request = 214, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-11-24 15:06:21.868Z debug(replica): 0N: on_prepare_ok: not preparing op=216 checksum=99037102129548232079275319312002273434
2025-11-24 15:06:21.869Z debug(replica): 0N: on_message: view=3 status=normal vsr.message_header.Header.Request{ .checksum = 117120712331201783637358421417106789438, .checksum_padding = 0, .checksum_body = 322263339554650050380922881321413982200, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 222336, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 272150941072900534306056524688249254576, .parent_padding = 0, .client = 101421002854235361169396488099400081924, .session = 2, .timestamp = 0, .request = 215, .operation = vsr.Operation(139), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 2476604798, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:06:21.869Z debug(replica): 0N: on_request: new request
2025-11-24 15:06:21.869Z debug(replica): 0N: on_request: ignoring (already preparing)
2025-11-24 15:06:21.869Z debug(replica): 1n: on_message: view=3 status=normal vsr.message_header.Header.Prepare{ .checksum = 190464554993171704940395981855707690071, .checksum_padding = 0, .checksum_body = 322263339554650050380922881321413982200, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 222336, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 99037102129548232079275319312002273434, .parent_padding = 0, .request_checksum = 117120712331201783637358421417106789438, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 101421002854235361169396488099400081924, .op = 217, .commit = 216, .timestamp = 1763996781867376548, .request = 215, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-11-24 15:06:21.869Z debug(replica): 1n: on_prepare: advancing commit_max=215..216
2025-11-24 15:06:21.869Z debug(replica): 1n: on_prepare: caching prepare.op=217 (commit_min=215 op=216 commit_max=216 prepare_max=1007)
2025-11-24 15:06:21.869Z debug(journal): 0: write_sectors: ring=vsr.journal.Ring.prepares offset=227540992 len=225280 unlocked
2025-11-24 15:06:21.869Z debug(replica): 2n: on_message: view=3 status=normal vsr.message_header.Header.Prepare{ .checksum = 190464554993171704940395981855707690071, .checksum_padding = 0, .checksum_body = 322263339554650050380922881321413982200, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 222336, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 99037102129548232079275319312002273434, .parent_padding = 0, .request_checksum = 117120712331201783637358421417106789438, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 101421002854235361169396488099400081924, .op = 217, .commit = 216, .timestamp = 1763996781867376548, .request = 215, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-11-24 15:06:21.869Z debug(journal): 0: write_header: op=217 sectors[53248..57344]
2025-11-24 15:06:21.869Z debug(journal): 0: write_sectors: ring=vsr.journal.Ring.headers offset=53248 len=4096 locked
2025-11-24 15:06:21.869Z debug(replica): 2n: on_prepare: advancing commit_max=215..216
2025-11-24 15:06:21.869Z debug(replica): 2n: on_prepare: caching prepare.op=217 (commit_min=215 op=216 commit_max=216 prepare_max=1007)
2025-11-24 15:06:21.870Z debug(replica): 1n: on_prepare: advancing: op=216..217 checksum=99037102129548232079275319312002273434..190464554993171704940395981855707690071
2025-11-24 15:06:21.870Z debug(journal): 1: set_header_as_dirty: op=217 checksum=190464554993171704940395981855707690071
2025-11-24 15:06:21.870Z debug(replica): 1n: append: appending to journal op=217
2025-11-24 15:06:21.870Z debug(journal): 1: write: view=3 slot=217 op=217 len=222336: 190464554993171704940395981855707690071 starting
2025-11-24 15:06:21.870Z debug(replica): 2n: on_prepare: advancing: op=216..217 checksum=99037102129548232079275319312002273434..190464554993171704940395981855707690071
2025-11-24 15:06:21.870Z debug(journal): 2: set_header_as_dirty: op=217 checksum=190464554993171704940395981855707690071
2025-11-24 15:06:21.870Z debug(replica): 2n: append: appending to journal op=217
2025-11-24 15:06:21.870Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.prepares offset=227540992 len=225280 locked
2025-11-24 15:06:21.870Z debug(journal): 2: write: view=3 slot=217 op=217 len=222336: 190464554993171704940395981855707690071 starting
2025-11-24 15:06:21.870Z debug(replica): 1n: commit_start_journal: cached prepare op=216 checksum=99037102129548232079275319312002273434
2025-11-24 15:06:21.870Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.prepares offset=227540992 len=225280 locked
2025-11-24 15:06:21.870Z debug(replica): 2n: commit_start_journal: cached prepare op=216 checksum=99037102129548232079275319312002273434
2025-11-24 15:06:21.870Z debug(replica): 1n: repair_prepare: op=217 checksum=190464554993171704940395981855707690071 (already writing)
2025-11-24 15:06:21.870Z debug(replica): 2n: repair_prepare: op=217 checksum=190464554993171704940395981855707690071 (already writing)
2025-11-24 15:06:21.870Z debug(replica): 1n: commit_journal: already committing (prefetch; commit_min=215)
2025-11-24 15:06:21.870Z debug(replica): 2n: commit_journal: already committing (prefetch; commit_min=215)
2025-11-24 15:06:21.870Z debug(replica): 2n: execute_op: executing view=3 primary=false op=216 checksum=99037102129548232079275319312002273434 (lookup_accounts)
2025-11-24 15:06:21.870Z debug(replica): 1n: execute_op: executing view=3 primary=false op=216 checksum=99037102129548232079275319312002273434 (lookup_accounts)
2025-11-24 15:06:21.870Z debug(replica): 2n: execute_op: commit_timestamp=1763996779354175499 prepare.header.timestamp=1763996779387713878
2025-11-24 15:06:21.870Z debug(replica): 1n: execute_op: commit_timestamp=1763996779354175499 prepare.header.timestamp=1763996779387713878
2025-11-24 15:06:21.870Z debug(replica): 1n: client_table_entry_update: client=101421002854235361169396488099400081924 session=2 request=214
2025-11-24 15:06:21.870Z debug(replica): 2n: client_table_entry_update: client=101421002854235361169396488099400081924 session=2 request=214
2025-11-24 15:06:21.870Z debug(forest): entering forest.compact() op=216 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2025-11-24 15:06:21.870Z debug(replica): 2n: execute_op: replying to client: vsr.message_header.Header.Reply{ .checksum = 328716309843731570778453509540666711245, .checksum_padding = 0, .checksum_body = 189610271883321161562449566723649409024, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 16768, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 248958360981229250101762850819705921646, .request_checksum_padding = 0, .context = 272150941072900534306056524688249254576, .context_padding = 0, .client = 101421002854235361169396488099400081924, .op = 216, .commit = 216, .timestamp = 1763996779387713878, .request = 214, .operation = vsr.Operation(140), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:06:21.870Z debug(replica): 2n: sending reply to client 101421002854235361169396488099400081924: vsr.message_header.Header.Reply{ .checksum = 328716309843731570778453509540666711245, .checksum_padding = 0, .checksum_body = 189610271883321161562449566723649409024, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 16768, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 248958360981229250101762850819705921646, .request_checksum_padding = 0, .context = 272150941072900534306056524688249254576, .context_padding = 0, .client = 101421002854235361169396488099400081924, .op = 216, .commit = 216, .timestamp = 1763996779387713878, .request = 214, .operation = vsr.Operation(140), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:06:21.870Z debug(forest): entering forest.compact() op=216 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2025-11-24 15:06:21.871Z debug(client_replies): 1: write_reply: wrote (client=101421002854235361169396488099400081924 request=214)
2025-11-24 15:06:21.871Z debug(client_replies): 2: write_reply: wrote (client=101421002854235361169396488099400081924 request=214)
2025-11-24 15:06:21.871Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.prepares offset=227540992 len=225280 unlocked
2025-11-24 15:06:21.871Z debug(journal): 1: write_header: op=217 sectors[53248..57344]
2025-11-24 15:06:21.871Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.headers offset=53248 len=4096 locked
2025-11-24 15:06:21.871Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.headers offset=53248 len=4096 unlocked
2025-11-24 15:06:21.871Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.prepares offset=227540992 len=225280 unlocked
2025-11-24 15:06:21.871Z debug(journal): 1: write: view=3 slot=217 op=217 len=222336: 190464554993171704940395981855707690071 complete, marking clean
2025-11-24 15:06:21.871Z debug(journal): 2: write_header: op=217 sectors[53248..57344]
2025-11-24 15:06:21.871Z debug(replica): 1n: send_prepare_ok: op=217 checksum=190464554993171704940395981855707690071
2025-11-24 15:06:21.871Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.headers offset=53248 len=4096 locked
2025-11-24 15:06:21.871Z debug(replica): 1n: sending prepare_ok to replica 0: vsr.message_header.Header.PrepareOk{ .checksum = 200455666169191606434665318031488147360, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 99037102129548232079275319312002273434, .parent_padding = 0, .prepare_checksum = 190464554993171704940395981855707690071, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 101421002854235361169396488099400081924, .op = 217, .commit_min = 216, .timestamp = 1763996781867376548, .request = 215, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-11-24 15:06:21.871Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.headers offset=53248 len=4096 unlocked
2025-11-24 15:06:21.871Z debug(journal): 2: write: view=3 slot=217 op=217 len=222336: 190464554993171704940395981855707690071 complete, marking clean
2025-11-24 15:06:21.871Z debug(replica): 2n: send_prepare_ok: op=217 checksum=190464554993171704940395981855707690071
2025-11-24 15:06:21.871Z debug(replica): 2n: sending prepare_ok to replica 0: vsr.message_header.Header.PrepareOk{ .checksum = 239895957605776520797258666438870844909, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 99037102129548232079275319312002273434, .parent_padding = 0, .prepare_checksum = 190464554993171704940395981855707690071, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 101421002854235361169396488099400081924, .op = 217, .commit_min = 216, .timestamp = 1763996781867376548, .request = 215, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-11-24 15:06:21.872Z debug(vsr): 1: journal_repair_budget_timeout fired
2025-11-24 15:06:21.872Z debug(vsr): 1: journal_repair_budget_timeout reset
2025-11-24 15:06:21.876Z debug(vsr): 2: journal_repair_budget_timeout fired
2025-11-24 15:06:21.876Z debug(vsr): 2: journal_repair_budget_timeout reset
2025-11-24 15:06:21.880Z debug(journal): 0: write_sectors: ring=vsr.journal.Ring.headers offset=53248 len=4096 unlocked
2025-11-24 15:06:21.880Z debug(journal): 0: write: view=3 slot=217 op=217 len=222336: 190464554993171704940395981855707690071 complete, marking clean
2025-11-24 15:06:21.880Z debug(replica): 0N: send_prepare_ok: op=217 checksum=190464554993171704940395981855707690071
2025-11-24 15:06:21.880Z debug(replica): 0N: sending prepare_ok to replica 0: vsr.message_header.Header.PrepareOk{ .checksum = 87437131101866414718761581328558103972, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 99037102129548232079275319312002273434, .parent_padding = 0, .prepare_checksum = 190464554993171704940395981855707690071, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 101421002854235361169396488099400081924, .op = 217, .commit_min = 216, .timestamp = 1763996781867376548, .request = 215, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-11-24 15:06:21.880Z debug(replica): 0N: on_message: view=3 status=normal vsr.message_header.Header.PrepareOk{ .checksum = 87437131101866414718761581328558103972, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 99037102129548232079275319312002273434, .parent_padding = 0, .prepare_checksum = 190464554993171704940395981855707690071, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 101421002854235361169396488099400081924, .op = 217, .commit_min = 216, .timestamp = 1763996781867376548, .request = 215, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-11-24 15:06:21.880Z debug(vsr): 0: primary_abdicate_timeout reset
2025-11-24 15:06:21.880Z debug(replica): 0N: on_prepare_ok: 1 message(s)
2025-11-24 15:06:21.880Z debug(replica): 0N: on_prepare_ok: waiting for quorum
2025-11-24 15:06:21.880Z debug(vsr): 0: journal_repair_budget_timeout fired
2025-11-24 15:06:21.880Z debug(vsr): 0: journal_repair_budget_timeout reset
2025-11-24 15:06:21.892Z debug(vsr): 1: journal_repair_budget_timeout fired
2025-11-24 15:06:21.892Z debug(vsr): 1: journal_repair_budget_timeout reset
2025-11-24 15:06:21.896Z debug(vsr): 2: journal_repair_budget_timeout fired
2025-11-24 15:06:21.896Z debug(vsr): 2: journal_repair_budget_timeout reset
2025-11-24 15:06:21.900Z debug(vsr): 0: journal_repair_budget_timeout fired
2025-11-24 15:06:21.900Z debug(vsr): 0: journal_repair_budget_timeout reset
2025-11-24 15:06:21.918Z debug(vsr): 2: journal_repair_budget_timeout fired
2025-11-24 15:06:21.912Z debug(vsr): 1: journal_repair_budget_timeout fired
2025-11-24 15:06:24.361Z debug(vsr): 0: journal_repair_timeout fired
2025-11-24 15:06:24.361Z debug(vsr): 2: journal_repair_budget_timeout reset
2025-11-24 15:06:24.361Z debug(vsr): 0: journal_repair_timeout reset
2025-11-24 15:06:24.361Z debug(vsr): 1: journal_repair_budget_timeout reset
2025-11-24 15:06:24.361Z debug(replica): 0N: on_message: view=3 status=normal vsr.message_header.Header.PrepareOk{ .checksum = 239895957605776520797258666438870844909, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 99037102129548232079275319312002273434, .parent_padding = 0, .prepare_checksum = 190464554993171704940395981855707690071, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 101421002854235361169396488099400081924, .op = 217, .commit_min = 216, .timestamp = 1763996781867376548, .request = 215, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-11-24 15:06:24.361Z debug(vsr): 0: primary_abdicate_timeout reset
2025-11-24 15:06:24.361Z debug(replica): 0N: on_prepare_ok: 2 message(s)
2025-11-24 15:06:24.361Z debug(replica): 0N: on_prepare_ok: quorum received, context=190464554993171704940395981855707690071
2025-11-24 15:06:24.361Z debug(vsr): 0: prepare_timeout stopped
2025-11-24 15:06:24.361Z debug(vsr): 0: primary_abdicate_timeout stopped
2025-11-24 15:06:24.362Z debug(replica): 0N: on_message: view=3 status=normal vsr.message_header.Header.PrepareOk{ .checksum = 200455666169191606434665318031488147360, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 99037102129548232079275319312002273434, .parent_padding = 0, .prepare_checksum = 190464554993171704940395981855707690071, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 101421002854235361169396488099400081924, .op = 217, .commit_min = 216, .timestamp = 1763996781867376548, .request = 215, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-11-24 15:06:24.362Z debug(replica): 0N: on_prepare_ok: 3 message(s)
2025-11-24 15:06:24.362Z debug(replica): 0N: on_prepare_ok: ignoring (quorum received already)
2025-11-24 15:06:24.362Z debug(replica): 1n: on_message: view=3 status=normal vsr.message_header.Header.Request{ .checksum = 117120712331201783637358421417106789438, .checksum_padding = 0, .checksum_body = 322263339554650050380922881321413982200, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 222336, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 272150941072900534306056524688249254576, .parent_padding = 0, .client = 101421002854235361169396488099400081924, .session = 2, .timestamp = 0, .request = 215, .operation = vsr.Operation(139), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 2476604798, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:06:24.362Z debug(replica): 1n: on_request: forwarding new request to primary (view=3)
2025-11-24 15:06:24.362Z debug(replica): 1n: sending request to replica 0: vsr.message_header.Header.Request{ .checksum = 117120712331201783637358421417106789438, .checksum_padding = 0, .checksum_body = 322263339554650050380922881321413982200, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 222336, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 272150941072900534306056524688249254576, .parent_padding = 0, .client = 101421002854235361169396488099400081924, .session = 2, .timestamp = 0, .request = 215, .operation = vsr.Operation(139), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 2476604798, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:06:24.362Z debug(replica): 2n: on_message: view=3 status=normal vsr.message_header.Header.Request{ .checksum = 117120712331201783637358421417106789438, .checksum_padding = 0, .checksum_body = 322263339554650050380922881321413982200, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 222336, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 272150941072900534306056524688249254576, .parent_padding = 0, .client = 101421002854235361169396488099400081924, .session = 2, .timestamp = 0, .request = 215, .operation = vsr.Operation(139), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 2476604798, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:06:24.362Z debug(replica): 2n: on_request: forwarding new request to primary (view=3)
2025-11-24 15:06:24.362Z debug(replica): 2n: sending request to replica 0: vsr.message_header.Header.Request{ .checksum = 117120712331201783637358421417106789438, .checksum_padding = 0, .checksum_body = 322263339554650050380922881321413982200, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 222336, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 272150941072900534306056524688249254576, .parent_padding = 0, .client = 101421002854235361169396488099400081924, .session = 2, .timestamp = 0, .request = 215, .operation = vsr.Operation(139), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 2476604798, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:06:24.363Z debug(replica): 0N: execute_op: executing view=3 primary=true op=217 checksum=190464554993171704940395981855707690071 (create_transfers)
2025-11-24 15:06:24.363Z debug(replica): 0N: execute_op: commit_timestamp=1763996779387713878 prepare.header.timestamp=1763996781867376548
2025-11-24 15:06:24.371Z debug(replica): 0N: execute_op: advancing commit_max=216..217
2025-11-24 15:06:24.371Z debug(replica): 0N: client_table_entry_update: client=101421002854235361169396488099400081924 session=2 request=215
2025-11-24 15:06:24.371Z debug(replica): 0N: execute_op: replying to client: vsr.message_header.Header.Reply{ .checksum = 300383450418319664392271804354834352691, .checksum_padding = 0, .checksum_body = 311752944233308762869332694583075543730, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 264, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 117120712331201783637358421417106789438, .request_checksum_padding = 0, .context = 136923102711713963694217296273828626159, .context_padding = 0, .client = 101421002854235361169396488099400081924, .op = 217, .commit = 217, .timestamp = 1763996781867376548, .request = 215, .operation = vsr.Operation(139), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:06:24.371Z debug(replica): 0N: sending reply to client 101421002854235361169396488099400081924: vsr.message_header.Header.Reply{ .checksum = 300383450418319664392271804354834352691, .checksum_padding = 0, .checksum_body = 311752944233308762869332694583075543730, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 264, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 117120712331201783637358421417106789438, .request_checksum_padding = 0, .context = 136923102711713963694217296273828626159, .context_padding = 0, .client = 101421002854235361169396488099400081924, .op = 217, .commit = 217, .timestamp = 1763996781867376548, .request = 215, .operation = vsr.Operation(139), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:06:24.371Z debug(forest): entering forest.compact() op=217 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
warning(client): 101421002854235361169396488099400081924: on_reply: slow request, request=215 op=217 size=222336 create_transfers time=2506ms
2025-11-24 15:06:24.378Z debug(replica): 0N: on_message: view=3 status=normal vsr.message_header.Header.Request{ .checksum = 117120712331201783637358421417106789438, .checksum_padding = 0, .checksum_body = 322263339554650050380922881321413982200, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 222336, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 272150941072900534306056524688249254576, .parent_padding = 0, .client = 101421002854235361169396488099400081924, .session = 2, .timestamp = 0, .request = 215, .operation = vsr.Operation(139), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 2476604798, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:06:24.378Z debug(replica): 0N: on_request: replying to duplicate request
2025-11-24 15:06:24.378Z debug(replica): 0N: on_request: repeat reply (client=101421002854235361169396488099400081924 request=215)
2025-11-24 15:06:24.378Z debug(replica): 0N: sending reply to client 101421002854235361169396488099400081924: vsr.message_header.Header.Reply{ .checksum = 300383450418319664392271804354834352691, .checksum_padding = 0, .checksum_body = 311752944233308762869332694583075543730, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 264, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 117120712331201783637358421417106789438, .request_checksum_padding = 0, .context = 136923102711713963694217296273828626159, .context_padding = 0, .client = 101421002854235361169396488099400081924, .op = 217, .commit = 217, .timestamp = 1763996781867376548, .request = 215, .operation = vsr.Operation(139), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:06:24.379Z debug(client_replies): 0: write_reply: wrote (client=101421002854235361169396488099400081924 request=215)
2025-11-24 15:06:24.379Z debug(replica): 2n: on_message: view=3 status=normal vsr.message_header.Header.Request{ .checksum = 278197053062824014314437366294464108039, .checksum_padding = 0, .checksum_body = 144059847831243404350899927634767905925, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2320, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 136923102711713963694217296273828626159, .parent_padding = 0, .client = 101421002854235361169396488099400081924, .session = 2, .timestamp = 0, .request = 216, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 2506985495, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:06:24.379Z debug(replica): 2n: on_request: forwarding new request to primary (view=3)
2025-11-24 15:06:24.379Z debug(replica): 2n: sending request to replica 0: vsr.message_header.Header.Request{ .checksum = 278197053062824014314437366294464108039, .checksum_padding = 0, .checksum_body = 144059847831243404350899927634767905925, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2320, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 136923102711713963694217296273828626159, .parent_padding = 0, .client = 101421002854235361169396488099400081924, .session = 2, .timestamp = 0, .request = 216, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 2506985495, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:06:24.380Z debug(replica): 0N: on_message: view=3 status=normal vsr.message_header.Header.Request{ .checksum = 117120712331201783637358421417106789438, .checksum_padding = 0, .checksum_body = 322263339554650050380922881321413982200, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 222336, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 272150941072900534306056524688249254576, .parent_padding = 0, .client = 101421002854235361169396488099400081924, .session = 2, .timestamp = 0, .request = 215, .operation = vsr.Operation(139), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 2476604798, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:06:24.380Z debug(replica): 0N: on_request: replying to duplicate request
2025-11-24 15:06:24.380Z debug(client_replies): 0: read_reply: start (client=101421002854235361169396488099400081924 reply=300383450418319664392271804354834352691)
2025-11-24 15:06:24.381Z debug(vsr): 2: journal_repair_budget_timeout fired
2025-11-24 15:06:24.381Z debug(vsr): 2: journal_repair_budget_timeout reset
2025-11-24 15:06:24.381Z debug(vsr): 1: journal_repair_budget_timeout fired
2025-11-24 15:06:24.381Z debug(replica): 0N: on_message: view=3 status=normal vsr.message_header.Header.Request{ .checksum = 117120712331201783637358421417106789438, .checksum_padding = 0, .checksum_body = 322263339554650050380922881321413982200, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 222336, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 272150941072900534306056524688249254576, .parent_padding = 0, .client = 101421002854235361169396488099400081924, .session = 2, .timestamp = 0, .request = 215, .operation = vsr.Operation(139), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 2476604798, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:06:24.381Z debug(vsr): 1: journal_repair_budget_timeout reset
2025-11-24 15:06:24.381Z debug(replica): 0N: on_request: replying to duplicate request
2025-11-24 15:06:24.381Z debug(client_replies): 0: read_reply: busy (client=101421002854235361169396488099400081924 reply=300383450418319664392271804354834352691)
2025-11-24 15:06:24.381Z debug(replica): 0N: on_request: ignoring (client_replies busy)
2025-11-24 15:06:24.382Z debug(replica): 0N: on_message: view=3 status=normal vsr.message_header.Header.Request{ .checksum = 117120712331201783637358421417106789438, .checksum_padding = 0, .checksum_body = 322263339554650050380922881321413982200, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 222336, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 272150941072900534306056524688249254576, .parent_padding = 0, .client = 101421002854235361169396488099400081924, .session = 2, .timestamp = 0, .request = 215, .operation = vsr.Operation(139), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 2476604798, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:06:24.382Z debug(replica): 0N: on_request: replying to duplicate request
2025-11-24 15:06:24.382Z debug(client_replies): 0: read_reply: busy (client=101421002854235361169396488099400081924 reply=300383450418319664392271804354834352691)
2025-11-24 15:06:24.382Z debug(replica): 0N: on_request: ignoring (client_replies busy)
2025-11-24 15:06:24.382Z debug(replica): 0N: on_message: view=3 status=normal vsr.message_header.Header.Request{ .checksum = 278197053062824014314437366294464108039, .checksum_padding = 0, .checksum_body = 144059847831243404350899927634767905925, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2320, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 136923102711713963694217296273828626159, .parent_padding = 0, .client = 101421002854235361169396488099400081924, .session = 2, .timestamp = 0, .request = 216, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 2506985495, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:06:24.383Z debug(replica): 0N: on_request: new request
2025-11-24 15:06:24.383Z debug(replica): 0N: primary_pipeline_prepare: request checksum=278197053062824014314437366294464108039 client=101421002854235361169396488099400081924
2025-11-24 15:06:24.383Z debug(replica): 0N: primary_pipeline_prepare: prepare checksum=164887385035895215519306019321569754778 op=218
2025-11-24 15:06:24.383Z debug(vsr): 0: prepare_timeout started
2025-11-24 15:06:24.383Z debug(vsr): 0: primary_abdicate_timeout started
2025-11-24 15:06:24.383Z debug(vsr): 0: pulse_timeout reset
2025-11-24 15:06:24.383Z debug(replica): 0N: replicate: replicating op=218 to replica 2
2025-11-24 15:06:24.383Z debug(replica): 0N: sending prepare to replica 2: vsr.message_header.Header.Prepare{ .checksum = 164887385035895215519306019321569754778, .checksum_padding = 0, .checksum_body = 144059847831243404350899927634767905925, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2320, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 190464554993171704940395981855707690071, .parent_padding = 0, .request_checksum = 278197053062824014314437366294464108039, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 101421002854235361169396488099400081924, .op = 218, .commit = 217, .timestamp = 1763996784383036276, .request = 216, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-11-24 15:06:24.383Z debug(replica): 0N: replicate: replicating op=218 to replica 1
2025-11-24 15:06:24.383Z debug(replica): 0N: sending prepare to replica 1: vsr.message_header.Header.Prepare{ .checksum = 164887385035895215519306019321569754778, .checksum_padding = 0, .checksum_body = 144059847831243404350899927634767905925, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2320, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 190464554993171704940395981855707690071, .parent_padding = 0, .request_checksum = 278197053062824014314437366294464108039, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 101421002854235361169396488099400081924, .op = 218, .commit = 217, .timestamp = 1763996784383036276, .request = 216, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-11-24 15:06:24.383Z debug(replica): 0N: on_prepare: advancing: op=217..218 checksum=190464554993171704940395981855707690071..164887385035895215519306019321569754778
2025-11-24 15:06:24.383Z debug(journal): 0: set_header_as_dirty: op=218 checksum=164887385035895215519306019321569754778
2025-11-24 15:06:24.383Z debug(replica): 0N: append: appending to journal op=218
2025-11-24 15:06:24.383Z debug(journal): 0: write: view=3 slot=218 op=218 len=2320: 164887385035895215519306019321569754778 starting
2025-11-24 15:06:24.383Z debug(replica): 2n: on_message: view=3 status=normal vsr.message_header.Header.Prepare{ .checksum = 164887385035895215519306019321569754778, .checksum_padding = 0, .checksum_body = 144059847831243404350899927634767905925, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2320, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 190464554993171704940395981855707690071, .parent_padding = 0, .request_checksum = 278197053062824014314437366294464108039, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 101421002854235361169396488099400081924, .op = 218, .commit = 217, .timestamp = 1763996784383036276, .request = 216, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-11-24 15:06:24.383Z debug(journal): 0: write_sectors: ring=vsr.journal.Ring.prepares offset=228589568 len=4096 locked
2025-11-24 15:06:24.383Z debug(replica): 2n: on_prepare: advancing commit_max=216..217
2025-11-24 15:06:24.383Z debug(replica): 1n: on_message: view=3 status=normal vsr.message_header.Header.Prepare{ .checksum = 164887385035895215519306019321569754778, .checksum_padding = 0, .checksum_body = 144059847831243404350899927634767905925, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2320, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 190464554993171704940395981855707690071, .parent_padding = 0, .request_checksum = 278197053062824014314437366294464108039, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 101421002854235361169396488099400081924, .op = 218, .commit = 217, .timestamp = 1763996784383036276, .request = 216, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-11-24 15:06:24.383Z debug(replica): 2n: on_prepare: caching prepare.op=218 (commit_min=216 op=217 commit_max=217 prepare_max=1007)
2025-11-24 15:06:24.383Z debug(replica): 1n: on_prepare: advancing commit_max=216..217
2025-11-24 15:06:24.383Z debug(replica): 1n: on_prepare: caching prepare.op=218 (commit_min=216 op=217 commit_max=217 prepare_max=1007)
2025-11-24 15:06:24.383Z debug(replica): 1n: on_prepare: advancing: op=217..218 checksum=190464554993171704940395981855707690071..164887385035895215519306019321569754778
2025-11-24 15:06:24.383Z debug(journal): 1: set_header_as_dirty: op=218 checksum=164887385035895215519306019321569754778
2025-11-24 15:06:24.383Z debug(replica): 1n: append: appending to journal op=218
2025-11-24 15:06:24.383Z debug(journal): 1: write: view=3 slot=218 op=218 len=2320: 164887385035895215519306019321569754778 starting
2025-11-24 15:06:24.383Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.prepares offset=228589568 len=4096 locked
2025-11-24 15:06:24.383Z debug(replica): 1n: commit_start_journal: cached prepare op=217 checksum=190464554993171704940395981855707690071
2025-11-24 15:06:24.383Z debug(replica): 2n: on_prepare: advancing: op=217..218 checksum=190464554993171704940395981855707690071..164887385035895215519306019321569754778
2025-11-24 15:06:24.383Z debug(journal): 2: set_header_as_dirty: op=218 checksum=164887385035895215519306019321569754778
2025-11-24 15:06:24.383Z debug(replica): 2n: append: appending to journal op=218
2025-11-24 15:06:24.383Z debug(journal): 2: write: view=3 slot=218 op=218 len=2320: 164887385035895215519306019321569754778 starting
2025-11-24 15:06:24.383Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.prepares offset=228589568 len=4096 locked
2025-11-24 15:06:24.383Z debug(replica): 2n: commit_start_journal: cached prepare op=217 checksum=190464554993171704940395981855707690071
2025-11-24 15:06:24.383Z debug(replica): 0N: on_message: view=3 status=normal vsr.message_header.Header.Request{ .checksum = 278197053062824014314437366294464108039, .checksum_padding = 0, .checksum_body = 144059847831243404350899927634767905925, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2320, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 136923102711713963694217296273828626159, .parent_padding = 0, .client = 101421002854235361169396488099400081924, .session = 2, .timestamp = 0, .request = 216, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 2506985495, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:06:24.383Z debug(replica): 0N: on_request: new request
2025-11-24 15:06:24.383Z debug(replica): 0N: on_request: ignoring (already preparing)
2025-11-24 15:06:24.383Z debug(journal): 0: write_sectors: ring=vsr.journal.Ring.prepares offset=228589568 len=4096 unlocked
2025-11-24 15:06:24.383Z debug(journal): 0: write_header: op=218 sectors[53248..57344]
2025-11-24 15:06:24.383Z debug(journal): 0: write_sectors: ring=vsr.journal.Ring.headers offset=53248 len=4096 locked
2025-11-24 15:06:24.383Z debug(client_replies): 0: read_reply: done (client=101421002854235361169396488099400081924 reply=300383450418319664392271804354834352691)
2025-11-24 15:06:24.383Z debug(replica): 0N: on_request: repeat reply (client=101421002854235361169396488099400081924 request=215)
2025-11-24 15:06:24.383Z debug(replica): 0N: sending reply to client 101421002854235361169396488099400081924: vsr.message_header.Header.Reply{ .checksum = 300383450418319664392271804354834352691, .checksum_padding = 0, .checksum_body = 311752944233308762869332694583075543730, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 264, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 117120712331201783637358421417106789438, .request_checksum_padding = 0, .context = 136923102711713963694217296273828626159, .context_padding = 0, .client = 101421002854235361169396488099400081924, .op = 217, .commit = 217, .timestamp = 1763996781867376548, .request = 215, .operation = vsr.Operation(139), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:06:24.384Z debug(journal): 0: write_sectors: ring=vsr.journal.Ring.headers offset=53248 len=4096 unlocked
2025-11-24 15:06:24.384Z debug(journal): 0: write: view=3 slot=218 op=218 len=2320: 164887385035895215519306019321569754778 complete, marking clean
2025-11-24 15:06:24.384Z debug(replica): 0N: send_prepare_ok: op=218 checksum=164887385035895215519306019321569754778
2025-11-24 15:06:24.384Z debug(replica): 0N: sending prepare_ok to replica 0: vsr.message_header.Header.PrepareOk{ .checksum = 221414420661975508767218057088277836328, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 190464554993171704940395981855707690071, .parent_padding = 0, .prepare_checksum = 164887385035895215519306019321569754778, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 101421002854235361169396488099400081924, .op = 218, .commit_min = 217, .timestamp = 1763996784383036276, .request = 216, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-11-24 15:06:24.384Z debug(replica): 0N: on_message: view=3 status=normal vsr.message_header.Header.PrepareOk{ .checksum = 221414420661975508767218057088277836328, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 190464554993171704940395981855707690071, .parent_padding = 0, .prepare_checksum = 164887385035895215519306019321569754778, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 101421002854235361169396488099400081924, .op = 218, .commit_min = 217, .timestamp = 1763996784383036276, .request = 216, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-11-24 15:06:24.384Z debug(vsr): 0: primary_abdicate_timeout reset
2025-11-24 15:06:24.384Z debug(replica): 0N: on_prepare_ok: 1 message(s)
2025-11-24 15:06:24.384Z debug(replica): 0N: on_prepare_ok: waiting for quorum
2025-11-24 15:06:24.384Z debug(replica): 1n: repair_prepare: op=218 checksum=164887385035895215519306019321569754778 (already writing)
2025-11-24 15:06:24.384Z debug(replica): 2n: repair_prepare: op=218 checksum=164887385035895215519306019321569754778 (already writing)
2025-11-24 15:06:24.384Z debug(replica): 1n: commit_journal: already committing (prefetch; commit_min=216)
2025-11-24 15:06:24.384Z debug(replica): 2n: commit_journal: already committing (prefetch; commit_min=216)
2025-11-24 15:06:24.385Z debug(replica): 2n: execute_op: executing view=3 primary=false op=217 checksum=190464554993171704940395981855707690071 (create_transfers)
2025-11-24 15:06:24.385Z debug(replica): 2n: execute_op: commit_timestamp=1763996779387713878 prepare.header.timestamp=1763996781867376548
2025-11-24 15:06:24.385Z debug(replica): 1n: execute_op: executing view=3 primary=false op=217 checksum=190464554993171704940395981855707690071 (create_transfers)
2025-11-24 15:06:24.385Z debug(replica): 1n: execute_op: commit_timestamp=1763996779387713878 prepare.header.timestamp=1763996781867376548
2025-11-24 15:06:24.389Z debug(vsr): 0: journal_repair_budget_timeout fired
2025-11-24 15:06:24.389Z debug(vsr): 0: journal_repair_budget_timeout reset
2025-11-24 15:06:24.392Z debug(replica): 2n: client_table_entry_update: client=101421002854235361169396488099400081924 session=2 request=215
2025-11-24 15:06:24.392Z debug(replica): 2n: execute_op: replying to client: vsr.message_header.Header.Reply{ .checksum = 300383450418319664392271804354834352691, .checksum_padding = 0, .checksum_body = 311752944233308762869332694583075543730, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 264, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 117120712331201783637358421417106789438, .request_checksum_padding = 0, .context = 136923102711713963694217296273828626159, .context_padding = 0, .client = 101421002854235361169396488099400081924, .op = 217, .commit = 217, .timestamp = 1763996781867376548, .request = 215, .operation = vsr.Operation(139), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:06:24.392Z debug(replica): 2n: sending reply to client 101421002854235361169396488099400081924: vsr.message_header.Header.Reply{ .checksum = 300383450418319664392271804354834352691, .checksum_padding = 0, .checksum_body = 311752944233308762869332694583075543730, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 264, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 117120712331201783637358421417106789438, .request_checksum_padding = 0, .context = 136923102711713963694217296273828626159, .context_padding = 0, .client = 101421002854235361169396488099400081924, .op = 217, .commit = 217, .timestamp = 1763996781867376548, .request = 215, .operation = vsr.Operation(139), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:06:24.392Z debug(forest): entering forest.compact() op=217 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2025-11-24 15:06:24.395Z debug(replica): 1n: client_table_entry_update: client=101421002854235361169396488099400081924 session=2 request=215
2025-11-24 15:06:24.395Z debug(forest): entering forest.compact() op=217 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2025-11-24 15:06:24.397Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.prepares offset=228589568 len=4096 unlocked
2025-11-24 15:06:24.397Z debug(journal): 2: write_header: op=218 sectors[53248..57344]
2025-11-24 15:06:24.397Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.headers offset=53248 len=4096 locked
2025-11-24 15:06:24.397Z debug(client_replies): 2: write_reply: wrote (client=101421002854235361169396488099400081924 request=215)
2025-11-24 15:06:24.397Z debug(vsr): 2: journal_repair_timeout fired
2025-11-24 15:06:24.397Z debug(vsr): 2: journal_repair_timeout reset
2025-11-24 15:06:24.397Z debug(replica): 2n: repair_prepare: op=218 checksum=164887385035895215519306019321569754778 (already writing)
2025-11-24 15:06:24.397Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.headers offset=53248 len=4096 unlocked
2025-11-24 15:06:24.397Z debug(journal): 2: write: view=3 slot=218 op=218 len=2320: 164887385035895215519306019321569754778 complete, marking clean
2025-11-24 15:06:24.397Z debug(replica): 2n: send_prepare_ok: op=218 checksum=164887385035895215519306019321569754778
2025-11-24 15:06:24.397Z debug(replica): 2n: sending prepare_ok to replica 0: vsr.message_header.Header.PrepareOk{ .checksum = 250891438735314739328470163197472115809, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 190464554993171704940395981855707690071, .parent_padding = 0, .prepare_checksum = 164887385035895215519306019321569754778, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 101421002854235361169396488099400081924, .op = 218, .commit_min = 217, .timestamp = 1763996784383036276, .request = 216, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-11-24 15:06:24.397Z debug(replica): 0N: on_message: view=3 status=normal vsr.message_header.Header.PrepareOk{ .checksum = 250891438735314739328470163197472115809, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 190464554993171704940395981855707690071, .parent_padding = 0, .prepare_checksum = 164887385035895215519306019321569754778, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 101421002854235361169396488099400081924, .op = 218, .commit_min = 217, .timestamp = 1763996784383036276, .request = 216, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-11-24 15:06:24.397Z debug(vsr): 0: primary_abdicate_timeout reset
2025-11-24 15:06:24.397Z debug(replica): 0N: on_prepare_ok: 2 message(s)
2025-11-24 15:06:24.397Z debug(replica): 0N: on_prepare_ok: quorum received, context=164887385035895215519306019321569754778
2025-11-24 15:06:24.397Z debug(vsr): 0: prepare_timeout stopped
2025-11-24 15:06:24.397Z debug(vsr): 0: primary_abdicate_timeout stopped
2025-11-24 15:06:24.398Z debug(replica): 0N: execute_op: executing view=3 primary=true op=218 checksum=164887385035895215519306019321569754778 (lookup_accounts)
2025-11-24 15:06:24.398Z debug(replica): 0N: execute_op: commit_timestamp=1763996781867376548 prepare.header.timestamp=1763996784383036276
2025-11-24 15:06:24.398Z debug(replica): 0N: execute_op: advancing commit_max=217..218
2025-11-24 15:06:24.398Z debug(replica): 0N: client_table_entry_update: client=101421002854235361169396488099400081924 session=2 request=216
2025-11-24 15:06:24.398Z debug(replica): 0N: execute_op: replying to client: vsr.message_header.Header.Reply{ .checksum = 95692323037617267217894070979553659077, .checksum_padding = 0, .checksum_body = 286247090439151265021645198572738072135, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 16768, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 278197053062824014314437366294464108039, .request_checksum_padding = 0, .context = 161037782269836548286005782561456408572, .context_padding = 0, .client = 101421002854235361169396488099400081924, .op = 218, .commit = 218, .timestamp = 1763996784383036276, .request = 216, .operation = vsr.Operation(140), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:06:24.398Z debug(replica): 0N: sending reply to client 101421002854235361169396488099400081924: vsr.message_header.Header.Reply{ .checksum = 95692323037617267217894070979553659077, .checksum_padding = 0, .checksum_body = 286247090439151265021645198572738072135, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 16768, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 278197053062824014314437366294464108039, .request_checksum_padding = 0, .context = 161037782269836548286005782561456408572, .context_padding = 0, .client = 101421002854235361169396488099400081924, .op = 218, .commit = 218, .timestamp = 1763996784383036276, .request = 216, .operation = vsr.Operation(140), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:06:24.398Z debug(forest): entering forest.compact() op=218 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2025-11-24 15:06:24.398Z debug(client_replies): 0: write_reply: wrote (client=101421002854235361169396488099400081924 request=216)
2025-11-24 15:06:24.399Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.prepares offset=228589568 len=4096 unlocked
2025-11-24 15:06:24.399Z debug(journal): 1: write_header: op=218 sectors[53248..57344]
2025-11-24 15:06:24.399Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.headers offset=53248 len=4096 locked
2025-11-24 15:06:24.399Z debug(client_replies): 1: write_reply: wrote (client=101421002854235361169396488099400081924 request=215)
2025-11-24 15:06:24.399Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.headers offset=53248 len=4096 unlocked
2025-11-24 15:06:24.399Z debug(journal): 1: write: view=3 slot=218 op=218 len=2320: 164887385035895215519306019321569754778 complete, marking clean
2025-11-24 15:06:24.399Z debug(replica): 1n: send_prepare_ok: op=218 checksum=164887385035895215519306019321569754778
2025-11-24 15:06:24.399Z debug(replica): 1n: sending prepare_ok to replica 0: vsr.message_header.Header.PrepareOk{ .checksum = 270069439329625995859832743273332433, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 190464554993171704940395981855707690071, .parent_padding = 0, .prepare_checksum = 164887385035895215519306019321569754778, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 101421002854235361169396488099400081924, .op = 218, .commit_min = 217, .timestamp = 1763996784383036276, .request = 216, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-11-24 15:06:24.399Z debug(replica): 0N: on_message: view=3 status=normal vsr.message_header.Header.PrepareOk{ .checksum = 270069439329625995859832743273332433, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 190464554993171704940395981855707690071, .parent_padding = 0, .prepare_checksum = 164887385035895215519306019321569754778, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 101421002854235361169396488099400081924, .op = 218, .commit_min = 217, .timestamp = 1763996784383036276, .request = 216, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-11-24 15:06:24.399Z debug(replica): 0N: on_prepare_ok: not preparing op=218 checksum=164887385035895215519306019321569754778
2025-11-24 15:06:24.407Z debug(vsr): 2: journal_repair_budget_timeout fired
2025-11-24 15:06:24.407Z debug(vsr): 2: journal_repair_budget_timeout reset
2025-11-24 15:06:24.409Z debug(vsr): 1: journal_repair_budget_timeout fired
2025-11-24 15:06:24.409Z debug(vsr): 1: journal_repair_budget_timeout reset
2025-11-24 15:06:24.409Z debug(vsr): 1: journal_repair_timeout fired
2025-11-24 15:06:24.409Z debug(vsr): 1: journal_repair_timeout reset
2025-11-24 15:06:24.409Z debug(vsr): 0: journal_repair_budget_timeout fired
2025-11-24 15:06:24.409Z debug(vsr): 0: journal_repair_budget_timeout reset
2025-11-24 15:06:24.420Z info(workload): accounts created = 128, transfers = 265144, pending transfers = 0, commands run = 108
2025-11-24 15:06:24.422Z debug(replica): 2n: on_message: view=3 status=normal vsr.message_header.Header.Request{ .checksum = 164437738156500457482155243347275494368, .checksum_padding = 0, .checksum_body = 298999408630731256803105946019073290003, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 130896, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 161037782269836548286005782561456408572, .parent_padding = 0, .client = 101421002854235361169396488099400081924, .session = 2, .timestamp = 0, .request = 217, .operation = vsr.Operation(141), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 41518474, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:06:24.422Z debug(replica): 0N: on_message: view=3 status=normal vsr.message_header.Header.Request{ .checksum = 164437738156500457482155243347275494368, .checksum_padding = 0, .checksum_body = 298999408630731256803105946019073290003, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 130896, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 161037782269836548286005782561456408572, .parent_padding = 0, .client = 101421002854235361169396488099400081924, .session = 2, .timestamp = 0, .request = 217, .operation = vsr.Operation(141), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 41518474, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:06:24.422Z debug(replica): 2n: on_request: forwarding new request to primary (view=3)
2025-11-24 15:06:24.422Z debug(replica): 0N: on_request: new request
2025-11-24 15:06:24.422Z debug(replica): 0N: primary_pipeline_prepare: request checksum=164437738156500457482155243347275494368 client=101421002854235361169396488099400081924
2025-11-24 15:06:24.422Z debug(replica): 2n: sending request to replica 0: vsr.message_header.Header.Request{ .checksum = 164437738156500457482155243347275494368, .checksum_padding = 0, .checksum_body = 298999408630731256803105946019073290003, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 130896, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 161037782269836548286005782561456408572, .parent_padding = 0, .client = 101421002854235361169396488099400081924, .session = 2, .timestamp = 0, .request = 217, .operation = vsr.Operation(141), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 41518474, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:06:24.423Z debug(replica): 0N: primary_pipeline_prepare: prepare checksum=173537522157310976560125732223881428821 op=219
2025-11-24 15:06:24.423Z debug(vsr): 0: prepare_timeout started
2025-11-24 15:06:24.423Z debug(vsr): 0: primary_abdicate_timeout started
2025-11-24 15:06:24.423Z debug(vsr): 0: pulse_timeout reset
2025-11-24 15:06:24.423Z debug(replica): 0N: replicate: replicating op=219 to replica 2
2025-11-24 15:06:24.423Z debug(replica): 0N: sending prepare to replica 2: vsr.message_header.Header.Prepare{ .checksum = 173537522157310976560125732223881428821, .checksum_padding = 0, .checksum_body = 298999408630731256803105946019073290003, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 130896, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 164887385035895215519306019321569754778, .parent_padding = 0, .request_checksum = 164437738156500457482155243347275494368, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 101421002854235361169396488099400081924, .op = 219, .commit = 218, .timestamp = 1763996784422544821, .request = 217, .operation = vsr.Operation(141), .reserved = { 0, 0, 0 } }
2025-11-24 15:06:24.423Z debug(replica): 0N: replicate: replicating op=219 to replica 1
2025-11-24 15:06:24.423Z debug(replica): 0N: sending prepare to replica 1: vsr.message_header.Header.Prepare{ .checksum = 173537522157310976560125732223881428821, .checksum_padding = 0, .checksum_body = 298999408630731256803105946019073290003, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 130896, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 164887385035895215519306019321569754778, .parent_padding = 0, .request_checksum = 164437738156500457482155243347275494368, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 101421002854235361169396488099400081924, .op = 219, .commit = 218, .timestamp = 1763996784422544821, .request = 217, .operation = vsr.Operation(141), .reserved = { 0, 0, 0 } }
2025-11-24 15:06:24.423Z debug(replica): 0N: on_prepare: advancing: op=218..219 checksum=164887385035895215519306019321569754778..173537522157310976560125732223881428821
2025-11-24 15:06:24.423Z debug(journal): 0: set_header_as_dirty: op=219 checksum=173537522157310976560125732223881428821
2025-11-24 15:06:24.423Z debug(replica): 0N: append: appending to journal op=219
2025-11-24 15:06:24.423Z debug(journal): 0: write: view=3 slot=219 op=219 len=130896: 173537522157310976560125732223881428821 starting
2025-11-24 15:06:24.423Z debug(journal): 0: write_sectors: ring=vsr.journal.Ring.prepares offset=229638144 len=131072 locked
2025-11-24 15:06:24.423Z debug(replica): 2n: on_message: view=3 status=normal vsr.message_header.Header.Prepare{ .checksum = 173537522157310976560125732223881428821, .checksum_padding = 0, .checksum_body = 298999408630731256803105946019073290003, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 130896, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 164887385035895215519306019321569754778, .parent_padding = 0, .request_checksum = 164437738156500457482155243347275494368, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 101421002854235361169396488099400081924, .op = 219, .commit = 218, .timestamp = 1763996784422544821, .request = 217, .operation = vsr.Operation(141), .reserved = { 0, 0, 0 } }
2025-11-24 15:06:24.423Z debug(replica): 2n: on_prepare: advancing commit_max=217..218
2025-11-24 15:06:24.423Z debug(replica): 2n: on_prepare: caching prepare.op=219 (commit_min=217 op=218 commit_max=218 prepare_max=1007)
2025-11-24 15:06:24.423Z debug(replica): 2n: on_prepare: advancing: op=218..219 checksum=164887385035895215519306019321569754778..173537522157310976560125732223881428821
2025-11-24 15:06:24.423Z debug(journal): 2: set_header_as_dirty: op=219 checksum=173537522157310976560125732223881428821
2025-11-24 15:06:24.423Z debug(replica): 2n: append: appending to journal op=219
2025-11-24 15:06:24.423Z debug(journal): 2: write: view=3 slot=219 op=219 len=130896: 173537522157310976560125732223881428821 starting
2025-11-24 15:06:24.423Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.prepares offset=229638144 len=131072 locked
2025-11-24 15:06:24.423Z debug(replica): 1n: on_message: view=3 status=normal vsr.message_header.Header.Prepare{ .checksum = 173537522157310976560125732223881428821, .checksum_padding = 0, .checksum_body = 298999408630731256803105946019073290003, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 130896, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 164887385035895215519306019321569754778, .parent_padding = 0, .request_checksum = 164437738156500457482155243347275494368, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 101421002854235361169396488099400081924, .op = 219, .commit = 218, .timestamp = 1763996784422544821, .request = 217, .operation = vsr.Operation(141), .reserved = { 0, 0, 0 } }
2025-11-24 15:06:24.423Z debug(replica): 2n: commit_start_journal: cached prepare op=218 checksum=164887385035895215519306019321569754778
2025-11-24 15:06:24.424Z debug(replica): 1n: on_prepare: advancing commit_max=217..218
2025-11-24 15:06:24.423Z debug(replica): 0N: on_message: view=3 status=normal vsr.message_header.Header.Request{ .checksum = 164437738156500457482155243347275494368, .checksum_padding = 0, .checksum_body = 298999408630731256803105946019073290003, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 130896, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 161037782269836548286005782561456408572, .parent_padding = 0, .client = 101421002854235361169396488099400081924, .session = 2, .timestamp = 0, .request = 217, .operation = vsr.Operation(141), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 41518474, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:06:24.424Z debug(replica): 1n: on_prepare: caching prepare.op=219 (commit_min=217 op=218 commit_max=218 prepare_max=1007)
2025-11-24 15:06:24.424Z debug(replica): 0N: on_request: new request
2025-11-24 15:06:24.424Z debug(replica): 0N: on_request: ignoring (already preparing)
2025-11-24 15:06:24.424Z debug(replica): 1n: on_prepare: advancing: op=218..219 checksum=164887385035895215519306019321569754778..173537522157310976560125732223881428821
2025-11-24 15:06:24.424Z debug(journal): 1: set_header_as_dirty: op=219 checksum=173537522157310976560125732223881428821
2025-11-24 15:06:24.424Z debug(replica): 1n: append: appending to journal op=219
2025-11-24 15:06:24.424Z debug(journal): 0: write_sectors: ring=vsr.journal.Ring.prepares offset=229638144 len=131072 unlocked
2025-11-24 15:06:24.424Z debug(journal): 1: write: view=3 slot=219 op=219 len=130896: 173537522157310976560125732223881428821 starting
2025-11-24 15:06:24.424Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.prepares offset=229638144 len=131072 locked
2025-11-24 15:06:24.424Z debug(journal): 0: write_header: op=219 sectors[53248..57344]
2025-11-24 15:06:24.424Z debug(journal): 0: write_sectors: ring=vsr.journal.Ring.headers offset=53248 len=4096 locked
2025-11-24 15:06:24.424Z debug(replica): 1n: commit_start_journal: cached prepare op=218 checksum=164887385035895215519306019321569754778
2025-11-24 15:06:24.424Z debug(replica): 2n: repair_prepare: op=219 checksum=173537522157310976560125732223881428821 (already writing)
2025-11-24 15:06:24.424Z debug(journal): 0: write_sectors: ring=vsr.journal.Ring.headers offset=53248 len=4096 unlocked
2025-11-24 15:06:24.424Z debug(replica): 2n: commit_journal: already committing (prefetch; commit_min=217)
2025-11-24 15:06:24.424Z debug(journal): 0: write: view=3 slot=219 op=219 len=130896: 173537522157310976560125732223881428821 complete, marking clean
2025-11-24 15:06:24.424Z debug(replica): 0N: send_prepare_ok: op=219 checksum=173537522157310976560125732223881428821
2025-11-24 15:06:24.424Z debug(replica): 2n: execute_op: executing view=3 primary=false op=218 checksum=164887385035895215519306019321569754778 (lookup_accounts)
2025-11-24 15:06:24.424Z debug(replica): 2n: execute_op: commit_timestamp=1763996781867376548 prepare.header.timestamp=1763996784383036276
2025-11-24 15:06:24.424Z debug(replica): 0N: sending prepare_ok to replica 0: vsr.message_header.Header.PrepareOk{ .checksum = 101711476094378214047347826445887714125, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 164887385035895215519306019321569754778, .parent_padding = 0, .prepare_checksum = 173537522157310976560125732223881428821, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 101421002854235361169396488099400081924, .op = 219, .commit_min = 218, .timestamp = 1763996784422544821, .request = 217, .operation = vsr.Operation(141), .reserved = { 0, 0, 0 } }
2025-11-24 15:06:24.424Z debug(replica): 1n: repair_prepare: op=219 checksum=173537522157310976560125732223881428821 (already writing)
2025-11-24 15:06:24.424Z debug(replica): 0N: on_message: view=3 status=normal vsr.message_header.Header.PrepareOk{ .checksum = 101711476094378214047347826445887714125, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 164887385035895215519306019321569754778, .parent_padding = 0, .prepare_checksum = 173537522157310976560125732223881428821, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 101421002854235361169396488099400081924, .op = 219, .commit_min = 218, .timestamp = 1763996784422544821, .request = 217, .operation = vsr.Operation(141), .reserved = { 0, 0, 0 } }
2025-11-24 15:06:24.424Z debug(vsr): 0: primary_abdicate_timeout reset
2025-11-24 15:06:24.424Z debug(replica): 0N: on_prepare_ok: 1 message(s)
2025-11-24 15:06:24.424Z debug(replica): 0N: on_prepare_ok: waiting for quorum
2025-11-24 15:06:24.424Z debug(replica): 1n: commit_journal: already committing (prefetch; commit_min=217)
2025-11-24 15:06:24.424Z debug(replica): 1n: execute_op: executing view=3 primary=false op=218 checksum=164887385035895215519306019321569754778 (lookup_accounts)
2025-11-24 15:06:24.424Z debug(replica): 1n: execute_op: commit_timestamp=1763996781867376548 prepare.header.timestamp=1763996784383036276
2025-11-24 15:06:24.424Z debug(replica): 2n: client_table_entry_update: client=101421002854235361169396488099400081924 session=2 request=216
2025-11-24 15:06:24.424Z debug(forest): entering forest.compact() op=218 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2025-11-24 15:06:24.424Z debug(replica): 1n: client_table_entry_update: client=101421002854235361169396488099400081924 session=2 request=216
2025-11-24 15:06:24.424Z debug(client_replies): 2: write_reply: wrote (client=101421002854235361169396488099400081924 request=216)
2025-11-24 15:06:24.424Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.prepares offset=229638144 len=131072 unlocked
2025-11-24 15:06:24.424Z debug(journal): 2: write_header: op=219 sectors[53248..57344]
2025-11-24 15:06:24.424Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.headers offset=53248 len=4096 locked
2025-11-24 15:06:24.429Z debug(vsr): 0: journal_repair_budget_timeout fired
2025-11-24 15:06:24.424Z debug(replica): 1n: execute_op: replying to client: vsr.message_header.Header.Reply{ .checksum = 95692323037617267217894070979553659077, .checksum_padding = 0, .checksum_body = 286247090439151265021645198572738072135, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 16768, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 278197053062824014314437366294464108039, .request_checksum_padding = 0, .context = 161037782269836548286005782561456408572, .context_padding = 0, .client = 101421002854235361169396488099400081924, .op = 218, .commit = 218, .timestamp = 1763996784383036276, .request = 216, .operation = vsr.Operation(140), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
