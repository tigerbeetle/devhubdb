cluster:00000000000000000000000000000000,replica:2,tree:Transfer.user_data_64
tb.compact_mutable_us.min:0|g|#cluster:00000000000000000000000000000000,replica:2,tree:Transfer.user_data_32
tb.compact_mutable_us.max:0|g|#cluster:00000000000000000000000000000000,replica:2,tree:Transfer.user_data_32
tb.compact_mutable_us.avg:0|g|#cluster:00000000000000000000000000000000,replica:2,tree:Transfer.user_data_32
tb.compact_mutable_us.sum:1|c|#cluster:00000000000000000000000000000000,replica:2,tree:Transfer.user_data_32
tb.compact_mutable_us.count:3|c|#cluster:00000000000000000000000000000000,replica:2,tree:Transfer.user_data_32
tb.compact_mutable_us.min:0|g|#cluster:00000000000000000000000000000000,replica:2,tree:Transfer.ledger
tb.compact_mutable_us.max:14433|g|#cluster:00000000000000000000000000000000,replica:2,tree:Transfer.ledger
tb.compact_mutable_us.avg:8461|g|#cluster:00000000000000000000000000000000,replica:2,tree:Transfer.ledger

2025-11-24 15:49:02.596Z debug(statsd): 2: statsd packet: tb.compact_mutable_us.sum:25383|c|#cluster:00000000000000000000000000000000,replica:2,tree:Transfer.ledger
tb.compact_mutable_us.count:3|c|#cluster:00000000000000000000000000000000,replica:2,tree:Transfer.ledger
tb.compact_mutable_us.min:8011|g|#cluster:00000000000000000000000000000000,replica:2,tree:Transfer.code
tb.compact_mutable_us.max:20244|g|#cluster:00000000000000000000000000000000,replica:2,tree:Transfer.code
tb.compact_mutable_us.avg:15312|g|#cluster:00000000000000000000000000000000,replica:2,tree:Transfer.code
tb.compact_mutable_us.sum:45937|c|#cluster:00000000000000000000000000000000,replica:2,tree:Transfer.code
tb.compact_mutable_us.count:3|c|#cluster:00000000000000000000000000000000,replica:2,tree:Transfer.code
tb.compact_mutable_us.min:1|g|#cluster:00000000000000000000000000000000,replica:2,tree:Transfer.timestamp
tb.compact_mutable_us.max:20603|g|#cluster:00000000000000000000000000000000,replica:2,tree:Transfer.timestamp
tb.compact_mutable_us.avg:12213|g|#cluster:00000000000000000000000000000000,replica:2,tree:Transfer.timestamp
tb.compact_mutable_us.sum:36641|c|#cluster:00000000000000000000000000000000,replica:2,tree:Transfer.timestamp
tb.compact_mutable_us.count:3|c|#cluster:00000000000000000000000000000000,replica:2,tree:Transfer.timestamp
tb.compact_mutable_us.min:0|g|#cluster:00000000000000000000000000000000,replica:2,tree:Transfer.expires_at

2025-11-24 15:49:02.596Z debug(statsd): 2: statsd packet: tb.compact_mutable_us.max:2|g|#cluster:00000000000000000000000000000000,replica:2,tree:Transfer.expires_at
tb.compact_mutable_us.avg:1|g|#cluster:00000000000000000000000000000000,replica:2,tree:Transfer.expires_at
tb.compact_mutable_us.sum:3|c|#cluster:00000000000000000000000000000000,replica:2,tree:Transfer.expires_at
tb.compact_mutable_us.count:3|c|#cluster:00000000000000000000000000000000,replica:2,tree:Transfer.expires_at
tb.compact_mutable_us.min:0|g|#cluster:00000000000000000000000000000000,replica:2,tree:Transfer.imported
tb.compact_mutable_us.max:0|g|#cluster:00000000000000000000000000000000,replica:2,tree:Transfer.imported
tb.compact_mutable_us.avg:0|g|#cluster:00000000000000000000000000000000,replica:2,tree:Transfer.imported
tb.compact_mutable_us.sum:1|c|#cluster:00000000000000000000000000000000,replica:2,tree:Transfer.imported
tb.compact_mutable_us.count:3|c|#cluster:00000000000000000000000000000000,replica:2,tree:Transfer.imported
tb.compact_mutable_us.min:0|g|#cluster:00000000000000000000000000000000,replica:2,tree:Transfer.closing
tb.compact_mutable_us.max:0|g|#cluster:00000000000000000000000000000000,replica:2,tree:Transfer.closing
tb.compact_mutable_us.avg:0|g|#cluster:00000000000000000000000000000000,replica:2,tree:Transfer.closing
tb.compact_mutable_us.sum:1|c|#cluster:00000000000000000000000000000000,replica:2,tree:Transfer.closing

2025-11-24 15:49:02.596Z debug(statsd): 2: statsd packet: tb.compact_mutable_us.count:3|c|#cluster:00000000000000000000000000000000,replica:2,tree:Transfer.closing
tb.compact_mutable_us.min:0|g|#cluster:00000000000000000000000000000000,replica:2,tree:TransferPending.timestamp
tb.compact_mutable_us.max:1|g|#cluster:00000000000000000000000000000000,replica:2,tree:TransferPending.timestamp
tb.compact_mutable_us.avg:1|g|#cluster:00000000000000000000000000000000,replica:2,tree:TransferPending.timestamp
tb.compact_mutable_us.sum:3|c|#cluster:00000000000000000000000000000000,replica:2,tree:TransferPending.timestamp
tb.compact_mutable_us.count:3|c|#cluster:00000000000000000000000000000000,replica:2,tree:TransferPending.timestamp
tb.compact_mutable_us.min:0|g|#cluster:00000000000000000000000000000000,replica:2,tree:TransferPending.status
tb.compact_mutable_us.max:1|g|#cluster:00000000000000000000000000000000,replica:2,tree:TransferPending.status
tb.compact_mutable_us.avg:1|g|#cluster:00000000000000000000000000000000,replica:2,tree:TransferPending.status
tb.compact_mutable_us.sum:3|c|#cluster:00000000000000000000000000000000,replica:2,tree:TransferPending.status
tb.compact_mutable_us.count:3|c|#cluster:00000000000000000000000000000000,replica:2,tree:TransferPending.status
tb.compact_mutable_us.min:1|g|#cluster:00000000000000000000000000000000,replica:2,tree:AccountEvents.timestamp

2025-11-24 15:49:02.596Z debug(statsd): 2: statsd packet: tb.compact_mutable_us.max:24256|g|#cluster:00000000000000000000000000000000,replica:2,tree:AccountEvents.timestamp
tb.compact_mutable_us.avg:14457|g|#cluster:00000000000000000000000000000000,replica:2,tree:AccountEvents.timestamp
tb.compact_mutable_us.sum:43373|c|#cluster:00000000000000000000000000000000,replica:2,tree:AccountEvents.timestamp
tb.compact_mutable_us.count:3|c|#cluster:00000000000000000000000000000000,replica:2,tree:AccountEvents.timestamp
tb.compact_mutable_us.min:2425|g|#cluster:00000000000000000000000000000000,replica:2,tree:AccountEvents.account_timestamp
tb.compact_mutable_us.max:5232|g|#cluster:00000000000000000000000000000000,replica:2,tree:AccountEvents.account_timestamp
tb.compact_mutable_us.avg:4141|g|#cluster:00000000000000000000000000000000,replica:2,tree:AccountEvents.account_timestamp
tb.compact_mutable_us.sum:12423|c|#cluster:00000000000000000000000000000000,replica:2,tree:AccountEvents.account_timestamp
tb.compact_mutable_us.count:3|c|#cluster:00000000000000000000000000000000,replica:2,tree:AccountEvents.account_timestamp
tb.compact_mutable_us.min:1|g|#cluster:00000000000000000000000000000000,replica:2,tree:AccountEvents.transfer_pending_status
tb.compact_mutable_us.max:14419|g|#cluster:00000000000000000000000000000000,replica:2,tree:AccountEvents.transfer_pending_status

2025-11-24 15:49:02.596Z debug(statsd): 2: statsd packet: tb.compact_mutable_us.avg:8483|g|#cluster:00000000000000000000000000000000,replica:2,tree:AccountEvents.transfer_pending_status
tb.compact_mutable_us.sum:25451|c|#cluster:00000000000000000000000000000000,replica:2,tree:AccountEvents.transfer_pending_status
tb.compact_mutable_us.count:3|c|#cluster:00000000000000000000000000000000,replica:2,tree:AccountEvents.transfer_pending_status
tb.compact_mutable_us.min:0|g|#cluster:00000000000000000000000000000000,replica:2,tree:AccountEvents.dr_account_id_expired
tb.compact_mutable_us.max:1|g|#cluster:00000000000000000000000000000000,replica:2,tree:AccountEvents.dr_account_id_expired
tb.compact_mutable_us.avg:1|g|#cluster:00000000000000000000000000000000,replica:2,tree:AccountEvents.dr_account_id_expired
tb.compact_mutable_us.sum:3|c|#cluster:00000000000000000000000000000000,replica:2,tree:AccountEvents.dr_account_id_expired
tb.compact_mutable_us.count:3|c|#cluster:00000000000000000000000000000000,replica:2,tree:AccountEvents.dr_account_id_expired
tb.compact_mutable_us.min:0|g|#cluster:00000000000000000000000000000000,replica:2,tree:AccountEvents.cr_account_id_expired
tb.compact_mutable_us.max:0|g|#cluster:00000000000000000000000000000000,replica:2,tree:AccountEvents.cr_account_id_expired
tb.compact_mutable_us.avg:0|g|#cluster:00000000000000000000000000000000,replica:2,tree:AccountEvents.cr_account_id_expired

2025-11-24 15:49:02.596Z debug(replica): 0n: client_table_entry_update: client=298030292540495332668092515795273542819 session=2 request=10
2025-11-24 15:49:02.596Z debug(statsd): 2: statsd packet: tb.compact_mutable_us.sum:1|c|#cluster:00000000000000000000000000000000,replica:2,tree:AccountEvents.cr_account_id_expired
tb.compact_mutable_us.count:3|c|#cluster:00000000000000000000000000000000,replica:2,tree:AccountEvents.cr_account_id_expired
tb.compact_mutable_us.min:0|g|#cluster:00000000000000000000000000000000,replica:2,tree:AccountEvents.transfer_pending_id_expired
tb.compact_mutable_us.max:0|g|#cluster:00000000000000000000000000000000,replica:2,tree:AccountEvents.transfer_pending_id_expired
tb.compact_mutable_us.avg:0|g|#cluster:00000000000000000000000000000000,replica:2,tree:AccountEvents.transfer_pending_id_expired
tb.compact_mutable_us.sum:1|c|#cluster:00000000000000000000000000000000,replica:2,tree:AccountEvents.transfer_pending_id_expired
tb.compact_mutable_us.count:3|c|#cluster:00000000000000000000000000000000,replica:2,tree:AccountEvents.transfer_pending_id_expired
tb.compact_mutable_us.min:0|g|#cluster:00000000000000000000000000000000,replica:2,tree:AccountEvents.ledger_expired
tb.compact_mutable_us.max:0|g|#cluster:00000000000000000000000000000000,replica:2,tree:AccountEvents.ledger_expired
tb.compact_mutable_us.avg:0|g|#cluster:00000000000000000000000000000000,replica:2,tree:AccountEvents.ledger_expired
tb.compact_mutable_us.sum:1|c|#cluster:00000000000000000000000000000000,replica:2,tree:AccountEvents.ledger_expired

2025-11-24 15:49:02.596Z debug(statsd): 2: statsd packet: tb.compact_mutable_us.count:3|c|#cluster:00000000000000000000000000000000,replica:2,tree:AccountEvents.ledger_expired
tb.compact_mutable_us.min:1|g|#cluster:00000000000000000000000000000000,replica:2,tree:AccountEvents.prunable
tb.compact_mutable_us.max:9937|g|#cluster:00000000000000000000000000000000,replica:2,tree:AccountEvents.prunable
tb.compact_mutable_us.avg:5814|g|#cluster:00000000000000000000000000000000,replica:2,tree:AccountEvents.prunable
tb.compact_mutable_us.sum:17443|c|#cluster:00000000000000000000000000000000,replica:2,tree:AccountEvents.prunable
tb.compact_mutable_us.count:3|c|#cluster:00000000000000000000000000000000,replica:2,tree:AccountEvents.prunable
tb.compact_mutable_suffix_us.min:0|g|#cluster:00000000000000000000000000000000,replica:2,tree:Account.id
tb.compact_mutable_suffix_us.max:0|g|#cluster:00000000000000000000000000000000,replica:2,tree:Account.id
tb.compact_mutable_suffix_us.avg:2|g|#cluster:00000000000000000000000000000000,replica:2,tree:Account.id
tb.compact_mutable_suffix_us.sum:237|c|#cluster:00000000000000000000000000000000,replica:2,tree:Account.id
tb.compact_mutable_suffix_us.count:99|c|#cluster:00000000000000000000000000000000,replica:2,tree:Account.id
tb.compact_mutable_suffix_us.min:0|g|#cluster:00000000000000000000000000000000,replica:2,tree:Account.user_data_128

2025-11-24 15:49:02.596Z debug(statsd): 2: statsd packet: tb.compact_mutable_suffix_us.max:0|g|#cluster:00000000000000000000000000000000,replica:2,tree:Account.user_data_128
tb.compact_mutable_suffix_us.avg:0|g|#cluster:00000000000000000000000000000000,replica:2,tree:Account.user_data_128
tb.compact_mutable_suffix_us.sum:55|c|#cluster:00000000000000000000000000000000,replica:2,tree:Account.user_data_128
tb.compact_mutable_suffix_us.count:99|c|#cluster:00000000000000000000000000000000,replica:2,tree:Account.user_data_128
tb.compact_mutable_suffix_us.min:0|g|#cluster:00000000000000000000000000000000,replica:2,tree:Account.user_data_64
tb.compact_mutable_suffix_us.max:0|g|#cluster:00000000000000000000000000000000,replica:2,tree:Account.user_data_64
tb.compact_mutable_suffix_us.avg:0|g|#cluster:00000000000000000000000000000000,replica:2,tree:Account.user_data_64
tb.compact_mutable_suffix_us.sum:79|c|#cluster:00000000000000000000000000000000,replica:2,tree:Account.user_data_64
tb.compact_mutable_suffix_us.count:99|c|#cluster:00000000000000000000000000000000,replica:2,tree:Account.user_data_64
tb.compact_mutable_suffix_us.min:0|g|#cluster:00000000000000000000000000000000,replica:2,tree:Account.user_data_32
tb.compact_mutable_suffix_us.max:0|g|#cluster:00000000000000000000000000000000,replica:2,tree:Account.user_data_32
tb.compact_mutable_suffix_us.avg:0|g|#cluster:00000000000000000000000000000000,replica:2,tree:Account.user_data_32

2025-11-24 15:49:02.596Z debug(statsd): 2: statsd packet: tb.compact_mutable_suffix_us.sum:25|c|#cluster:00000000000000000000000000000000,replica:2,tree:Account.user_data_32
tb.compact_mutable_suffix_us.count:99|c|#cluster:00000000000000000000000000000000,replica:2,tree:Account.user_data_32
tb.compact_mutable_suffix_us.min:0|g|#cluster:00000000000000000000000000000000,replica:2,tree:Account.ledger
tb.compact_mutable_suffix_us.max:0|g|#cluster:00000000000000000000000000000000,replica:2,tree:Account.ledger
tb.compact_mutable_suffix_us.avg:0|g|#cluster:00000000000000000000000000000000,replica:2,tree:Account.ledger
tb.compact_mutable_suffix_us.sum:51|c|#cluster:00000000000000000000000000000000,replica:2,tree:Account.ledger
tb.compact_mutable_suffix_us.count:99|c|#cluster:00000000000000000000000000000000,replica:2,tree:Account.ledger
tb.compact_mutable_suffix_us.min:0|g|#cluster:00000000000000000000000000000000,replica:2,tree:Account.code
tb.compact_mutable_suffix_us.max:0|g|#cluster:00000000000000000000000000000000,replica:2,tree:Account.code
tb.compact_mutable_suffix_us.avg:0|g|#cluster:00000000000000000000000000000000,replica:2,tree:Account.code
tb.compact_mutable_suffix_us.sum:76|c|#cluster:00000000000000000000000000000000,replica:2,tree:Account.code
tb.compact_mutable_suffix_us.count:99|c|#cluster:00000000000000000000000000000000,replica:2,tree:Account.code

2025-11-24 15:49:02.596Z debug(statsd): 2: statsd packet: tb.compact_mutable_suffix_us.min:0|g|#cluster:00000000000000000000000000000000,replica:2,tree:Account.timestamp
tb.compact_mutable_suffix_us.max:1052|g|#cluster:00000000000000000000000000000000,replica:2,tree:Account.timestamp
tb.compact_mutable_suffix_us.avg:421|g|#cluster:00000000000000000000000000000000,replica:2,tree:Account.timestamp
tb.compact_mutable_suffix_us.sum:41698|c|#cluster:00000000000000000000000000000000,replica:2,tree:Account.timestamp
tb.compact_mutable_suffix_us.count:99|c|#cluster:00000000000000000000000000000000,replica:2,tree:Account.timestamp
tb.compact_mutable_suffix_us.min:0|g|#cluster:00000000000000000000000000000000,replica:2,tree:Account.imported
tb.compact_mutable_suffix_us.max:0|g|#cluster:00000000000000000000000000000000,replica:2,tree:Account.imported
tb.compact_mutable_suffix_us.avg:0|g|#cluster:00000000000000000000000000000000,replica:2,tree:Account.imported
tb.compact_mutable_suffix_us.sum:63|c|#cluster:00000000000000000000000000000000,replica:2,tree:Account.imported
tb.compact_mutable_suffix_us.count:99|c|#cluster:00000000000000000000000000000000,replica:2,tree:Account.imported
tb.compact_mutable_suffix_us.min:0|g|#cluster:00000000000000000000000000000000,replica:2,tree:Account.closed
tb.compact_mutable_suffix_us.max:0|g|#cluster:00000000000000000000000000000000,replica:2,tree:Account.closed

2025-11-24 15:49:02.596Z debug(statsd): 2: statsd packet: tb.compact_mutable_suffix_us.avg:0|g|#cluster:00000000000000000000000000000000,replica:2,tree:Account.closed
tb.compact_mutable_suffix_us.sum:47|c|#cluster:00000000000000000000000000000000,replica:2,tree:Account.closed
tb.compact_mutable_suffix_us.count:99|c|#cluster:00000000000000000000000000000000,replica:2,tree:Account.closed
tb.compact_mutable_suffix_us.min:0|g|#cluster:00000000000000000000000000000000,replica:2,tree:Transfer.id
tb.compact_mutable_suffix_us.max:332|g|#cluster:00000000000000000000000000000000,replica:2,tree:Transfer.id
tb.compact_mutable_suffix_us.avg:14|g|#cluster:00000000000000000000000000000000,replica:2,tree:Transfer.id
tb.compact_mutable_suffix_us.sum:1393|c|#cluster:00000000000000000000000000000000,replica:2,tree:Transfer.id
tb.compact_mutable_suffix_us.count:99|c|#cluster:00000000000000000000000000000000,replica:2,tree:Transfer.id
tb.compact_mutable_suffix_us.min:0|g|#cluster:00000000000000000000000000000000,replica:2,tree:Transfer.debit_account_id
tb.compact_mutable_suffix_us.max:1158|g|#cluster:00000000000000000000000000000000,replica:2,tree:Transfer.debit_account_id
tb.compact_mutable_suffix_us.avg:531|g|#cluster:00000000000000000000000000000000,replica:2,tree:Transfer.debit_account_id
tb.compact_mutable_suffix_us.sum:52572|c|#cluster:00000000000000000000000000000000,replica:2,tree:Transfer.debit_account_id

2025-11-24 15:49:02.596Z debug(statsd): 2: statsd packet: tb.compact_mutable_suffix_us.count:99|c|#cluster:00000000000000000000000000000000,replica:2,tree:Transfer.debit_account_id
tb.compact_mutable_suffix_us.min:0|g|#cluster:00000000000000000000000000000000,replica:2,tree:Transfer.credit_account_id
tb.compact_mutable_suffix_us.max:1150|g|#cluster:00000000000000000000000000000000,replica:2,tree:Transfer.credit_account_id
tb.compact_mutable_suffix_us.avg:516|g|#cluster:00000000000000000000000000000000,replica:2,tree:Transfer.credit_account_id
tb.compact_mutable_suffix_us.sum:51182|c|#cluster:00000000000000000000000000000000,replica:2,tree:Transfer.credit_account_id
tb.compact_mutable_suffix_us.count:99|c|#cluster:00000000000000000000000000000000,replica:2,tree:Transfer.credit_account_id
tb.compact_mutable_suffix_us.min:0|g|#cluster:00000000000000000000000000000000,replica:2,tree:Transfer.amount
tb.compact_mutable_suffix_us.max:701|g|#cluster:00000000000000000000000000000000,replica:2,tree:Transfer.amount
tb.compact_mutable_suffix_us.avg:317|g|#cluster:00000000000000000000000000000000,replica:2,tree:Transfer.amount
tb.compact_mutable_suffix_us.sum:31461|c|#cluster:00000000000000000000000000000000,replica:2,tree:Transfer.amount
tb.compact_mutable_suffix_us.count:99|c|#cluster:00000000000000000000000000000000,replica:2,tree:Transfer.amount

2025-11-24 15:49:02.596Z debug(replica): 0n: execute_op: replying to client: vsr.message_header.Header.Reply{ .checksum = 130033293029223601980884922963150708834, .checksum_padding = 0, .checksum_body = 1992188748057206946799512429522411257, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 3968, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 222790507203810298680000771897161819359, .request_checksum_padding = 0, .context = 314115203014460869051807656669823376246, .context_padding = 0, .client = 298030292540495332668092515795273542819, .op = 12, .commit = 12, .timestamp = 1763999187499586418, .request = 10, .operation = vsr.Operation(140), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:49:02.596Z debug(statsd): 2: statsd packet: tb.compact_mutable_suffix_us.min:0|g|#cluster:00000000000000000000000000000000,replica:2,tree:Transfer.pending_id
tb.compact_mutable_suffix_us.max:0|g|#cluster:00000000000000000000000000000000,replica:2,tree:Transfer.pending_id
tb.compact_mutable_suffix_us.avg:0|g|#cluster:00000000000000000000000000000000,replica:2,tree:Transfer.pending_id
tb.compact_mutable_suffix_us.sum:29|c|#cluster:00000000000000000000000000000000,replica:2,tree:Transfer.pending_id
tb.compact_mutable_suffix_us.count:99|c|#cluster:00000000000000000000000000000000,replica:2,tree:Transfer.pending_id
tb.compact_mutable_suffix_us.min:0|g|#cluster:00000000000000000000000000000000,replica:2,tree:Transfer.user_data_128
tb.compact_mutable_suffix_us.max:0|g|#cluster:00000000000000000000000000000000,replica:2,tree:Transfer.user_data_128
tb.compact_mutable_suffix_us.avg:0|g|#cluster:00000000000000000000000000000000,replica:2,tree:Transfer.user_data_128
tb.compact_mutable_suffix_us.sum:23|c|#cluster:00000000000000000000000000000000,replica:2,tree:Transfer.user_data_128
tb.compact_mutable_suffix_us.count:99|c|#cluster:00000000000000000000000000000000,replica:2,tree:Transfer.user_data_128
tb.compact_mutable_suffix_us.min:0|g|#cluster:00000000000000000000000000000000,replica:2,tree:Transfer.user_data_64
tb.compact_mutable_suffix_us.max:0|g|#cluster:00000000000000000000000000000000,replica:2,tree:Transfer.user_data_64

2025-11-24 15:49:02.596Z debug(statsd): 2: statsd packet: tb.compact_mutable_suffix_us.avg:0|g|#cluster:00000000000000000000000000000000,replica:2,tree:Transfer.user_data_64
tb.compact_mutable_suffix_us.sum:30|c|#cluster:00000000000000000000000000000000,replica:2,tree:Transfer.user_data_64
tb.compact_mutable_suffix_us.count:99|c|#cluster:00000000000000000000000000000000,replica:2,tree:Transfer.user_data_64
tb.compact_mutable_suffix_us.min:0|g|#cluster:00000000000000000000000000000000,replica:2,tree:Transfer.user_data_32
tb.compact_mutable_suffix_us.max:0|g|#cluster:00000000000000000000000000000000,replica:2,tree:Transfer.user_data_32
tb.compact_mutable_suffix_us.avg:0|g|#cluster:00000000000000000000000000000000,replica:2,tree:Transfer.user_data_32
tb.compact_mutable_suffix_us.sum:24|c|#cluster:00000000000000000000000000000000,replica:2,tree:Transfer.user_data_32
tb.compact_mutable_suffix_us.count:99|c|#cluster:00000000000000000000000000000000,replica:2,tree:Transfer.user_data_32
tb.compact_mutable_suffix_us.min:0|g|#cluster:00000000000000000000000000000000,replica:2,tree:Transfer.ledger
tb.compact_mutable_suffix_us.max:363|g|#cluster:00000000000000000000000000000000,replica:2,tree:Transfer.ledger
tb.compact_mutable_suffix_us.avg:15|g|#cluster:00000000000000000000000000000000,replica:2,tree:Transfer.ledger
tb.compact_mutable_suffix_us.sum:1505|c|#cluster:00000000000000000000000000000000,replica:2,tree:Transfer.ledger

2025-11-24 15:49:02.596Z debug(statsd): 2: statsd packet: tb.compact_mutable_suffix_us.count:99|c|#cluster:00000000000000000000000000000000,replica:2,tree:Transfer.ledger
tb.compact_mutable_suffix_us.min:0|g|#cluster:00000000000000000000000000000000,replica:2,tree:Transfer.code
tb.compact_mutable_suffix_us.max:395|g|#cluster:00000000000000000000000000000000,replica:2,tree:Transfer.code
tb.compact_mutable_suffix_us.avg:174|g|#cluster:00000000000000000000000000000000,replica:2,tree:Transfer.code
tb.compact_mutable_suffix_us.sum:17231|c|#cluster:00000000000000000000000000000000,replica:2,tree:Transfer.code
tb.compact_mutable_suffix_us.count:99|c|#cluster:00000000000000000000000000000000,replica:2,tree:Transfer.code
tb.compact_mutable_suffix_us.min:0|g|#cluster:00000000000000000000000000000000,replica:2,tree:Transfer.timestamp
tb.compact_mutable_suffix_us.max:338|g|#cluster:00000000000000000000000000000000,replica:2,tree:Transfer.timestamp
tb.compact_mutable_suffix_us.avg:14|g|#cluster:00000000000000000000000000000000,replica:2,tree:Transfer.timestamp
tb.compact_mutable_suffix_us.sum:1468|c|#cluster:00000000000000000000000000000000,replica:2,tree:Transfer.timestamp
tb.compact_mutable_suffix_us.count:99|c|#cluster:00000000000000000000000000000000,replica:2,tree:Transfer.timestamp
tb.compact_mutable_suffix_us.min:0|g|#cluster:00000000000000000000000000000000,replica:2,tree:Transfer.expires_at

2025-11-24 15:49:02.596Z debug(statsd): 2: statsd packet: tb.compact_mutable_suffix_us.max:0|g|#cluster:00000000000000000000000000000000,replica:2,tree:Transfer.expires_at
tb.compact_mutable_suffix_us.avg:0|g|#cluster:00000000000000000000000000000000,replica:2,tree:Transfer.expires_at
tb.compact_mutable_suffix_us.sum:21|c|#cluster:00000000000000000000000000000000,replica:2,tree:Transfer.expires_at
tb.compact_mutable_suffix_us.count:99|c|#cluster:00000000000000000000000000000000,replica:2,tree:Transfer.expires_at
tb.compact_mutable_suffix_us.min:0|g|#cluster:00000000000000000000000000000000,replica:2,tree:Transfer.imported
tb.compact_mutable_suffix_us.max:0|g|#cluster:00000000000000000000000000000000,replica:2,tree:Transfer.imported
tb.compact_mutable_suffix_us.avg:0|g|#cluster:00000000000000000000000000000000,replica:2,tree:Transfer.imported
tb.compact_mutable_suffix_us.sum:25|c|#cluster:00000000000000000000000000000000,replica:2,tree:Transfer.imported
tb.compact_mutable_suffix_us.count:99|c|#cluster:00000000000000000000000000000000,replica:2,tree:Transfer.imported
tb.compact_mutable_suffix_us.min:0|g|#cluster:00000000000000000000000000000000,replica:2,tree:Transfer.closing
tb.compact_mutable_suffix_us.max:0|g|#cluster:00000000000000000000000000000000,replica:2,tree:Transfer.closing
tb.compact_mutable_suffix_us.avg:0|g|#cluster:00000000000000000000000000000000,replica:2,tree:Transfer.closing

2025-11-24 15:49:02.596Z debug(replica): 1N: execute_op: executing view=1 primary=true op=100 checksum=238677827125483749928610148474545706755 (lookup_accounts)
2025-11-24 15:49:02.596Z debug(statsd): 2: statsd packet: tb.compact_mutable_suffix_us.sum:21|c|#cluster:00000000000000000000000000000000,replica:2,tree:Transfer.closing
tb.compact_mutable_suffix_us.count:99|c|#cluster:00000000000000000000000000000000,replica:2,tree:Transfer.closing
tb.compact_mutable_suffix_us.min:0|g|#cluster:00000000000000000000000000000000,replica:2,tree:TransferPending.timestamp
tb.compact_mutable_suffix_us.max:1|g|#cluster:00000000000000000000000000000000,replica:2,tree:TransferPending.timestamp
tb.compact_mutable_suffix_us.avg:0|g|#cluster:00000000000000000000000000000000,replica:2,tree:TransferPending.timestamp
tb.compact_mutable_suffix_us.sum:63|c|#cluster:00000000000000000000000000000000,replica:2,tree:TransferPending.timestamp
tb.compact_mutable_suffix_us.count:99|c|#cluster:00000000000000000000000000000000,replica:2,tree:TransferPending.timestamp
tb.compact_mutable_suffix_us.min:0|g|#cluster:00000000000000000000000000000000,replica:2,tree:TransferPending.status
tb.compact_mutable_suffix_us.max:0|g|#cluster:00000000000000000000000000000000,replica:2,tree:TransferPending.status
tb.compact_mutable_suffix_us.avg:0|g|#cluster:00000000000000000000000000000000,replica:2,tree:TransferPending.status
tb.compact_mutable_suffix_us.sum:42|c|#cluster:00000000000000000000000000000000,replica:2,tree:TransferPending.status

2025-11-24 15:49:02.596Z debug(replica): 0n: sending reply to client 298030292540495332668092515795273542819: vsr.message_header.Header.Reply{ .checksum = 130033293029223601980884922963150708834, .checksum_padding = 0, .checksum_body = 1992188748057206946799512429522411257, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 3968, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 222790507203810298680000771897161819359, .request_checksum_padding = 0, .context = 314115203014460869051807656669823376246, .context_padding = 0, .client = 298030292540495332668092515795273542819, .op = 12, .commit = 12, .timestamp = 1763999187499586418, .request = 10, .operation = vsr.Operation(140), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:49:02.596Z debug(statsd): 2: statsd packet: tb.compact_mutable_suffix_us.count:99|c|#cluster:00000000000000000000000000000000,replica:2,tree:TransferPending.status
tb.compact_mutable_suffix_us.min:0|g|#cluster:00000000000000000000000000000000,replica:2,tree:AccountEvents.timestamp
tb.compact_mutable_suffix_us.max:399|g|#cluster:00000000000000000000000000000000,replica:2,tree:AccountEvents.timestamp
tb.compact_mutable_suffix_us.avg:17|g|#cluster:00000000000000000000000000000000,replica:2,tree:AccountEvents.timestamp
tb.compact_mutable_suffix_us.sum:1730|c|#cluster:00000000000000000000000000000000,replica:2,tree:AccountEvents.timestamp
tb.compact_mutable_suffix_us.count:99|c|#cluster:00000000000000000000000000000000,replica:2,tree:AccountEvents.timestamp
tb.compact_mutable_suffix_us.min:0|g|#cluster:00000000000000000000000000000000,replica:2,tree:AccountEvents.account_timestamp
tb.compact_mutable_suffix_us.max:143|g|#cluster:00000000000000000000000000000000,replica:2,tree:AccountEvents.account_timestamp
tb.compact_mutable_suffix_us.avg:73|g|#cluster:00000000000000000000000000000000,replica:2,tree:AccountEvents.account_timestamp
tb.compact_mutable_suffix_us.sum:7254|c|#cluster:00000000000000000000000000000000,replica:2,tree:AccountEvents.account_timestamp
tb.compact_mutable_suffix_us.count:99|c|#cluster:00000000000000000000000000000000,replica:2,tree:AccountEvents.account_timestamp

2025-11-24 15:49:02.596Z debug(replica): 1N: execute_op: commit_timestamp=1763999335441831733 prepare.header.timestamp=1763999337851456830
2025-11-24 15:49:02.596Z debug(replica): 1N: execute_op: advancing commit_max=99..100
2025-11-24 15:49:02.596Z debug(forest): entering forest.compact() op=12 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2025-11-24 15:49:02.596Z debug(statsd): 2: statsd packet: tb.compact_mutable_suffix_us.min:0|g|#cluster:00000000000000000000000000000000,replica:2,tree:AccountEvents.transfer_pending_status
tb.compact_mutable_suffix_us.max:348|g|#cluster:00000000000000000000000000000000,replica:2,tree:AccountEvents.transfer_pending_status
tb.compact_mutable_suffix_us.avg:14|g|#cluster:00000000000000000000000000000000,replica:2,tree:AccountEvents.transfer_pending_status
tb.compact_mutable_suffix_us.sum:1454|c|#cluster:00000000000000000000000000000000,replica:2,tree:AccountEvents.transfer_pending_status
tb.compact_mutable_suffix_us.count:99|c|#cluster:00000000000000000000000000000000,replica:2,tree:AccountEvents.transfer_pending_status
tb.compact_mutable_suffix_us.min:0|g|#cluster:00000000000000000000000000000000,replica:2,tree:AccountEvents.dr_account_id_expired
tb.compact_mutable_suffix_us.max:0|g|#cluster:00000000000000000000000000000000,replica:2,tree:AccountEvents.dr_account_id_expired
tb.compact_mutable_suffix_us.avg:0|g|#cluster:00000000000000000000000000000000,replica:2,tree:AccountEvents.dr_account_id_expired
tb.compact_mutable_suffix_us.sum:27|c|#cluster:00000000000000000000000000000000,replica:2,tree:AccountEvents.dr_account_id_expired
tb.compact_mutable_suffix_us.count:99|c|#cluster:00000000000000000000000000000000,replica:2,tree:AccountEvents.dr_account_id_expired

2025-11-24 15:49:04.964Z debug(statsd): 2: statsd packet: tb.compact_mutable_suffix_us.min:0|g|#cluster:00000000000000000000000000000000,replica:2,tree:AccountEvents.cr_account_id_expired
tb.compact_mutable_suffix_us.max:0|g|#cluster:00000000000000000000000000000000,replica:2,tree:AccountEvents.cr_account_id_expired
tb.compact_mutable_suffix_us.avg:0|g|#cluster:00000000000000000000000000000000,replica:2,tree:AccountEvents.cr_account_id_expired
tb.compact_mutable_suffix_us.sum:23|c|#cluster:00000000000000000000000000000000,replica:2,tree:AccountEvents.cr_account_id_expired
tb.compact_mutable_suffix_us.count:99|c|#cluster:00000000000000000000000000000000,replica:2,tree:AccountEvents.cr_account_id_expired
tb.compact_mutable_suffix_us.min:0|g|#cluster:00000000000000000000000000000000,replica:2,tree:AccountEvents.transfer_pending_id_expired
tb.compact_mutable_suffix_us.max:0|g|#cluster:00000000000000000000000000000000,replica:2,tree:AccountEvents.transfer_pending_id_expired
tb.compact_mutable_suffix_us.avg:0|g|#cluster:00000000000000000000000000000000,replica:2,tree:AccountEvents.transfer_pending_id_expired
tb.compact_mutable_suffix_us.sum:24|c|#cluster:00000000000000000000000000000000,replica:2,tree:AccountEvents.transfer_pending_id_expired
tb.compact_mutable_suffix_us.count:99|c|#cluster:00000000000000000000000000000000,replica:2,tree:AccountEvents.transfer_pending_id_expired

2025-11-24 15:49:04.964Z debug(statsd): 2: statsd packet: tb.compact_mutable_suffix_us.min:0|g|#cluster:00000000000000000000000000000000,replica:2,tree:AccountEvents.ledger_expired
tb.compact_mutable_suffix_us.max:0|g|#cluster:00000000000000000000000000000000,replica:2,tree:AccountEvents.ledger_expired
tb.compact_mutable_suffix_us.avg:0|g|#cluster:00000000000000000000000000000000,replica:2,tree:AccountEvents.ledger_expired
tb.compact_mutable_suffix_us.sum:22|c|#cluster:00000000000000000000000000000000,replica:2,tree:AccountEvents.ledger_expired
tb.compact_mutable_suffix_us.count:99|c|#cluster:00000000000000000000000000000000,replica:2,tree:AccountEvents.ledger_expired
tb.compact_mutable_suffix_us.min:0|g|#cluster:00000000000000000000000000000000,replica:2,tree:AccountEvents.prunable
tb.compact_mutable_suffix_us.max:206|g|#cluster:00000000000000000000000000000000,replica:2,tree:AccountEvents.prunable
tb.compact_mutable_suffix_us.avg:8|g|#cluster:00000000000000000000000000000000,replica:2,tree:AccountEvents.prunable
tb.compact_mutable_suffix_us.sum:819|c|#cluster:00000000000000000000000000000000,replica:2,tree:AccountEvents.prunable
tb.compact_mutable_suffix_us.count:99|c|#cluster:00000000000000000000000000000000,replica:2,tree:AccountEvents.prunable
tb.lookup_us.min:3|g|#cluster:00000000000000000000000000000000,replica:2,tree:Account.timestamp

2025-11-24 15:49:04.964Z debug(statsd): 2: statsd packet: tb.lookup_us.max:6|g|#cluster:00000000000000000000000000000000,replica:2,tree:Account.timestamp
tb.lookup_us.avg:79|g|#cluster:00000000000000000000000000000000,replica:2,tree:Account.timestamp
tb.lookup_us.sum:6269|c|#cluster:00000000000000000000000000000000,replica:2,tree:Account.timestamp
tb.lookup_us.count:79|c|#cluster:00000000000000000000000000000000,replica:2,tree:Account.timestamp
tb.lookup_us.min:2|g|#cluster:00000000000000000000000000000000,replica:2,tree:Transfer.timestamp
tb.lookup_us.max:159|g|#cluster:00000000000000000000000000000000,replica:2,tree:Transfer.timestamp
tb.lookup_us.avg:253255|g|#cluster:00000000000000000000000000000000,replica:2,tree:Transfer.timestamp
tb.lookup_us.sum:11649740|c|#cluster:00000000000000000000000000000000,replica:2,tree:Transfer.timestamp
tb.lookup_us.count:46|c|#cluster:00000000000000000000000000000000,replica:2,tree:Transfer.timestamp
tb.lookup_us.min:3|g|#cluster:00000000000000000000000000000000,replica:2,tree:TransferPending.timestamp
tb.lookup_us.max:5|g|#cluster:00000000000000000000000000000000,replica:2,tree:TransferPending.timestamp
tb.lookup_us.avg:4|g|#cluster:00000000000000000000000000000000,replica:2,tree:TransferPending.timestamp
tb.lookup_us.sum:128|c|#cluster:00000000000000000000000000000000,replica:2,tree:TransferPending.timestamp

2025-11-24 15:49:04.964Z debug(statsd): 2: statsd packet: tb.lookup_us.count:27|c|#cluster:00000000000000000000000000000000,replica:2,tree:TransferPending.timestamp
tb.lookup_worker_us.min:0|g|#cluster:00000000000000000000000000000000,replica:2,tree:Account.timestamp
tb.lookup_worker_us.max:0|g|#cluster:00000000000000000000000000000000,replica:2,tree:Account.timestamp
tb.lookup_worker_us.avg:0|g|#cluster:00000000000000000000000000000000,replica:2,tree:Account.timestamp
tb.lookup_worker_us.sum:75|c|#cluster:00000000000000000000000000000000,replica:2,tree:Account.timestamp
tb.lookup_worker_us.count:79|c|#cluster:00000000000000000000000000000000,replica:2,tree:Account.timestamp
tb.lookup_worker_us.min:0|g|#cluster:00000000000000000000000000000000,replica:2,tree:Transfer.timestamp
tb.lookup_worker_us.max:1|g|#cluster:00000000000000000000000000000000,replica:2,tree:Transfer.timestamp
tb.lookup_worker_us.avg:1|g|#cluster:00000000000000000000000000000000,replica:2,tree:Transfer.timestamp
tb.lookup_worker_us.sum:47|c|#cluster:00000000000000000000000000000000,replica:2,tree:Transfer.timestamp
tb.lookup_worker_us.count:46|c|#cluster:00000000000000000000000000000000,replica:2,tree:Transfer.timestamp
tb.lookup_worker_us.min:0|g|#cluster:00000000000000000000000000000000,replica:2,tree:TransferPending.timestamp
tb.lookup_worker_us.max:1|g|#cluster:00000000000000000000000000000000,replica:2,tree:TransferPending.timestamp

2025-11-24 15:49:04.964Z debug(statsd): 2: statsd packet: tb.lookup_worker_us.avg:1|g|#cluster:00000000000000000000000000000000,replica:2,tree:TransferPending.timestamp
tb.lookup_worker_us.sum:31|c|#cluster:00000000000000000000000000000000,replica:2,tree:TransferPending.timestamp
tb.lookup_worker_us.count:27|c|#cluster:00000000000000000000000000000000,replica:2,tree:TransferPending.timestamp
tb.scan_tree_us.min:59|g|#cluster:00000000000000000000000000000000,replica:2,tree:Transfer.expires_at
tb.scan_tree_us.max:59|g|#cluster:00000000000000000000000000000000,replica:2,tree:Transfer.expires_at
tb.scan_tree_us.avg:59|g|#cluster:00000000000000000000000000000000,replica:2,tree:Transfer.expires_at
tb.scan_tree_us.sum:59|c|#cluster:00000000000000000000000000000000,replica:2,tree:Transfer.expires_at
tb.scan_tree_us.count:1|c|#cluster:00000000000000000000000000000000,replica:2,tree:Transfer.expires_at
tb.scan_tree_level_us.min:48|g|#cluster:00000000000000000000000000000000,replica:2,tree:Transfer.expires_at
tb.scan_tree_level_us.max:48|g|#cluster:00000000000000000000000000000000,replica:2,tree:Transfer.expires_at
tb.scan_tree_level_us.avg:48|g|#cluster:00000000000000000000000000000000,replica:2,tree:Transfer.expires_at
tb.scan_tree_level_us.sum:340|c|#cluster:00000000000000000000000000000000,replica:2,tree:Transfer.expires_at
tb.scan_tree_level_us.count:7|c|#cluster:00000000000000000000000000000000,replica:2,tree:Transfer.expires_at

2025-11-24 15:49:04.964Z debug(statsd): 2: statsd packet: tb.storage_read_us.min:31|g|#cluster:00000000000000000000000000000000,replica:2,zone:superblock
tb.storage_read_us.max:37|g|#cluster:00000000000000000000000000000000,replica:2,zone:superblock
tb.storage_read_us.avg:43|g|#cluster:00000000000000000000000000000000,replica:2,zone:superblock
tb.storage_read_us.sum:527|c|#cluster:00000000000000000000000000000000,replica:2,zone:superblock
tb.storage_read_us.count:12|c|#cluster:00000000000000000000000000000000,replica:2,zone:superblock
tb.storage_read_us.min:672|g|#cluster:00000000000000000000000000000000,replica:2,zone:wal_headers
tb.storage_read_us.max:672|g|#cluster:00000000000000000000000000000000,replica:2,zone:wal_headers
tb.storage_read_us.avg:672|g|#cluster:00000000000000000000000000000000,replica:2,zone:wal_headers
tb.storage_read_us.sum:672|c|#cluster:00000000000000000000000000000000,replica:2,zone:wal_headers
tb.storage_read_us.count:1|c|#cluster:00000000000000000000000000000000,replica:2,zone:wal_headers
tb.storage_read_us.min:247|g|#cluster:00000000000000000000000000000000,replica:2,zone:wal_prepares
tb.storage_read_us.max:351|g|#cluster:00000000000000000000000000000000,replica:2,zone:wal_prepares
tb.storage_read_us.avg:54015|g|#cluster:00000000000000000000000000000000,replica:2,zone:wal_prepares
tb.storage_read_us.sum:55311595|c|#cluster:00000000000000000000000000000000,replica:2,zone:wal_prepares

2025-11-24 15:49:04.964Z debug(statsd): 2: statsd packet: tb.storage_read_us.count:1024|c|#cluster:00000000000000000000000000000000,replica:2,zone:wal_prepares
tb.storage_write_us.min:31|g|#cluster:00000000000000000000000000000000,replica:2,zone:superblock
tb.storage_write_us.max:32|g|#cluster:00000000000000000000000000000000,replica:2,zone:superblock
tb.storage_write_us.avg:137|g|#cluster:00000000000000000000000000000000,replica:2,zone:superblock
tb.storage_write_us.sum:1102|c|#cluster:00000000000000000000000000000000,replica:2,zone:superblock
tb.storage_write_us.count:8|c|#cluster:00000000000000000000000000000000,replica:2,zone:superblock
tb.storage_write_us.min:26|g|#cluster:00000000000000000000000000000000,replica:2,zone:wal_headers
tb.storage_write_us.max:192|g|#cluster:00000000000000000000000000000000,replica:2,zone:wal_headers
tb.storage_write_us.avg:172|g|#cluster:00000000000000000000000000000000,replica:2,zone:wal_headers
tb.storage_write_us.sum:17253|c|#cluster:00000000000000000000000000000000,replica:2,zone:wal_headers
tb.storage_write_us.count:100|c|#cluster:00000000000000000000000000000000,replica:2,zone:wal_headers
tb.storage_write_us.min:104|g|#cluster:00000000000000000000000000000000,replica:2,zone:wal_prepares
tb.storage_write_us.max:17916|g|#cluster:00000000000000000000000000000000,replica:2,zone:wal_prepares
tb.storage_write_us.avg:241310|g|#cluster:00000000000000000000000000000000,replica:2,zone:wal_prepares

2025-11-24 15:49:04.964Z debug(statsd): 2: statsd packet: tb.storage_write_us.sum:24131061|c|#cluster:00000000000000000000000000000000,replica:2,zone:wal_prepares
tb.storage_write_us.count:100|c|#cluster:00000000000000000000000000000000,replica:2,zone:wal_prepares
tb.storage_write_us.min:139|g|#cluster:00000000000000000000000000000000,replica:2,zone:client_replies
tb.storage_write_us.max:7288|g|#cluster:00000000000000000000000000000000,replica:2,zone:client_replies
tb.storage_write_us.avg:72757|g|#cluster:00000000000000000000000000000000,replica:2,zone:client_replies
tb.storage_write_us.sum:7130201|c|#cluster:00000000000000000000000000000000,replica:2,zone:client_replies
tb.storage_write_us.count:98|c|#cluster:00000000000000000000000000000000,replica:2,zone:client_replies

2025-11-24 15:49:02.596Z debug(replica): 1N: client_table_entry_update: client=298030292540495332668092515795273542819 session=2 request=98
2025-11-24 15:49:04.964Z debug(replica): 1N: execute_op: replying to client: vsr.message_header.Header.Reply{ .checksum = 164317131457518485027543019975599698432, .checksum_padding = 0, .checksum_body = 105397134507487429849597353631841704520, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 16768, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 309516316461109883505924379923659149677, .request_checksum_padding = 0, .context = 167874422028109602154416850712294931450, .context_padding = 0, .client = 298030292540495332668092515795273542819, .op = 100, .commit = 100, .timestamp = 1763999337851456830, .request = 98, .operation = vsr.Operation(140), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:49:04.964Z debug(replica): 1N: sending reply to client 298030292540495332668092515795273542819: vsr.message_header.Header.Reply{ .checksum = 164317131457518485027543019975599698432, .checksum_padding = 0, .checksum_body = 105397134507487429849597353631841704520, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 16768, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 309516316461109883505924379923659149677, .request_checksum_padding = 0, .context = 167874422028109602154416850712294931450, .context_padding = 0, .client = 298030292540495332668092515795273542819, .op = 100, .commit = 100, .timestamp = 1763999337851456830, .request = 98, .operation = vsr.Operation(140), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:49:04.964Z debug(forest): entering forest.compact() op=100 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2025-11-24 15:49:04.964Z warning(replica): 1N: commit_dispatch: slow request, request=98 size=2320 lookup_accounts time=2368ms
warning(client): 298030292540495332668092515795273542819: on_reply: slow request, request=98 op=100 size=2320 lookup_accounts time=7117ms
2025-11-24 15:49:02.596Z warning(replica): 0n: commit_dispatch: slow request, request=10 size=720 lookup_accounts time=2122ms
2025-11-24 15:49:04.964Z debug(client_replies): 0: write_reply: wrote (client=298030292540495332668092515795273542819 request=9)
2025-11-24 15:49:04.964Z info(workload): accounts created = 128, transfers = 106373, pending transfers = 0, commands run = 49
2025-11-24 15:49:04.965Z debug(replica): 0n: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 309516316461109883505924379923659149677, .checksum_padding = 0, .checksum_body = 44623810401707250643847267175380040479, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2320, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 219404026347130389370143172928294192415, .parent_padding = 0, .client = 298030292540495332668092515795273542819, .session = 2, .timestamp = 0, .request = 98, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 2399907613, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:49:04.965Z debug(replica): 0n: on_request: forwarding new request to primary (view=1)
2025-11-24 15:49:04.965Z debug(replica): 0n: sending request to replica 1: vsr.message_header.Header.Request{ .checksum = 309516316461109883505924379923659149677, .checksum_padding = 0, .checksum_body = 44623810401707250643847267175380040479, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2320, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 219404026347130389370143172928294192415, .parent_padding = 0, .client = 298030292540495332668092515795273542819, .session = 2, .timestamp = 0, .request = 98, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 2399907613, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:49:04.966Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 309516316461109883505924379923659149677, .checksum_padding = 0, .checksum_body = 44623810401707250643847267175380040479, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2320, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 219404026347130389370143172928294192415, .parent_padding = 0, .client = 298030292540495332668092515795273542819, .session = 2, .timestamp = 0, .request = 98, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 2399907613, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:49:04.966Z debug(replica): 0n: execute_op: executing view=1 primary=false op=13 checksum=223865853707122748963569461414244892427 (create_transfers)
2025-11-24 15:49:04.966Z debug(replica): 0n: execute_op: commit_timestamp=1763999187499586418 prepare.header.timestamp=1763999190253248652
2025-11-24 15:49:04.966Z debug(replica): 1N: on_request: replying to duplicate request
2025-11-24 15:49:04.966Z debug(replica): 1N: on_request: repeat reply (client=298030292540495332668092515795273542819 request=98)
2025-11-24 15:49:04.966Z debug(replica): 1N: sending reply to client 298030292540495332668092515795273542819: vsr.message_header.Header.Reply{ .checksum = 164317131457518485027543019975599698432, .checksum_padding = 0, .checksum_body = 105397134507487429849597353631841704520, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 16768, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 309516316461109883505924379923659149677, .request_checksum_padding = 0, .context = 167874422028109602154416850712294931450, .context_padding = 0, .client = 298030292540495332668092515795273542819, .op = 100, .commit = 100, .timestamp = 1763999337851456830, .request = 98, .operation = vsr.Operation(140), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:49:04.966Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 309516316461109883505924379923659149677, .checksum_padding = 0, .checksum_body = 44623810401707250643847267175380040479, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2320, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 219404026347130389370143172928294192415, .parent_padding = 0, .client = 298030292540495332668092515795273542819, .session = 2, .timestamp = 0, .request = 98, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 2399907613, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:49:04.967Z debug(replica): 1N: on_request: replying to duplicate request
2025-11-24 15:49:04.967Z debug(replica): 1N: on_request: repeat reply (client=298030292540495332668092515795273542819 request=98)
2025-11-24 15:49:04.967Z debug(replica): 1N: sending reply to client 298030292540495332668092515795273542819: vsr.message_header.Header.Reply{ .checksum = 164317131457518485027543019975599698432, .checksum_padding = 0, .checksum_body = 105397134507487429849597353631841704520, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 16768, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 309516316461109883505924379923659149677, .request_checksum_padding = 0, .context = 167874422028109602154416850712294931450, .context_padding = 0, .client = 298030292540495332668092515795273542819, .op = 100, .commit = 100, .timestamp = 1763999337851456830, .request = 98, .operation = vsr.Operation(140), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:49:04.967Z debug(replica): 2n: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 74134751242057941182801239028481715788, .checksum_padding = 0, .checksum_body = 251738383762583446446837871748805361337, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 128912, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 167874422028109602154416850712294931450, .parent_padding = 0, .client = 298030292540495332668092515795273542819, .session = 2, .timestamp = 0, .request = 99, .operation = vsr.Operation(141), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 4294967295, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:49:04.967Z debug(replica): 2n: on_request: forwarding new request to primary (view=1)
2025-11-24 15:49:04.967Z debug(client_replies): 1: write_reply: wrote (client=298030292540495332668092515795273542819 request=98)
2025-11-24 15:49:04.967Z debug(replica): 2n: sending request to replica 1: vsr.message_header.Header.Request{ .checksum = 74134751242057941182801239028481715788, .checksum_padding = 0, .checksum_body = 251738383762583446446837871748805361337, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 128912, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 167874422028109602154416850712294931450, .parent_padding = 0, .client = 298030292540495332668092515795273542819, .session = 2, .timestamp = 0, .request = 99, .operation = vsr.Operation(141), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 4294967295, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:49:04.967Z debug(vsr): 1: journal_repair_budget_timeout fired
2025-11-24 15:49:04.967Z debug(vsr): 1: journal_repair_budget_timeout reset
2025-11-24 15:49:04.967Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 74134751242057941182801239028481715788, .checksum_padding = 0, .checksum_body = 251738383762583446446837871748805361337, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 128912, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 167874422028109602154416850712294931450, .parent_padding = 0, .client = 298030292540495332668092515795273542819, .session = 2, .timestamp = 0, .request = 99, .operation = vsr.Operation(141), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 4294967295, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:49:04.967Z debug(replica): 1N: on_request: new request
2025-11-24 15:49:04.967Z debug(replica): 1N: primary_pipeline_prepare: request checksum=74134751242057941182801239028481715788 client=298030292540495332668092515795273542819
2025-11-24 15:49:04.968Z debug(replica): 1N: primary_pipeline_prepare: prepare checksum=174665921592427942389153505260327062958 op=101
2025-11-24 15:49:04.968Z debug(vsr): 1: prepare_timeout started
2025-11-24 15:49:04.968Z debug(vsr): 1: primary_abdicate_timeout started
2025-11-24 15:49:04.968Z debug(vsr): 1: pulse_timeout reset
2025-11-24 15:49:04.968Z debug(replica): 1N: replicate: replicating op=101 to replica 0
2025-11-24 15:49:04.968Z debug(replica): 1N: sending prepare to replica 0: vsr.message_header.Header.Prepare{ .checksum = 174665921592427942389153505260327062958, .checksum_padding = 0, .checksum_body = 251738383762583446446837871748805361337, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 128912, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 238677827125483749928610148474545706755, .parent_padding = 0, .request_checksum = 74134751242057941182801239028481715788, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 298030292540495332668092515795273542819, .op = 101, .commit = 100, .timestamp = 1763999344967886190, .request = 99, .operation = vsr.Operation(141), .reserved = { 0, 0, 0 } }
2025-11-24 15:49:04.968Z debug(message_bus): 1: send_message_to_replica: no connection to=0 header=vsr.message_header.Header.Prepare{ .checksum = 174665921592427942389153505260327062958, .checksum_padding = 0, .checksum_body = 251738383762583446446837871748805361337, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 128912, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 238677827125483749928610148474545706755, .parent_padding = 0, .request_checksum = 74134751242057941182801239028481715788, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 298030292540495332668092515795273542819, .op = 101, .commit = 100, .timestamp = 1763999344967886190, .request = 99, .operation = vsr.Operation(141), .reserved = { 0, 0, 0 } }
2025-11-24 15:49:04.968Z debug(replica): 1N: replicate: replicating op=101 to replica 2
2025-11-24 15:49:04.968Z debug(replica): 1N: sending prepare to replica 2: vsr.message_header.Header.Prepare{ .checksum = 174665921592427942389153505260327062958, .checksum_padding = 0, .checksum_body = 251738383762583446446837871748805361337, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 128912, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 238677827125483749928610148474545706755, .parent_padding = 0, .request_checksum = 74134751242057941182801239028481715788, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 298030292540495332668092515795273542819, .op = 101, .commit = 100, .timestamp = 1763999344967886190, .request = 99, .operation = vsr.Operation(141), .reserved = { 0, 0, 0 } }
2025-11-24 15:49:04.968Z debug(replica): 1N: on_prepare: advancing: op=100..101 checksum=238677827125483749928610148474545706755..174665921592427942389153505260327062958
2025-11-24 15:49:04.968Z debug(journal): 1: set_header_as_dirty: op=101 checksum=174665921592427942389153505260327062958
2025-11-24 15:49:04.968Z debug(replica): 1N: append: appending to journal op=101
2025-11-24 15:49:04.968Z debug(journal): 1: write: view=1 slot=101 op=101 len=128912: 174665921592427942389153505260327062958 starting
2025-11-24 15:49:04.968Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.prepares offset=105906176 len=131072 locked
2025-11-24 15:49:04.969Z debug(replica): 2n: on_message: view=1 status=normal vsr.message_header.Header.Prepare{ .checksum = 174665921592427942389153505260327062958, .checksum_padding = 0, .checksum_body = 251738383762583446446837871748805361337, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 128912, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 238677827125483749928610148474545706755, .parent_padding = 0, .request_checksum = 74134751242057941182801239028481715788, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 298030292540495332668092515795273542819, .op = 101, .commit = 100, .timestamp = 1763999344967886190, .request = 99, .operation = vsr.Operation(141), .reserved = { 0, 0, 0 } }
2025-11-24 15:49:04.969Z debug(replica): 2n: on_prepare: advancing commit_max=99..100
2025-11-24 15:49:04.969Z debug(replica): 2n: on_prepare: caching prepare.op=101 (commit_min=99 op=100 commit_max=100 prepare_max=1007)
2025-11-24 15:49:04.969Z debug(replica): 2n: on_prepare: advancing: op=100..101 checksum=238677827125483749928610148474545706755..174665921592427942389153505260327062958
2025-11-24 15:49:04.969Z debug(journal): 2: set_header_as_dirty: op=101 checksum=174665921592427942389153505260327062958
2025-11-24 15:49:04.969Z debug(replica): 2n: append: appending to journal op=101
2025-11-24 15:49:04.969Z debug(journal): 2: write: view=1 slot=101 op=101 len=128912: 174665921592427942389153505260327062958 starting
2025-11-24 15:49:04.969Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.prepares offset=105906176 len=131072 locked
2025-11-24 15:49:04.969Z debug(replica): 2n: commit_start_journal: cached prepare op=100 checksum=238677827125483749928610148474545706755
2025-11-24 15:49:04.969Z debug(replica): 2n: repair_prepare: op=101 checksum=174665921592427942389153505260327062958 (already writing)
2025-11-24 15:49:04.969Z debug(replica): 2n: commit_journal: already committing (prefetch; commit_min=99)
2025-11-24 15:49:04.969Z debug(replica): 2n: execute_op: executing view=1 primary=false op=100 checksum=238677827125483749928610148474545706755 (lookup_accounts)
2025-11-24 15:49:04.969Z debug(replica): 2n: execute_op: commit_timestamp=1763999335441831733 prepare.header.timestamp=1763999337851456830
2025-11-24 15:49:04.970Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 74134751242057941182801239028481715788, .checksum_padding = 0, .checksum_body = 251738383762583446446837871748805361337, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 128912, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 167874422028109602154416850712294931450, .parent_padding = 0, .client = 298030292540495332668092515795273542819, .session = 2, .timestamp = 0, .request = 99, .operation = vsr.Operation(141), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 4294967295, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:49:04.970Z debug(replica): 1N: on_request: new request
2025-11-24 15:49:04.970Z debug(replica): 1N: on_request: ignoring (already preparing)
2025-11-24 15:49:04.970Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.prepares offset=105906176 len=131072 unlocked
2025-11-24 15:49:04.970Z debug(replica): 2n: client_table_entry_update: client=298030292540495332668092515795273542819 session=2 request=98
2025-11-24 15:49:04.970Z debug(journal): 1: write_header: op=101 sectors[24576..28672]
2025-11-24 15:49:04.970Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.headers offset=24576 len=4096 locked
2025-11-24 15:49:04.970Z debug(forest): entering forest.compact() op=100 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2025-11-24 15:49:04.970Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.headers offset=24576 len=4096 unlocked
2025-11-24 15:49:04.970Z debug(journal): 1: write: view=1 slot=101 op=101 len=128912: 174665921592427942389153505260327062958 complete, marking clean
2025-11-24 15:49:04.970Z debug(replica): 1N: send_prepare_ok: op=101 checksum=174665921592427942389153505260327062958
2025-11-24 15:49:04.970Z debug(replica): 1N: sending prepare_ok to replica 1: vsr.message_header.Header.PrepareOk{ .checksum = 73998336906415779693631414198386784745, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 1, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 238677827125483749928610148474545706755, .parent_padding = 0, .prepare_checksum = 174665921592427942389153505260327062958, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 298030292540495332668092515795273542819, .op = 101, .commit_min = 100, .timestamp = 1763999344967886190, .request = 99, .operation = vsr.Operation(141), .reserved = { 0, 0, 0 } }
2025-11-24 15:49:04.970Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.PrepareOk{ .checksum = 73998336906415779693631414198386784745, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 1, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 238677827125483749928610148474545706755, .parent_padding = 0, .prepare_checksum = 174665921592427942389153505260327062958, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 298030292540495332668092515795273542819, .op = 101, .commit_min = 100, .timestamp = 1763999344967886190, .request = 99, .operation = vsr.Operation(141), .reserved = { 0, 0, 0 } }
2025-11-24 15:49:04.970Z debug(vsr): 1: primary_abdicate_timeout reset
2025-11-24 15:49:04.970Z debug(replica): 1N: on_prepare_ok: 1 message(s)
2025-11-24 15:49:04.970Z debug(replica): 1N: on_prepare_ok: waiting for quorum
2025-11-24 15:49:04.970Z debug(client_replies): 2: write_reply: wrote (client=298030292540495332668092515795273542819 request=98)
2025-11-24 15:49:04.970Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.prepares offset=105906176 len=131072 unlocked
2025-11-24 15:49:04.970Z debug(journal): 2: write_header: op=101 sectors[24576..28672]
2025-11-24 15:49:04.970Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.headers offset=24576 len=4096 locked
2025-11-24 15:49:04.970Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.headers offset=24576 len=4096 unlocked
2025-11-24 15:49:04.970Z debug(journal): 2: write: view=1 slot=101 op=101 len=128912: 174665921592427942389153505260327062958 complete, marking clean
2025-11-24 15:49:04.970Z debug(replica): 2n: send_prepare_ok: op=101 checksum=174665921592427942389153505260327062958
2025-11-24 15:49:04.970Z debug(replica): 2n: sending prepare_ok to replica 1: vsr.message_header.Header.PrepareOk{ .checksum = 225347889539150607135694363809351983489, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 1, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 238677827125483749928610148474545706755, .parent_padding = 0, .prepare_checksum = 174665921592427942389153505260327062958, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 298030292540495332668092515795273542819, .op = 101, .commit_min = 100, .timestamp = 1763999344967886190, .request = 99, .operation = vsr.Operation(141), .reserved = { 0, 0, 0 } }
2025-11-24 15:49:04.970Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.PrepareOk{ .checksum = 225347889539150607135694363809351983489, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 1, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 238677827125483749928610148474545706755, .parent_padding = 0, .prepare_checksum = 174665921592427942389153505260327062958, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 298030292540495332668092515795273542819, .op = 101, .commit_min = 100, .timestamp = 1763999344967886190, .request = 99, .operation = vsr.Operation(141), .reserved = { 0, 0, 0 } }
2025-11-24 15:49:04.970Z debug(vsr): 1: primary_abdicate_timeout reset
2025-11-24 15:49:04.970Z debug(replica): 1N: on_prepare_ok: 2 message(s)
2025-11-24 15:49:04.970Z debug(replica): 1N: on_prepare_ok: quorum received, context=174665921592427942389153505260327062958
2025-11-24 15:49:04.970Z debug(vsr): 1: prepare_timeout stopped
2025-11-24 15:49:04.970Z debug(vsr): 1: primary_abdicate_timeout stopped
2025-11-24 15:49:04.971Z debug(replica): 0n: client_table_entry_update: client=298030292540495332668092515795273542819 session=2 request=11
2025-11-24 15:49:04.972Z debug(replica): 0n: execute_op: replying to client: vsr.message_header.Header.Reply{ .checksum = 317564028676290845224812460828759108481, .checksum_padding = 0, .checksum_body = 308147209625837732394595700023258139155, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 384, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 5032731542642238067879718239532577817, .request_checksum_padding = 0, .context = 212881487558122615814173951517986266506, .context_padding = 0, .client = 298030292540495332668092515795273542819, .op = 13, .commit = 13, .timestamp = 1763999190253248652, .request = 11, .operation = vsr.Operation(139), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:49:04.972Z debug(replica): 0n: sending reply to client 298030292540495332668092515795273542819: vsr.message_header.Header.Reply{ .checksum = 317564028676290845224812460828759108481, .checksum_padding = 0, .checksum_body = 308147209625837732394595700023258139155, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 384, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 5032731542642238067879718239532577817, .request_checksum_padding = 0, .context = 212881487558122615814173951517986266506, .context_padding = 0, .client = 298030292540495332668092515795273542819, .op = 13, .commit = 13, .timestamp = 1763999190253248652, .request = 11, .operation = vsr.Operation(139), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:49:04.972Z debug(forest): entering forest.compact() op=13 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2025-11-24 15:49:04.973Z debug(replica): 1N: execute_op: executing view=1 primary=true op=101 checksum=174665921592427942389153505260327062958 (lookup_transfers)
2025-11-24 15:49:04.973Z debug(replica): 1N: execute_op: commit_timestamp=1763999337851456830 prepare.header.timestamp=1763999344967886190
2025-11-24 15:49:04.974Z debug(vsr): 0: journal_repair_budget_timeout fired
2025-11-24 15:49:04.974Z debug(vsr): 0: journal_repair_budget_timeout reset
2025-11-24 15:49:04.974Z debug(client_replies): 0: write_reply: wrote (client=298030292540495332668092515795273542819 request=10)
2025-11-24 15:49:04.974Z debug(replica): 1N: execute_op: advancing commit_max=100..101
2025-11-24 15:49:04.975Z debug(replica): 0n: execute_op: executing view=1 primary=false op=14 checksum=51643025799332948711417785349205295400 (lookup_accounts)
2025-11-24 15:49:04.975Z debug(replica): 0n: execute_op: commit_timestamp=1763999190253248652 prepare.header.timestamp=1763999190266689026
2025-11-24 15:49:04.975Z debug(replica): 0n: client_table_entry_update: client=298030292540495332668092515795273542819 session=2 request=12
2025-11-24 15:49:04.975Z debug(forest): entering forest.compact() op=14 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2025-11-24 15:49:04.975Z debug(client_replies): 0: write_reply: wrote (client=298030292540495332668092515795273542819 request=11)
2025-11-24 15:49:04.975Z debug(client_replies): 0: write_reply: wrote (client=298030292540495332668092515795273542819 request=12)
2025-11-24 15:49:04.975Z debug(replica): 0n: execute_op: executing view=1 primary=false op=15 checksum=105910262239771448157055053754585681945 (create_accounts)
2025-11-24 15:49:04.975Z debug(replica): 0n: execute_op: commit_timestamp=1763999190266689026 prepare.header.timestamp=1763999192677220091
2025-11-24 15:49:04.975Z debug(replica): 0n: client_table_entry_update: client=298030292540495332668092515795273542819 session=2 request=13
2025-11-24 15:49:04.975Z debug(forest): entering forest.compact() op=15 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=true half_beat=false last_beat=false
2025-11-24 15:49:04.975Z debug(client_replies): 0: write_reply: wrote (client=298030292540495332668092515795273542819 request=13)
2025-11-24 15:49:04.975Z debug(replica): 0n: execute_op: executing view=1 primary=false op=16 checksum=56416731039885117186256054043266502079 (lookup_accounts)
2025-11-24 15:49:04.975Z debug(replica): 0n: execute_op: commit_timestamp=1763999192677220091 prepare.header.timestamp=1763999192678933046
2025-11-24 15:49:04.975Z debug(replica): 0n: client_table_entry_update: client=298030292540495332668092515795273542819 session=2 request=14
2025-11-24 15:49:04.975Z debug(forest): entering forest.compact() op=16 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=true last_beat=false
2025-11-24 15:49:04.976Z debug(client_replies): 0: write_reply: wrote (client=298030292540495332668092515795273542819 request=14)
2025-11-24 15:49:04.979Z debug(replica): 1N: client_table_entry_update: client=298030292540495332668092515795273542819 session=2 request=99
2025-11-24 15:49:04.979Z debug(replica): 1N: execute_op: replying to client: vsr.message_header.Header.Reply{ .checksum = 338017630850920746827540554014237719646, .checksum_padding = 0, .checksum_body = 317546057423652125302457183747655624567, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 1029504, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 74134751242057941182801239028481715788, .request_checksum_padding = 0, .context = 310456564613318698644614147352014968918, .context_padding = 0, .client = 298030292540495332668092515795273542819, .op = 101, .commit = 101, .timestamp = 1763999344967886190, .request = 99, .operation = vsr.Operation(141), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:49:04.979Z debug(replica): 1N: sending reply to client 298030292540495332668092515795273542819: vsr.message_header.Header.Reply{ .checksum = 338017630850920746827540554014237719646, .checksum_padding = 0, .checksum_body = 317546057423652125302457183747655624567, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 1029504, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 74134751242057941182801239028481715788, .request_checksum_padding = 0, .context = 310456564613318698644614147352014968918, .context_padding = 0, .client = 298030292540495332668092515795273542819, .op = 101, .commit = 101, .timestamp = 1763999344967886190, .request = 99, .operation = vsr.Operation(141), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:49:04.979Z debug(forest): entering forest.compact() op=101 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2025-11-24 15:49:04.980Z debug(client_replies): 1: write_reply: wrote (client=298030292540495332668092515795273542819 request=99)
2025-11-24 15:49:04.981Z debug(replica): 0n: execute_op: executing view=1 primary=false op=17 checksum=157814263233101731339771890057051449023 (create_transfers)
2025-11-24 15:49:04.981Z debug(replica): 0n: execute_op: commit_timestamp=1763999192678933046 prepare.header.timestamp=1763999195845318700
2025-11-24 15:49:04.984Z debug(vsr): 2: journal_repair_budget_timeout fired
2025-11-24 15:49:04.984Z debug(vsr): 2: journal_repair_budget_timeout reset
2025-11-24 15:49:04.990Z debug(vsr): 1: journal_repair_budget_timeout fired
2025-11-24 15:49:04.990Z debug(vsr): 1: journal_repair_budget_timeout reset
2025-11-24 15:49:04.992Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 18297403943594761543438752698813349882, .checksum_padding = 0, .checksum_body = 44623810401707250643847267175380040479, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2320, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 310456564613318698644614147352014968918, .parent_padding = 0, .client = 298030292540495332668092515795273542819, .session = 2, .timestamp = 0, .request = 100, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 25249099, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:49:04.992Z debug(replica): 2n: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 18297403943594761543438752698813349882, .checksum_padding = 0, .checksum_body = 44623810401707250643847267175380040479, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2320, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 310456564613318698644614147352014968918, .parent_padding = 0, .client = 298030292540495332668092515795273542819, .session = 2, .timestamp = 0, .request = 100, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 25249099, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:49:04.992Z debug(replica): 2n: on_request: forwarding new request to primary (view=1)
2025-11-24 15:49:04.992Z debug(replica): 1N: on_request: new request
2025-11-24 15:49:04.992Z debug(replica): 1N: primary_pipeline_prepare: request checksum=18297403943594761543438752698813349882 client=298030292540495332668092515795273542819
2025-11-24 15:49:04.992Z debug(replica): 2n: sending request to replica 1: vsr.message_header.Header.Request{ .checksum = 18297403943594761543438752698813349882, .checksum_padding = 0, .checksum_body = 44623810401707250643847267175380040479, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2320, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 310456564613318698644614147352014968918, .parent_padding = 0, .client = 298030292540495332668092515795273542819, .session = 2, .timestamp = 0, .request = 100, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 25249099, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:49:04.992Z debug(replica): 1N: primary_pipeline_prepare: prepare checksum=120160434843970571395657420149742784851 op=102
2025-11-24 15:49:04.992Z debug(vsr): 1: prepare_timeout started
2025-11-24 15:49:04.992Z debug(vsr): 1: primary_abdicate_timeout started
2025-11-24 15:49:04.992Z debug(vsr): 1: pulse_timeout reset
2025-11-24 15:49:04.992Z debug(replica): 1N: replicate: replicating op=102 to replica 0
2025-11-24 15:49:04.992Z debug(replica): 1N: sending prepare to replica 0: vsr.message_header.Header.Prepare{ .checksum = 120160434843970571395657420149742784851, .checksum_padding = 0, .checksum_body = 44623810401707250643847267175380040479, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2320, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 174665921592427942389153505260327062958, .parent_padding = 0, .request_checksum = 18297403943594761543438752698813349882, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 298030292540495332668092515795273542819, .op = 102, .commit = 101, .timestamp = 1763999344992358281, .request = 100, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-11-24 15:49:04.992Z debug(message_bus): 1: send_message_to_replica: no connection to=0 header=vsr.message_header.Header.Prepare{ .checksum = 120160434843970571395657420149742784851, .checksum_padding = 0, .checksum_body = 44623810401707250643847267175380040479, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2320, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 174665921592427942389153505260327062958, .parent_padding = 0, .request_checksum = 18297403943594761543438752698813349882, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 298030292540495332668092515795273542819, .op = 102, .commit = 101, .timestamp = 1763999344992358281, .request = 100, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-11-24 15:49:04.992Z debug(replica): 1N: replicate: replicating op=102 to replica 2
2025-11-24 15:49:04.992Z debug(replica): 1N: sending prepare to replica 2: vsr.message_header.Header.Prepare{ .checksum = 120160434843970571395657420149742784851, .checksum_padding = 0, .checksum_body = 44623810401707250643847267175380040479, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2320, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 174665921592427942389153505260327062958, .parent_padding = 0, .request_checksum = 18297403943594761543438752698813349882, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 298030292540495332668092515795273542819, .op = 102, .commit = 101, .timestamp = 1763999344992358281, .request = 100, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-11-24 15:49:04.992Z debug(replica): 1N: on_prepare: advancing: op=101..102 checksum=174665921592427942389153505260327062958..120160434843970571395657420149742784851
2025-11-24 15:49:04.992Z debug(journal): 1: set_header_as_dirty: op=102 checksum=120160434843970571395657420149742784851
2025-11-24 15:49:04.992Z debug(replica): 1N: append: appending to journal op=102
2025-11-24 15:49:04.992Z debug(journal): 1: write: view=1 slot=102 op=102 len=2320: 120160434843970571395657420149742784851 starting
2025-11-24 15:49:04.992Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.prepares offset=106954752 len=4096 locked
2025-11-24 15:49:04.992Z debug(replica): 2n: on_message: view=1 status=normal vsr.message_header.Header.Prepare{ .checksum = 120160434843970571395657420149742784851, .checksum_padding = 0, .checksum_body = 44623810401707250643847267175380040479, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2320, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 174665921592427942389153505260327062958, .parent_padding = 0, .request_checksum = 18297403943594761543438752698813349882, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 298030292540495332668092515795273542819, .op = 102, .commit = 101, .timestamp = 1763999344992358281, .request = 100, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-11-24 15:49:04.992Z debug(replica): 2n: on_prepare: advancing commit_max=100..101
2025-11-24 15:49:04.992Z debug(replica): 2n: on_prepare: caching prepare.op=102 (commit_min=100 op=101 commit_max=101 prepare_max=1007)
2025-11-24 15:49:04.992Z debug(replica): 2n: on_prepare: advancing: op=101..102 checksum=174665921592427942389153505260327062958..120160434843970571395657420149742784851
2025-11-24 15:49:04.992Z debug(journal): 2: set_header_as_dirty: op=102 checksum=120160434843970571395657420149742784851
2025-11-24 15:49:04.992Z debug(replica): 2n: append: appending to journal op=102
2025-11-24 15:49:04.992Z debug(journal): 2: write: view=1 slot=102 op=102 len=2320: 120160434843970571395657420149742784851 starting
2025-11-24 15:49:04.992Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 18297403943594761543438752698813349882, .checksum_padding = 0, .checksum_body = 44623810401707250643847267175380040479, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2320, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 310456564613318698644614147352014968918, .parent_padding = 0, .client = 298030292540495332668092515795273542819, .session = 2, .timestamp = 0, .request = 100, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 25249099, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:49:04.992Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.prepares offset=106954752 len=4096 locked
2025-11-24 15:49:04.992Z debug(replica): 1N: on_request: new request
2025-11-24 15:49:04.992Z debug(replica): 1N: on_request: ignoring (already preparing)
2025-11-24 15:49:04.992Z debug(replica): 2n: commit_start_journal: cached prepare op=101 checksum=174665921592427942389153505260327062958
2025-11-24 15:49:04.992Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.prepares offset=106954752 len=4096 unlocked
2025-11-24 15:49:04.992Z debug(journal): 1: write_header: op=102 sectors[24576..28672]
2025-11-24 15:49:04.992Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.headers offset=24576 len=4096 locked
2025-11-24 15:49:04.992Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.headers offset=24576 len=4096 unlocked
2025-11-24 15:49:04.992Z debug(journal): 1: write: view=1 slot=102 op=102 len=2320: 120160434843970571395657420149742784851 complete, marking clean
2025-11-24 15:49:04.992Z debug(replica): 1N: send_prepare_ok: op=102 checksum=120160434843970571395657420149742784851
2025-11-24 15:49:04.995Z debug(replica): 2n: repair_prepare: op=102 checksum=120160434843970571395657420149742784851 (already writing)
2025-11-24 15:49:04.995Z debug(replica): 2n: commit_journal: already committing (prefetch; commit_min=100)
2025-11-24 15:49:04.995Z debug(replica): 2n: execute_op: executing view=1 primary=false op=101 checksum=174665921592427942389153505260327062958 (lookup_transfers)
2025-11-24 15:49:05.001Z debug(replica): 0n: client_table_entry_update: client=298030292540495332668092515795273542819 session=2 request=15
2025-11-24 15:49:06.586Z debug(forest): entering forest.compact() op=17 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2025-11-24 15:49:04.992Z debug(replica): 1N: sending prepare_ok to replica 1: vsr.message_header.Header.PrepareOk{ .checksum = 302694426076241727452592257195016333291, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 1, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 174665921592427942389153505260327062958, .parent_padding = 0, .prepare_checksum = 120160434843970571395657420149742784851, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 298030292540495332668092515795273542819, .op = 102, .commit_min = 101, .timestamp = 1763999344992358281, .request = 100, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-11-24 15:49:06.590Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.PrepareOk{ .checksum = 302694426076241727452592257195016333291, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 1, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 174665921592427942389153505260327062958, .parent_padding = 0, .prepare_checksum = 120160434843970571395657420149742784851, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 298030292540495332668092515795273542819, .op = 102, .commit_min = 101, .timestamp = 1763999344992358281, .request = 100, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-11-24 15:49:06.590Z debug(vsr): 1: primary_abdicate_timeout reset
2025-11-24 15:49:06.590Z debug(replica): 1N: on_prepare_ok: 1 message(s)
2025-11-24 15:49:06.590Z debug(replica): 1N: on_prepare_ok: waiting for quorum
2025-11-24 15:49:06.590Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 18297403943594761543438752698813349882, .checksum_padding = 0, .checksum_body = 44623810401707250643847267175380040479, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2320, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 310456564613318698644614147352014968918, .parent_padding = 0, .client = 298030292540495332668092515795273542819, .session = 2, .timestamp = 0, .request = 100, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 25249099, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:49:06.590Z debug(replica): 1N: on_request: new request
2025-11-24 15:49:06.590Z debug(replica): 1N: on_request: ignoring (already preparing)
2025-11-24 15:49:04.995Z debug(replica): 2n: execute_op: commit_timestamp=1763999337851456830 prepare.header.timestamp=1763999344967886190
2025-11-24 15:49:06.595Z warning(replica): 0n: commit_dispatch: slow request, request=15 size=652416 create_transfers time=1616ms
2025-11-24 15:49:06.596Z debug(client_replies): 0: write_reply: wrote (client=298030292540495332668092515795273542819 request=15)
2025-11-24 15:49:06.596Z debug(replica): 0n: execute_op: executing view=1 primary=false op=18 checksum=168128740548084110787600963917989579074 (lookup_accounts)
2025-11-24 15:49:06.596Z debug(replica): 0n: execute_op: commit_timestamp=1763999195845318700 prepare.header.timestamp=1763999195893880191
2025-11-24 15:49:06.596Z debug(replica): 0n: client_table_entry_update: client=298030292540495332668092515795273542819 session=2 request=16
2025-11-24 15:49:06.596Z debug(forest): entering forest.compact() op=18 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2025-11-24 15:49:06.596Z debug(client_replies): 0: write_reply: wrote (client=298030292540495332668092515795273542819 request=16)
2025-11-24 15:49:06.597Z debug(replica): 2n: client_table_entry_update: client=298030292540495332668092515795273542819 session=2 request=99
2025-11-24 15:49:06.597Z debug(forest): entering forest.compact() op=101 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2025-11-24 15:49:06.597Z warning(replica): 2n: commit_dispatch: slow request, request=99 size=128912 lookup_transfers time=1604ms
2025-11-24 15:49:06.597Z debug(replica): 2n: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 18297403943594761543438752698813349882, .checksum_padding = 0, .checksum_body = 44623810401707250643847267175380040479, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2320, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 310456564613318698644614147352014968918, .parent_padding = 0, .client = 298030292540495332668092515795273542819, .session = 2, .timestamp = 0, .request = 100, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 25249099, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:49:06.597Z debug(replica): 2n: on_request: forwarding new request to primary (view=1)
2025-11-24 15:49:06.597Z debug(replica): 2n: sending request to replica 1: vsr.message_header.Header.Request{ .checksum = 18297403943594761543438752698813349882, .checksum_padding = 0, .checksum_body = 44623810401707250643847267175380040479, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2320, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 310456564613318698644614147352014968918, .parent_padding = 0, .client = 298030292540495332668092515795273542819, .session = 2, .timestamp = 0, .request = 100, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 25249099, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:49:06.597Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.prepares offset=106954752 len=4096 unlocked
2025-11-24 15:49:06.597Z debug(journal): 2: write_header: op=102 sectors[24576..28672]
2025-11-24 15:49:06.597Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.headers offset=24576 len=4096 locked
2025-11-24 15:49:06.597Z debug(vsr): 2: journal_repair_timeout fired
2025-11-24 15:49:06.597Z debug(vsr): 2: journal_repair_timeout reset
2025-11-24 15:49:06.597Z debug(replica): 2n: repair_prepare: op=102 checksum=120160434843970571395657420149742784851 (already writing)
2025-11-24 15:49:06.597Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 18297403943594761543438752698813349882, .checksum_padding = 0, .checksum_body = 44623810401707250643847267175380040479, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2320, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 310456564613318698644614147352014968918, .parent_padding = 0, .client = 298030292540495332668092515795273542819, .session = 2, .timestamp = 0, .request = 100, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 25249099, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:49:06.597Z debug(replica): 1N: on_request: new request
2025-11-24 15:49:06.597Z debug(replica): 1N: on_request: ignoring (already preparing)
2025-11-24 15:49:06.597Z debug(client_replies): 2: write_reply: wrote (client=298030292540495332668092515795273542819 request=99)
2025-11-24 15:49:06.597Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.headers offset=24576 len=4096 unlocked
2025-11-24 15:49:06.597Z debug(journal): 2: write: view=1 slot=102 op=102 len=2320: 120160434843970571395657420149742784851 complete, marking clean
2025-11-24 15:49:06.597Z debug(replica): 2n: send_prepare_ok: op=102 checksum=120160434843970571395657420149742784851
2025-11-24 15:49:06.597Z debug(replica): 2n: sending prepare_ok to replica 1: vsr.message_header.Header.PrepareOk{ .checksum = 107713728248493068671165121300673700220, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 1, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 174665921592427942389153505260327062958, .parent_padding = 0, .prepare_checksum = 120160434843970571395657420149742784851, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 298030292540495332668092515795273542819, .op = 102, .commit_min = 101, .timestamp = 1763999344992358281, .request = 100, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-11-24 15:49:06.599Z debug(replica): 0n: execute_op: executing view=1 primary=false op=19 checksum=210487801002140003928328539846358902289 (create_transfers)
2025-11-24 15:49:06.599Z debug(replica): 0n: execute_op: commit_timestamp=1763999195893880191 prepare.header.timestamp=1763999198489722427
2025-11-24 15:49:06.600Z debug(vsr): 1: journal_repair_budget_timeout fired
2025-11-24 15:49:06.600Z debug(vsr): 1: journal_repair_budget_timeout reset
2025-11-24 15:49:06.607Z debug(vsr): 2: journal_repair_budget_timeout fired
2025-11-24 15:49:06.607Z debug(vsr): 2: journal_repair_budget_timeout reset
2025-11-24 15:49:06.608Z debug(replica): 0n: client_table_entry_update: client=298030292540495332668092515795273542819 session=2 request=17
2025-11-24 15:49:06.608Z debug(forest): entering forest.compact() op=19 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2025-11-24 15:49:06.613Z debug(vsr): 0: journal_repair_budget_timeout fired
2025-11-24 15:49:06.613Z debug(vsr): 0: journal_repair_budget_timeout reset
2025-11-24 15:49:06.613Z debug(client_replies): 0: write_reply: wrote (client=298030292540495332668092515795273542819 request=17)
2025-11-24 15:49:06.613Z debug(replica): 0n: execute_op: executing view=1 primary=false op=20 checksum=324848246716630119937062992773599665376 (lookup_accounts)
2025-11-24 15:49:06.613Z debug(replica): 0n: execute_op: commit_timestamp=1763999198489722427 prepare.header.timestamp=1763999198509074405
2025-11-24 15:49:06.613Z debug(replica): 0n: client_table_entry_update: client=298030292540495332668092515795273542819 session=2 request=18
2025-11-24 15:49:06.613Z debug(replica): 0n: execute_op: replying to client: vsr.message_header.Header.Reply{ .checksum = 87795315214995451718046494191440317798, .checksum_padding = 0, .checksum_body = 128913515254408253754751590935654424865, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 13440, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 41026135155457269722360897724548369617, .request_checksum_padding = 0, .context = 189206463504435358447559892872955171438, .context_padding = 0, .client = 298030292540495332668092515795273542819, .op = 20, .commit = 20, .timestamp = 1763999198509074405, .request = 18, .operation = vsr.Operation(140), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:49:06.613Z debug(replica): 0n: sending reply to client 298030292540495332668092515795273542819: vsr.message_header.Header.Reply{ .checksum = 87795315214995451718046494191440317798, .checksum_padding = 0, .checksum_body = 128913515254408253754751590935654424865, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 13440, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 41026135155457269722360897724548369617, .request_checksum_padding = 0, .context = 189206463504435358447559892872955171438, .context_padding = 0, .client = 298030292540495332668092515795273542819, .op = 20, .commit = 20, .timestamp = 1763999198509074405, .request = 18, .operation = vsr.Operation(140), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:49:06.613Z debug(forest): entering forest.compact() op=20 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2025-11-24 15:49:06.614Z debug(client_replies): 0: write_reply: wrote (client=298030292540495332668092515795273542819 request=18)
2025-11-24 15:49:06.615Z debug(replica): 0n: execute_op: executing view=1 primary=false op=21 checksum=159303687877283669187455945117122701482 (create_transfers)
2025-11-24 15:49:06.615Z debug(replica): 0n: execute_op: commit_timestamp=1763999198509074405 prepare.header.timestamp=1763999201607084025
2025-11-24 15:49:06.618Z debug(replica): 0n: client_table_entry_update: client=298030292540495332668092515795273542819 session=2 request=19
2025-11-24 15:49:06.618Z debug(forest): entering forest.compact() op=21 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2025-11-24 15:49:06.620Z debug(client_replies): 0: write_reply: wrote (client=298030292540495332668092515795273542819 request=19)
2025-11-24 15:49:06.620Z debug(vsr): 1: journal_repair_budget_timeout fired
2025-11-24 15:49:06.620Z debug(vsr): 1: journal_repair_budget_timeout reset
2025-11-24 15:49:06.620Z debug(replica): 0n: execute_op: executing view=1 primary=false op=22 checksum=87199884348561500791674558798824137237 (lookup_accounts)
2025-11-24 15:49:06.620Z debug(replica): 0n: execute_op: commit_timestamp=1763999201607084025 prepare.header.timestamp=1763999201657286807
2025-11-24 15:49:06.620Z debug(replica): 0n: client_table_entry_update: client=298030292540495332668092515795273542819 session=2 request=20
2025-11-24 15:49:06.620Z debug(replica): 0n: execute_op: replying to client: vsr.message_header.Header.Reply{ .checksum = 128387935682756846926243815695134333170, .checksum_padding = 0, .checksum_body = 249678148951327800645582432099250458155, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 13440, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 218713782539216100369571621999641622401, .request_checksum_padding = 0, .context = 173165534114555973817964210459646648583, .context_padding = 0, .client = 298030292540495332668092515795273542819, .op = 22, .commit = 22, .timestamp = 1763999201657286807, .request = 20, .operation = vsr.Operation(140), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:49:06.620Z debug(replica): 0n: sending reply to client 298030292540495332668092515795273542819: vsr.message_header.Header.Reply{ .checksum = 128387935682756846926243815695134333170, .checksum_padding = 0, .checksum_body = 249678148951327800645582432099250458155, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 13440, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 218713782539216100369571621999641622401, .request_checksum_padding = 0, .context = 173165534114555973817964210459646648583, .context_padding = 0, .client = 298030292540495332668092515795273542819, .op = 22, .commit = 22, .timestamp = 1763999201657286807, .request = 20, .operation = vsr.Operation(140), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:49:06.620Z debug(forest): entering forest.compact() op=22 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2025-11-24 15:49:06.620Z debug(client_replies): 0: write_reply: wrote (client=298030292540495332668092515795273542819 request=20)
2025-11-24 15:49:06.626Z debug(replica): 0n: execute_op: executing view=1 primary=false op=23 checksum=145786114807629522231130441036185162317 (create_transfers)
2025-11-24 15:49:06.626Z debug(replica): 0n: execute_op: commit_timestamp=1763999201657286807 prepare.header.timestamp=1763999204357266351
2025-11-24 15:49:06.627Z debug(vsr): 2: journal_repair_budget_timeout fired
2025-11-24 15:49:06.627Z debug(vsr): 2: journal_repair_budget_timeout reset
2025-11-24 15:49:06.637Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.PrepareOk{ .checksum = 107713728248493068671165121300673700220, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 1, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 174665921592427942389153505260327062958, .parent_padding = 0, .prepare_checksum = 120160434843970571395657420149742784851, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 298030292540495332668092515795273542819, .op = 102, .commit_min = 101, .timestamp = 1763999344992358281, .request = 100, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-11-24 15:49:06.638Z debug(vsr): 1: primary_abdicate_timeout reset
2025-11-24 15:49:06.638Z debug(replica): 1N: on_prepare_ok: 2 message(s)
2025-11-24 15:49:06.638Z debug(replica): 1N: on_prepare_ok: quorum received, context=120160434843970571395657420149742784851
2025-11-24 15:49:06.638Z debug(vsr): 1: prepare_timeout stopped
2025-11-24 15:49:06.638Z debug(vsr): 1: primary_abdicate_timeout stopped
2025-11-24 15:49:06.638Z debug(replica): 1N: execute_op: executing view=1 primary=true op=102 checksum=120160434843970571395657420149742784851 (lookup_accounts)
2025-11-24 15:49:06.638Z debug(replica): 1N: execute_op: commit_timestamp=1763999344967886190 prepare.header.timestamp=1763999344992358281
2025-11-24 15:49:06.638Z debug(replica): 1N: execute_op: advancing commit_max=101..102
2025-11-24 15:49:06.638Z debug(replica): 1N: client_table_entry_update: client=298030292540495332668092515795273542819 session=2 request=100
2025-11-24 15:49:06.638Z debug(replica): 1N: execute_op: replying to client: vsr.message_header.Header.Reply{ .checksum = 22601772805599575367225163930730122979, .checksum_padding = 0, .checksum_body = 105397134507487429849597353631841704520, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 16768, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 18297403943594761543438752698813349882, .request_checksum_padding = 0, .context = 70182949699061791115048667700619468859, .context_padding = 0, .client = 298030292540495332668092515795273542819, .op = 102, .commit = 102, .timestamp = 1763999344992358281, .request = 100, .operation = vsr.Operation(140), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:49:06.638Z debug(replica): 1N: sending reply to client 298030292540495332668092515795273542819: vsr.message_header.Header.Reply{ .checksum = 22601772805599575367225163930730122979, .checksum_padding = 0, .checksum_body = 105397134507487429849597353631841704520, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 16768, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 18297403943594761543438752698813349882, .request_checksum_padding = 0, .context = 70182949699061791115048667700619468859, .context_padding = 0, .client = 298030292540495332668092515795273542819, .op = 102, .commit = 102, .timestamp = 1763999344992358281, .request = 100, .operation = vsr.Operation(140), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:49:06.638Z debug(forest): entering forest.compact() op=102 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
warning(client): 298030292540495332668092515795273542819: on_reply: slow request, request=100 op=102 size=2320 lookup_accounts time=1646ms
2025-11-24 15:49:06.638Z debug(client_replies): 1: write_reply: wrote (client=298030292540495332668092515795273542819 request=100)
2025-11-24 15:49:06.638Z info(workload): accounts created = 128, transfers = 106373, pending transfers = 0, commands run = 50
2025-11-24 15:49:06.640Z debug(vsr): 1: journal_repair_budget_timeout fired
2025-11-24 15:49:06.640Z debug(vsr): 1: journal_repair_budget_timeout reset
2025-11-24 15:49:06.640Z debug(vsr): 1: journal_repair_timeout fired
2025-11-24 15:49:06.640Z debug(vsr): 1: journal_repair_timeout reset
2025-11-24 15:49:06.643Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 283395094107644095756372548547942113441, .checksum_padding = 0, .checksum_body = 247188413010721141500325901792642464903, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 275584, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 70182949699061791115048667700619468859, .parent_padding = 0, .client = 298030292540495332668092515795273542819, .session = 2, .timestamp = 0, .request = 101, .operation = vsr.Operation(139), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 1646677158, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:49:06.643Z debug(replica): 1N: on_request: new request
2025-11-24 15:49:06.643Z debug(replica): 1N: primary_pipeline_prepare: request checksum=283395094107644095756372548547942113441 client=298030292540495332668092515795273542819
2025-11-24 15:49:06.645Z debug(replica): 1N: primary_pipeline_prepare: prepare checksum=35095514805082375829918721528197449464 op=103
2025-11-24 15:49:06.645Z debug(vsr): 1: prepare_timeout started
2025-11-24 15:49:06.645Z debug(vsr): 1: primary_abdicate_timeout started
2025-11-24 15:49:06.645Z debug(vsr): 1: pulse_timeout reset
2025-11-24 15:49:06.645Z debug(replica): 1N: replicate: replicating op=103 to replica 0
2025-11-24 15:49:06.645Z debug(replica): 1N: sending prepare to replica 0: vsr.message_header.Header.Prepare{ .checksum = 35095514805082375829918721528197449464, .checksum_padding = 0, .checksum_body = 247188413010721141500325901792642464903, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 275584, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 120160434843970571395657420149742784851, .parent_padding = 0, .request_checksum = 283395094107644095756372548547942113441, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 298030292540495332668092515795273542819, .op = 103, .commit = 102, .timestamp = 1763999346643725485, .request = 101, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-11-24 15:49:06.645Z debug(message_bus): 1: send_message_to_replica: no connection to=0 header=vsr.message_header.Header.Prepare{ .checksum = 35095514805082375829918721528197449464, .checksum_padding = 0, .checksum_body = 247188413010721141500325901792642464903, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 275584, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 120160434843970571395657420149742784851, .parent_padding = 0, .request_checksum = 283395094107644095756372548547942113441, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 298030292540495332668092515795273542819, .op = 103, .commit = 102, .timestamp = 1763999346643725485, .request = 101, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-11-24 15:49:06.645Z debug(replica): 1N: replicate: replicating op=103 to replica 2
2025-11-24 15:49:06.645Z debug(replica): 1N: sending prepare to replica 2: vsr.message_header.Header.Prepare{ .checksum = 35095514805082375829918721528197449464, .checksum_padding = 0, .checksum_body = 247188413010721141500325901792642464903, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 275584, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 120160434843970571395657420149742784851, .parent_padding = 0, .request_checksum = 283395094107644095756372548547942113441, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 298030292540495332668092515795273542819, .op = 103, .commit = 102, .timestamp = 1763999346643725485, .request = 101, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-11-24 15:49:06.645Z debug(replica): 1N: on_prepare: advancing: op=102..103 checksum=120160434843970571395657420149742784851..35095514805082375829918721528197449464
2025-11-24 15:49:06.645Z debug(journal): 1: set_header_as_dirty: op=103 checksum=35095514805082375829918721528197449464
2025-11-24 15:49:06.645Z debug(replica): 1N: append: appending to journal op=103
2025-11-24 15:49:06.645Z debug(journal): 1: write: view=1 slot=103 op=103 len=275584: 35095514805082375829918721528197449464 starting
2025-11-24 15:49:06.645Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.prepares offset=108003328 len=278528 locked
2025-11-24 15:49:06.645Z debug(replica): 0n: client_table_entry_update: client=298030292540495332668092515795273542819 session=2 request=21
2025-11-24 15:49:06.645Z debug(forest): entering forest.compact() op=23 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2025-11-24 15:49:06.645Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.prepares offset=108003328 len=278528 unlocked
2025-11-24 15:49:06.645Z debug(journal): 1: write_header: op=103 sectors[24576..28672]
2025-11-24 15:49:06.645Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.headers offset=24576 len=4096 locked
2025-11-24 15:49:06.645Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.headers offset=24576 len=4096 unlocked
2025-11-24 15:49:06.645Z debug(journal): 1: write: view=1 slot=103 op=103 len=275584: 35095514805082375829918721528197449464 complete, marking clean
2025-11-24 15:49:06.645Z debug(replica): 1N: send_prepare_ok: op=103 checksum=35095514805082375829918721528197449464
2025-11-24 15:49:06.645Z debug(replica): 1N: sending prepare_ok to replica 1: vsr.message_header.Header.PrepareOk{ .checksum = 11399712909483070143689391670122437260, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 1, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 120160434843970571395657420149742784851, .parent_padding = 0, .prepare_checksum = 35095514805082375829918721528197449464, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 298030292540495332668092515795273542819, .op = 103, .commit_min = 102, .timestamp = 1763999346643725485, .request = 101, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-11-24 15:49:06.645Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.PrepareOk{ .checksum = 11399712909483070143689391670122437260, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 1, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 120160434843970571395657420149742784851, .parent_padding = 0, .prepare_checksum = 35095514805082375829918721528197449464, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 298030292540495332668092515795273542819, .op = 103, .commit_min = 102, .timestamp = 1763999346643725485, .request = 101, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-11-24 15:49:06.645Z debug(vsr): 1: primary_abdicate_timeout reset
2025-11-24 15:49:06.645Z debug(replica): 1N: on_prepare_ok: 1 message(s)
2025-11-24 15:49:06.645Z debug(replica): 1N: on_prepare_ok: waiting for quorum
2025-11-24 15:49:06.646Z debug(replica): 2n: on_message: view=1 status=normal vsr.message_header.Header.Prepare{ .checksum = 35095514805082375829918721528197449464, .checksum_padding = 0, .checksum_body = 247188413010721141500325901792642464903, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 275584, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 120160434843970571395657420149742784851, .parent_padding = 0, .request_checksum = 283395094107644095756372548547942113441, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 298030292540495332668092515795273542819, .op = 103, .commit = 102, .timestamp = 1763999346643725485, .request = 101, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-11-24 15:49:06.646Z debug(replica): 2n: on_prepare: advancing commit_max=101..102
2025-11-24 15:49:06.646Z debug(replica): 2n: on_prepare: caching prepare.op=103 (commit_min=101 op=102 commit_max=102 prepare_max=1007)
2025-11-24 15:49:06.646Z debug(replica): 2n: on_prepare: advancing: op=102..103 checksum=120160434843970571395657420149742784851..35095514805082375829918721528197449464
2025-11-24 15:49:06.646Z debug(journal): 2: set_header_as_dirty: op=103 checksum=35095514805082375829918721528197449464
2025-11-24 15:49:06.646Z debug(replica): 2n: append: appending to journal op=103
2025-11-24 15:49:06.646Z debug(journal): 2: write: view=1 slot=103 op=103 len=275584: 35095514805082375829918721528197449464 starting
2025-11-24 15:49:06.646Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.prepares offset=108003328 len=278528 locked
2025-11-24 15:49:06.646Z debug(replica): 2n: commit_start_journal: cached prepare op=102 checksum=120160434843970571395657420149742784851
2025-11-24 15:49:06.646Z debug(replica): 2n: repair_prepare: op=103 checksum=35095514805082375829918721528197449464 (already writing)
2025-11-24 15:49:06.647Z debug(replica): 2n: commit_journal: already committing (prefetch; commit_min=101)
2025-11-24 15:49:06.647Z debug(replica): 2n: execute_op: executing view=1 primary=false op=102 checksum=120160434843970571395657420149742784851 (lookup_accounts)
2025-11-24 15:49:06.647Z debug(replica): 2n: execute_op: commit_timestamp=1763999344967886190 prepare.header.timestamp=1763999344992358281
2025-11-24 15:49:06.647Z debug(replica): 2n: client_table_entry_update: client=298030292540495332668092515795273542819 session=2 request=100
2025-11-24 15:49:06.647Z debug(replica): 2n: execute_op: replying to client: vsr.message_header.Header.Reply{ .checksum = 22601772805599575367225163930730122979, .checksum_padding = 0, .checksum_body = 105397134507487429849597353631841704520, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 16768, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 18297403943594761543438752698813349882, .request_checksum_padding = 0, .context = 70182949699061791115048667700619468859, .context_padding = 0, .client = 298030292540495332668092515795273542819, .op = 102, .commit = 102, .timestamp = 1763999344992358281, .request = 100, .operation = vsr.Operation(140), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:49:06.647Z debug(replica): 2n: sending reply to client 298030292540495332668092515795273542819: vsr.message_header.Header.Reply{ .checksum = 22601772805599575367225163930730122979, .checksum_padding = 0, .checksum_body = 105397134507487429849597353631841704520, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 16768, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 18297403943594761543438752698813349882, .request_checksum_padding = 0, .context = 70182949699061791115048667700619468859, .context_padding = 0, .client = 298030292540495332668092515795273542819, .op = 102, .commit = 102, .timestamp = 1763999344992358281, .request = 100, .operation = vsr.Operation(140), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:49:06.647Z debug(forest): entering forest.compact() op=102 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2025-11-24 15:49:06.647Z debug(client_replies): 2: write_reply: wrote (client=298030292540495332668092515795273542819 request=100)
2025-11-24 15:49:06.647Z debug(vsr): 2: journal_repair_budget_timeout fired
2025-11-24 15:49:06.647Z debug(vsr): 2: journal_repair_budget_timeout reset
2025-11-24 15:49:06.647Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.prepares offset=108003328 len=278528 unlocked
2025-11-24 15:49:06.647Z debug(journal): 2: write_header: op=103 sectors[24576..28672]
2025-11-24 15:49:06.647Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.headers offset=24576 len=4096 locked
2025-11-24 15:49:06.647Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.headers offset=24576 len=4096 unlocked
2025-11-24 15:49:06.647Z debug(journal): 2: write: view=1 slot=103 op=103 len=275584: 35095514805082375829918721528197449464 complete, marking clean
2025-11-24 15:49:06.647Z debug(replica): 2n: send_prepare_ok: op=103 checksum=35095514805082375829918721528197449464
2025-11-24 15:49:06.647Z debug(replica): 2n: sending prepare_ok to replica 1: vsr.message_header.Header.PrepareOk{ .checksum = 238482079648975869421058712111172190127, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 1, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 120160434843970571395657420149742784851, .parent_padding = 0, .prepare_checksum = 35095514805082375829918721528197449464, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 298030292540495332668092515795273542819, .op = 103, .commit_min = 102, .timestamp = 1763999346643725485, .request = 101, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-11-24 15:49:06.648Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.PrepareOk{ .checksum = 238482079648975869421058712111172190127, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 1, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 120160434843970571395657420149742784851, .parent_padding = 0, .prepare_checksum = 35095514805082375829918721528197449464, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 298030292540495332668092515795273542819, .op = 103, .commit_min = 102, .timestamp = 1763999346643725485, .request = 101, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-11-24 15:49:06.648Z debug(vsr): 1: primary_abdicate_timeout reset
2025-11-24 15:49:06.648Z debug(replica): 1N: on_prepare_ok: 2 message(s)
2025-11-24 15:49:06.648Z debug(replica): 1N: on_prepare_ok: quorum received, context=35095514805082375829918721528197449464
2025-11-24 15:49:06.648Z debug(vsr): 1: prepare_timeout stopped
2025-11-24 15:49:06.648Z debug(vsr): 1: primary_abdicate_timeout stopped
2025-11-24 15:49:06.649Z debug(replica): 1N: execute_op: executing view=1 primary=true op=103 checksum=35095514805082375829918721528197449464 (create_transfers)
2025-11-24 15:49:06.649Z debug(replica): 1N: execute_op: commit_timestamp=1763999344992358281 prepare.header.timestamp=1763999346643725485
2025-11-24 15:49:06.655Z debug(client_replies): 0: write_reply: wrote (client=298030292540495332668092515795273542819 request=21)
2025-11-24 15:49:06.655Z debug(replica): 0n: execute_op: executing view=1 primary=false op=24 checksum=122566622110927330858950845265097241057 (lookup_accounts)
2025-11-24 15:49:06.655Z debug(replica): 0n: execute_op: commit_timestamp=1763999204357266351 prepare.header.timestamp=1763999204404044766
2025-11-24 15:49:06.655Z debug(replica): 0n: client_table_entry_update: client=298030292540495332668092515795273542819 session=2 request=22
2025-11-24 15:49:06.655Z debug(replica): 0n: execute_op: replying to client: vsr.message_header.Header.Reply{ .checksum = 199987601150596510817883914625258172518, .checksum_padding = 0, .checksum_body = 229984777389359920140327988121816431595, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 13440, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 2599930558112327309890832102675162774, .request_checksum_padding = 0, .context = 281424959223889192047142727154860433116, .context_padding = 0, .client = 298030292540495332668092515795273542819, .op = 24, .commit = 24, .timestamp = 1763999204404044766, .request = 22, .operation = vsr.Operation(140), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:49:06.655Z debug(replica): 0n: sending reply to client 298030292540495332668092515795273542819: vsr.message_header.Header.Reply{ .checksum = 199987601150596510817883914625258172518, .checksum_padding = 0, .checksum_body = 229984777389359920140327988121816431595, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 13440, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 2599930558112327309890832102675162774, .request_checksum_padding = 0, .context = 281424959223889192047142727154860433116, .context_padding = 0, .client = 298030292540495332668092515795273542819, .op = 24, .commit = 24, .timestamp = 1763999204404044766, .request = 22, .operation = vsr.Operation(140), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:49:06.655Z debug(forest): entering forest.compact() op=24 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2025-11-24 15:49:06.657Z debug(replica): 0n: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 283395094107644095756372548547942113441, .checksum_padding = 0, .checksum_body = 247188413010721141500325901792642464903, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 275584, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 70182949699061791115048667700619468859, .parent_padding = 0, .client = 298030292540495332668092515795273542819, .session = 2, .timestamp = 0, .request = 101, .operation = vsr.Operation(139), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 1646677158, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:49:06.657Z debug(replica): 0n: on_request: forwarding new request to primary (view=1)
2025-11-24 15:49:06.657Z debug(replica): 0n: sending request to replica 1: vsr.message_header.Header.Request{ .checksum = 283395094107644095756372548547942113441, .checksum_padding = 0, .checksum_body = 247188413010721141500325901792642464903, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 275584, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 70182949699061791115048667700619468859, .parent_padding = 0, .client = 298030292540495332668092515795273542819, .session = 2, .timestamp = 0, .request = 101, .operation = vsr.Operation(139), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 1646677158, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:49:06.657Z debug(client_replies): 0: write_reply: wrote (client=298030292540495332668092515795273542819 request=22)
2025-11-24 15:49:06.657Z debug(replica): 1N: execute_op: advancing commit_max=102..103
2025-11-24 15:49:06.657Z debug(replica): 1N: client_table_entry_update: client=298030292540495332668092515795273542819 session=2 request=101
2025-11-24 15:49:06.657Z debug(replica): 1N: execute_op: replying to client: vsr.message_header.Header.Reply{ .checksum = 43985472792754587905213871128511385718, .checksum_padding = 0, .checksum_body = 223417394656666036718618137822350877152, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 272, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 283395094107644095756372548547942113441, .request_checksum_padding = 0, .context = 74236036170469988347439447705696151666, .context_padding = 0, .client = 298030292540495332668092515795273542819, .op = 103, .commit = 103, .timestamp = 1763999346643725485, .request = 101, .operation = vsr.Operation(139), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:49:06.657Z debug(replica): 1N: sending reply to client 298030292540495332668092515795273542819: vsr.message_header.Header.Reply{ .checksum = 43985472792754587905213871128511385718, .checksum_padding = 0, .checksum_body = 223417394656666036718618137822350877152, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 272, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 283395094107644095756372548547942113441, .request_checksum_padding = 0, .context = 74236036170469988347439447705696151666, .context_padding = 0, .client = 298030292540495332668092515795273542819, .op = 103, .commit = 103, .timestamp = 1763999346643725485, .request = 101, .operation = vsr.Operation(139), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:49:06.657Z debug(forest): entering forest.compact() op=103 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2025-11-24 15:49:06.662Z debug(replica): 0n: execute_op: executing view=1 primary=false op=25 checksum=29024730744012681418514152413944647530 (create_transfers)
2025-11-24 15:49:06.662Z debug(replica): 0n: execute_op: commit_timestamp=1763999204404044766 prepare.header.timestamp=1763999207567045696
2025-11-24 15:49:06.662Z debug(client_replies): 1: write_reply: wrote (client=298030292540495332668092515795273542819 request=101)
2025-11-24 15:49:06.664Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 283395094107644095756372548547942113441, .checksum_padding = 0, .checksum_body = 247188413010721141500325901792642464903, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 275584, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 70182949699061791115048667700619468859, .parent_padding = 0, .client = 298030292540495332668092515795273542819, .session = 2, .timestamp = 0, .request = 101, .operation = vsr.Operation(139), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 1646677158, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:49:06.664Z debug(replica): 1N: on_request: replying to duplicate request
2025-11-24 15:49:06.664Z debug(client_replies): 1: read_reply: start (client=298030292540495332668092515795273542819 reply=43985472792754587905213871128511385718)
2025-11-24 15:49:06.664Z debug(client_replies): 1: read_reply: done (client=298030292540495332668092515795273542819 reply=43985472792754587905213871128511385718)
2025-11-24 15:49:06.664Z debug(replica): 1N: on_request: repeat reply (client=298030292540495332668092515795273542819 request=101)
2025-11-24 15:49:06.664Z debug(replica): 1N: sending reply to client 298030292540495332668092515795273542819: vsr.message_header.Header.Reply{ .checksum = 43985472792754587905213871128511385718, .checksum_padding = 0, .checksum_body = 223417394656666036718618137822350877152, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 272, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 283395094107644095756372548547942113441, .request_checksum_padding = 0, .context = 74236036170469988347439447705696151666, .context_padding = 0, .client = 298030292540495332668092515795273542819, .op = 103, .commit = 103, .timestamp = 1763999346643725485, .request = 101, .operation = vsr.Operation(139), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:49:06.667Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 136067825776572891384243261491247707778, .checksum_padding = 0, .checksum_body = 44623810401707250643847267175380040479, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2320, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 74236036170469988347439447705696151666, .parent_padding = 0, .client = 298030292540495332668092515795273542819, .session = 2, .timestamp = 0, .request = 102, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 17255427, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:49:06.667Z debug(replica): 1N: on_request: new request
2025-11-24 15:49:06.667Z debug(replica): 1N: primary_pipeline_prepare: request checksum=136067825776572891384243261491247707778 client=298030292540495332668092515795273542819
2025-11-24 15:49:06.667Z debug(replica): 2n: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 136067825776572891384243261491247707778, .checksum_padding = 0, .checksum_body = 44623810401707250643847267175380040479, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2320, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 74236036170469988347439447705696151666, .parent_padding = 0, .client = 298030292540495332668092515795273542819, .session = 2, .timestamp = 0, .request = 102, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 17255427, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:49:06.667Z debug(replica): 1N: primary_pipeline_prepare: prepare checksum=157867683682477682780499459339995395511 op=104
2025-11-24 15:49:06.667Z debug(replica): 2n: on_request: forwarding new request to primary (view=1)
2025-11-24 15:49:06.667Z debug(vsr): 1: prepare_timeout started
2025-11-24 15:49:06.667Z debug(vsr): 1: primary_abdicate_timeout started
2025-11-24 15:49:06.667Z debug(vsr): 1: pulse_timeout reset
2025-11-24 15:49:06.667Z debug(replica): 2n: sending request to replica 1: vsr.message_header.Header.Request{ .checksum = 136067825776572891384243261491247707778, .checksum_padding = 0, .checksum_body = 44623810401707250643847267175380040479, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2320, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 74236036170469988347439447705696151666, .parent_padding = 0, .client = 298030292540495332668092515795273542819, .session = 2, .timestamp = 0, .request = 102, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 17255427, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:49:06.667Z debug(replica): 1N: replicate: replicating op=104 to replica 0
2025-11-24 15:49:06.667Z debug(replica): 1N: sending prepare to replica 0: vsr.message_header.Header.Prepare{ .checksum = 157867683682477682780499459339995395511, .checksum_padding = 0, .checksum_body = 44623810401707250643847267175380040479, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2320, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 35095514805082375829918721528197449464, .parent_padding = 0, .request_checksum = 136067825776572891384243261491247707778, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 298030292540495332668092515795273542819, .op = 104, .commit = 103, .timestamp = 1763999346667064346, .request = 102, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-11-24 15:49:06.667Z debug(message_bus): 1: send_message_to_replica: no connection to=0 header=vsr.message_header.Header.Prepare{ .checksum = 157867683682477682780499459339995395511, .checksum_padding = 0, .checksum_body = 44623810401707250643847267175380040479, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2320, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 35095514805082375829918721528197449464, .parent_padding = 0, .request_checksum = 136067825776572891384243261491247707778, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 298030292540495332668092515795273542819, .op = 104, .commit = 103, .timestamp = 1763999346667064346, .request = 102, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-11-24 15:49:06.667Z debug(replica): 1N: replicate: replicating op=104 to replica 2
2025-11-24 15:49:06.667Z debug(replica): 1N: sending prepare to replica 2: vsr.message_header.Header.Prepare{ .checksum = 157867683682477682780499459339995395511, .checksum_padding = 0, .checksum_body = 44623810401707250643847267175380040479, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2320, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 35095514805082375829918721528197449464, .parent_padding = 0, .request_checksum = 136067825776572891384243261491247707778, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 298030292540495332668092515795273542819, .op = 104, .commit = 103, .timestamp = 1763999346667064346, .request = 102, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-11-24 15:49:06.667Z debug(replica): 1N: on_prepare: advancing: op=103..104 checksum=35095514805082375829918721528197449464..157867683682477682780499459339995395511
2025-11-24 15:49:06.667Z debug(journal): 1: set_header_as_dirty: op=104 checksum=157867683682477682780499459339995395511
2025-11-24 15:49:06.667Z debug(replica): 1N: append: appending to journal op=104
2025-11-24 15:49:06.667Z debug(journal): 1: write: view=1 slot=104 op=104 len=2320: 157867683682477682780499459339995395511 starting
2025-11-24 15:49:06.667Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.prepares offset=109051904 len=4096 locked
2025-11-24 15:49:06.667Z debug(replica): 2n: on_message: view=1 status=normal vsr.message_header.Header.Prepare{ .checksum = 157867683682477682780499459339995395511, .checksum_padding = 0, .checksum_body = 44623810401707250643847267175380040479, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2320, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 35095514805082375829918721528197449464, .parent_padding = 0, .request_checksum = 136067825776572891384243261491247707778, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 298030292540495332668092515795273542819, .op = 104, .commit = 103, .timestamp = 1763999346667064346, .request = 102, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-11-24 15:49:06.667Z debug(replica): 2n: on_prepare: advancing commit_max=102..103
2025-11-24 15:49:06.667Z debug(replica): 2n: on_prepare: caching prepare.op=104 (commit_min=102 op=103 commit_max=103 prepare_max=1007)
2025-11-24 15:49:06.667Z debug(replica): 2n: on_prepare: advancing: op=103..104 checksum=35095514805082375829918721528197449464..157867683682477682780499459339995395511
2025-11-24 15:49:06.667Z debug(journal): 2: set_header_as_dirty: op=104 checksum=157867683682477682780499459339995395511
2025-11-24 15:49:06.667Z debug(replica): 2n: append: appending to journal op=104
2025-11-24 15:49:06.667Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 136067825776572891384243261491247707778, .checksum_padding = 0, .checksum_body = 44623810401707250643847267175380040479, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2320, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 74236036170469988347439447705696151666, .parent_padding = 0, .client = 298030292540495332668092515795273542819, .session = 2, .timestamp = 0, .request = 102, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 17255427, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:49:06.667Z debug(journal): 2: write: view=1 slot=104 op=104 len=2320: 157867683682477682780499459339995395511 starting
2025-11-24 15:49:06.667Z debug(replica): 1N: on_request: new request
2025-11-24 15:49:06.667Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.prepares offset=109051904 len=4096 locked
2025-11-24 15:49:06.667Z debug(replica): 1N: on_request: ignoring (already preparing)
2025-11-24 15:49:06.667Z debug(replica): 2n: commit_start_journal: cached prepare op=103 checksum=35095514805082375829918721528197449464
2025-11-24 15:49:06.667Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.prepares offset=109051904 len=4096 unlocked
2025-11-24 15:49:06.667Z debug(journal): 1: write_header: op=104 sectors[24576..28672]
2025-11-24 15:49:06.667Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.headers offset=24576 len=4096 locked
2025-11-24 15:49:06.667Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.headers offset=24576 len=4096 unlocked
2025-11-24 15:49:06.667Z debug(journal): 1: write: view=1 slot=104 op=104 len=2320: 157867683682477682780499459339995395511 complete, marking clean
2025-11-24 15:49:06.667Z debug(replica): 1N: send_prepare_ok: op=104 checksum=157867683682477682780499459339995395511
2025-11-24 15:49:06.667Z debug(replica): 2n: repair_prepare: op=104 checksum=157867683682477682780499459339995395511 (already writing)
2025-11-24 15:49:06.679Z debug(replica): 0n: client_table_entry_update: client=298030292540495332668092515795273542819 session=2 request=23
2025-11-24 15:49:06.667Z debug(replica): 1N: sending prepare_ok to replica 1: vsr.message_header.Header.PrepareOk{ .checksum = 74827319145090005473513118415203860580, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 1, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 35095514805082375829918721528197449464, .parent_padding = 0, .prepare_checksum = 157867683682477682780499459339995395511, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 298030292540495332668092515795273542819, .op = 104, .commit_min = 103, .timestamp = 1763999346667064346, .request = 102, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-11-24 15:49:06.667Z debug(replica): 2n: commit_journal: already committing (prefetch; commit_min=102)
2025-11-24 15:49:08.784Z debug(forest): entering forest.compact() op=25 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2025-11-24 15:49:08.784Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.PrepareOk{ .checksum = 74827319145090005473513118415203860580, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 1, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 35095514805082375829918721528197449464, .parent_padding = 0, .prepare_checksum = 157867683682477682780499459339995395511, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 298030292540495332668092515795273542819, .op = 104, .commit_min = 103, .timestamp = 1763999346667064346, .request = 102, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-11-24 15:49:08.784Z debug(vsr): 1: primary_abdicate_timeout reset
2025-11-24 15:49:08.784Z debug(replica): 1N: on_prepare_ok: 1 message(s)
2025-11-24 15:49:08.784Z debug(replica): 1N: on_prepare_ok: waiting for quorum
2025-11-24 15:49:08.784Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 136067825776572891384243261491247707778, .checksum_padding = 0, .checksum_body = 44623810401707250643847267175380040479, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2320, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 74236036170469988347439447705696151666, .parent_padding = 0, .client = 298030292540495332668092515795273542819, .session = 2, .timestamp = 0, .request = 102, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 17255427, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:49:08.784Z debug(replica): 1N: on_request: new request
2025-11-24 15:49:08.784Z debug(replica): 1N: on_request: ignoring (already preparing)
2025-11-24 15:49:08.784Z debug(vsr): 1: journal_repair_budget_timeout fired
2025-11-24 15:49:08.784Z debug(vsr): 1: journal_repair_budget_timeout reset
2025-11-24 15:49:08.784Z debug(replica): 2n: execute_op: executing view=1 primary=false op=103 checksum=35095514805082375829918721528197449464 (create_transfers)
2025-11-24 15:49:08.784Z debug(replica): 2n: execute_op: commit_timestamp=1763999344992358281 prepare.header.timestamp=1763999346643725485
2025-11-24 15:49:08.792Z warning(replica): 0n: commit_dispatch: slow request, request=23 size=576384 create_transfers time=2132ms
2025-11-24 15:49:08.792Z debug(vsr): 0: journal_repair_budget_timeout fired
2025-11-24 15:49:08.792Z debug(vsr): 0: journal_repair_budget_timeout reset
2025-11-24 15:49:08.792Z debug(vsr): 0: journal_repair_timeout fired
2025-11-24 15:49:08.792Z debug(vsr): 0: journal_repair_timeout reset
2025-11-24 15:49:08.793Z debug(replica): 0n: commit_journal: already committing (start; commit_min=25)
2025-11-24 15:49:08.793Z debug(client_replies): 0: write_reply: wrote (client=298030292540495332668092515795273542819 request=23)
2025-11-24 15:49:08.793Z debug(replica): 0n: execute_op: executing view=1 primary=false op=26 checksum=44010453224747623019868124150268765745 (lookup_accounts)
2025-11-24 15:49:08.793Z debug(replica): 0n: execute_op: commit_timestamp=1763999207567045696 prepare.header.timestamp=1763999207614060611
2025-11-24 15:49:08.793Z debug(replica): 0n: client_table_entry_update: client=298030292540495332668092515795273542819 session=2 request=24
2025-11-24 15:49:08.793Z debug(forest): entering forest.compact() op=26 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2025-11-24 15:49:08.793Z debug(replica): 2n: client_table_entry_update: client=298030292540495332668092515795273542819 session=2 request=101
2025-11-24 15:49:08.793Z debug(replica): 2n: execute_op: replying to client: vsr.message_header.Header.Reply{ .checksum = 43985472792754587905213871128511385718, .checksum_padding = 0, .checksum_body = 223417394656666036718618137822350877152, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 272, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 283395094107644095756372548547942113441, .request_checksum_padding = 0, .context = 74236036170469988347439447705696151666, .context_padding = 0, .client = 298030292540495332668092515795273542819, .op = 103, .commit = 103, .timestamp = 1763999346643725485, .request = 101, .operation = vsr.Operation(139), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:49:08.793Z debug(replica): 2n: sending reply to client 298030292540495332668092515795273542819: vsr.message_header.Header.Reply{ .checksum = 43985472792754587905213871128511385718, .checksum_padding = 0, .checksum_body = 223417394656666036718618137822350877152, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 272, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 283395094107644095756372548547942113441, .request_checksum_padding = 0, .context = 74236036170469988347439447705696151666, .context_padding = 0, .client = 298030292540495332668092515795273542819, .op = 103, .commit = 103, .timestamp = 1763999346643725485, .request = 101, .operation = vsr.Operation(139), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:49:08.793Z debug(client_replies): 0: write_reply: wrote (client=298030292540495332668092515795273542819 request=24)
2025-11-24 15:49:08.793Z debug(forest): entering forest.compact() op=103 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2025-11-24 15:49:08.798Z warning(replica): 2n: commit_dispatch: slow request, request=101 size=275584 create_transfers time=2130ms
2025-11-24 15:49:08.798Z debug(replica): 2n: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 136067825776572891384243261491247707778, .checksum_padding = 0, .checksum_body = 44623810401707250643847267175380040479, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2320, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 74236036170469988347439447705696151666, .parent_padding = 0, .client = 298030292540495332668092515795273542819, .session = 2, .timestamp = 0, .request = 102, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 17255427, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:49:08.798Z debug(replica): 2n: on_request: forwarding new request to primary (view=1)
2025-11-24 15:49:08.798Z debug(replica): 2n: sending request to replica 1: vsr.message_header.Header.Request{ .checksum = 136067825776572891384243261491247707778, .checksum_padding = 0, .checksum_body = 44623810401707250643847267175380040479, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2320, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 74236036170469988347439447705696151666, .parent_padding = 0, .client = 298030292540495332668092515795273542819, .session = 2, .timestamp = 0, .request = 102, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 17255427, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:49:08.798Z debug(vsr): 2: journal_repair_budget_timeout fired
2025-11-24 15:49:08.798Z debug(vsr): 2: journal_repair_budget_timeout reset
2025-11-24 15:49:08.798Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.prepares offset=109051904 len=4096 unlocked
2025-11-24 15:49:08.798Z debug(journal): 2: write_header: op=104 sectors[24576..28672]
2025-11-24 15:49:08.798Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.headers offset=24576 len=4096 locked
2025-11-24 15:49:08.798Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 136067825776572891384243261491247707778, .checksum_padding = 0, .checksum_body = 44623810401707250643847267175380040479, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2320, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 74236036170469988347439447705696151666, .parent_padding = 0, .client = 298030292540495332668092515795273542819, .session = 2, .timestamp = 0, .request = 102, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 17255427, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:49:08.798Z debug(client_replies): 2: write_reply: wrote (client=298030292540495332668092515795273542819 request=101)
2025-11-24 15:49:08.798Z debug(replica): 1N: on_request: new request
2025-11-24 15:49:08.798Z debug(replica): 1N: on_request: ignoring (already preparing)
2025-11-24 15:49:08.798Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.headers offset=24576 len=4096 unlocked
2025-11-24 15:49:08.798Z debug(journal): 2: write: view=1 slot=104 op=104 len=2320: 157867683682477682780499459339995395511 complete, marking clean
2025-11-24 15:49:08.798Z debug(replica): 2n: send_prepare_ok: op=104 checksum=157867683682477682780499459339995395511
2025-11-24 15:49:08.798Z debug(replica): 2n: sending prepare_ok to replica 1: vsr.message_header.Header.PrepareOk{ .checksum = 63825911818264534045659789935797290745, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 1, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 35095514805082375829918721528197449464, .parent_padding = 0, .prepare_checksum = 157867683682477682780499459339995395511, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 298030292540495332668092515795273542819, .op = 104, .commit_min = 103, .timestamp = 1763999346667064346, .request = 102, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-11-24 15:49:08.798Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.PrepareOk{ .checksum = 63825911818264534045659789935797290745, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 1, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 35095514805082375829918721528197449464, .parent_padding = 0, .prepare_checksum = 157867683682477682780499459339995395511, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 298030292540495332668092515795273542819, .op = 104, .commit_min = 103, .timestamp = 1763999346667064346, .request = 102, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-11-24 15:49:08.798Z debug(vsr): 1: primary_abdicate_timeout reset
2025-11-24 15:49:08.798Z debug(replica): 1N: on_prepare_ok: 2 message(s)
2025-11-24 15:49:08.798Z debug(replica): 1N: on_prepare_ok: quorum received, context=157867683682477682780499459339995395511
2025-11-24 15:49:08.798Z debug(vsr): 1: prepare_timeout stopped
2025-11-24 15:49:08.798Z debug(vsr): 1: primary_abdicate_timeout stopped
2025-11-24 15:49:08.798Z debug(replica): 1N: execute_op: executing view=1 primary=true op=104 checksum=157867683682477682780499459339995395511 (lookup_accounts)
2025-11-24 15:49:08.798Z debug(replica): 1N: execute_op: commit_timestamp=1763999346643725485 prepare.header.timestamp=1763999346667064346
2025-11-24 15:49:08.798Z debug(replica): 1N: execute_op: advancing commit_max=103..104
2025-11-24 15:49:08.798Z debug(replica): 0n: execute_op: executing view=1 primary=false op=27 checksum=174150501709482509293187011707226872926 (create_transfers)
2025-11-24 15:49:08.798Z debug(replica): 0n: execute_op: commit_timestamp=1763999207614060611 prepare.header.timestamp=1763999210356191698
2025-11-24 15:49:08.798Z debug(replica): 1N: client_table_entry_update: client=298030292540495332668092515795273542819 session=2 request=102
2025-11-24 15:49:08.798Z debug(replica): 1N: execute_op: replying to client: vsr.message_header.Header.Reply{ .checksum = 228200537825007687732124106592170143240, .checksum_padding = 0, .checksum_body = 147307255110559166759930831306407429881, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 16768, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 136067825776572891384243261491247707778, .request_checksum_padding = 0, .context = 11719396547211079030644286204146178843, .context_padding = 0, .client = 298030292540495332668092515795273542819, .op = 104, .commit = 104, .timestamp = 1763999346667064346, .request = 102, .operation = vsr.Operation(140), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:49:08.798Z debug(replica): 1N: sending reply to client 298030292540495332668092515795273542819: vsr.message_header.Header.Reply{ .checksum = 228200537825007687732124106592170143240, .checksum_padding = 0, .checksum_body = 147307255110559166759930831306407429881, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 16768, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 136067825776572891384243261491247707778, .request_checksum_padding = 0, .context = 11719396547211079030644286204146178843, .context_padding = 0, .client = 298030292540495332668092515795273542819, .op = 104, .commit = 104, .timestamp = 1763999346667064346, .request = 102, .operation = vsr.Operation(140), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:49:08.798Z debug(forest): entering forest.compact() op=104 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
warning(client): 298030292540495332668092515795273542819: on_reply: slow request, request=102 op=104 size=2320 lookup_accounts time=2132ms
2025-11-24 15:49:08.799Z debug(client_replies): 1: write_reply: wrote (client=298030292540495332668092515795273542819 request=102)
2025-11-24 15:49:08.799Z info(workload): accounts created = 128, transfers = 108523, pending transfers = 0, commands run = 51
2025-11-24 15:49:08.804Z debug(vsr): 1: journal_repair_budget_timeout fired
2025-11-24 15:49:08.804Z debug(vsr): 1: journal_repair_budget_timeout reset
2025-11-24 15:49:08.816Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 241568716451372832266903333121300811239, .checksum_padding = 0, .checksum_body = 12832614736473184592477998549274425566, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 1019136, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 11719396547211079030644286204146178843, .parent_padding = 0, .client = 298030292540495332668092515795273542819, .session = 2, .timestamp = 0, .request = 103, .operation = vsr.Operation(139), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 2132344437, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:49:08.816Z debug(replica): 1N: on_request: new request
2025-11-24 15:49:08.816Z debug(replica): 1N: primary_pipeline_prepare: request checksum=241568716451372832266903333121300811239 client=298030292540495332668092515795273542819
2025-11-24 15:49:08.816Z debug(replica): 0n: client_table_entry_update: client=298030292540495332668092515795273542819 session=2 request=25
2025-11-24 15:49:08.816Z debug(replica): 0n: execute_op: replying to client: vsr.message_header.Header.Reply{ .checksum = 122756246690604967635776595102863559237, .checksum_padding = 0, .checksum_body = 284926549341496480287633384891432179083, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 352, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 61461383702793773886038991147146199257, .request_checksum_padding = 0, .context = 249531552189828351147002547080639704090, .context_padding = 0, .client = 298030292540495332668092515795273542819, .op = 27, .commit = 27, .timestamp = 1763999210356191698, .request = 25, .operation = vsr.Operation(139), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:49:08.816Z debug(replica): 0n: sending reply to client 298030292540495332668092515795273542819: vsr.message_header.Header.Reply{ .checksum = 122756246690604967635776595102863559237, .checksum_padding = 0, .checksum_body = 284926549341496480287633384891432179083, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 352, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 61461383702793773886038991147146199257, .request_checksum_padding = 0, .context = 249531552189828351147002547080639704090, .context_padding = 0, .client = 298030292540495332668092515795273542819, .op = 27, .commit = 27, .timestamp = 1763999210356191698, .request = 25, .operation = vsr.Operation(139), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:49:08.817Z debug(forest): entering forest.compact() op=27 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2025-11-24 15:49:08.818Z debug(vsr): 2: journal_repair_budget_timeout fired
2025-11-24 15:49:08.818Z debug(vsr): 2: journal_repair_budget_timeout reset
2025-11-24 15:49:08.820Z debug(replica): 1N: primary_pipeline_prepare: prepare checksum=223993988688182942188955290449752137586 op=105
2025-11-24 15:49:08.820Z debug(vsr): 1: prepare_timeout started
2025-11-24 15:49:08.820Z debug(vsr): 1: primary_abdicate_timeout started
2025-11-24 15:49:08.820Z debug(vsr): 1: pulse_timeout reset
2025-11-24 15:49:08.820Z debug(replica): 1N: replicate: replicating op=105 to replica 0
2025-11-24 15:49:08.820Z debug(replica): 1N: sending prepare to replica 0: vsr.message_header.Header.Prepare{ .checksum = 223993988688182942188955290449752137586, .checksum_padding = 0, .checksum_body = 12832614736473184592477998549274425566, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 1019136, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 157867683682477682780499459339995395511, .parent_padding = 0, .request_checksum = 241568716451372832266903333121300811239, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 298030292540495332668092515795273542819, .op = 105, .commit = 104, .timestamp = 1763999348816165648, .request = 103, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-11-24 15:49:08.820Z debug(message_bus): 1: send_message_to_replica: no connection to=0 header=vsr.message_header.Header.Prepare{ .checksum = 223993988688182942188955290449752137586, .checksum_padding = 0, .checksum_body = 12832614736473184592477998549274425566, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 1019136, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 157867683682477682780499459339995395511, .parent_padding = 0, .request_checksum = 241568716451372832266903333121300811239, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 298030292540495332668092515795273542819, .op = 105, .commit = 104, .timestamp = 1763999348816165648, .request = 103, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-11-24 15:49:08.820Z debug(replica): 1N: replicate: replicating op=105 to replica 2
2025-11-24 15:49:08.820Z debug(replica): 1N: sending prepare to replica 2: vsr.message_header.Header.Prepare{ .checksum = 223993988688182942188955290449752137586, .checksum_padding = 0, .checksum_body = 12832614736473184592477998549274425566, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 1019136, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 157867683682477682780499459339995395511, .parent_padding = 0, .request_checksum = 241568716451372832266903333121300811239, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 298030292540495332668092515795273542819, .op = 105, .commit = 104, .timestamp = 1763999348816165648, .request = 103, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-11-24 15:49:08.820Z debug(replica): 1N: on_prepare: advancing: op=104..105 checksum=157867683682477682780499459339995395511..223993988688182942188955290449752137586
2025-11-24 15:49:08.820Z debug(journal): 1: set_header_as_dirty: op=105 checksum=223993988688182942188955290449752137586
2025-11-24 15:49:08.820Z debug(replica): 1N: append: appending to journal op=105
2025-11-24 15:49:08.820Z debug(journal): 1: write: view=1 slot=105 op=105 len=1019136: 223993988688182942188955290449752137586 starting
2025-11-24 15:49:08.820Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.prepares offset=110100480 len=1019904 locked
2025-11-24 15:49:08.821Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.prepares offset=110100480 len=1019904 unlocked
2025-11-24 15:49:08.821Z debug(journal): 1: write_header: op=105 sectors[24576..28672]
2025-11-24 15:49:08.821Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.headers offset=24576 len=4096 locked
2025-11-24 15:49:08.822Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.headers offset=24576 len=4096 unlocked
2025-11-24 15:49:08.822Z debug(journal): 1: write: view=1 slot=105 op=105 len=1019136: 223993988688182942188955290449752137586 complete, marking clean
2025-11-24 15:49:08.822Z debug(replica): 1N: send_prepare_ok: op=105 checksum=223993988688182942188955290449752137586
2025-11-24 15:49:08.822Z debug(replica): 1N: sending prepare_ok to replica 1: vsr.message_header.Header.PrepareOk{ .checksum = 152167020234286820676827079486162908191, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 1, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 157867683682477682780499459339995395511, .parent_padding = 0, .prepare_checksum = 223993988688182942188955290449752137586, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 298030292540495332668092515795273542819, .op = 105, .commit_min = 104, .timestamp = 1763999348816165648, .request = 103, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-11-24 15:49:08.822Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.PrepareOk{ .checksum = 152167020234286820676827079486162908191, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 1, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 157867683682477682780499459339995395511, .parent_padding = 0, .prepare_checksum = 223993988688182942188955290449752137586, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 298030292540495332668092515795273542819, .op = 105, .commit_min = 104, .timestamp = 1763999348816165648, .request = 103, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-11-24 15:49:08.822Z debug(vsr): 1: primary_abdicate_timeout reset
2025-11-24 15:49:08.822Z debug(replica): 1N: on_prepare_ok: 1 message(s)
2025-11-24 15:49:08.822Z debug(replica): 1N: on_prepare_ok: waiting for quorum
2025-11-24 15:49:08.826Z debug(replica): 2n: on_message: view=1 status=normal vsr.message_header.Header.Prepare{ .checksum = 223993988688182942188955290449752137586, .checksum_padding = 0, .checksum_body = 12832614736473184592477998549274425566, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 1019136, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 157867683682477682780499459339995395511, .parent_padding = 0, .request_checksum = 241568716451372832266903333121300811239, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 298030292540495332668092515795273542819, .op = 105, .commit = 104, .timestamp = 1763999348816165648, .request = 103, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-11-24 15:49:08.826Z debug(replica): 2n: on_prepare: advancing commit_max=103..104
2025-11-24 15:49:08.826Z debug(replica): 2n: on_prepare: caching prepare.op=105 (commit_min=103 op=104 commit_max=104 prepare_max=1007)
2025-11-24 15:49:08.826Z debug(replica): 2n: on_prepare: advancing: op=104..105 checksum=157867683682477682780499459339995395511..223993988688182942188955290449752137586
2025-11-24 15:49:08.826Z debug(journal): 2: set_header_as_dirty: op=105 checksum=223993988688182942188955290449752137586
2025-11-24 15:49:08.826Z debug(replica): 2n: append: appending to journal op=105
2025-11-24 15:49:08.826Z debug(journal): 2: write: view=1 slot=105 op=105 len=1019136: 223993988688182942188955290449752137586 starting
2025-11-24 15:49:08.826Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.prepares offset=110100480 len=1019904 locked
2025-11-24 15:49:08.826Z debug(replica): 2n: commit_start_journal: cached prepare op=104 checksum=157867683682477682780499459339995395511
2025-11-24 15:49:08.826Z debug(replica): 2n: repair_prepare: op=105 checksum=223993988688182942188955290449752137586 (already writing)
2025-11-24 15:49:08.826Z debug(client_replies): 0: write_reply: wrote (client=298030292540495332668092515795273542819 request=25)
2025-11-24 15:49:08.826Z debug(replica): 2n: commit_journal: already committing (prefetch; commit_min=103)
2025-11-24 15:49:08.826Z debug(replica): 2n: execute_op: executing view=1 primary=false op=104 checksum=157867683682477682780499459339995395511 (lookup_accounts)
2025-11-24 15:49:08.826Z debug(replica): 2n: execute_op: commit_timestamp=1763999346643725485 prepare.header.timestamp=1763999346667064346
2025-11-24 15:49:08.826Z debug(replica): 0n: execute_op: executing view=1 primary=false op=28 checksum=251730897157851005911358872293926166124 (lookup_accounts)
2025-11-24 15:49:08.826Z debug(replica): 0n: execute_op: commit_timestamp=1763999210356191698 prepare.header.timestamp=1763999210404914549
2025-11-24 15:49:08.826Z debug(replica): 2n: client_table_entry_update: client=298030292540495332668092515795273542819 session=2 request=102
2025-11-24 15:49:08.826Z debug(replica): 2n: execute_op: replying to client: vsr.message_header.Header.Reply{ .checksum = 228200537825007687732124106592170143240, .checksum_padding = 0, .checksum_body = 147307255110559166759930831306407429881, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 16768, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 136067825776572891384243261491247707778, .request_checksum_padding = 0, .context = 11719396547211079030644286204146178843, .context_padding = 0, .client = 298030292540495332668092515795273542819, .op = 104, .commit = 104, .timestamp = 1763999346667064346, .request = 102, .operation = vsr.Operation(140), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:49:08.826Z debug(replica): 2n: sending reply to client 298030292540495332668092515795273542819: vsr.message_header.Header.Reply{ .checksum = 228200537825007687732124106592170143240, .checksum_padding = 0, .checksum_body = 147307255110559166759930831306407429881, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 16768, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 136067825776572891384243261491247707778, .request_checksum_padding = 0, .context = 11719396547211079030644286204146178843, .context_padding = 0, .client = 298030292540495332668092515795273542819, .op = 104, .commit = 104, .timestamp = 1763999346667064346, .request = 102, .operation = vsr.Operation(140), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:49:08.826Z debug(replica): 0n: client_table_entry_update: client=298030292540495332668092515795273542819 session=2 request=26
2025-11-24 15:49:08.826Z debug(forest): entering forest.compact() op=28 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2025-11-24 15:49:08.826Z debug(forest): entering forest.compact() op=104 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2025-11-24 15:49:08.826Z debug(client_replies): 0: write_reply: wrote (client=298030292540495332668092515795273542819 request=26)
2025-11-24 15:49:08.826Z debug(client_replies): 2: write_reply: wrote (client=298030292540495332668092515795273542819 request=102)
2025-11-24 15:49:08.827Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.prepares offset=110100480 len=1019904 unlocked
2025-11-24 15:49:08.827Z debug(journal): 2: write_header: op=105 sectors[24576..28672]
2025-11-24 15:49:08.827Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.headers offset=24576 len=4096 locked
2025-11-24 15:49:08.827Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.headers offset=24576 len=4096 unlocked
2025-11-24 15:49:08.827Z debug(journal): 2: write: view=1 slot=105 op=105 len=1019136: 223993988688182942188955290449752137586 complete, marking clean
2025-11-24 15:49:08.827Z debug(replica): 2n: send_prepare_ok: op=105 checksum=223993988688182942188955290449752137586
2025-11-24 15:49:08.827Z debug(replica): 2n: sending prepare_ok to replica 1: vsr.message_header.Header.PrepareOk{ .checksum = 96477167240680932070188866766524424100, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 1, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 157867683682477682780499459339995395511, .parent_padding = 0, .prepare_checksum = 223993988688182942188955290449752137586, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 298030292540495332668092515795273542819, .op = 105, .commit_min = 104, .timestamp = 1763999348816165648, .request = 103, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-11-24 15:49:08.827Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.PrepareOk{ .checksum = 96477167240680932070188866766524424100, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 1, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 157867683682477682780499459339995395511, .parent_padding = 0, .prepare_checksum = 223993988688182942188955290449752137586, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 298030292540495332668092515795273542819, .op = 105, .commit_min = 104, .timestamp = 1763999348816165648, .request = 103, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-11-24 15:49:08.827Z debug(vsr): 1: primary_abdicate_timeout reset
2025-11-24 15:49:08.827Z debug(replica): 1N: on_prepare_ok: 2 message(s)
2025-11-24 15:49:08.827Z debug(replica): 1N: on_prepare_ok: quorum received, context=223993988688182942188955290449752137586
2025-11-24 15:49:08.827Z debug(vsr): 1: prepare_timeout stopped
2025-11-24 15:49:08.827Z debug(vsr): 1: primary_abdicate_timeout stopped
2025-11-24 15:49:08.828Z debug(vsr): 2: journal_repair_timeout fired
2025-11-24 15:49:08.828Z debug(vsr): 2: journal_repair_timeout reset
2025-11-24 15:49:08.831Z debug(replica): 0n: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 241568716451372832266903333121300811239, .checksum_padding = 0, .checksum_body = 12832614736473184592477998549274425566, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 1019136, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 11719396547211079030644286204146178843, .parent_padding = 0, .client = 298030292540495332668092515795273542819, .session = 2, .timestamp = 0, .request = 103, .operation = vsr.Operation(139), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 2132344437, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:49:08.831Z debug(replica): 0n: on_request: forwarding new request to primary (view=1)
2025-11-24 15:49:08.831Z debug(replica): 0n: sending request to replica 1: vsr.message_header.Header.Request{ .checksum = 241568716451372832266903333121300811239, .checksum_padding = 0, .checksum_body = 12832614736473184592477998549274425566, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 1019136, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 11719396547211079030644286204146178843, .parent_padding = 0, .client = 298030292540495332668092515795273542819, .session = 2, .timestamp = 0, .request = 103, .operation = vsr.Operation(139), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 2132344437, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:49:08.831Z debug(replica): 1N: execute_op: executing view=1 primary=true op=105 checksum=223993988688182942188955290449752137586 (create_transfers)
2025-11-24 15:49:08.831Z debug(replica): 1N: execute_op: commit_timestamp=1763999346667064346 prepare.header.timestamp=1763999348816165648
2025-11-24 15:49:08.835Z debug(replica): 0n: execute_op: executing view=1 primary=false op=29 checksum=38518612592802887877196351272135010314 (create_transfers)
2025-11-24 15:49:08.835Z debug(replica): 0n: execute_op: commit_timestamp=1763999210404914549 prepare.header.timestamp=1763999212613495942
2025-11-24 15:49:08.838Z debug(vsr): 2: journal_repair_budget_timeout fired
2025-11-24 15:49:08.838Z debug(vsr): 2: journal_repair_budget_timeout reset
2025-11-24 15:49:08.846Z debug(replica): 0n: client_table_entry_update: client=298030292540495332668092515795273542819 session=2 request=27
2025-11-24 15:49:08.846Z debug(forest): entering forest.compact() op=29 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2025-11-24 15:49:08.852Z debug(vsr): 0: journal_repair_budget_timeout fired
2025-11-24 15:49:08.852Z debug(vsr): 0: journal_repair_budget_timeout reset
2025-11-24 15:49:08.852Z debug(client_replies): 0: write_reply: wrote (client=298030292540495332668092515795273542819 request=27)
2025-11-24 15:49:08.852Z debug(replica): 0n: execute_op: executing view=1 primary=false op=30 checksum=79890304092819468674462044602139938636 (lookup_accounts)
2025-11-24 15:49:08.852Z debug(replica): 0n: execute_op: commit_timestamp=1763999212613495942 prepare.header.timestamp=1763999212645478215
2025-11-24 15:49:08.852Z debug(replica): 0n: client_table_entry_update: client=298030292540495332668092515795273542819 session=2 request=28
2025-11-24 15:49:08.852Z debug(forest): entering forest.compact() op=30 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2025-11-24 15:49:08.852Z debug(client_replies): 0: write_reply: wrote (client=298030292540495332668092515795273542819 request=28)
2025-11-24 15:49:08.854Z debug(replica): 0n: execute_op: executing view=1 primary=false op=31 checksum=216760414030699453562657614392836654096 (lookup_transfers)
2025-11-24 15:49:08.854Z debug(replica): 0n: execute_op: commit_timestamp=1763999212645478215 prepare.header.timestamp=1763999215160759357
2025-11-24 15:49:08.858Z debug(vsr): 2: journal_repair_budget_timeout fired
2025-11-24 15:49:08.858Z debug(replica): 0n: client_table_entry_update: client=298030292540495332668092515795273542819 session=2 request=29
2025-11-24 15:49:08.858Z debug(vsr): 2: journal_repair_budget_timeout reset
2025-11-24 15:49:08.858Z debug(forest): entering forest.compact() op=31 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=true
2025-11-24 15:49:08.858Z debug(forest): swap_mutable_and_immutable(Account.id)
2025-11-24 15:49:08.858Z debug(forest): swap_mutable_and_immutable(Account.user_data_128)
2025-11-24 15:49:08.858Z debug(forest): swap_mutable_and_immutable(Account.user_data_64)
2025-11-24 15:49:08.858Z debug(forest): swap_mutable_and_immutable(Account.user_data_32)
2025-11-24 15:49:08.858Z debug(forest): swap_mutable_and_immutable(Account.ledger)
2025-11-24 15:49:08.858Z debug(forest): swap_mutable_and_immutable(Account.code)
2025-11-24 15:49:08.858Z debug(forest): swap_mutable_and_immutable(Account)
2025-11-24 15:49:08.859Z debug(forest): swap_mutable_and_immutable(Transfer.id)
2025-11-24 15:49:08.859Z debug(forest): swap_mutable_and_immutable(Transfer.debit_account_id)
2025-11-24 15:49:08.862Z debug(replica): 1N: execute_op: advancing commit_max=104..105
2025-11-24 15:49:08.862Z debug(replica): 1N: client_table_entry_update: client=298030292540495332668092515795273542819 session=2 request=103
2025-11-24 15:49:08.862Z debug(replica): 1N: execute_op: replying to client: vsr.message_header.Header.Reply{ .checksum = 79538654794308839994674048699444821845, .checksum_padding = 0, .checksum_body = 304712166592455415203881989831159197017, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 376, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 241568716451372832266903333121300811239, .request_checksum_padding = 0, .context = 30526188159800205422548803028458873505, .context_padding = 0, .client = 298030292540495332668092515795273542819, .op = 105, .commit = 105, .timestamp = 1763999348816165648, .request = 103, .operation = vsr.Operation(139), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:49:08.862Z debug(replica): 1N: sending reply to client 298030292540495332668092515795273542819: vsr.message_header.Header.Reply{ .checksum = 79538654794308839994674048699444821845, .checksum_padding = 0, .checksum_body = 304712166592455415203881989831159197017, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 376, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 241568716451372832266903333121300811239, .request_checksum_padding = 0, .context = 30526188159800205422548803028458873505, .context_padding = 0, .client = 298030292540495332668092515795273542819, .op = 105, .commit = 105, .timestamp = 1763999348816165648, .request = 103, .operation = vsr.Operation(139), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:49:08.862Z debug(forest): entering forest.compact() op=105 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2025-11-24 15:49:08.868Z debug(forest): swap_mutable_and_immutable(Transfer.credit_account_id)
2025-11-24 15:49:08.877Z debug(vsr): 1: journal_repair_budget_timeout fired
2025-11-24 15:49:08.877Z debug(vsr): 1: journal_repair_budget_timeout reset
2025-11-24 15:49:08.878Z debug(client_replies): 1: write_reply: wrote (client=298030292540495332668092515795273542819 request=103)
2025-11-24 15:49:08.878Z debug(vsr): 2: journal_repair_budget_timeout fired
2025-11-24 15:49:08.878Z debug(vsr): 2: journal_repair_budget_timeout reset
2025-11-24 15:49:08.878Z debug(forest): swap_mutable_and_immutable(Transfer.amount)
2025-11-24 15:49:08.882Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 241568716451372832266903333121300811239, .checksum_padding = 0, .checksum_body = 12832614736473184592477998549274425566, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 1019136, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 11719396547211079030644286204146178843, .parent_padding = 0, .client = 298030292540495332668092515795273542819, .session = 2, .timestamp = 0, .request = 103, .operation = vsr.Operation(139), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 2132344437, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:49:08.882Z debug(replica): 1N: on_request: replying to duplicate request
2025-11-24 15:49:08.882Z debug(client_replies): 1: read_reply: start (client=298030292540495332668092515795273542819 reply=79538654794308839994674048699444821845)
2025-11-24 15:49:08.882Z debug(client_replies): 1: read_reply: done (client=298030292540495332668092515795273542819 reply=79538654794308839994674048699444821845)
2025-11-24 15:49:08.882Z debug(replica): 1N: on_request: repeat reply (client=298030292540495332668092515795273542819 request=103)
2025-11-24 15:49:08.882Z debug(replica): 1N: sending reply to client 298030292540495332668092515795273542819: vsr.message_header.Header.Reply{ .checksum = 79538654794308839994674048699444821845, .checksum_padding = 0, .checksum_body = 304712166592455415203881989831159197017, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 376, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 241568716451372832266903333121300811239, .request_checksum_padding = 0, .context = 30526188159800205422548803028458873505, .context_padding = 0, .client = 298030292540495332668092515795273542819, .op = 105, .commit = 105, .timestamp = 1763999348816165648, .request = 103, .operation = vsr.Operation(139), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:49:08.889Z debug(forest): swap_mutable_and_immutable(Transfer.pending_id)
2025-11-24 15:49:08.889Z debug(forest): swap_mutable_and_immutable(Transfer.user_data_128)
2025-11-24 15:49:08.889Z debug(forest): swap_mutable_and_immutable(Transfer.user_data_64)
2025-11-24 15:49:08.889Z debug(forest): swap_mutable_and_immutable(Transfer.user_data_32)
2025-11-24 15:49:08.889Z debug(forest): swap_mutable_and_immutable(Transfer.ledger)
2025-11-24 15:49:08.889Z debug(forest): swap_mutable_and_immutable(Transfer.code)
2025-11-24 15:49:08.892Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 142716952148735961052966968291013007357, .checksum_padding = 0, .checksum_body = 44623810401707250643847267175380040479, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2320, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 30526188159800205422548803028458873505, .parent_padding = 0, .client = 298030292540495332668092515795273542819, .session = 2, .timestamp = 0, .request = 104, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 56963134, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:49:08.892Z debug(replica): 1N: on_request: new request
2025-11-24 15:49:08.892Z debug(replica): 1N: primary_pipeline_prepare: request checksum=142716952148735961052966968291013007357 client=298030292540495332668092515795273542819
2025-11-24 15:49:08.893Z debug(replica): 1N: primary_pipeline_prepare: prepare checksum=256718603192109629945700705192119048178 op=106
2025-11-24 15:49:08.893Z debug(vsr): 1: prepare_timeout started
2025-11-24 15:49:08.893Z debug(vsr): 1: primary_abdicate_timeout started
2025-11-24 15:49:08.893Z debug(vsr): 1: pulse_timeout reset
2025-11-24 15:49:08.893Z debug(replica): 1N: replicate: replicating op=106 to replica 0
2025-11-24 15:49:08.893Z debug(replica): 1N: sending prepare to replica 0: vsr.message_header.Header.Prepare{ .checksum = 256718603192109629945700705192119048178, .checksum_padding = 0, .checksum_body = 44623810401707250643847267175380040479, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2320, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 223993988688182942188955290449752137586, .parent_padding = 0, .request_checksum = 142716952148735961052966968291013007357, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 298030292540495332668092515795273542819, .op = 106, .commit = 105, .timestamp = 1763999348892988987, .request = 104, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-11-24 15:49:08.893Z debug(message_bus): 1: send_message_to_replica: no connection to=0 header=vsr.message_header.Header.Prepare{ .checksum = 256718603192109629945700705192119048178, .checksum_padding = 0, .checksum_body = 44623810401707250643847267175380040479, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2320, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 223993988688182942188955290449752137586, .parent_padding = 0, .request_checksum = 142716952148735961052966968291013007357, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 298030292540495332668092515795273542819, .op = 106, .commit = 105, .timestamp = 1763999348892988987, .request = 104, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-11-24 15:49:08.893Z debug(replica): 1N: replicate: replicating op=106 to replica 2
2025-11-24 15:49:08.893Z debug(replica): 1N: sending prepare to replica 2: vsr.message_header.Header.Prepare{ .checksum = 256718603192109629945700705192119048178, .checksum_padding = 0, .checksum_body = 44623810401707250643847267175380040479, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2320, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 223993988688182942188955290449752137586, .parent_padding = 0, .request_checksum = 142716952148735961052966968291013007357, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 298030292540495332668092515795273542819, .op = 106, .commit = 105, .timestamp = 1763999348892988987, .request = 104, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-11-24 15:49:08.893Z debug(replica): 1N: on_prepare: advancing: op=105..106 checksum=223993988688182942188955290449752137586..256718603192109629945700705192119048178
2025-11-24 15:49:08.893Z debug(journal): 1: set_header_as_dirty: op=106 checksum=256718603192109629945700705192119048178
2025-11-24 15:49:08.893Z debug(replica): 1N: append: appending to journal op=106
2025-11-24 15:49:08.893Z debug(journal): 1: write: view=1 slot=106 op=106 len=2320: 256718603192109629945700705192119048178 starting
2025-11-24 15:49:08.893Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.prepares offset=111149056 len=4096 locked
2025-11-24 15:49:08.893Z debug(replica): 2n: on_message: view=1 status=normal vsr.message_header.Header.Prepare{ .checksum = 256718603192109629945700705192119048178, .checksum_padding = 0, .checksum_body = 44623810401707250643847267175380040479, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2320, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 223993988688182942188955290449752137586, .parent_padding = 0, .request_checksum = 142716952148735961052966968291013007357, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 298030292540495332668092515795273542819, .op = 106, .commit = 105, .timestamp = 1763999348892988987, .request = 104, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-11-24 15:49:08.893Z debug(replica): 2n: on_prepare: advancing commit_max=104..105
2025-11-24 15:49:08.893Z debug(replica): 2n: on_prepare: caching prepare.op=106 (commit_min=104 op=105 commit_max=105 prepare_max=1007)
2025-11-24 15:49:08.893Z debug(replica): 2n: on_prepare: advancing: op=105..106 checksum=223993988688182942188955290449752137586..256718603192109629945700705192119048178
2025-11-24 15:49:08.893Z debug(journal): 2: set_header_as_dirty: op=106 checksum=256718603192109629945700705192119048178
2025-11-24 15:49:08.893Z debug(replica): 2n: append: appending to journal op=106
2025-11-24 15:49:08.893Z debug(journal): 2: write: view=1 slot=106 op=106 len=2320: 256718603192109629945700705192119048178 starting
2025-11-24 15:49:08.893Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.prepares offset=111149056 len=4096 locked
2025-11-24 15:49:08.893Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.prepares offset=111149056 len=4096 unlocked
2025-11-24 15:49:08.893Z debug(replica): 2n: commit_start_journal: cached prepare op=105 checksum=223993988688182942188955290449752137586
2025-11-24 15:49:08.893Z debug(journal): 1: write_header: op=106 sectors[24576..28672]
2025-11-24 15:49:08.893Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.headers offset=24576 len=4096 locked
2025-11-24 15:49:08.893Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.headers offset=24576 len=4096 unlocked
2025-11-24 15:49:08.893Z debug(journal): 1: write: view=1 slot=106 op=106 len=2320: 256718603192109629945700705192119048178 complete, marking clean
2025-11-24 15:49:08.893Z debug(replica): 1N: send_prepare_ok: op=106 checksum=256718603192109629945700705192119048178
2025-11-24 15:49:08.893Z debug(replica): 1N: sending prepare_ok to replica 1: vsr.message_header.Header.PrepareOk{ .checksum = 163859498701177905945197564868045484734, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 1, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 223993988688182942188955290449752137586, .parent_padding = 0, .prepare_checksum = 256718603192109629945700705192119048178, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 298030292540495332668092515795273542819, .op = 106, .commit_min = 105, .timestamp = 1763999348892988987, .request = 104, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-11-24 15:49:08.893Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.PrepareOk{ .checksum = 163859498701177905945197564868045484734, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 1, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 223993988688182942188955290449752137586, .parent_padding = 0, .prepare_checksum = 256718603192109629945700705192119048178, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 298030292540495332668092515795273542819, .op = 106, .commit_min = 105, .timestamp = 1763999348892988987, .request = 104, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-11-24 15:49:08.893Z debug(vsr): 1: primary_abdicate_timeout reset
2025-11-24 15:49:08.893Z debug(replica): 1N: on_prepare_ok: 1 message(s)
2025-11-24 15:49:08.893Z debug(replica): 1N: on_prepare_ok: waiting for quorum
2025-11-24 15:49:08.894Z debug(replica): 2n: repair_prepare: op=106 checksum=256718603192109629945700705192119048178 (already writing)
2025-11-24 15:49:08.895Z debug(replica): 2n: commit_journal: already committing (prefetch; commit_min=104)
2025-11-24 15:49:08.897Z debug(forest): swap_mutable_and_immutable(Transfer)
2025-11-24 15:49:08.897Z debug(forest): swap_mutable_and_immutable(Transfer.expires_at)
2025-11-24 15:49:08.897Z debug(forest): swap_mutable_and_immutable(TransferPending)
2025-11-24 15:49:08.897Z debug(forest): swap_mutable_and_immutable(TransferPending.status)
2025-11-24 15:49:08.897Z debug(forest): swap_mutable_and_immutable(AccountEvent)
2025-11-24 15:49:08.897Z debug(forest): swap_mutable_and_immutable(Account.imported)
2025-11-24 15:49:08.897Z debug(forest): swap_mutable_and_immutable(Transfer.imported)
2025-11-24 15:49:08.897Z debug(forest): swap_mutable_and_immutable(Account.closed)
2025-11-24 15:49:08.897Z debug(forest): swap_mutable_and_immutable(Transfer.closing)
2025-11-24 15:49:08.897Z debug(forest): swap_mutable_and_immutable(AccountEvent.account_timestamp)
2025-11-24 15:49:08.897Z debug(replica): 2n: execute_op: executing view=1 primary=false op=105 checksum=223993988688182942188955290449752137586 (create_transfers)
2025-11-24 15:49:08.897Z debug(replica): 2n: execute_op: commit_timestamp=1763999346667064346 prepare.header.timestamp=1763999348816165648
2025-11-24 15:49:08.898Z debug(vsr): 1: journal_repair_budget_timeout fired
2025-11-24 15:49:08.898Z debug(vsr): 1: journal_repair_budget_timeout reset
2025-11-24 15:49:08.899Z debug(forest): swap_mutable_and_immutable(AccountEvent.transfer_pending_status)
2025-11-24 15:49:08.899Z debug(forest): swap_mutable_and_immutable(AccountEvent.dr_account_id_expired)
2025-11-24 15:49:08.899Z debug(forest): swap_mutable_and_immutable(AccountEvent.cr_account_id_expired)
2025-11-24 15:49:08.899Z debug(forest): swap_mutable_and_immutable(AccountEvent.transfer_pending_id_expired)
2025-11-24 15:49:08.899Z debug(forest): swap_mutable_and_immutable(AccountEvent.ledger_expired)
2025-11-24 15:49:08.899Z debug(forest): swap_mutable_and_immutable(AccountEvent.prunable)
2025-11-24 15:49:08.918Z debug(vsr): 1: journal_repair_budget_timeout fired
2025-11-24 15:49:08.918Z debug(vsr): 1: journal_repair_budget_timeout reset
2025-11-24 15:49:08.918Z debug(vsr): 1: journal_repair_timeout fired
2025-11-24 15:49:08.918Z debug(vsr): 1: journal_repair_timeout reset
2025-11-24 15:49:08.929Z debug(replica): 2n: client_table_entry_update: client=298030292540495332668092515795273542819 session=2 request=103
2025-11-24 15:49:08.938Z debug(vsr): 1: journal_repair_budget_timeout fired
2025-11-24 15:49:08.938Z debug(vsr): 1: journal_repair_budget_timeout reset
2025-11-24 15:49:08.958Z debug(vsr): 1: journal_repair_budget_timeout fired
2025-11-24 15:49:08.958Z debug(vsr): 1: journal_repair_budget_timeout reset
2025-11-24 15:49:08.978Z debug(vsr): 1: journal_repair_budget_timeout fired
2025-11-24 15:49:08.899Z debug(replica): 0n: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 142716952148735961052966968291013007357, .checksum_padding = 0, .checksum_body = 44623810401707250643847267175380040479, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2320, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 30526188159800205422548803028458873505, .parent_padding = 0, .client = 298030292540495332668092515795273542819, .session = 2, .timestamp = 0, .request = 104, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 56963134, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:49:08.929Z debug(replica): 2n: execute_op: replying to client: vsr.message_header.Header.Reply{ .checksum = 79538654794308839994674048699444821845, .checksum_padding = 0, .checksum_body = 304712166592455415203881989831159197017, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 376, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 241568716451372832266903333121300811239, .request_checksum_padding = 0, .context = 30526188159800205422548803028458873505, .context_padding = 0, .client = 298030292540495332668092515795273542819, .op = 105, .commit = 105, .timestamp = 1763999348816165648, .request = 103, .operation = vsr.Operation(139), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:49:08.978Z debug(vsr): 1: journal_repair_budget_timeout reset
2025-11-24 15:49:11.496Z debug(replica): 0n: on_request: forwarding new request to primary (view=1)
2025-11-24 15:49:11.496Z debug(replica): 2n: sending reply to client 298030292540495332668092515795273542819: vsr.message_header.Header.Reply{ .checksum = 79538654794308839994674048699444821845, .checksum_padding = 0, .checksum_body = 304712166592455415203881989831159197017, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 376, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 241568716451372832266903333121300811239, .request_checksum_padding = 0, .context = 30526188159800205422548803028458873505, .context_padding = 0, .client = 298030292540495332668092515795273542819, .op = 105, .commit = 105, .timestamp = 1763999348816165648, .request = 103, .operation = vsr.Operation(139), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:49:11.496Z debug(replica): 0n: sending request to replica 1: vsr.message_header.Header.Request{ .checksum = 142716952148735961052966968291013007357, .checksum_padding = 0, .checksum_body = 44623810401707250643847267175380040479, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2320, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 30526188159800205422548803028458873505, .parent_padding = 0, .client = 298030292540495332668092515795273542819, .session = 2, .timestamp = 0, .request = 104, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 56963134, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:49:11.496Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 142716952148735961052966968291013007357, .checksum_padding = 0, .checksum_body = 44623810401707250643847267175380040479, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2320, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 30526188159800205422548803028458873505, .parent_padding = 0, .client = 298030292540495332668092515795273542819, .session = 2, .timestamp = 0, .request = 104, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 56963134, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:49:11.496Z debug(forest): entering forest.compact() op=105 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2025-11-24 15:49:11.496Z debug(replica): 1N: on_request: new request
2025-11-24 15:49:11.496Z debug(replica): 1N: on_request: ignoring (already preparing)
2025-11-24 15:49:11.496Z debug(client_replies): 0: write_reply: wrote (client=298030292540495332668092515795273542819 request=29)
2025-11-24 15:49:11.496Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 142716952148735961052966968291013007357, .checksum_padding = 0, .checksum_body = 44623810401707250643847267175380040479, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2320, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 30526188159800205422548803028458873505, .parent_padding = 0, .client = 298030292540495332668092515795273542819, .session = 2, .timestamp = 0, .request = 104, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 56963134, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:49:11.496Z debug(replica): 1N: on_request: new request
2025-11-24 15:49:11.496Z debug(replica): 1N: on_request: ignoring (already preparing)
2025-11-24 15:49:11.496Z debug(replica): 0n: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 142716952148735961052966968291013007357, .checksum_padding = 0, .checksum_body = 44623810401707250643847267175380040479, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2320, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 30526188159800205422548803028458873505, .parent_padding = 0, .client = 298030292540495332668092515795273542819, .session = 2, .timestamp = 0, .request = 104, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 56963134, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:49:11.496Z debug(replica): 0n: on_request: forwarding new request to primary (view=1)
2025-11-24 15:49:11.496Z debug(replica): 0n: sending request to replica 1: vsr.message_header.Header.Request{ .checksum = 142716952148735961052966968291013007357, .checksum_padding = 0, .checksum_body = 44623810401707250643847267175380040479, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2320, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 30526188159800205422548803028458873505, .parent_padding = 0, .client = 298030292540495332668092515795273542819, .session = 2, .timestamp = 0, .request = 104, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 56963134, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:49:11.497Z debug(replica): 0n: execute_op: executing view=1 primary=false op=32 checksum=311306344211001688254025320056880065164 (lookup_accounts)
2025-11-24 15:49:11.497Z debug(replica): 0n: execute_op: commit_timestamp=1763999215160759357 prepare.header.timestamp=1763999217524182976
2025-11-24 15:49:11.497Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 142716952148735961052966968291013007357, .checksum_padding = 0, .checksum_body = 44623810401707250643847267175380040479, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2320, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 30526188159800205422548803028458873505, .parent_padding = 0, .client = 298030292540495332668092515795273542819, .session = 2, .timestamp = 0, .request = 104, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 56963134, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:49:11.497Z debug(replica): 1N: on_request: new request
2025-11-24 15:49:11.497Z debug(replica): 1N: on_request: ignoring (already preparing)
2025-11-24 15:49:11.497Z debug(replica): 0n: client_table_entry_update: client=298030292540495332668092515795273542819 session=2 request=30
2025-11-24 15:49:11.497Z debug(forest): entering forest.compact() op=32 constants.lsm_compaction_ops=32 first_beat=true last_half_beat=false half_beat=false last_beat=false
2025-11-24 15:49:11.497Z debug(compaction): Account.id:1: bar_commence: nothing to compact
2025-11-24 15:49:11.497Z debug(compaction): Account.user_data_128:1: bar_commence: nothing to compact
2025-11-24 15:49:11.497Z debug(compaction): Account.user_data_64:1: bar_commence: nothing to compact
2025-11-24 15:49:11.497Z debug(compaction): Account.user_data_32:1: bar_commence: nothing to compact
2025-11-24 15:49:11.497Z debug(compaction): Account.ledger:1: bar_commence: nothing to compact
2025-11-24 15:49:11.497Z debug(compaction): Account.code:1: bar_commence: nothing to compact
2025-11-24 15:49:11.497Z debug(compaction): Account:1: bar_commence: nothing to compact
2025-11-24 15:49:11.497Z debug(compaction): Transfer.id:1: bar_commence: nothing to compact
2025-11-24 15:49:11.497Z debug(compaction): Transfer.debit_account_id:1: bar_commence: nothing to compact
2025-11-24 15:49:11.497Z debug(compaction): Transfer.credit_account_id:1: bar_commence: nothing to compact
2025-11-24 15:49:11.497Z debug(compaction): Transfer.amount:1: bar_commence: nothing to compact
2025-11-24 15:49:11.497Z debug(compaction): Transfer.pending_id:1: bar_commence: nothing to compact
2025-11-24 15:49:11.497Z debug(compaction): Transfer.user_data_128:1: bar_commence: nothing to compact
2025-11-24 15:49:11.497Z debug(compaction): Transfer.user_data_64:1: bar_commence: nothing to compact
2025-11-24 15:49:11.497Z debug(compaction): Transfer.user_data_32:1: bar_commence: nothing to compact
2025-11-24 15:49:11.497Z debug(compaction): Transfer.ledger:1: bar_commence: nothing to compact
2025-11-24 15:49:11.497Z debug(compaction): Transfer.code:1: bar_commence: nothing to compact
2025-11-24 15:49:11.497Z debug(compaction): Transfer:1: bar_commence: nothing to compact
2025-11-24 15:49:11.497Z debug(compaction): Transfer.expires_at:1: bar_commence: nothing to compact
2025-11-24 15:49:11.497Z debug(compaction): TransferPending:1: bar_commence: nothing to compact
2025-11-24 15:49:11.497Z debug(compaction): TransferPending.status:1: bar_commence: nothing to compact
2025-11-24 15:49:11.497Z debug(compaction): AccountEvent:1: bar_commence: nothing to compact
2025-11-24 15:49:11.497Z debug(compaction): Account.imported:1: bar_commence: nothing to compact
2025-11-24 15:49:11.497Z debug(compaction): Transfer.imported:1: bar_commence: nothing to compact
2025-11-24 15:49:11.497Z debug(compaction): Account.closed:1: bar_commence: nothing to compact
2025-11-24 15:49:11.497Z debug(compaction): Transfer.closing:1: bar_commence: nothing to compact
2025-11-24 15:49:11.497Z debug(compaction): AccountEvent.account_timestamp:1: bar_commence: nothing to compact
2025-11-24 15:49:11.497Z debug(compaction): AccountEvent.transfer_pending_status:1: bar_commence: nothing to compact
2025-11-24 15:49:11.497Z debug(compaction): AccountEvent.dr_account_id_expired:1: bar_commence: nothing to compact
2025-11-24 15:49:11.497Z debug(compaction): AccountEvent.cr_account_id_expired:1: bar_commence: nothing to compact
2025-11-24 15:49:11.497Z debug(compaction): AccountEvent.transfer_pending_id_expired:1: bar_commence: nothing to compact
2025-11-24 15:49:11.497Z debug(compaction): AccountEvent.ledger_expired:1: bar_commence: nothing to compact
2025-11-24 15:49:11.497Z debug(compaction): AccountEvent.prunable:1: bar_commence: nothing to compact
2025-11-24 15:49:11.497Z debug(compaction): Account.id:3: bar_commence: nothing to compact
2025-11-24 15:49:11.497Z debug(compaction): Account.user_data_128:3: bar_commence: nothing to compact
2025-11-24 15:49:11.497Z debug(compaction): Account.user_data_64:3: bar_commence: nothing to compact
2025-11-24 15:49:11.497Z debug(compaction): Account.user_data_32:3: bar_commence: nothing to compact
2025-11-24 15:49:11.497Z debug(compaction): Account.ledger:3: bar_commence: nothing to compact
2025-11-24 15:49:11.497Z debug(compaction): Account.code:3: bar_commence: nothing to compact
2025-11-24 15:49:11.497Z debug(compaction): Account:3: bar_commence: nothing to compact
2025-11-24 15:49:11.497Z debug(compaction): Transfer.id:3: bar_commence: nothing to compact
2025-11-24 15:49:11.497Z debug(compaction): Transfer.debit_account_id:3: bar_commence: nothing to compact
2025-11-24 15:49:11.497Z debug(compaction): Transfer.credit_account_id:3: bar_commence: nothing to compact
2025-11-24 15:49:11.497Z debug(compaction): Transfer.amount:3: bar_commence: nothing to compact
2025-11-24 15:49:11.497Z debug(compaction): Transfer.pending_id:3: bar_commence: nothing to compact
2025-11-24 15:49:11.497Z debug(compaction): Transfer.user_data_128:3: bar_commence: nothing to compact
2025-11-24 15:49:11.497Z debug(compaction): Transfer.user_data_64:3: bar_commence: nothing to compact
2025-11-24 15:49:11.497Z debug(compaction): Transfer.user_data_32:3: bar_commence: nothing to compact
2025-11-24 15:49:11.497Z debug(compaction): Transfer.ledger:3: bar_commence: nothing to compact
2025-11-24 15:49:11.497Z debug(compaction): Transfer.code:3: bar_commence: nothing to compact
2025-11-24 15:49:11.497Z debug(compaction): Transfer:3: bar_commence: nothing to compact
2025-11-24 15:49:11.497Z debug(compaction): Transfer.expires_at:3: bar_commence: nothing to compact
2025-11-24 15:49:11.497Z debug(compaction): TransferPending:3: bar_commence: nothing to compact
2025-11-24 15:49:11.497Z debug(compaction): TransferPending.status:3: bar_commence: nothing to compact
2025-11-24 15:49:11.497Z debug(compaction): AccountEvent:3: bar_commence: nothing to compact
2025-11-24 15:49:11.497Z debug(compaction): Account.imported:3: bar_commence: nothing to compact
2025-11-24 15:49:11.497Z debug(compaction): Transfer.imported:3: bar_commence: nothing to compact
2025-11-24 15:49:11.497Z debug(compaction): Account.closed:3: bar_commence: nothing to compact
2025-11-24 15:49:11.497Z debug(compaction): Transfer.closing:3: bar_commence: nothing to compact
2025-11-24 15:49:11.497Z debug(compaction): AccountEvent.account_timestamp:3: bar_commence: nothing to compact
2025-11-24 15:49:11.497Z debug(compaction): AccountEvent.transfer_pending_status:3: bar_commence: nothing to compact
2025-11-24 15:49:11.497Z debug(compaction): AccountEvent.dr_account_id_expired:3: bar_commence: nothing to compact
2025-11-24 15:49:11.497Z debug(compaction): AccountEvent.cr_account_id_expired:3: bar_commence: nothing to compact
2025-11-24 15:49:11.497Z debug(compaction): AccountEvent.transfer_pending_id_expired:3: bar_commence: nothing to compact
2025-11-24 15:49:11.497Z debug(compaction): AccountEvent.ledger_expired:3: bar_commence: nothing to compact
2025-11-24 15:49:11.497Z debug(compaction): AccountEvent.prunable:3: bar_commence: nothing to compact
2025-11-24 15:49:11.497Z debug(compaction): Account.id:5: bar_commence: nothing to compact
2025-11-24 15:49:11.497Z debug(compaction): Account.user_data_128:5: bar_commence: nothing to compact
2025-11-24 15:49:11.497Z debug(compaction): Account.user_data_64:5: bar_commence: nothing to compact
2025-11-24 15:49:11.497Z debug(compaction): Account.user_data_32:5: bar_commence: nothing to compact
2025-11-24 15:49:11.497Z debug(compaction): Account.ledger:5: bar_commence: nothing to compact
2025-11-24 15:49:11.497Z debug(compaction): Account.code:5: bar_commence: nothing to compact
2025-11-24 15:49:11.497Z debug(compaction): Account:5: bar_commence: nothing to compact
2025-11-24 15:49:11.497Z debug(compaction): Transfer.id:5: bar_commence: nothing to compact
2025-11-24 15:49:11.497Z debug(compaction): Transfer.debit_account_id:5: bar_commence: nothing to compact
2025-11-24 15:49:11.497Z debug(compaction): Transfer.credit_account_id:5: bar_commence: nothing to compact
2025-11-24 15:49:11.497Z debug(compaction): Transfer.amount:5: bar_commence: nothing to compact
2025-11-24 15:49:11.497Z debug(compaction): Transfer.pending_id:5: bar_commence: nothing to compact
2025-11-24 15:49:11.497Z debug(compaction): Transfer.user_data_128:5: bar_commence: nothing to compact
2025-11-24 15:49:11.497Z debug(compaction): Transfer.user_data_64:5: bar_commence: nothing to compact
2025-11-24 15:49:11.497Z debug(compaction): Transfer.user_data_32:5: bar_commence: nothing to compact
2025-11-24 15:49:11.497Z debug(compaction): Transfer.ledger:5: bar_commence: nothing to compact
2025-11-24 15:49:11.497Z debug(compaction): Transfer.code:5: bar_commence: nothing to compact
2025-11-24 15:49:11.497Z debug(compaction): Transfer:5: bar_commence: nothing to compact
2025-11-24 15:49:11.497Z debug(compaction): Transfer.expires_at:5: bar_commence: nothing to compact
2025-11-24 15:49:11.497Z debug(compaction): TransferPending:5: bar_commence: nothing to compact
2025-11-24 15:49:11.497Z debug(compaction): TransferPending.status:5: bar_commence: nothing to compact
2025-11-24 15:49:11.497Z debug(compaction): AccountEvent:5: bar_commence: nothing to compact
2025-11-24 15:49:11.497Z debug(compaction): Account.imported:5: bar_commence: nothing to compact
2025-11-24 15:49:11.497Z debug(compaction): Transfer.imported:5: bar_commence: nothing to compact
2025-11-24 15:49:11.497Z debug(compaction): Account.closed:5: bar_commence: nothing to compact
2025-11-24 15:49:11.497Z debug(compaction): Transfer.closing:5: bar_commence: nothing to compact
2025-11-24 15:49:11.497Z debug(compaction): AccountEvent.account_timestamp:5: bar_commence: nothing to compact
2025-11-24 15:49:11.497Z debug(compaction): AccountEvent.transfer_pending_status:5: bar_commence: nothing to compact
2025-11-24 15:49:11.497Z debug(compaction): AccountEvent.dr_account_id_expired:5: bar_commence: nothing to compact
2025-11-24 15:49:11.497Z debug(compaction): AccountEvent.cr_account_id_expired:5: bar_commence: nothing to compact
2025-11-24 15:49:11.497Z debug(compaction): AccountEvent.transfer_pending_id_expired:5: bar_commence: nothing to compact
2025-11-24 15:49:11.497Z debug(compaction): AccountEvent.ledger_expired:5: bar_commence: nothing to compact
2025-11-24 15:49:11.497Z debug(compaction): AccountEvent.prunable:5: bar_commence: nothing to compact
2025-11-24 15:49:11.498Z debug(client_replies): 0: write_reply: wrote (client=298030292540495332668092515795273542819 request=30)
2025-11-24 15:49:11.506Z debug(vsr): 1: pulse_timeout fired
2025-11-24 15:49:11.506Z debug(vsr): 1: pulse_timeout reset
2025-11-24 15:49:11.510Z debug(replica): 0n: execute_op: executing view=1 primary=false op=33 checksum=201843485919175037346003797442351833588 (lookup_transfers)
2025-11-24 15:49:11.510Z debug(replica): 0n: execute_op: commit_timestamp=1763999217524182976 prepare.header.timestamp=1763999223102340376
2025-11-24 15:49:11.511Z warning(replica): 2n: commit_dispatch: slow request, request=103 size=1019136 create_transfers time=2618ms
2025-11-24 15:49:11.512Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.prepares offset=111149056 len=4096 unlocked
2025-11-24 15:49:11.512Z debug(journal): 2: write_header: op=106 sectors[24576..28672]
2025-11-24 15:49:11.512Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.headers offset=24576 len=4096 locked
2025-11-24 15:49:11.512Z debug(client_replies): 2: write_reply: wrote (client=298030292540495332668092515795273542819 request=103)
2025-11-24 15:49:11.512Z debug(vsr): 2: journal_repair_budget_timeout fired
2025-11-24 15:49:11.512Z debug(vsr): 2: journal_repair_budget_timeout reset
2025-11-24 15:49:11.512Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.headers offset=24576 len=4096 unlocked
2025-11-24 15:49:11.512Z debug(journal): 2: write: view=1 slot=106 op=106 len=2320: 256718603192109629945700705192119048178 complete, marking clean
2025-11-24 15:49:11.512Z debug(replica): 2n: send_prepare_ok: op=106 checksum=256718603192109629945700705192119048178
2025-11-24 15:49:11.512Z debug(replica): 2n: sending prepare_ok to replica 1: vsr.message_header.Header.PrepareOk{ .checksum = 100766039535540298198838363003041545842, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 1, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 223993988688182942188955290449752137586, .parent_padding = 0, .prepare_checksum = 256718603192109629945700705192119048178, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 298030292540495332668092515795273542819, .op = 106, .commit_min = 105, .timestamp = 1763999348892988987, .request = 104, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-11-24 15:49:11.512Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.PrepareOk{ .checksum = 100766039535540298198838363003041545842, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 1, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 223993988688182942188955290449752137586, .parent_padding = 0, .prepare_checksum = 256718603192109629945700705192119048178, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 298030292540495332668092515795273542819, .op = 106, .commit_min = 105, .timestamp = 1763999348892988987, .request = 104, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-11-24 15:49:11.512Z debug(vsr): 1: primary_abdicate_timeout reset
2025-11-24 15:49:11.512Z debug(replica): 1N: on_prepare_ok: 2 message(s)
2025-11-24 15:49:11.512Z debug(replica): 1N: on_prepare_ok: quorum received, context=256718603192109629945700705192119048178
2025-11-24 15:49:11.512Z debug(vsr): 1: prepare_timeout stopped
2025-11-24 15:49:11.512Z debug(vsr): 1: primary_abdicate_timeout stopped
2025-11-24 15:49:11.512Z debug(replica): 1N: execute_op: executing view=1 primary=true op=106 checksum=256718603192109629945700705192119048178 (lookup_accounts)
2025-11-24 15:49:11.512Z debug(replica): 1N: execute_op: commit_timestamp=1763999348816165648 prepare.header.timestamp=1763999348892988987
2025-11-24 15:49:11.512Z debug(replica): 1N: execute_op: advancing commit_max=105..106
2025-11-24 15:49:11.513Z debug(replica): 1N: client_table_entry_update: client=298030292540495332668092515795273542819 session=2 request=104
2025-11-24 15:49:11.513Z debug(replica): 1N: execute_op: replying to client: vsr.message_header.Header.Reply{ .checksum = 43099743928699825457656854703242109267, .checksum_padding = 0, .checksum_body = 165544376397603317221627375259491241046, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 16768, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 142716952148735961052966968291013007357, .request_checksum_padding = 0, .context = 168541217024042339066595389197651340921, .context_padding = 0, .client = 298030292540495332668092515795273542819, .op = 106, .commit = 106, .timestamp = 1763999348892988987, .request = 104, .operation = vsr.Operation(140), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:49:11.513Z debug(replica): 1N: sending reply to client 298030292540495332668092515795273542819: vsr.message_header.Header.Reply{ .checksum = 43099743928699825457656854703242109267, .checksum_padding = 0, .checksum_body = 165544376397603317221627375259491241046, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 16768, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 142716952148735961052966968291013007357, .request_checksum_padding = 0, .context = 168541217024042339066595389197651340921, .context_padding = 0, .client = 298030292540495332668092515795273542819, .op = 106, .commit = 106, .timestamp = 1763999348892988987, .request = 104, .operation = vsr.Operation(140), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:49:11.513Z debug(forest): entering forest.compact() op=106 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
warning(client): 298030292540495332668092515795273542819: on_reply: slow request, request=104 op=106 size=2320 lookup_accounts time=2620ms
2025-11-24 15:49:11.513Z debug(client_replies): 1: write_reply: wrote (client=298030292540495332668092515795273542819 request=104)
2025-11-24 15:49:11.513Z info(workload): accounts created = 128, transfers = 116482, pending transfers = 0, commands run = 52
2025-11-24 15:49:11.515Z debug(replica): 0n: client_table_entry_update: client=298030292540495332668092515795273542819 session=2 request=31
2025-11-24 15:49:11.516Z debug(replica): 0n: execute_op: replying to client: vsr.message_header.Header.Reply{ .checksum = 178839253961035260190793592064588292899, .checksum_padding = 0, .checksum_body = 297779319024906908633480767905372168322, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 702592, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 184738066067272628782324368700258162405, .request_checksum_padding = 0, .context = 268421642787813526154842951410007831951, .context_padding = 0, .client = 298030292540495332668092515795273542819, .op = 33, .commit = 33, .timestamp = 1763999223102340376, .request = 31, .operation = vsr.Operation(141), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:49:11.516Z debug(replica): 0n: sending reply to client 298030292540495332668092515795273542819: vsr.message_header.Header.Reply{ .checksum = 178839253961035260190793592064588292899, .checksum_padding = 0, .checksum_body = 297779319024906908633480767905372168322, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 702592, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 184738066067272628782324368700258162405, .request_checksum_padding = 0, .context = 268421642787813526154842951410007831951, .context_padding = 0, .client = 298030292540495332668092515795273542819, .op = 33, .commit = 33, .timestamp = 1763999223102340376, .request = 31, .operation = vsr.Operation(141), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:49:11.516Z debug(forest): entering forest.compact() op=33 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2025-11-24 15:49:11.516Z debug(vsr): 1: journal_repair_budget_timeout fired
2025-11-24 15:49:11.516Z debug(vsr): 1: journal_repair_budget_timeout reset
2025-11-24 15:49:11.516Z debug(vsr): 0: journal_repair_budget_timeout fired
2025-11-24 15:49:11.516Z debug(vsr): 0: journal_repair_budget_timeout reset
2025-11-24 15:49:11.516Z debug(replica): 0n: execute_op: executing view=1 primary=false op=34 checksum=21567882588600953245247311102209322427 (lookup_accounts)
2025-11-24 15:49:11.516Z debug(replica): 0n: execute_op: commit_timestamp=1763999223102340376 prepare.header.timestamp=1763999223128581107
2025-11-24 15:49:11.516Z debug(replica): 0n: client_table_entry_update: client=298030292540495332668092515795273542819 session=2 request=32
2025-11-24 15:49:11.516Z debug(replica): 0n: execute_op: replying to client: vsr.message_header.Header.Reply{ .checksum = 304042727504646345444185013680300315193, .checksum_padding = 0, .checksum_body = 251171533035307454327101219508620682320, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 13440, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 141675858366065951864750068736990337373, .request_checksum_padding = 0, .context = 257818870090417986932310667413612997741, .context_padding = 0, .client = 298030292540495332668092515795273542819, .op = 34, .commit = 34, .timestamp = 1763999223128581107, .request = 32, .operation = vsr.Operation(140), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:49:11.517Z debug(replica): 0n: sending reply to client 298030292540495332668092515795273542819: vsr.message_header.Header.Reply{ .checksum = 304042727504646345444185013680300315193, .checksum_padding = 0, .checksum_body = 251171533035307454327101219508620682320, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 13440, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 141675858366065951864750068736990337373, .request_checksum_padding = 0, .context = 257818870090417986932310667413612997741, .context_padding = 0, .client = 298030292540495332668092515795273542819, .op = 34, .commit = 34, .timestamp = 1763999223128581107, .request = 32, .operation = vsr.Operation(140), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:49:11.517Z debug(forest): entering forest.compact() op=34 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2025-11-24 15:49:11.517Z debug(client_replies): 0: write_reply: wrote (client=298030292540495332668092515795273542819 request=31)
2025-11-24 15:49:11.519Z debug(client_replies): 0: write_reply: wrote (client=298030292540495332668092515795273542819 request=32)
2025-11-24 15:49:11.519Z debug(replica): 0n: execute_op: executing view=1 primary=false op=35 checksum=274554786783741723635752817765553229716 (lookup_transfers)
2025-11-24 15:49:11.519Z debug(replica): 0n: execute_op: commit_timestamp=1763999223128581107 prepare.header.timestamp=1763999225739408532
2025-11-24 15:49:11.523Z debug(replica): 0n: client_table_entry_update: client=298030292540495332668092515795273542819 session=2 request=33
2025-11-24 15:49:11.523Z debug(replica): 0n: execute_op: replying to client: vsr.message_header.Header.Reply{ .checksum = 211893949938073106161965115177185212009, .checksum_padding = 0, .checksum_body = 297779319024906908633480767905372168322, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 702592, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 197899467872262172731593785377519879705, .request_checksum_padding = 0, .context = 105575818528440058961222278908188120287, .context_padding = 0, .client = 298030292540495332668092515795273542819, .op = 35, .commit = 35, .timestamp = 1763999225739408532, .request = 33, .operation = vsr.Operation(141), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:49:11.523Z debug(replica): 0n: sending reply to client 298030292540495332668092515795273542819: vsr.message_header.Header.Reply{ .checksum = 211893949938073106161965115177185212009, .checksum_padding = 0, .checksum_body = 297779319024906908633480767905372168322, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 702592, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 197899467872262172731593785377519879705, .request_checksum_padding = 0, .context = 105575818528440058961222278908188120287, .context_padding = 0, .client = 298030292540495332668092515795273542819, .op = 35, .commit = 35, .timestamp = 1763999225739408532, .request = 33, .operation = vsr.Operation(141), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:49:11.523Z debug(forest): entering forest.compact() op=35 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2025-11-24 15:49:11.523Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 339451632836478585737081486804755205823, .checksum_padding = 0, .checksum_body = 196634536410313638840965506586093320918, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 614272, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 168541217024042339066595389197651340921, .parent_padding = 0, .client = 298030292540495332668092515795273542819, .session = 2, .timestamp = 0, .request = 105, .operation = vsr.Operation(139), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 2620799350, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:49:11.524Z debug(replica): 1N: on_request: new request
2025-11-24 15:49:11.524Z debug(replica): 1N: primary_pipeline_prepare: request checksum=339451632836478585737081486804755205823 client=298030292540495332668092515795273542819
2025-11-24 15:49:11.524Z debug(replica): 0n: execute_op: executing view=1 primary=false op=36 checksum=125269375374496384370310794301165385666 (lookup_accounts)
2025-11-24 15:49:11.524Z debug(replica): 0n: execute_op: commit_timestamp=1763999225739408532 prepare.header.timestamp=1763999225755674960
2025-11-24 15:49:11.524Z debug(replica): 2n: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 339451632836478585737081486804755205823, .checksum_padding = 0, .checksum_body = 196634536410313638840965506586093320918, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 614272, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 168541217024042339066595389197651340921, .parent_padding = 0, .client = 298030292540495332668092515795273542819, .session = 2, .timestamp = 0, .request = 105, .operation = vsr.Operation(139), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 2620799350, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:49:11.524Z debug(replica): 2n: on_request: forwarding new request to primary (view=1)
2025-11-24 15:49:11.524Z debug(replica): 2n: sending request to replica 1: vsr.message_header.Header.Request{ .checksum = 339451632836478585737081486804755205823, .checksum_padding = 0, .checksum_body = 196634536410313638840965506586093320918, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 614272, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 168541217024042339066595389197651340921, .parent_padding = 0, .client = 298030292540495332668092515795273542819, .session = 2, .timestamp = 0, .request = 105, .operation = vsr.Operation(139), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 2620799350, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:49:11.524Z debug(replica): 0n: client_table_entry_update: client=298030292540495332668092515795273542819 session=2 request=34
2025-11-24 15:49:11.524Z debug(forest): entering forest.compact() op=36 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2025-11-24 15:49:11.524Z debug(client_replies): 0: write_reply: wrote (client=298030292540495332668092515795273542819 request=33)
2025-11-24 15:49:11.524Z debug(client_replies): 0: write_reply: wrote (client=298030292540495332668092515795273542819 request=34)
2025-11-24 15:49:11.526Z debug(replica): 1N: primary_pipeline_prepare: prepare checksum=296798491623493328405749438614499535467 op=107
2025-11-24 15:49:11.526Z debug(vsr): 1: prepare_timeout started
2025-11-24 15:49:11.526Z debug(vsr): 1: primary_abdicate_timeout started
2025-11-24 15:49:11.526Z debug(vsr): 1: pulse_timeout reset
2025-11-24 15:49:11.526Z debug(replica): 1N: replicate: replicating op=107 to replica 0
2025-11-24 15:49:11.526Z debug(replica): 1N: sending prepare to replica 0: vsr.message_header.Header.Prepare{ .checksum = 296798491623493328405749438614499535467, .checksum_padding = 0, .checksum_body = 196634536410313638840965506586093320918, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 614272, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 256718603192109629945700705192119048178, .parent_padding = 0, .request_checksum = 339451632836478585737081486804755205823, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 298030292540495332668092515795273542819, .op = 107, .commit = 106, .timestamp = 1763999351524037005, .request = 105, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-11-24 15:49:11.526Z debug(message_bus): 1: send_message_to_replica: no connection to=0 header=vsr.message_header.Header.Prepare{ .checksum = 296798491623493328405749438614499535467, .checksum_padding = 0, .checksum_body = 196634536410313638840965506586093320918, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 614272, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 256718603192109629945700705192119048178, .parent_padding = 0, .request_checksum = 339451632836478585737081486804755205823, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 298030292540495332668092515795273542819, .op = 107, .commit = 106, .timestamp = 1763999351524037005, .request = 105, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-11-24 15:49:11.526Z debug(replica): 1N: replicate: replicating op=107 to replica 2
2025-11-24 15:49:11.526Z debug(replica): 1N: sending prepare to replica 2: vsr.message_header.Header.Prepare{ .checksum = 296798491623493328405749438614499535467, .checksum_padding = 0, .checksum_body = 196634536410313638840965506586093320918, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 614272, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 256718603192109629945700705192119048178, .parent_padding = 0, .request_checksum = 339451632836478585737081486804755205823, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 298030292540495332668092515795273542819, .op = 107, .commit = 106, .timestamp = 1763999351524037005, .request = 105, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-11-24 15:49:11.527Z debug(replica): 1N: on_prepare: advancing: op=106..107 checksum=256718603192109629945700705192119048178..296798491623493328405749438614499535467
2025-11-24 15:49:11.527Z debug(journal): 1: set_header_as_dirty: op=107 checksum=296798491623493328405749438614499535467
2025-11-24 15:49:11.527Z debug(replica): 1N: append: appending to journal op=107
2025-11-24 15:49:11.527Z debug(journal): 1: write: view=1 slot=107 op=107 len=614272: 296798491623493328405749438614499535467 starting
2025-11-24 15:49:11.527Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.prepares offset=112197632 len=614400 locked
2025-11-24 15:49:11.528Z debug(replica): 0n: execute_op: executing view=1 primary=false op=37 checksum=28321122743655198533169063638028888264 (create_transfers)
2025-11-24 15:49:11.528Z debug(replica): 0n: execute_op: commit_timestamp=1763999225755674960 prepare.header.timestamp=1763999228420119234
2025-11-24 15:49:11.530Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.Request{ .checksum = 339451632836478585737081486804755205823, .checksum_padding = 0, .checksum_body = 196634536410313638840965506586093320918, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 614272, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 168541217024042339066595389197651340921, .parent_padding = 0, .client = 298030292540495332668092515795273542819, .session = 2, .timestamp = 0, .request = 105, .operation = vsr.Operation(139), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 2620799350, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:49:11.530Z debug(replica): 1N: on_request: new request
2025-11-24 15:49:11.530Z debug(replica): 1N: on_request: ignoring (already preparing)
2025-11-24 15:49:11.530Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.prepares offset=112197632 len=614400 unlocked
2025-11-24 15:49:11.530Z debug(journal): 1: write_header: op=107 sectors[24576..28672]
2025-11-24 15:49:11.530Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.headers offset=24576 len=4096 locked
2025-11-24 15:49:11.530Z debug(replica): 2n: on_message: view=1 status=normal vsr.message_header.Header.Prepare{ .checksum = 296798491623493328405749438614499535467, .checksum_padding = 0, .checksum_body = 196634536410313638840965506586093320918, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 614272, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 256718603192109629945700705192119048178, .parent_padding = 0, .request_checksum = 339451632836478585737081486804755205823, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 298030292540495332668092515795273542819, .op = 107, .commit = 106, .timestamp = 1763999351524037005, .request = 105, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-11-24 15:49:11.530Z debug(replica): 2n: on_prepare: advancing commit_max=105..106
2025-11-24 15:49:11.530Z debug(replica): 2n: on_prepare: caching prepare.op=107 (commit_min=105 op=106 commit_max=106 prepare_max=1007)
2025-11-24 15:49:11.530Z debug(replica): 2n: on_prepare: advancing: op=106..107 checksum=256718603192109629945700705192119048178..296798491623493328405749438614499535467
2025-11-24 15:49:11.530Z debug(journal): 2: set_header_as_dirty: op=107 checksum=296798491623493328405749438614499535467
2025-11-24 15:49:11.530Z debug(replica): 2n: append: appending to journal op=107
2025-11-24 15:49:11.530Z debug(journal): 2: write: view=1 slot=107 op=107 len=614272: 296798491623493328405749438614499535467 starting
2025-11-24 15:49:11.530Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.prepares offset=112197632 len=614400 locked
2025-11-24 15:49:11.530Z debug(replica): 2n: commit_start_journal: cached prepare op=106 checksum=256718603192109629945700705192119048178
2025-11-24 15:49:11.530Z debug(replica): 2n: repair_prepare: op=107 checksum=296798491623493328405749438614499535467 (already writing)
2025-11-24 15:49:11.530Z debug(replica): 2n: commit_journal: already committing (prefetch; commit_min=105)
2025-11-24 15:49:11.530Z debug(replica): 2n: execute_op: executing view=1 primary=false op=106 checksum=256718603192109629945700705192119048178 (lookup_accounts)
2025-11-24 15:49:11.530Z debug(replica): 2n: execute_op: commit_timestamp=1763999348816165648 prepare.header.timestamp=1763999348892988987
2025-11-24 15:49:11.530Z debug(replica): 2n: client_table_entry_update: client=298030292540495332668092515795273542819 session=2 request=104
2025-11-24 15:49:11.530Z debug(replica): 2n: execute_op: replying to client: vsr.message_header.Header.Reply{ .checksum = 43099743928699825457656854703242109267, .checksum_padding = 0, .checksum_body = 165544376397603317221627375259491241046, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 16768, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 142716952148735961052966968291013007357, .request_checksum_padding = 0, .context = 168541217024042339066595389197651340921, .context_padding = 0, .client = 298030292540495332668092515795273542819, .op = 106, .commit = 106, .timestamp = 1763999348892988987, .request = 104, .operation = vsr.Operation(140), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:49:11.530Z debug(replica): 2n: sending reply to client 298030292540495332668092515795273542819: vsr.message_header.Header.Reply{ .checksum = 43099743928699825457656854703242109267, .checksum_padding = 0, .checksum_body = 165544376397603317221627375259491241046, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 16768, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 142716952148735961052966968291013007357, .request_checksum_padding = 0, .context = 168541217024042339066595389197651340921, .context_padding = 0, .client = 298030292540495332668092515795273542819, .op = 106, .commit = 106, .timestamp = 1763999348892988987, .request = 104, .operation = vsr.Operation(140), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:49:11.531Z debug(forest): entering forest.compact() op=106 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2025-11-24 15:49:11.531Z debug(client_replies): 2: write_reply: wrote (client=298030292540495332668092515795273542819 request=104)
2025-11-24 15:49:11.531Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.prepares offset=112197632 len=614400 unlocked
2025-11-24 15:49:11.531Z debug(journal): 2: write_header: op=107 sectors[24576..28672]
2025-11-24 15:49:11.531Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.headers offset=24576 len=4096 locked
2025-11-24 15:49:11.531Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.headers offset=24576 len=4096 unlocked
2025-11-24 15:49:11.531Z debug(journal): 2: write: view=1 slot=107 op=107 len=614272: 296798491623493328405749438614499535467 complete, marking clean
2025-11-24 15:49:11.531Z debug(replica): 2n: send_prepare_ok: op=107 checksum=296798491623493328405749438614499535467
2025-11-24 15:49:11.531Z debug(replica): 2n: sending prepare_ok to replica 1: vsr.message_header.Header.PrepareOk{ .checksum = 136745567203173098815941007785310309423, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 1, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 256718603192109629945700705192119048178, .parent_padding = 0, .prepare_checksum = 296798491623493328405749438614499535467, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 298030292540495332668092515795273542819, .op = 107, .commit_min = 106, .timestamp = 1763999351524037005, .request = 105, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-11-24 15:49:11.531Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.headers offset=24576 len=4096 unlocked
2025-11-24 15:49:11.531Z debug(journal): 1: write: view=1 slot=107 op=107 len=614272: 296798491623493328405749438614499535467 complete, marking clean
2025-11-24 15:49:11.531Z debug(replica): 1N: send_prepare_ok: op=107 checksum=296798491623493328405749438614499535467
2025-11-24 15:49:11.531Z debug(replica): 1N: sending prepare_ok to replica 1: vsr.message_header.Header.PrepareOk{ .checksum = 206765865285599359903559623928237181026, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 1, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 256718603192109629945700705192119048178, .parent_padding = 0, .prepare_checksum = 296798491623493328405749438614499535467, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 298030292540495332668092515795273542819, .op = 107, .commit_min = 106, .timestamp = 1763999351524037005, .request = 105, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-11-24 15:49:11.531Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.PrepareOk{ .checksum = 206765865285599359903559623928237181026, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 1, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 256718603192109629945700705192119048178, .parent_padding = 0, .prepare_checksum = 296798491623493328405749438614499535467, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 298030292540495332668092515795273542819, .op = 107, .commit_min = 106, .timestamp = 1763999351524037005, .request = 105, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-11-24 15:49:11.532Z debug(vsr): 1: primary_abdicate_timeout reset
2025-11-24 15:49:11.532Z debug(replica): 1N: on_prepare_ok: 1 message(s)
2025-11-24 15:49:11.532Z debug(replica): 1N: on_prepare_ok: waiting for quorum
2025-11-24 15:49:11.532Z debug(replica): 1N: on_message: view=1 status=normal vsr.message_header.Header.PrepareOk{ .checksum = 136745567203173098815941007785310309423, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 1, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 256718603192109629945700705192119048178, .parent_padding = 0, .prepare_checksum = 296798491623493328405749438614499535467, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 298030292540495332668092515795273542819, .op = 107, .commit_min = 106, .timestamp = 1763999351524037005, .request = 105, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-11-24 15:49:11.532Z debug(vsr): 1: primary_abdicate_timeout reset
2025-11-24 15:49:11.532Z debug(replica): 1N: on_prepare_ok: 2 message(s)
2025-11-24 15:49:11.532Z debug(replica): 1N: on_prepare_ok: quorum received, context=296798491623493328405749438614499535467
2025-11-24 15:49:11.532Z debug(vsr): 1: prepare_timeout stopped
2025-11-24 15:49:11.532Z debug(vsr): 1: primary_abdicate_timeout stopped
2025-11-24 15:49:11.534Z debug(replica): 1N: execute_op: executing view=1 primary=true op=107 checksum=296798491623493328405749438614499535467 (create_transfers)
2025-11-24 15:49:11.534Z debug(replica): 1N: execute_op: commit_timestamp=1763999348892988987 prepare.header.timestamp=1763999351524037005
2025-11-24 15:49:11.534Z debug(vsr): 2: journal_repair_budget_timeout fired
2025-11-24 15:49:11.534Z debug(vsr): 2: journal_repair_budget_timeout reset
2025-11-24 15:49:11.540Z debug(replica): 0n: client_table_entry_update: client=298030292540495332668092515795273542819 session=2 request=35
2025-11-24 15:49:11.540Z debug(replica): 0n: execute_op: replying to client: vsr.message_header.Header.Reply{ .checksum = 24377273313568027489152171010941277365, .checksum_padding = 0, .checksum_body = 311752944233308762869332694583075543730, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 264, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 83576000670927652240050933902559007252, .request_checksum_padding = 0, .context = 254161628681245481305572187296310046650, .context_padding = 0, .client = 298030292540495332668092515795273542819, .op = 37, .commit = 37, .timestamp = 1763999228420119234, .request = 35, .operation = vsr.Operation(139), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:49:11.540Z debug(replica): 0n: sending reply to client 298030292540495332668092515795273542819: vsr.message_header.Header.Reply{ .checksum = 24377273313568027489152171010941277365, .checksum_padding = 0, .checksum_body = 311752944233308762869332694583075543730, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 264, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 83576000670927652240050933902559007252, .request_checksum_padding = 0, .context = 254161628681245481305572187296310046650, .context_padding = 0, .client = 298030292540495332668092515795273542819, .op = 37, .commit = 37, .timestamp = 1763999228420119234, .request = 35, .operation = vsr.Operation(139), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:49:11.540Z debug(forest): entering forest.compact() op=37 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2025-11-24 15:49:11.544Z debug(vsr): 2: ping_timeout fired
2025-11-24 15:49:11.544Z debug(vsr): 2: ping_timeout reset
2025-11-24 15:49:11.544Z debug(replica): 2n: sending ping to replica 0: vsr.message_header.Header.Ping{ .checksum = 245737073631085342988092594951994738968, .checksum_padding = 0, .checksum_body = 154787626362930377789479683857780696253, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 512, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.ping, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .checkpoint_id = 321854455202207724029466302309042662424, .checkpoint_op = 0, .ping_timestamp_monotonic = 36119433062929953, .release_count = 1, .route_padding = { 0, 0, 0, 0, 0, 0 }, .route = 0, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:49:11.544Z debug(message_bus): 2: send_message_to_replica: no connection to=0 header=vsr.message_header.Header.Ping{ .checksum = 245737073631085342988092594951994738968, .checksum_padding = 0, .checksum_body = 154787626362930377789479683857780696253, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 512, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.ping, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .checkpoint_id = 321854455202207724029466302309042662424, .checkpoint_op = 0, .ping_timestamp_monotonic = 36119433062929953, .release_count = 1, .route_padding = { 0, 0, 0, 0, 0, 0 }, .route = 0, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:49:11.544Z debug(replica): 2n: sending ping to replica 1: vsr.message_header.Header.Ping{ .checksum = 245737073631085342988092594951994738968, .checksum_padding = 0, .checksum_body = 154787626362930377789479683857780696253, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 512, .epoch = 0, .view = 1, .release = 0.0.1, .protocol = 0, .command = vsr.Command.ping, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .checkpoint_id = 321854455202207724029466302309042662424, .checkpoint_op = 0, .ping_timestamp_monotonic = 36119433062929953, .release_count = 1, .route_padding = { 0, 0, 0, 0, 0, 0 }, .route = 0, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-24 15:49:11.544Z debug(vsr): 2: start_view_change_message_timeout fired
2025-11-24 15:49:11.549Z debug(client_replies): 0: write_reply: wrote (client=298030292540495332668092515795273542819 request=35)
