se = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 190956040946507374666480675525609733999, .parent_padding = 0, .prepare_checksum = 200539457665853230988629620405319647153, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 338580951294615966557548891273477627502, .op = 257, .commit_min = 256, .timestamp = 1763395828821023020, .request = 255, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-11-17 16:10:28.923Z debug(replica): 0N: on_message: view=3 status=normal vsr.message_header.Header.PrepareOk{ .checksum = 282464016843324516993816679175519087797, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 190956040946507374666480675525609733999, .parent_padding = 0, .prepare_checksum = 200539457665853230988629620405319647153, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 338580951294615966557548891273477627502, .op = 257, .commit_min = 256, .timestamp = 1763395828821023020, .request = 255, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-11-17 16:10:28.923Z debug(vsr): 0: primary_abdicate_timeout reset
2025-11-17 16:10:28.923Z debug(replica): 0N: on_prepare_ok: 1 message(s)
2025-11-17 16:10:28.923Z debug(replica): 0N: on_prepare_ok: waiting for quorum
2025-11-17 16:10:28.931Z debug(vsr): 2: journal_repair_budget_timeout fired
2025-11-17 16:10:28.931Z debug(vsr): 2: journal_repair_budget_timeout reset
2025-11-17 16:10:28.931Z debug(vsr): 1: journal_repair_budget_timeout fired
2025-11-17 16:10:28.931Z debug(vsr): 1: journal_repair_budget_timeout reset
2025-11-17 16:10:28.933Z debug(vsr): 0: journal_repair_budget_timeout fired
2025-11-17 16:10:28.933Z debug(vsr): 0: journal_repair_budget_timeout reset
2025-11-17 16:10:28.941Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.prepares offset=269484032 len=532480 unlocked
2025-11-17 16:10:28.941Z debug(journal): 1: write_header: op=257 sectors[65536..69632]
2025-11-17 16:10:28.941Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.headers offset=65536 len=4096 locked
2025-11-17 16:10:28.941Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.prepares offset=269484032 len=532480 unlocked
2025-11-17 16:10:28.941Z debug(journal): 2: write_header: op=257 sectors[65536..69632]
2025-11-17 16:10:28.941Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.headers offset=65536 len=4096 locked
2025-11-17 16:10:28.951Z debug(vsr): 2: journal_repair_budget_timeout fired
2025-11-17 16:10:28.953Z debug(vsr): 0: journal_repair_budget_timeout fired
2025-11-17 16:10:28.963Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.headers offset=65536 len=4096 unlocked
2025-11-17 16:10:28.976Z debug(vsr): 2: journal_repair_budget_timeout reset
2025-11-17 16:10:28.976Z debug(vsr): 0: journal_repair_budget_timeout reset
2025-11-17 16:10:28.976Z debug(journal): 1: write: view=3 slot=257 op=257 len=530688: 200539457665853230988629620405319647153 complete, marking clean
2025-11-17 16:10:28.976Z debug(vsr): 0: pulse_timeout fired
2025-11-17 16:10:28.976Z debug(vsr): 0: pulse_timeout reset
2025-11-17 16:10:28.976Z debug(replica): 1n: send_prepare_ok: op=257 checksum=200539457665853230988629620405319647153
2025-11-17 16:10:28.976Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.headers offset=65536 len=4096 unlocked
2025-11-17 16:10:28.976Z debug(replica): 1n: sending prepare_ok to replica 0: vsr.message_header.Header.PrepareOk{ .checksum = 28920772505847140989696795139120577435, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 190956040946507374666480675525609733999, .parent_padding = 0, .prepare_checksum = 200539457665853230988629620405319647153, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 338580951294615966557548891273477627502, .op = 257, .commit_min = 256, .timestamp = 1763395828821023020, .request = 255, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-11-17 16:10:28.976Z debug(journal): 2: write: view=3 slot=257 op=257 len=530688: 200539457665853230988629620405319647153 complete, marking clean
2025-11-17 16:10:28.976Z debug(replica): 2n: send_prepare_ok: op=257 checksum=200539457665853230988629620405319647153
2025-11-17 16:10:28.976Z debug(replica): 2n: sending prepare_ok to replica 0: vsr.message_header.Header.PrepareOk{ .checksum = 263955175710671561422449186308805459343, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 190956040946507374666480675525609733999, .parent_padding = 0, .prepare_checksum = 200539457665853230988629620405319647153, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 338580951294615966557548891273477627502, .op = 257, .commit_min = 256, .timestamp = 1763395828821023020, .request = 255, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-11-17 16:10:28.976Z debug(vsr): 1: journal_repair_budget_timeout fired
2025-11-17 16:10:28.976Z debug(vsr): 1: journal_repair_budget_timeout reset
2025-11-17 16:10:28.976Z debug(replica): 0N: on_message: view=3 status=normal vsr.message_header.Header.PrepareOk{ .checksum = 28920772505847140989696795139120577435, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 190956040946507374666480675525609733999, .parent_padding = 0, .prepare_checksum = 200539457665853230988629620405319647153, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 338580951294615966557548891273477627502, .op = 257, .commit_min = 256, .timestamp = 1763395828821023020, .request = 255, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-11-17 16:10:28.976Z debug(vsr): 0: primary_abdicate_timeout reset
2025-11-17 16:10:28.976Z debug(replica): 0N: on_prepare_ok: 2 message(s)
2025-11-17 16:10:28.976Z debug(replica): 0N: on_prepare_ok: quorum received, context=200539457665853230988629620405319647153
2025-11-17 16:10:28.976Z debug(vsr): 0: prepare_timeout stopped
2025-11-17 16:10:28.976Z debug(vsr): 0: primary_abdicate_timeout stopped
2025-11-17 16:10:28.977Z debug(replica): 0N: execute_op: executing view=3 primary=true op=257 checksum=200539457665853230988629620405319647153 (create_transfers)
2025-11-17 16:10:28.977Z debug(replica): 0N: execute_op: commit_timestamp=1763395828655074883 prepare.header.timestamp=1763395828821023020
2025-11-17 16:10:28.985Z debug(replica): 0N: execute_op: advancing commit_max=256..257
2025-11-17 16:10:28.985Z debug(replica): 0N: client_table_entry_update: client=338580951294615966557548891273477627502 session=2 request=255
2025-11-17 16:10:28.985Z debug(replica): 0N: execute_op: replying to client: vsr.message_header.Header.Reply{ .checksum = 27488576782724851019145324836262546075, .checksum_padding = 0, .checksum_body = 269103610752764575290500596750881178446, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 376, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 312299134456236574178426835121749097925, .request_checksum_padding = 0, .context = 95172868999774881601153482631721879483, .context_padding = 0, .client = 338580951294615966557548891273477627502, .op = 257, .commit = 257, .timestamp = 1763395828821023020, .request = 255, .operation = vsr.Operation(139), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-17 16:10:28.985Z debug(replica): 0N: sending reply to client 338580951294615966557548891273477627502: vsr.message_header.Header.Reply{ .checksum = 27488576782724851019145324836262546075, .checksum_padding = 0, .checksum_body = 269103610752764575290500596750881178446, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 376, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 312299134456236574178426835121749097925, .request_checksum_padding = 0, .context = 95172868999774881601153482631721879483, .context_padding = 0, .client = 338580951294615966557548891273477627502, .op = 257, .commit = 257, .timestamp = 1763395828821023020, .request = 255, .operation = vsr.Operation(139), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-17 16:10:28.985Z debug(forest): entering forest.compact() op=257 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2025-11-17 16:10:28.990Z debug(replica): 0N: on_message: view=3 status=normal vsr.message_header.Header.PrepareOk{ .checksum = 263955175710671561422449186308805459343, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 190956040946507374666480675525609733999, .parent_padding = 0, .prepare_checksum = 200539457665853230988629620405319647153, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 338580951294615966557548891273477627502, .op = 257, .commit_min = 256, .timestamp = 1763395828821023020, .request = 255, .operation = vsr.Operation(139), .reserved = { 0, 0, 0 } }
2025-11-17 16:10:28.990Z debug(replica): 0N: on_prepare_ok: not preparing op=257 checksum=200539457665853230988629620405319647153
2025-11-17 16:10:28.996Z debug(replica): 0N: on_message: view=3 status=normal vsr.message_header.Header.Request{ .checksum = 9970498207980889321767525195137580718, .checksum_padding = 0, .checksum_body = 210141981684789195362703101137304005777, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2320, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 95172868999774881601153482631721879483, .parent_padding = 0, .client = 338580951294615966557548891273477627502, .session = 2, .timestamp = 0, .request = 256, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 167729851, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-17 16:10:28.996Z debug(replica): 1n: on_message: view=3 status=normal vsr.message_header.Header.Request{ .checksum = 9970498207980889321767525195137580718, .checksum_padding = 0, .checksum_body = 210141981684789195362703101137304005777, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2320, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 95172868999774881601153482631721879483, .parent_padding = 0, .client = 338580951294615966557548891273477627502, .session = 2, .timestamp = 0, .request = 256, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 167729851, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-17 16:10:28.996Z debug(replica): 0N: on_request: new request
2025-11-17 16:10:28.996Z debug(replica): 1n: on_request: forwarding new request to primary (view=3)
2025-11-17 16:10:28.996Z debug(replica): 0N: primary_pipeline_prepare: request checksum=9970498207980889321767525195137580718 client=338580951294615966557548891273477627502
2025-11-17 16:10:28.996Z debug(replica): 1n: sending request to replica 0: vsr.message_header.Header.Request{ .checksum = 9970498207980889321767525195137580718, .checksum_padding = 0, .checksum_body = 210141981684789195362703101137304005777, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2320, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 95172868999774881601153482631721879483, .parent_padding = 0, .client = 338580951294615966557548891273477627502, .session = 2, .timestamp = 0, .request = 256, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 167729851, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-17 16:10:28.996Z debug(replica): 0N: primary_pipeline_prepare: prepare checksum=282269821537083419855059398888850248019 op=258
2025-11-17 16:10:28.996Z debug(vsr): 0: prepare_timeout started
2025-11-17 16:10:28.996Z debug(vsr): 0: primary_abdicate_timeout started
2025-11-17 16:10:28.996Z debug(vsr): 0: pulse_timeout reset
2025-11-17 16:10:28.996Z debug(replica): 0N: replicate: replicating op=258 to replica 2
2025-11-17 16:10:28.996Z debug(replica): 0N: sending prepare to replica 2: vsr.message_header.Header.Prepare{ .checksum = 282269821537083419855059398888850248019, .checksum_padding = 0, .checksum_body = 210141981684789195362703101137304005777, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2320, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 200539457665853230988629620405319647153, .parent_padding = 0, .request_checksum = 9970498207980889321767525195137580718, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 338580951294615966557548891273477627502, .op = 258, .commit = 257, .timestamp = 1763395828996426447, .request = 256, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-11-17 16:10:28.996Z debug(replica): 0N: replicate: replicating op=258 to replica 1
2025-11-17 16:10:28.996Z debug(replica): 0N: sending prepare to replica 1: vsr.message_header.Header.Prepare{ .checksum = 282269821537083419855059398888850248019, .checksum_padding = 0, .checksum_body = 210141981684789195362703101137304005777, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2320, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 200539457665853230988629620405319647153, .parent_padding = 0, .request_checksum = 9970498207980889321767525195137580718, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 338580951294615966557548891273477627502, .op = 258, .commit = 257, .timestamp = 1763395828996426447, .request = 256, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-11-17 16:10:28.996Z debug(replica): 0N: on_prepare: advancing: op=257..258 checksum=200539457665853230988629620405319647153..282269821537083419855059398888850248019
2025-11-17 16:10:28.996Z debug(journal): 0: set_header_as_dirty: op=258 checksum=282269821537083419855059398888850248019
2025-11-17 16:10:28.996Z debug(replica): 0N: append: appending to journal op=258
2025-11-17 16:10:28.996Z debug(journal): 0: write: view=3 slot=258 op=258 len=2320: 282269821537083419855059398888850248019 starting
2025-11-17 16:10:28.996Z debug(journal): 0: write_sectors: ring=vsr.journal.Ring.prepares offset=270532608 len=4096 locked
2025-11-17 16:10:28.996Z debug(replica): 1n: on_message: view=3 status=normal vsr.message_header.Header.Prepare{ .checksum = 282269821537083419855059398888850248019, .checksum_padding = 0, .checksum_body = 210141981684789195362703101137304005777, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2320, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 200539457665853230988629620405319647153, .parent_padding = 0, .request_checksum = 9970498207980889321767525195137580718, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 338580951294615966557548891273477627502, .op = 258, .commit = 257, .timestamp = 1763395828996426447, .request = 256, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-11-17 16:10:28.996Z debug(replica): 1n: on_prepare: advancing commit_max=256..257
2025-11-17 16:10:28.996Z debug(replica): 2n: on_message: view=3 status=normal vsr.message_header.Header.Prepare{ .checksum = 282269821537083419855059398888850248019, .checksum_padding = 0, .checksum_body = 210141981684789195362703101137304005777, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2320, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.prepare, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 200539457665853230988629620405319647153, .parent_padding = 0, .request_checksum = 9970498207980889321767525195137580718, .request_checksum_padding = 0, .checkpoint_id = 0, .client = 338580951294615966557548891273477627502, .op = 258, .commit = 257, .timestamp = 1763395828996426447, .request = 256, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-11-17 16:10:28.996Z debug(replica): 1n: on_prepare: caching prepare.op=258 (commit_min=256 op=257 commit_max=257 prepare_max=1007)
2025-11-17 16:10:28.996Z debug(replica): 2n: on_prepare: advancing commit_max=256..257
2025-11-17 16:10:28.996Z debug(replica): 2n: on_prepare: caching prepare.op=258 (commit_min=256 op=257 commit_max=257 prepare_max=1007)
2025-11-17 16:10:28.996Z debug(replica): 0N: on_message: view=3 status=normal vsr.message_header.Header.Request{ .checksum = 9970498207980889321767525195137580718, .checksum_padding = 0, .checksum_body = 210141981684789195362703101137304005777, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 2320, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 95172868999774881601153482631721879483, .parent_padding = 0, .client = 338580951294615966557548891273477627502, .session = 2, .timestamp = 0, .request = 256, .operation = vsr.Operation(140), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 167729851, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-17 16:10:28.996Z debug(replica): 0N: on_request: new request
2025-11-17 16:10:28.996Z debug(replica): 0N: on_request: ignoring (already preparing)
2025-11-17 16:10:28.996Z debug(replica): 2n: on_prepare: advancing: op=257..258 checksum=200539457665853230988629620405319647153..282269821537083419855059398888850248019
2025-11-17 16:10:28.996Z debug(journal): 2: set_header_as_dirty: op=258 checksum=282269821537083419855059398888850248019
2025-11-17 16:10:28.996Z debug(replica): 2n: append: appending to journal op=258
2025-11-17 16:10:28.996Z debug(replica): 1n: on_prepare: advancing: op=257..258 checksum=200539457665853230988629620405319647153..282269821537083419855059398888850248019
2025-11-17 16:10:28.996Z debug(journal): 1: set_header_as_dirty: op=258 checksum=282269821537083419855059398888850248019
2025-11-17 16:10:28.996Z debug(journal): 2: write: view=3 slot=258 op=258 len=2320: 282269821537083419855059398888850248019 starting
2025-11-17 16:10:28.996Z debug(replica): 1n: append: appending to journal op=258
2025-11-17 16:10:28.996Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.prepares offset=270532608 len=4096 locked
2025-11-17 16:10:28.996Z debug(journal): 1: write: view=3 slot=258 op=258 len=2320: 282269821537083419855059398888850248019 starting
2025-11-17 16:10:28.996Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.prepares offset=270532608 len=4096 locked
2025-11-17 16:10:28.996Z debug(replica): 2n: commit_start_journal: cached prepare op=257 checksum=200539457665853230988629620405319647153
2025-11-17 16:10:28.996Z debug(replica): 1n: commit_start_journal: cached prepare op=257 checksum=200539457665853230988629620405319647153
2025-11-17 16:10:28.996Z debug(replica): 2n: repair_prepare: op=258 checksum=282269821537083419855059398888850248019 (already writing)
2025-11-17 16:10:28.996Z debug(replica): 2n: commit_journal: already committing (prefetch; commit_min=256)
2025-11-17 16:10:28.996Z debug(replica): 1n: repair_prepare: op=258 checksum=282269821537083419855059398888850248019 (already writing)
2025-11-17 16:10:28.997Z debug(replica): 1n: commit_journal: already committing (prefetch; commit_min=256)
2025-11-17 16:10:28.997Z debug(replica): 2n: execute_op: executing view=3 primary=false op=257 checksum=200539457665853230988629620405319647153 (create_transfers)
2025-11-17 16:10:28.997Z debug(replica): 2n: execute_op: commit_timestamp=1763395828655074883 prepare.header.timestamp=1763395828821023020
2025-11-17 16:10:28.998Z debug(replica): 1n: execute_op: executing view=3 primary=false op=257 checksum=200539457665853230988629620405319647153 (create_transfers)
2025-11-17 16:10:28.998Z debug(replica): 1n: execute_op: commit_timestamp=1763395828655074883 prepare.header.timestamp=1763395828821023020
2025-11-17 16:10:28.998Z debug(client_replies): 0: write_reply: wrote (client=338580951294615966557548891273477627502 request=255)
2025-11-17 16:10:29.001Z debug(vsr): 0: journal_repair_budget_timeout fired
2025-11-17 16:10:29.001Z debug(vsr): 0: journal_repair_budget_timeout reset
2025-11-17 16:10:29.001Z debug(vsr): 0: journal_repair_timeout fired
2025-11-17 16:10:29.001Z debug(vsr): 0: journal_repair_timeout reset
2025-11-17 16:10:29.001Z debug(replica): 0N: repair_prepare: op=258 checksum=282269821537083419855059398888850248019 (already writing)
2025-11-17 16:10:29.001Z debug(journal): 0: write_sectors: ring=vsr.journal.Ring.prepares offset=270532608 len=4096 unlocked
2025-11-17 16:10:29.001Z debug(journal): 0: write_header: op=258 sectors[65536..69632]
2025-11-17 16:10:29.001Z debug(journal): 0: write_sectors: ring=vsr.journal.Ring.headers offset=65536 len=4096 locked
2025-11-17 16:10:29.007Z debug(replica): 1n: client_table_entry_update: client=338580951294615966557548891273477627502 session=2 request=255
2025-11-17 16:10:29.007Z debug(replica): 1n: execute_op: replying to client: vsr.message_header.Header.Reply{ .checksum = 27488576782724851019145324836262546075, .checksum_padding = 0, .checksum_body = 269103610752764575290500596750881178446, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 376, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 312299134456236574178426835121749097925, .request_checksum_padding = 0, .context = 95172868999774881601153482631721879483, .context_padding = 0, .client = 338580951294615966557548891273477627502, .op = 257, .commit = 257, .timestamp = 1763395828821023020, .request = 255, .operation = vsr.Operation(139), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-17 16:10:29.007Z debug(replica): 1n: sending reply to client 338580951294615966557548891273477627502: vsr.message_header.Header.Reply{ .checksum = 27488576782724851019145324836262546075, .checksum_padding = 0, .checksum_body = 269103610752764575290500596750881178446, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 376, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 312299134456236574178426835121749097925, .request_checksum_padding = 0, .context = 95172868999774881601153482631721879483, .context_padding = 0, .client = 338580951294615966557548891273477627502, .op = 257, .commit = 257, .timestamp = 1763395828821023020, .request = 255, .operation = vsr.Operation(139), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-17 16:10:29.007Z debug(forest): entering forest.compact() op=257 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2025-11-17 16:10:29.007Z debug(replica): 2n: client_table_entry_update: client=338580951294615966557548891273477627502 session=2 request=255
2025-11-17 16:10:29.007Z debug(forest): entering forest.compact() op=257 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2025-11-17 16:10:29.010Z debug(journal): 0: write_sectors: ring=vsr.journal.Ring.headers offset=65536 len=4096 unlocked
2025-11-17 16:10:29.010Z debug(journal): 0: write: view=3 slot=258 op=258 len=2320: 282269821537083419855059398888850248019 complete, marking clean
2025-11-17 16:10:29.010Z debug(replica): 0N: send_prepare_ok: op=258 checksum=282269821537083419855059398888850248019
2025-11-17 16:10:29.011Z debug(replica): 0N: sending prepare_ok to replica 0: vsr.message_header.Header.PrepareOk{ .checksum = 109148972936690968619217311283532094481, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 200539457665853230988629620405319647153, .parent_padding = 0, .prepare_checksum = 282269821537083419855059398888850248019, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 338580951294615966557548891273477627502, .op = 258, .commit_min = 257, .timestamp = 1763395828996426447, .request = 256, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-11-17 16:10:29.011Z debug(replica): 0N: on_message: view=3 status=normal vsr.message_header.Header.PrepareOk{ .checksum = 109148972936690968619217311283532094481, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 200539457665853230988629620405319647153, .parent_padding = 0, .prepare_checksum = 282269821537083419855059398888850248019, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 338580951294615966557548891273477627502, .op = 258, .commit_min = 257, .timestamp = 1763395828996426447, .request = 256, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-11-17 16:10:29.011Z debug(vsr): 0: primary_abdicate_timeout reset
2025-11-17 16:10:29.011Z debug(replica): 0N: on_prepare_ok: 1 message(s)
2025-11-17 16:10:29.011Z debug(replica): 0N: on_prepare_ok: waiting for quorum
2025-11-17 16:10:29.016Z debug(vsr): 2: journal_repair_budget_timeout fired
2025-11-17 16:10:29.016Z debug(vsr): 2: journal_repair_budget_timeout reset
2025-11-17 16:10:29.016Z debug(vsr): 1: journal_repair_budget_timeout fired
2025-11-17 16:10:29.016Z debug(vsr): 1: journal_repair_budget_timeout reset
2025-11-17 16:10:29.021Z debug(vsr): 0: journal_repair_budget_timeout fired
2025-11-17 16:10:29.021Z debug(vsr): 0: journal_repair_budget_timeout reset
2025-11-17 16:10:29.025Z debug(client_replies): 2: write_reply: wrote (client=338580951294615966557548891273477627502 request=255)
2025-11-17 16:10:29.025Z debug(client_replies): 1: write_reply: wrote (client=338580951294615966557548891273477627502 request=255)
2025-11-17 16:10:29.025Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.prepares offset=270532608 len=4096 unlocked
2025-11-17 16:10:29.025Z debug(journal): 2: write_header: op=258 sectors[65536..69632]
2025-11-17 16:10:29.025Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.headers offset=65536 len=4096 locked
2025-11-17 16:10:29.025Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.prepares offset=270532608 len=4096 unlocked
2025-11-17 16:10:29.025Z debug(journal): 1: write_header: op=258 sectors[65536..69632]
2025-11-17 16:10:29.025Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.headers offset=65536 len=4096 locked
2025-11-17 16:10:29.033Z debug(journal): 2: write_sectors: ring=vsr.journal.Ring.headers offset=65536 len=4096 unlocked
2025-11-17 16:10:29.033Z debug(journal): 2: write: view=3 slot=258 op=258 len=2320: 282269821537083419855059398888850248019 complete, marking clean
2025-11-17 16:10:29.033Z debug(journal): 1: write_sectors: ring=vsr.journal.Ring.headers offset=65536 len=4096 unlocked
2025-11-17 16:10:29.041Z debug(vsr): 0: journal_repair_budget_timeout fired
2025-11-17 16:10:29.047Z debug(vsr): 0: journal_repair_budget_timeout reset
2025-11-17 16:10:29.047Z debug(replica): 2n: send_prepare_ok: op=258 checksum=282269821537083419855059398888850248019
2025-11-17 16:10:29.047Z debug(journal): 1: write: view=3 slot=258 op=258 len=2320: 282269821537083419855059398888850248019 complete, marking clean
2025-11-17 16:10:29.047Z debug(replica): 1n: send_prepare_ok: op=258 checksum=282269821537083419855059398888850248019
2025-11-17 16:10:29.047Z debug(replica): 1n: sending prepare_ok to replica 0: vsr.message_header.Header.PrepareOk{ .checksum = 91736975082704603469566781618228024611, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 200539457665853230988629620405319647153, .parent_padding = 0, .prepare_checksum = 282269821537083419855059398888850248019, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 338580951294615966557548891273477627502, .op = 258, .commit_min = 257, .timestamp = 1763395828996426447, .request = 256, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-11-17 16:10:29.047Z debug(replica): 2n: sending prepare_ok to replica 0: vsr.message_header.Header.PrepareOk{ .checksum = 57142322217538335678129928059883882797, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 200539457665853230988629620405319647153, .parent_padding = 0, .prepare_checksum = 282269821537083419855059398888850248019, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 338580951294615966557548891273477627502, .op = 258, .commit_min = 257, .timestamp = 1763395828996426447, .request = 256, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-11-17 16:10:29.048Z debug(vsr): 2: journal_repair_budget_timeout fired
2025-11-17 16:10:29.048Z debug(vsr): 2: journal_repair_budget_timeout reset
2025-11-17 16:10:29.048Z debug(vsr): 1: journal_repair_budget_timeout fired
2025-11-17 16:10:29.048Z debug(vsr): 1: journal_repair_budget_timeout reset
2025-11-17 16:10:29.048Z debug(replica): 0N: on_message: view=3 status=normal vsr.message_header.Header.PrepareOk{ .checksum = 57142322217538335678129928059883882797, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 200539457665853230988629620405319647153, .parent_padding = 0, .prepare_checksum = 282269821537083419855059398888850248019, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 338580951294615966557548891273477627502, .op = 258, .commit_min = 257, .timestamp = 1763395828996426447, .request = 256, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-11-17 16:10:29.048Z debug(vsr): 0: primary_abdicate_timeout reset
2025-11-17 16:10:29.048Z debug(replica): 0N: on_prepare_ok: 2 message(s)
2025-11-17 16:10:29.048Z debug(replica): 0N: on_prepare_ok: quorum received, context=282269821537083419855059398888850248019
2025-11-17 16:10:29.048Z debug(vsr): 0: prepare_timeout stopped
2025-11-17 16:10:29.048Z debug(vsr): 0: primary_abdicate_timeout stopped
2025-11-17 16:10:29.048Z debug(replica): 0N: on_message: view=3 status=normal vsr.message_header.Header.PrepareOk{ .checksum = 91736975082704603469566781618228024611, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.0, .protocol = 0, .command = vsr.Command.prepare_ok, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 200539457665853230988629620405319647153, .parent_padding = 0, .prepare_checksum = 282269821537083419855059398888850248019, .prepare_checksum_padding = 0, .checkpoint_id = 0, .client = 338580951294615966557548891273477627502, .op = 258, .commit_min = 257, .timestamp = 1763395828996426447, .request = 256, .operation = vsr.Operation(140), .reserved = { 0, 0, 0 } }
2025-11-17 16:10:29.048Z debug(replica): 0N: on_prepare_ok: 3 message(s)
2025-11-17 16:10:29.048Z debug(replica): 0N: on_prepare_ok: ignoring (quorum received already)
2025-11-17 16:10:29.048Z debug(replica): 0N: execute_op: executing view=3 primary=true op=258 checksum=282269821537083419855059398888850248019 (lookup_accounts)
2025-11-17 16:10:29.048Z debug(replica): 0N: execute_op: commit_timestamp=1763395828821023020 prepare.header.timestamp=1763395828996426447
2025-11-17 16:10:29.048Z debug(replica): 0N: execute_op: advancing commit_max=257..258
2025-11-17 16:10:29.048Z debug(replica): 0N: client_table_entry_update: client=338580951294615966557548891273477627502 session=2 request=256
2025-11-17 16:10:29.048Z debug(replica): 0N: execute_op: replying to client: vsr.message_header.Header.Reply{ .checksum = 61167925992680336320395106960278355792, .checksum_padding = 0, .checksum_body = 265973449047451752075507039320381421141, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 16768, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 9970498207980889321767525195137580718, .request_checksum_padding = 0, .context = 313252885810432636354241530210119720780, .context_padding = 0, .client = 338580951294615966557548891273477627502, .op = 258, .commit = 258, .timestamp = 1763395828996426447, .request = 256, .operation = vsr.Operation(140), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-17 16:10:29.048Z debug(replica): 0N: sending reply to client 338580951294615966557548891273477627502: vsr.message_header.Header.Reply{ .checksum = 61167925992680336320395106960278355792, .checksum_padding = 0, .checksum_body = 265973449047451752075507039320381421141, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 16768, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 9970498207980889321767525195137580718, .request_checksum_padding = 0, .context = 313252885810432636354241530210119720780, .context_padding = 0, .client = 338580951294615966557548891273477627502, .op = 258, .commit = 258, .timestamp = 1763395828996426447, .request = 256, .operation = vsr.Operation(140), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-17 16:10:29.048Z debug(forest): entering forest.compact() op=258 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2025-11-17 16:10:29.052Z info(workload): accounts created = 128, transfers = 329606, pending transfers = 0, commands run = 128
2025-11-17 16:10:29.059Z debug(vsr): 1: journal_repair_timeout fired
2025-11-17 16:10:29.059Z debug(vsr): 1: journal_repair_timeout reset
2025-11-17 16:10:29.060Z debug(client_replies): 0: write_reply: wrote (client=338580951294615966557548891273477627502 request=256)
2025-11-17 16:10:29.067Z debug(vsr): 0: journal_repair_budget_timeout fired
2025-11-17 16:10:29.067Z debug(vsr): 0: journal_repair_budget_timeout reset
2025-11-17 16:10:29.068Z debug(vsr): 2: ping_timeout fired
2025-11-17 16:10:29.076Z debug(vsr): 2: ping_timeout reset
2025-11-17 16:10:29.076Z debug(replica): 2n: sending ping to replica 0: vsr.message_header.Header.Ping{ .checksum = 269155411374479360817955163960545875432, .checksum_padding = 0, .checksum_body = 154787626362930377789479683857780696253, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 512, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.ping, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .checkpoint_id = 321854455202207724029466302309042662424, .checkpoint_op = 0, .ping_timestamp_monotonic = 20654631162173925, .release_count = 1, .route_padding = { 0, 0, 0, 0, 0, 0 }, .route = 0, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-17 16:10:29.076Z debug(replica): 2n: sending ping to replica 1: vsr.message_header.Header.Ping{ .checksum = 269155411374479360817955163960545875432, .checksum_padding = 0, .checksum_body = 154787626362930377789479683857780696253, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 512, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.ping, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .checkpoint_id = 321854455202207724029466302309042662424, .checkpoint_op = 0, .ping_timestamp_monotonic = 20654631162173925, .release_count = 1, .route_padding = { 0, 0, 0, 0, 0, 0 }, .route = 0, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-17 16:10:29.076Z debug(vsr): 2: start_view_change_message_timeout fired
2025-11-17 16:10:29.076Z debug(vsr): 2: start_view_change_message_timeout reset
2025-11-17 16:10:29.076Z debug(vsr): 2: journal_repair_budget_timeout fired
2025-11-17 16:10:29.076Z debug(vsr): 2: journal_repair_budget_timeout reset
2025-11-17 16:10:29.076Z debug(vsr): 2: journal_repair_timeout fired
2025-11-17 16:10:29.076Z debug(vsr): 2: journal_repair_timeout reset
2025-11-17 16:10:29.069Z debug(vsr): 1: journal_repair_budget_timeout fired
2025-11-17 16:10:29.076Z debug(vsr): 1: journal_repair_budget_timeout reset
2025-11-17 16:10:29.076Z debug(vsr): 2: grid_repair_budget_timeout fired
2025-11-17 16:10:29.076Z debug(vsr): 2: grid_repair_budget_timeout reset
2025-11-17 16:10:29.087Z debug(vsr): 0: journal_repair_budget_timeout fired
2025-11-17 16:10:29.087Z debug(vsr): 0: journal_repair_budget_timeout reset
2025-11-17 16:10:29.096Z debug(vsr): 1: journal_repair_budget_timeout fired
2025-11-17 16:10:29.096Z debug(vsr): 2: journal_repair_budget_timeout fired
2025-11-17 16:10:29.096Z debug(vsr): 1: journal_repair_budget_timeout reset
2025-11-17 16:10:29.096Z debug(vsr): 2: journal_repair_budget_timeout reset
2025-11-17 16:10:29.098Z debug(vsr): 0: pulse_timeout fired
2025-11-17 16:10:29.098Z debug(vsr): 0: pulse_timeout reset
2025-11-17 16:10:29.108Z debug(vsr): 0: ping_timeout fired
2025-11-17 16:10:29.108Z debug(vsr): 0: ping_timeout reset
2025-11-17 16:10:29.108Z debug(replica): 0N: sending ping to replica 1: vsr.message_header.Header.Ping{ .checksum = 89280986740335920140557852328582006987, .checksum_padding = 0, .checksum_body = 154787626362930377789479683857780696253, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 512, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.ping, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .checkpoint_id = 321854455202207724029466302309042662424, .checkpoint_op = 0, .ping_timestamp_monotonic = 20654631194170638, .release_count = 1, .route_padding = { 0, 0, 0, 0, 0, 0 }, .route = 18446744073692839938, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-17 16:10:29.108Z debug(replica): 0N: sending ping to replica 2: vsr.message_header.Header.Ping{ .checksum = 89280986740335920140557852328582006987, .checksum_padding = 0, .checksum_body = 154787626362930377789479683857780696253, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 512, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.ping, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .checkpoint_id = 321854455202207724029466302309042662424, .checkpoint_op = 0, .ping_timestamp_monotonic = 20654631194170638, .release_count = 1, .route_padding = { 0, 0, 0, 0, 0, 0 }, .route = 18446744073692839938, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-17 16:10:29.108Z debug(vsr): 0: commit_message_timeout fired
2025-11-17 16:10:29.108Z debug(vsr): 0: commit_message_timeout reset
2025-11-17 16:10:29.108Z debug(replica): 0N: sending commit to replica 1: vsr.message_header.Header.Commit{ .checksum = 115869807885846889843745208158074898118, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.0, .protocol = 0, .command = vsr.Command.commit, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .commit_checksum = 282269821537083419855059398888850248019, .commit_checksum_padding = 0, .checkpoint_id = 321854455202207724029466302309042662424, .checkpoint_op = 0, .commit = 258, .timestamp_monotonic = 20654631194256669, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-17 16:10:29.108Z debug(replica): 0N: sending commit to replica 2: vsr.message_header.Header.Commit{ .checksum = 115869807885846889843745208158074898118, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.0, .protocol = 0, .command = vsr.Command.commit, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .commit_checksum = 282269821537083419855059398888850248019, .commit_checksum_padding = 0, .checkpoint_id = 321854455202207724029466302309042662424, .checkpoint_op = 0, .commit = 258, .timestamp_monotonic = 20654631194256669, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-17 16:10:29.108Z debug(vsr): 0: start_view_change_message_timeout fired
2025-11-17 16:10:29.108Z debug(vsr): 0: start_view_change_message_timeout reset
2025-11-17 16:10:29.108Z debug(vsr): 0: journal_repair_budget_timeout fired
2025-11-17 16:10:29.108Z debug(vsr): 0: journal_repair_budget_timeout reset
2025-11-17 16:10:29.108Z debug(vsr): 0: journal_repair_timeout fired
2025-11-17 16:10:29.108Z debug(vsr): 0: journal_repair_timeout reset
2025-11-17 16:10:29.108Z debug(vsr): 0: grid_repair_budget_timeout fired
2025-11-17 16:10:29.108Z debug(vsr): 0: grid_repair_budget_timeout reset
2025-11-17 16:10:29.116Z debug(vsr): 1: journal_repair_budget_timeout fired
2025-11-17 16:10:29.116Z debug(vsr): 1: journal_repair_budget_timeout reset
2025-11-17 16:10:29.116Z debug(vsr): 2: journal_repair_budget_timeout fired
2025-11-17 16:10:29.116Z debug(vsr): 2: journal_repair_budget_timeout reset
2025-11-17 16:10:29.127Z debug(replica): 2n: on_message: view=3 status=normal vsr.message_header.Header.Ping{ .checksum = 89280986740335920140557852328582006987, .checksum_padding = 0, .checksum_body = 154787626362930377789479683857780696253, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 512, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.ping, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .checkpoint_id = 321854455202207724029466302309042662424, .checkpoint_op = 0, .ping_timestamp_monotonic = 20654631194170638, .release_count = 1, .route_padding = { 0, 0, 0, 0, 0, 0 }, .route = 18446744073692839938, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-17 16:10:29.127Z debug(replica): 0N: on_message: view=3 status=normal vsr.message_header.Header.Ping{ .checksum = 269155411374479360817955163960545875432, .checksum_padding = 0, .checksum_body = 154787626362930377789479683857780696253, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 512, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.ping, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .checkpoint_id = 321854455202207724029466302309042662424, .checkpoint_op = 0, .ping_timestamp_monotonic = 20654631162173925, .release_count = 1, .route_padding = { 0, 0, 0, 0, 0, 0 }, .route = 0, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-17 16:10:29.127Z debug(replica): 0N: sending pong to replica 2: vsr.message_header.Header.Pong{ .checksum = 127958605251148285903928320636368486682, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.pong, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .ping_timestamp_monotonic = 20654631162173925, .pong_timestamp_wall = 1763395829127469881, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-17 16:10:29.127Z debug(replica): 2n: sending pong to replica 0: vsr.message_header.Header.Pong{ .checksum = 171465827915639980442439712349130047039, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.pong, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .ping_timestamp_monotonic = 20654631194170638, .pong_timestamp_wall = 1763395829127468408, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-17 16:10:29.127Z debug(replica): 2n: on_message: view=3 status=normal vsr.message_header.Header.Commit{ .checksum = 115869807885846889843745208158074898118, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.0, .protocol = 0, .command = vsr.Command.commit, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .commit_checksum = 282269821537083419855059398888850248019, .commit_checksum_padding = 0, .checkpoint_id = 321854455202207724029466302309042662424, .checkpoint_op = 0, .commit = 258, .timestamp_monotonic = 20654631194256669, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-17 16:10:29.127Z debug(vsr): 2: normal_heartbeat_timeout reset
2025-11-17 16:10:29.127Z debug(replica): 2n: on_commit: checksum verified
2025-11-17 16:10:29.127Z debug(replica): 2n: on_commit: advancing commit_max=257..258
2025-11-17 16:10:29.127Z debug(replica): 2n: commit_start_journal: cached prepare op=258 checksum=282269821537083419855059398888850248019
2025-11-17 16:10:29.127Z debug(replica): 2n: execute_op: executing view=3 primary=false op=258 checksum=282269821537083419855059398888850248019 (lookup_accounts)
2025-11-17 16:10:29.127Z debug(replica): 2n: execute_op: commit_timestamp=1763395828821023020 prepare.header.timestamp=1763395828996426447
2025-11-17 16:10:29.127Z debug(replica): 2n: client_table_entry_update: client=338580951294615966557548891273477627502 session=2 request=256
2025-11-17 16:10:29.127Z debug(forest): entering forest.compact() op=258 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2025-11-17 16:10:29.128Z debug(replica): 2n: on_message: view=3 status=normal vsr.message_header.Header.Pong{ .checksum = 127958605251148285903928320636368486682, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.pong, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .ping_timestamp_monotonic = 20654631162173925, .pong_timestamp_wall = 1763395829127469881, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-17 16:10:29.128Z debug(clock): 2: learn: replica=0 m0=20654631162173925 t1=1763395829127469881 m2=20654631214345699 t2=1763395829128225563 one_way_delay=26085887 asymmetric_delay=-10790054 clock_offset=14540151
2025-11-17 16:10:29.136Z debug(vsr): 2: journal_repair_budget_timeout fired
2025-11-17 16:10:29.136Z debug(vsr): 2: journal_repair_budget_timeout reset
2025-11-17 16:10:29.129Z debug(replica): 1n: on_message: view=3 status=normal vsr.message_header.Header.Request{ .checksum = 148764151415577424764577877717792864670, .checksum_padding = 0, .checksum_body = 154259352560381633127482863799514485316, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 835072, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 313252885810432636354241530210119720780, .parent_padding = 0, .client = 338580951294615966557548891273477627502, .session = 2, .timestamp = 0, .request = 257, .operation = vsr.Operation(139), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 52644929, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-17 16:10:31.280Z debug(replica): 1n: on_request: forwarding new request to primary (view=3)
2025-11-17 16:10:31.280Z debug(replica): 1n: sending request to replica 0: vsr.message_header.Header.Request{ .checksum = 148764151415577424764577877717792864670, .checksum_padding = 0, .checksum_body = 154259352560381633127482863799514485316, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 835072, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 313252885810432636354241530210119720780, .parent_padding = 0, .client = 338580951294615966557548891273477627502, .session = 2, .timestamp = 0, .request = 257, .operation = vsr.Operation(139), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 52644929, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-17 16:10:29.130Z debug(replica): 0N: on_message: view=3 status=normal vsr.message_header.Header.Request{ .checksum = 148764151415577424764577877717792864670, .checksum_padding = 0, .checksum_body = 154259352560381633127482863799514485316, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 835072, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.request, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .parent = 313252885810432636354241530210119720780, .parent_padding = 0, .client = 338580951294615966557548891273477627502, .session = 2, .timestamp = 0, .request = 257, .operation = vsr.Operation(139), .previous_request_latency_padding = { 0, 0, 0 }, .previous_request_latency = 52644929, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-17 16:10:31.217Z warning(faulty_network): recv error (2,9): error.ConnectionResetByPeer
2025-11-17 16:10:31.280Z debug(replica): 0N: on_request: new request
2025-11-17 16:10:31.280Z debug(replica): 0N: primary_pipeline_prepare: request checksum=148764151415577424764577877717792864670 client=338580951294615966557548891273477627502
2025-11-17 16:10:31.280Z debug(replica): 1n: on_message: view=3 status=normal vsr.message_header.Header.Ping{ .checksum = 89280986740335920140557852328582006987, .checksum_padding = 0, .checksum_body = 154787626362930377789479683857780696253, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 512, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.ping, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .checkpoint_id = 321854455202207724029466302309042662424, .checkpoint_op = 0, .ping_timestamp_monotonic = 20654631194170638, .release_count = 1, .route_padding = { 0, 0, 0, 0, 0, 0 }, .route = 18446744073692839938, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-17 16:10:31.280Z debug(replica): 1n: sending pong to replica 0: vsr.message_header.Header.Pong{ .checksum = 18242877628857217174180473852214014775, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.pong, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .ping_timestamp_monotonic = 20654631194170638, .pong_timestamp_wall = 1763395831280829244, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-17 16:10:31.280Z debug(replica): 1n: on_message: view=3 status=normal vsr.message_header.Header.Commit{ .checksum = 115869807885846889843745208158074898118, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.0, .protocol = 0, .command = vsr.Command.commit, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .commit_checksum = 282269821537083419855059398888850248019, .commit_checksum_padding = 0, .checkpoint_id = 321854455202207724029466302309042662424, .checkpoint_op = 0, .commit = 258, .timestamp_monotonic = 20654631194256669, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-17 16:10:31.280Z debug(vsr): 1: normal_heartbeat_timeout reset
2025-11-17 16:10:31.280Z debug(replica): 1n: on_commit: checksum verified
2025-11-17 16:10:31.280Z debug(replica): 1n: on_commit: advancing commit_max=257..258
2025-11-17 16:10:31.280Z debug(replica): 1n: commit_start_journal: cached prepare op=258 checksum=282269821537083419855059398888850248019
2025-11-17 16:10:31.281Z debug(replica): 1n: on_message: view=3 status=normal vsr.message_header.Header.Ping{ .checksum = 269155411374479360817955163960545875432, .checksum_padding = 0, .checksum_body = 154787626362930377789479683857780696253, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 512, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.ping, .replica = 2, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .checkpoint_id = 321854455202207724029466302309042662424, .checkpoint_op = 0, .ping_timestamp_monotonic = 20654631162173925, .release_count = 1, .route_padding = { 0, 0, 0, 0, 0, 0 }, .route = 0, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-17 16:10:31.281Z debug(replica): 1n: sending pong to replica 2: vsr.message_header.Header.Pong{ .checksum = 303137537311111279362248670194157735411, .checksum_padding = 0, .checksum_body = 98287347720187652707502696638535748739, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 256, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.pong, .replica = 1, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .ping_timestamp_monotonic = 20654631162173925, .pong_timestamp_wall = 1763395831281222829, .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-17 16:10:31.281Z error(supervisor): 2: replica terminated unexpectedly with process.Child.Term{ .Signal = 9 }
2025-11-17 16:10:31.283Z info(supervisor): 0: terminating replica
2025-11-17 16:10:31.295Z debug(replica): 1n: execute_op: executing view=3 primary=false op=258 checksum=282269821537083419855059398888850248019 (lookup_accounts)
2025-11-17 16:10:31.295Z debug(replica): 1n: execute_op: commit_timestamp=1763395828821023020 prepare.header.timestamp=1763395828996426447
2025-11-17 16:10:31.295Z debug(replica): 1n: client_table_entry_update: client=338580951294615966557548891273477627502 session=2 request=256
2025-11-17 16:10:31.295Z debug(replica): 1n: execute_op: replying to client: vsr.message_header.Header.Reply{ .checksum = 61167925992680336320395106960278355792, .checksum_padding = 0, .checksum_body = 265973449047451752075507039320381421141, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 16768, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 9970498207980889321767525195137580718, .request_checksum_padding = 0, .context = 313252885810432636354241530210119720780, .context_padding = 0, .client = 338580951294615966557548891273477627502, .op = 258, .commit = 258, .timestamp = 1763395828996426447, .request = 256, .operation = vsr.Operation(140), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-17 16:10:31.295Z debug(replica): 1n: sending reply to client 338580951294615966557548891273477627502: vsr.message_header.Header.Reply{ .checksum = 61167925992680336320395106960278355792, .checksum_padding = 0, .checksum_body = 265973449047451752075507039320381421141, .checksum_body_padding = 0, .nonce_reserved = 0, .cluster = 0, .size = 16768, .epoch = 0, .view = 3, .release = 0.0.1, .protocol = 0, .command = vsr.Command.reply, .replica = 0, .reserved_frame = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 }, .request_checksum = 9970498207980889321767525195137580718, .request_checksum_padding = 0, .context = 313252885810432636354241530210119720780, .context_padding = 0, .client = 338580951294615966557548891273477627502, .op = 258, .commit = 258, .timestamp = 1763395828996426447, .request = 256, .operation = vsr.Operation(140), .reserved = { 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0 } }
2025-11-17 16:10:31.295Z debug(forest): entering forest.compact() op=258 constants.lsm_compaction_ops=32 first_beat=false last_half_beat=false half_beat=false last_beat=false
2025-11-17 16:10:31.297Z info(message_bus): 1: on_recv: from=vsr.Peer{ .replica = 2 } orderly shutdown
2025-11-17 16:10:31.297Z debug(clock): 1: synchronized: truechimers=3/3 clock_offset=0ns..0ns accuracy=0ns
2025-11-17 16:10:31.297Z debug(clock): 1: system time is 100ns behind
2025-11-17 16:10:31.297Z debug(message_bus): 1: connect_to_replica: connecting to=2 after=88ms
2025-11-17 16:10:31.297Z debug(vsr): 1: journal_repair_budget_timeout fired
2025-11-17 16:10:31.297Z debug(vsr): 1: journal_repair_budget_timeout reset
2025-11-17 16:10:31.303Z debug(client_replies): 1: write_reply: wrote (client=338580951294615966557548891273477627502 request=256)
2025-11-17 16:10:31.320Z debug(vsr): 1: journal_repair_budget_timeout fired
2025-11-17 16:10:31.320Z debug(vsr): 1: journal_repair_budget_timeout reset
2025-11-17 16:10:31.330Z debug(vsr): 1: journal_repair_timeout fired
2025-11-17 16:10:31.330Z debug(vsr): 1: journal_repair_timeout reset
2025-11-17 16:10:31.341Z debug(vsr): 1: journal_repair_budget_timeout fired
2025-11-17 16:10:31.341Z debug(vsr): 1: journal_repair_budget_timeout reset
2025-11-17 16:10:31.361Z debug(vsr): 1: journal_repair_budget_timeout fired
2025-11-17 16:10:31.361Z debug(vsr): 1: journal_repair_budget_timeout reset
2025-11-17 16:10:31.381Z debug(vsr): 1: journal_repair_budget_timeout fired
2025-11-17 16:10:31.381Z debug(vsr): 1: journal_repair_budget_timeout reset
2025-11-17 16:10:31.383Z info(supervisor): 1: terminating replica
2025-11-17 16:10:31.998Z error: TestFailed
/root/tigerbeetle/working/main/src/testing/vortex/supervisor.zig:425:25: 0x1308fdf in run (vortex)
                        return error.TestFailed;
                        ^
/root/tigerbeetle/working/main/src/testing/vortex/supervisor.zig:207:5: 0x130c881 in main (vortex)
    try supervisor.run();
    ^
/root/tigerbeetle/working/main/src/vortex.zig:61:42: 0x13214e4 in main (vortex)
        .supervisor => |supervisor_args| try Supervisor.main(allocator, supervisor_args),
                                         ^
